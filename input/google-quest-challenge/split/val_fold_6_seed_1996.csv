,Unnamed: 0,qa_id,question_title,question_body,question_user_name,question_user_page,answer,answer_user_name,answer_user_page,url,category,host,question_asker_intent_understanding,question_body_critical,question_conversational,question_expect_short_answer,question_fact_seeking,question_has_commonly_accepted_answer,question_interestingness_others,question_interestingness_self,question_multi_intent,question_not_really_a_question,question_opinion_seeking,question_type_choice,question_type_compare,question_type_consequence,question_type_definition,question_type_entity,question_type_instructions,question_type_procedure,question_type_reason_explanation,question_type_spelling,question_well_written,answer_helpful,answer_level_of_information,answer_plausible,answer_relevance,answer_satisfaction,answer_type_instructions,answer_type_procedure,answer_type_reason_explanation,answer_well_written,t_aug,q_aug,a_aug
2874,2874,4574,How can I make my iPad apps retina in Xcode 5 iOS7,"Not long ago I started learning Objective-C with an interest of developing apps. I have just started my first app and I have no clue how to make my app retina. I made the design in photoshop and exported it as a png @ 2,048 x 1,536 but however the size of my storyboard is only 1,024 x 768. I have read somewhere on the internet that you need two story boards but I am not sure how to link everything together. I would really appreciate it if someone could help me.
",user2989426,https://stackoverflow.com/users/2989426,"please follow bellow tutorial for iOS.It's a first step towards the iOS.
http://mobile.tutsplus.com/
http://www.raywenderlich.com
",Renish Dadhaniya,https://stackoverflow.com/users/2128941,http://stackoverflow.com/questions/21129482/how-can-i-make-my-ipad-apps-retina-in-xcode-5-ios7,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How to make my iPad app retina in Xcode 5ios7,"Not long ago, I began to learn Objective-C, interested in developing applications. I've just started my first app, and I don't know how to make my app retina. I did this design in Photoshop and exported it as PNG @ 2048x 1536, but my storyboard is only 1024x768. I read on the Internet that you need a two-story blackboard, but I don't know how to connect everything. I would appreciate it if someone could help me.","please follow bellow tutorial for iOS.It's a first step towards the iOS.
http://mobile.tutsplus.com/
http://www.raywenderlich.com
"
5850,5850,9268,Is the intersection of two star-shaped sets star-shaped?,"Is the intersection of two star-shaped sets star-shaped?

I don't think so but can't think of an example.
",user24883,https://math.stackexchange.com/users/24883,"Intersection of two star shaped domain is again a star shaped domain provided previous two domains are star shaped with respect to same point. Otherwise the result is not true in general.See the counterexample given by Scott.
",timon,https://math.stackexchange.com/users/39274,http://math.stackexchange.com/questions/200152/is-the-intersection-of-two-star-shaped-sets-star-shaped,SCIENCE,math.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,Is the intersection of two stars star shaped?,"Is the intersection of two star-shaped sets star-shaped?

I don't think so but can't think of an example.
","The intersection of two star regions is another star region, provided that the first two regions are star relative to the same point. Otherwise, the result is usually incorrect. See Scott's counterexample."
908,908,1441,Angularjs show selected option from ng-repeat value,"I have drop down inside ng-repeat as follows. 

&lt;div ng-model=""list in lists""&gt;
&lt;div&gt;
   &lt;select ng-model=""pType"" ng-options=""c.name in projType""&gt;&lt;/select&gt;  
   &lt;option value=""{{list.value}""&gt;&lt;/option&gt; 
&lt;/div&gt;


My Controller is 

    App.controller('pOverCtrl', function ($scope, pOverRepository, $location) {
        $scope.lists = projOverRepository.query();

        $scope.projType = [
            { value: '0', name: 'None Selected' },
            { value: '1', name: 'Construction' },
            { value: '2', name: 'Maintenance' },
        ];
})


The dropdown gets populated fine. But my goal is that when ng-repeat is executed it automatically shows the value that is coming from lists scope as selected. 
Please let me know how to fix this issue. 
",J. Davidson,https://stackoverflow.com/users/1764254,"use the diretive ng-selected

&lt;div ng-model=""list in lists""&gt;
   &lt;select ng-model=""pType"" ng-options=""c.name in projType""&gt;                    
        &lt;option ng-selected=""list.value == list.selected"" value=""{{list.value}""&gt;&lt;/option&gt; 
   &lt;/select&gt;  

&lt;/div&gt;


assuming that list.selected variable contains the value of the option selects
",Leonardo Delfino,https://stackoverflow.com/users/1243251,http://stackoverflow.com/questions/22239167/angularjs-show-selected-option-from-ng-repeat-value,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Angularjs displays the selected option from the ng repeat value,"I have drop down inside ng-repeat as follows. 

&lt;div ng-model=""list in lists""&gt;
&lt;div&gt;
   &lt;select ng-model=""pType"" ng-options=""c.name in projType""&gt;&lt;/select&gt;  
   &lt;option value=""{{list.value}""&gt;&lt;/option&gt; 
&lt;/div&gt;


My Controller is 

    App.controller('pOverCtrl', function ($scope, pOverRepository, $location) {
        $scope.lists = projOverRepository.query();

        $scope.projType = [
            { value: '0', name: 'None Selected' },
            { value: '1', name: 'Construction' },
            { value: '2', name: 'Maintenance' },
        ];
})


The dropdown gets populated fine. But my goal is that when ng-repeat is executed it automatically shows the value that is coming from lists scope as selected. 
Please let me know how to fix this issue. 
","use the diretive ng-selected

&lt;div ng-model=""list in lists""&gt;
   &lt;select ng-model=""pType"" ng-options=""c.name in projType""&gt;                    
        &lt;option ng-selected=""list.value == list.selected"" value=""{{list.value}""&gt;&lt;/option&gt; 
   &lt;/select&gt;  

&lt;/div&gt;


assuming that list.selected variable contains the value of the option selects
"
4276,4276,6814,Complete induction,"I am very confused with complete induction. Because in every task there is something different to do, and I never know what to insert (thats my biggest problem). 
Here's the example:
Proof with complete induction. Please please help me, because I have exams coming up (I am just becoming a primary school teacher..)


  For $n\in\mathbb{N}$:
  
  $$\sum^n_{i=1}\frac{1}{(2i-1)(2i+1)}=\frac{n}{2n+1}$$

",Sophia,https://math.stackexchange.com/users/63169,"For a full solution, proceed like this:  

$n=1$: $$\sum_{i=1}^1 \frac{1}{(2i-1)(2i+1)} = \frac{1}{(2-1)(2+1)} = \frac{1}{3} = \frac{1}{2 \cdot 1 +1},$$
so it holds for $n=1$.  

Assume next that it holds for some generic $n$. You need to show that then it also holds for $n+1$. As it holds for $n$, you can assume that
$$\sum_{i=1}^n \frac{1}{(2i-1)(2i+1)} = \frac{n}{2n+1}. \quad (1),$$
and want to show that
$$\sum_{i=1}^{n+1} \frac{1}{(2i-1)(2i+1)} = \frac{n+1}{2(n+1)+1}. \quad (2)$$
Then:
$$\begin{align}
\sum_{i=1}^{n+1} \frac{1}{(2i-1)(2i+1} &amp;= \sum_{i=1}^n \frac{1}{(2i-1)(2i+1)} + \frac{1}{(2(n+1)-1)(2(n+1)+1)} \\
&amp; = \frac{n}{2n+1} + \frac{1}{(2n+1)(2n+3)} \quad \text{using (1)} \\
&amp; = \frac{n(2n+3)}{(2n+1)(2n+3)} + \frac{1}{(2n+1)(2n+3)} \\
&amp; = \frac{2n^2 +3n +1}{(2n+1)(2n+3)} \\ 
&amp; = \frac{(n+1)(2n+1)}{(2n+1)(2n+3)} = \frac{n+1}{2(n+1)+1},\\
\end{align}$$
which is (2), and
 was to be shown.
",gnometorule,https://math.stackexchange.com/users/21386,http://math.stackexchange.com/questions/309300/complete-induction-sumn-i-1-frac12i-12i1-fracn2n1,SCIENCE,math.stackexchange.com,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,Complete induction,"I am very confused with complete induction. Because in every task there is something different to do, and I never know what to insert (thats my biggest problem). 
Here's the example:
Proof with complete induction. Please please help me, because I have exams coming up (I am just becoming a primary school teacher..)


  For $n\in\mathbb{N}$:
  
  $$\sum^n_{i=1}\frac{1}{(2i-1)(2i+1)}=\frac{n}{2n+1}$$

","For a full solution, proceed like this:  

$n=1$: $$\sum_{i=1}^1 \frac{1}{(2i-1)(2i+1)} = \frac{1}{(2-1)(2+1)} = \frac{1}{3} = \frac{1}{2 \cdot 1 +1},$$
so it holds for $n=1$.  

Assume next that it holds for some generic $n$. You need to show that then it also holds for $n+1$. As it holds for $n$, you can assume that
$$\sum_{i=1}^n \frac{1}{(2i-1)(2i+1)} = \frac{n}{2n+1}. \quad (1),$$
and want to show that
$$\sum_{i=1}^{n+1} \frac{1}{(2i-1)(2i+1)} = \frac{n+1}{2(n+1)+1}. \quad (2)$$
Then:
$$\begin{align}
\sum_{i=1}^{n+1} \frac{1}{(2i-1)(2i+1} &amp;= \sum_{i=1}^n \frac{1}{(2i-1)(2i+1)} + \frac{1}{(2(n+1)-1)(2(n+1)+1)} \\
&amp; = \frac{n}{2n+1} + \frac{1}{(2n+1)(2n+3)} \quad \text{using (1)} \\
&amp; = \frac{n(2n+3)}{(2n+1)(2n+3)} + \frac{1}{(2n+1)(2n+3)} \\
&amp; = \frac{2n^2 +3n +1}{(2n+1)(2n+3)} \\ 
&amp; = \frac{(n+1)(2n+1)}{(2n+1)(2n+3)} = \frac{n+1}{2(n+1)+1},\\
\end{align}$$
which is (2), and
 was to be shown.
"
1020,1020,1609,Setup ntp client with embedded device,"I need to run an NTP client on a very limited embedded device.  

ntpd is available but I do not see anything like rc.conf, or ntp.conf, or xntp.conf?  Can someone advise on how to setup NTP?  

I ran ntpd, but the date and time haven't updated.
",Bob,https://unix.stackexchange.com/users/7295,"Try ntpd -bq

That will set the time and quit. It will allow you to sync to broadcast servers as well.

That said there are two important things to note. First I don't know who the NTP servers are on you network. If someone is being a bad little techie they could bork your time/date and invalidate some security protocols. 

Also be aware that a common problem is that your time is ""ahead"" of the NTP servers. so when you adjust your time, your files and other things exist in the future. This can really confuse things.  Linux doesn't like time travel and it's not afraid to let you know. Normally this is just warnings but can be more serious issues depending on how some scripts are written. I say this because an embedded device usually has some pretty narly scripts on it. 
",coteyr,https://unix.stackexchange.com/users/50370,http://unix.stackexchange.com/questions/113560/setup-ntp-client-with-embedded-device,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,1.0,0.7777777777777778,Installing NTP client with embedded device,"I need to run an NTP client on a very limited embedded device.  

ntpd is available but I do not see anything like rc.conf, or ntp.conf, or xntp.conf?  Can someone advise on how to setup NTP?  

I ran ntpd, but the date and time haven't updated.
","Try ntpd -bq

That will set the time and quit. It will allow you to sync to broadcast servers as well.

That said there are two important things to note. First I don't know who the NTP servers are on you network. If someone is being a bad little techie they could bork your time/date and invalidate some security protocols. 

Also be aware that a common problem is that your time is ""ahead"" of the NTP servers. so when you adjust your time, your files and other things exist in the future. This can really confuse things.  Linux doesn't like time travel and it's not afraid to let you know. Normally this is just warnings but can be more serious issues depending on how some scripts are written. I say this because an embedded device usually has some pretty narly scripts on it. 
"
546,546,859,High-Tech Dungeon Crawling in Hard Sci-Fi,"I've started playing Eclipse Phase with a group of friends. Most of them have a Dungeons and Dragon history, and love getting magic items and such. I've already made up my mind to take the party on more dungeon raids, but what specifically can I do in the way of loot? It is a hard science fiction setting; no magic. It's noted in the core book that some brand-name weapons and items will have special features, and there is something called Psi that is basically watered-down psychic abilities. What are some recommendations you would make for drops and treasure caches?
",Tasuret,https://rpg.stackexchange.com/users/1598,"The biggest difference between fantasy and sci-fi notions of value is that: ideas have value

Therefore, besides the standard stuff players receive, they can also discover what amounts to IP.

One of the oddest forms of IP is actually Real Estate, as it's a purely symbolic agreement that X owns area Y, even though X may not sit on Y with guns. (Note how this doesn't exist in most fantasy worlds.)

So one of the most interesting (from a cognitive dissonance point of view) rewards that players can get is the dungeon itself. They clear out an asteroid full of Nanoinfested Bots?  They now own the asteroid and derive value from it. Our heros don't engage in Loot, Pillage, Burn any more, instead, they secure the objectives and get a stream of income. Sure, they can sell it, but it's far more interesting to present to them a tally of their ""investment holdings"" and recent events on each one. Plenty of plot hooks there and a way to get exactly the level of loot into their hands that you want without having to find ways of pushing the shiny things into the mission de jour. 

Other forms of IP are roughtly grouped into the ""valuable memes"" grouping. So, one thing of great value would be an ancient mpX player with some hit songs from the 20th century. This is, of course, only of great value if managed correctly, but enterprising players will see the value in rare memes. And if they don't, then the first few times they release the IP into the infosphere, they get flamed/praised for their generosity. 

And so on. The notion of value was hugely changed by the Industrial Revolution (that we're still in, arguably.) and by hitting home with the idea that ""ideas have value"" you can give them loot and emphasize the non-fantasy setting in ways that will make the less thinky players quite squeamish (yay! cognitive dissonance!).

Of course, they can be compensated for their efforts with upgraded gear and stuff, but that's expected. 
",Brian Ballsun-Stanton,https://rpg.stackexchange.com/users/760,http://rpg.stackexchange.com/questions/6974/high-tech-dungeon-crawling-in-hard-sci-fi,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,High tech dungeons crawling in hard science fiction,"I've started the eclipse phase with a group of friends. Most of them have a history of dungeons and dragons, like to get magic items and so on. I have made up my mind to let the party make more raids in the dungeons, but what can I do to rob? It's a hard science fiction scene; there's no magic. As mentioned in the core book, some famous brand weapons and articles will have special functions. There is also something called psi, which basically weakens the psychological ability. What advice would you give to drips and treasures?","The biggest difference between fantasy and sci-fi notions of value is that: ideas have value

Therefore, besides the standard stuff players receive, they can also discover what amounts to IP.

One of the oddest forms of IP is actually Real Estate, as it's a purely symbolic agreement that X owns area Y, even though X may not sit on Y with guns. (Note how this doesn't exist in most fantasy worlds.)

So one of the most interesting (from a cognitive dissonance point of view) rewards that players can get is the dungeon itself. They clear out an asteroid full of Nanoinfested Bots?  They now own the asteroid and derive value from it. Our heros don't engage in Loot, Pillage, Burn any more, instead, they secure the objectives and get a stream of income. Sure, they can sell it, but it's far more interesting to present to them a tally of their ""investment holdings"" and recent events on each one. Plenty of plot hooks there and a way to get exactly the level of loot into their hands that you want without having to find ways of pushing the shiny things into the mission de jour. 

Other forms of IP are roughtly grouped into the ""valuable memes"" grouping. So, one thing of great value would be an ancient mpX player with some hit songs from the 20th century. This is, of course, only of great value if managed correctly, but enterprising players will see the value in rare memes. And if they don't, then the first few times they release the IP into the infosphere, they get flamed/praised for their generosity. 

And so on. The notion of value was hugely changed by the Industrial Revolution (that we're still in, arguably.) and by hitting home with the idea that ""ideas have value"" you can give them loot and emphasize the non-fantasy setting in ways that will make the less thinky players quite squeamish (yay! cognitive dissonance!).

Of course, they can be compensated for their efforts with upgraded gear and stuff, but that's expected. 
"
2869,2869,4566,How do I find the most populous cities in the world?,"I am attempting to plot the most populous cities on a world map.

Currently, I have the line of code:

numberofpeople = 
  Map[{#, Length[CityData[#, ""Population""]]} &amp;, CityData[All]];


which should give me the City name, and the population. However, when I type in the line of code

Reverse[SortBy[numberofpeople, Last]][[1 ;; 20]]


I am getting odd data, which is that the most populous cities have 1 person. 

Could somebody debug my code, and answer any future questions I have on the matter?
Much appreciated.

EDIT: How do I plot these points on a World Map? Currently I have

Graphics[{EdgeForm[Black], , CountryData[#, ""SchematicPolygon""]} &amp; /@ 
  CountryData[]]

but I have no idea what goes between the points.
",user9876,https://mathematica.stackexchange.com/users/9876,"Leave out Length in Length[CityData[#, ""Population""]], and delete cases of Missing data:

numberofpeople = Map[{#, CityData[#, ""Population""]} &amp;, CityData[All]];

Reverse[SortBy[DeleteCases[numberofpeople, {_, _Missing}], Last]] ~Take~ 20 // Grid



",Mr.Wizard,https://mathematica.stackexchange.com/users/121,http://mathematica.stackexchange.com/questions/34456/how-do-i-find-the-most-populous-cities-in-the-world,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9,1.0,0.0,0.0,0.7777777777777778,How can I find the most populous city in the world?,"I am attempting to plot the most populous cities on a world map.

Currently, I have the line of code:

numberofpeople = 
  Map[{#, Length[CityData[#, ""Population""]]} &amp;, CityData[All]];


which should give me the City name, and the population. However, when I type in the line of code

Reverse[SortBy[numberofpeople, Last]][[1 ;; 20]]


I am getting odd data, which is that the most populous cities have 1 person. 

Could somebody debug my code, and answer any future questions I have on the matter?
Much appreciated.

EDIT: How do I plot these points on a World Map? Currently I have

Graphics[{EdgeForm[Black], , CountryData[#, ""SchematicPolygon""]} &amp; /@ 
  CountryData[]]

but I have no idea what goes between the points.
","Leave out Length in Length[CityData[#, ""Population""]], and delete cases of Missing data:

numberofpeople = Map[{#, CityData[#, ""Population""]} &amp;, CityData[All]];

Reverse[SortBy[DeleteCases[numberofpeople, {_, _Missing}], Last]] ~Take~ 20 // Grid



"
3754,3754,5981,C++ return to main,"I want to be able to get back to the main.cpp file from another.  For example.

// Main.cpp
#include ""Globals.h""

int main()
{
    otherFile();
}

// Globals.h

#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;

bool otherFile();

//otherFile.cpp
#include ""Globals.h""

bool otherFile() 
{
    // do stuff
    // Here I want to be able to go back to the main.cpp file.
}


Sorry if my question makes no sense
",Luke Berry,https://stackoverflow.com/users/422287,"if you create a function in main.cpp and add declaration to Globals.h, then you can call this function from otherFile.cpp.

If you don't need any statements after ""do stuff"", then your program logic automatically will return to the main(), because end of function call, so just add instructions after otherFile(); call in main, and they will be executed after this function.

You decalred otherFile() as returning bool, so put and end of your function return true; or return false;
",Piotr MÃ¼ller,https://stackoverflow.com/users/403759,http://stackoverflow.com/questions/5282024/c-return-to-main,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.8666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,C + + return to master,"I want to be able to get back to the main.cpp file from another.  For example.

// Main.cpp
#include ""Globals.h""

int main()
{
    otherFile();
}

// Globals.h

#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;

bool otherFile();

//otherFile.cpp
#include ""Globals.h""

bool otherFile() 
{
    // do stuff
    // Here I want to be able to go back to the main.cpp file.
}


Sorry if my question makes no sense
","if you create a function in main.cpp and add declaration to Globals.h, then you can call this function from otherFile.cpp.

If you don't need any statements after ""do stuff"", then your program logic automatically will return to the main(), because end of function call, so just add instructions after otherFile(); call in main, and they will be executed after this function.

You decalred otherFile() as returning bool, so put and end of your function return true; or return false;
"
1851,1851,2937,How does arbitary code execution work?,"I'm unable to understand how arbitrary code execution vulnerabilities are supposed to work.

Wikipedia mentions:


  Arbitrary code execution is commonly achieved through control over the instruction pointer of a running process.


Say, the vulnerability is being triggered by some maliciously crafted file that said process is reading. How could it modify the instruction pointer, or, otherwise, corrupt the internal state of the application so as to cause it to execute the attacker's code?

Also, given that modern OSes implement DEP and ASLR, how is this even feasible? The data loaded from the application would not even be executable, and additionally, it's also difficult to determine the offset of the shellcode/payload.

Brownie points for showing a small snippet of code that would be vulnerable to such an exploit.
",user2064000,https://security.stackexchange.com/users/22260,"Each vulnerability has a specific cause, which in turn leads to ways of exploiting the vulnerability. It is hard to understand how one can exploit something abstract and gain some abstract results, but it is way easier to understand when illustrated with examples. The simplest would be the classical stack-based buffer overflow:

void f(const char *str) {
  char buf[10];
  strcpy(buf, str);
}


This is a primitive example that should be sufficient to demonstrate the issue. Suppose the str argument points to a NULL-terminated string longer than the 10 chars allocated for the variable it is being copied into. What will happen? strcpy() will blindly copy the date over the end of the buffer, overwriting whatever was there. But what exactly is there?

On x86, for example, the buf variable would be allocated on the stack. The stack is also used to save the return address when a CALL instruction is executed. So (simplified) stack layout would look like this (addresses are increasing top to bottom):

...
buf[0..3]
buf[4..7]
buf[8..9]
return address
...


So, by supplying an overly long string via the str argument, we would be able to overwrite the return address from f(). If the attacker is able to control the string, then he can control where the control flow will go after f() returns. This may occur when parsing a specially crafted file, for example.

The next thing would be to direct the control to a JMP ESP instruction or similar in effect, causing code from the stack to be executed. This ""direct"" code execution is prevented by DEP.

Of course, the example above doesn't include bypassing any of modern mitigations (stack canaries, SafeSEH, DEP). This does not mean it is globally impossible, but it may be impossible in certain cases. Bypassing DEP usually involves Return-oriented programming -- instead of code itself, specially crafted data is placed on the stack, which utilises fragments of already existing functions in the process image (called gadgets) to execute code. This, in turn, is mitigated by ASLR, making the gadget addresses somewhat unpredictable. There are techniques of bypassing ASLR as well.

If you would like to get your hands on exploiting real-life programs, I would suggest corelanc0d3r's tutorials as a starting point.

EDIT: Replaced the offending part.
",Dmitry Yanushkevich,https://security.stackexchange.com/users/18011,http://security.stackexchange.com/questions/63315/how-does-arbitary-code-execution-work,TECHNOLOGY,security.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,1.0,How does arbitrary code execution work?,"I'm unable to understand how arbitrary code execution vulnerabilities are supposed to work.

Wikipedia mentions:


  Arbitrary code execution is commonly achieved through control over the instruction pointer of a running process.


Say, the vulnerability is being triggered by some maliciously crafted file that said process is reading. How could it modify the instruction pointer, or, otherwise, corrupt the internal state of the application so as to cause it to execute the attacker's code?

Also, given that modern OSes implement DEP and ASLR, how is this even feasible? The data loaded from the application would not even be executable, and additionally, it's also difficult to determine the offset of the shellcode/payload.

Brownie points for showing a small snippet of code that would be vulnerable to such an exploit.
","Each vulnerability has a specific cause, which in turn leads to ways of exploiting the vulnerability. It is hard to understand how one can exploit something abstract and gain some abstract results, but it is way easier to understand when illustrated with examples. The simplest would be the classical stack-based buffer overflow:

void f(const char *str) {
  char buf[10];
  strcpy(buf, str);
}


This is a primitive example that should be sufficient to demonstrate the issue. Suppose the str argument points to a NULL-terminated string longer than the 10 chars allocated for the variable it is being copied into. What will happen? strcpy() will blindly copy the date over the end of the buffer, overwriting whatever was there. But what exactly is there?

On x86, for example, the buf variable would be allocated on the stack. The stack is also used to save the return address when a CALL instruction is executed. So (simplified) stack layout would look like this (addresses are increasing top to bottom):

...
buf[0..3]
buf[4..7]
buf[8..9]
return address
...


So, by supplying an overly long string via the str argument, we would be able to overwrite the return address from f(). If the attacker is able to control the string, then he can control where the control flow will go after f() returns. This may occur when parsing a specially crafted file, for example.

The next thing would be to direct the control to a JMP ESP instruction or similar in effect, causing code from the stack to be executed. This ""direct"" code execution is prevented by DEP.

Of course, the example above doesn't include bypassing any of modern mitigations (stack canaries, SafeSEH, DEP). This does not mean it is globally impossible, but it may be impossible in certain cases. Bypassing DEP usually involves Return-oriented programming -- instead of code itself, specially crafted data is placed on the stack, which utilises fragments of already existing functions in the process image (called gadgets) to execute code. This, in turn, is mitigated by ASLR, making the gadget addresses somewhat unpredictable. There are techniques of bypassing ASLR as well.

If you would like to get your hands on exploiting real-life programs, I would suggest corelanc0d3r's tutorials as a starting point.

EDIT: Replaced the offending part.
"
2713,2713,4326,Is there a way to fill your tires with nitrogen?,"I know this is a rather controversial issue. I was skeptical as well before doing this on my car, and I have not refilled my car tires for several months. Before that I needed to adjust the pressure every couple of months at least. 

Now I think it is a good idea to try this for our bikes. Especially since, when I see I need to fill up my bike tires, I get too lazy and give up the ride altogether. 

Is there a way to do this at home?

EDIT:
I thought I'd update the question for people who come and read later:  

Thanks for all the comments, I drive a lot (30kmiles/year) and I saw (to my surprise) a significant difference with nitrogen. 

I understand the reasoning with losing oxygen over time and increasing the N2 concentration but in practice that does not happen fast enough.  

I think I'll look into Helium/Argon and I'll update you if I managed to do something interesting. 

And I live in a small place I don't like to have a large pump but that is exactly why pumping is such a chore for me,
",Ali,https://bicycles.stackexchange.com/users/1924,"I can inflate my car tires to proper pressure by checking them once a month or so and inflating them as needed using free air.  It takes me maybe 5 minutes per month.

I can inflate my bike tires to proper pressure by checking them once a week or so and inflating them as needed using free air.  It takes me maybe 2 minutes per week.

There is no strategy of using alternative gasses that can even remotely compete with that in terms of economy, time or convenience.
",Carey Gregory,https://bicycles.stackexchange.com/users/3497,http://bicycles.stackexchange.com/questions/16001/is-there-a-way-to-fill-your-tires-with-nitrogen,CULTURE,bicycles.stackexchange.com,1.0,0.8333333333333334,0.0,1.0,1.0,1.0,0.5,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.5,0.5,0.0,0.8333333333333334,0.5,0.5,1.0,0.8333333333333334,0.4,0.0,0.0,0.5,1.0,Is there any way to nitrogen your tires?,"I know this is a rather controversial issue. I was skeptical as well before doing this on my car, and I have not refilled my car tires for several months. Before that I needed to adjust the pressure every couple of months at least. 

Now I think it is a good idea to try this for our bikes. Especially since, when I see I need to fill up my bike tires, I get too lazy and give up the ride altogether. 

Is there a way to do this at home?

EDIT:
I thought I'd update the question for people who come and read later:  

Thanks for all the comments, I drive a lot (30kmiles/year) and I saw (to my surprise) a significant difference with nitrogen. 

I understand the reasoning with losing oxygen over time and increasing the N2 concentration but in practice that does not happen fast enough.  

I think I'll look into Helium/Argon and I'll update you if I managed to do something interesting. 

And I live in a small place I don't like to have a large pump but that is exactly why pumping is such a chore for me,
","I can inflate my car tires to proper pressure by checking them once a month or so and inflating them as needed using free air.  It takes me maybe 5 minutes per month.

I can inflate my bike tires to proper pressure by checking them once a week or so and inflating them as needed using free air.  It takes me maybe 2 minutes per week.

There is no strategy of using alternative gasses that can even remotely compete with that in terms of economy, time or convenience.
"
141,141,224,What lightweight telephoto lens are available for Nikon bodies?,"I'm looking for a lightweight telephoto lens for my Nikon D700 body, with a focal length around 300mm, good sharpness and AF. After several days with the 70-200 vrII handheld, I found this lens too big and heavy. I usually prefer the prime lenses, but all the good ~300mm prime I know weight 1.5kg or more.

I will use it mostly for sport, wildlife and landscape. A bonus point if it is bright enough for a use in dark concert stages :)

The only two lightweight options I considered for now are


Nikon 70-300mm VR (750g, F5.6@300mm)
Nikon 180mm (760g) + 1.4x TC (F4@250mm)


Have you any recommandation on these possibilities ? e.g. with third party lenses.
I'm in love with my 85mm 1.4G, but I have the feeling that I won't be able to get the same quality at 300mm without carrying expensive kilos of glasses.
",Emile,https://photo.stackexchange.com/users/13738,"Really you seem to have done your research already. There are a few more similar lenses, from Sigma and Tamron but they will not save you much weight and certainly not improve on image quality and AF-speed. As you noticed, lightweight and quality telephoto do not mix.

What is left is for you to consider the total weight of your system instead. Maybe you can replace more than one lens with a longer zoom ratio one. Quality is not top-notch but still can be good enough given the constraints. Something like the Nikkor AF-S 28-300mm F/3.5-5.6 ED VR maybe.
",Itai,https://photo.stackexchange.com/users/1620,http://photo.stackexchange.com/questions/31099/what-lightweight-telephoto-lens-are-available-for-nikon-bodies,LIFE_ARTS,photo.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,What kind of light telephoto lens does Nikon have?,"I'm looking for a lightweight telephoto lens for my Nikon D700 body, with a focal length around 300mm, good sharpness and AF. After several days with the 70-200 vrII handheld, I found this lens too big and heavy. I usually prefer the prime lenses, but all the good ~300mm prime I know weight 1.5kg or more.

I will use it mostly for sport, wildlife and landscape. A bonus point if it is bright enough for a use in dark concert stages :)

The only two lightweight options I considered for now are


Nikon 70-300mm VR (750g, F5.6@300mm)
Nikon 180mm (760g) + 1.4x TC (F4@250mm)


Have you any recommandation on these possibilities ? e.g. with third party lenses.
I'm in love with my 85mm 1.4G, but I have the feeling that I won't be able to get the same quality at 300mm without carrying expensive kilos of glasses.
","Really you seem to have done your research already. There are a few more similar lenses, from Sigma and Tamron but they will not save you much weight and certainly not improve on image quality and AF-speed. As you noticed, lightweight and quality telephoto do not mix.

What is left is for you to consider the total weight of your system instead. Maybe you can replace more than one lens with a longer zoom ratio one. Quality is not top-notch but still can be good enough given the constraints. Something like the Nikkor AF-S 28-300mm F/3.5-5.6 ED VR maybe.
"
2720,2720,4335,Is there a way to fill your tires with nitrogen?,"I know this is a rather controversial issue. I was skeptical as well before doing this on my car, and I have not refilled my car tires for several months. Before that I needed to adjust the pressure every couple of months at least. 

Now I think it is a good idea to try this for our bikes. Especially since, when I see I need to fill up my bike tires, I get too lazy and give up the ride altogether. 

Is there a way to do this at home?

EDIT:
I thought I'd update the question for people who come and read later:  

Thanks for all the comments, I drive a lot (30kmiles/year) and I saw (to my surprise) a significant difference with nitrogen. 

I understand the reasoning with losing oxygen over time and increasing the N2 concentration but in practice that does not happen fast enough.  

I think I'll look into Helium/Argon and I'll update you if I managed to do something interesting. 

And I live in a small place I don't like to have a large pump but that is exactly why pumping is such a chore for me,
",Ali,https://bicycles.stackexchange.com/users/1924,"Prestacycle markets a home nitrogen system.  Have never used this product.  Bit too pricey for me. Personally a floor pump is a better value.  Different road conditions means different tire pressures for optimal ride. 
",WabiFGSS,https://bicycles.stackexchange.com/users/7100,http://bicycles.stackexchange.com/questions/16001/is-there-a-way-to-fill-your-tires-with-nitrogen,CULTURE,bicycles.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.4444444444444444,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,0.7777777777777778,Is there any way to nitrogen your tires?,"I know this is a rather controversial issue. I was skeptical as well before doing this on my car, and I have not refilled my car tires for several months. Before that I needed to adjust the pressure every couple of months at least. 

Now I think it is a good idea to try this for our bikes. Especially since, when I see I need to fill up my bike tires, I get too lazy and give up the ride altogether. 

Is there a way to do this at home?

EDIT:
I thought I'd update the question for people who come and read later:  

Thanks for all the comments, I drive a lot (30kmiles/year) and I saw (to my surprise) a significant difference with nitrogen. 

I understand the reasoning with losing oxygen over time and increasing the N2 concentration but in practice that does not happen fast enough.  

I think I'll look into Helium/Argon and I'll update you if I managed to do something interesting. 

And I live in a small place I don't like to have a large pump but that is exactly why pumping is such a chore for me,
","Prestacycle markets a home nitrogen system.  Have never used this product.  Bit too pricey for me. Personally a floor pump is a better value.  Different road conditions means different tire pressures for optimal ride. 
"
5924,5924,9382,Creating Excel document is very slow,"Attached is a generic code I wrote to create an Excel file with x number of worksheets.

The problem I am having is that it's pretty slow, like 5 seconds a sheet. It was my understanding that using a for loop when creating the tables was ideal, but the issue seems to be with tables containing over a thousand or so records... still wouldn't think it should take this long.

Any pointers would be appreciated, also, if I am completely left field with this code let me know, up-to-date Excel code resources seem to be hard to find.

public static string Export(string excelFileName, 
                            string[] excelWorksheetName, 
                            string tableStyle, 
                            params System.Data.DataTable[] dt)
{
    Application xls = new Application();
    xls.SheetsInNewWorkbook = dt.Length;

    // Create our new excel application and add our workbooks/worksheets
    Workbooks workbooks = xls.Workbooks;
    Workbook workbook = workbooks.Add();
    // Hide our excel object if it's visible.
    xls.Visible = false;
    // Turn off calculations if set to automatic; this can help prevent memory leaks.
    xls.Calculation = xls.Calculation == XlCalculation.xlCalculationAutomatic ? XlCalculation.xlCalculationManual : XlCalculation.xlCalculationManual;
    // Turn off screen updating so our export will process more quickly.
    xls.ScreenUpdating = false;
    // Create an excel table and fill it will our query table.

    int iterator = dt.Length - 1;
    for (int i = 0; i &lt;= iterator; i++)
    {
        // Turn off calculations if set to automatic; this can help prevent memory leaks.
        Worksheet worksheet = (Worksheet)xls.Worksheets[i + 1];
        worksheet.Name = excelWorksheetName[i];
        worksheet.Select();
        if (dt[i].Rows.Count &gt; 0)
        {
            // Format this information as a table.
            Range tblRange = worksheet.get_Range(""$A$1"");//string.Format(""$A$1"", dt[i].Rows.Count + 1));
            tblRange.Worksheet.ListObjects.Add(XlListObjectSourceType.xlSrcRange,
                                               tblRange,
                                               System.Type.Missing,
                                               XlYesNoGuess.xlYes,
                                               System.Type.Missing).Name = excelWorksheetName[i];
            tblRange.Select();
            tblRange.Worksheet.ListObjects[excelWorksheetName[i]].TableStyle = tableStyle;
            // Create a row with our column headers.
            for (int column = 0; column &lt; dt[i].Columns.Count; column++)
            {
                worksheet.Cells[1, column + 1] = dt[i].Columns[column].ColumnName;
            }

            // Export our data table information to excel.
            for (int row = 0; row &lt; dt[i].Rows.Count; row++)
            {
                for (int column = 0; column &lt; dt[i].Columns.Count; column++)
                {
                    worksheet.Cells[row + 2, column + 1] = (dt[i].Rows[row][column].ToString());
                }
            }
        }
        // Freeze our column headers.
        xls.Application.Range[""2:2""].Select();
        xls.ActiveWindow.FreezePanes = true;

        xls.ActiveWindow.DisplayGridlines = false;

        // Auto fit our rows and columns.
        xls.Application.Cells.EntireColumn.AutoFit();
        xls.Application.Cells.EntireRow.AutoFit();

        // Select the first cell in the worksheet.
        xls.Application.Range[""$A$2""].Select();

        // Turn off alerts to prevent asking for 'overwrite existing' and 'save changes' messages.
        xls.DisplayAlerts = false;
    }
    string SaveFilePath = string.Format(@""{0}.xls"", excelFileName);
    workbook.SaveAs(SaveFilePath, XlFileFormat.xlWorkbookNormal, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlExclusive, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);
    workbook.Close();

    // Release our resources.
    Marshal.ReleaseComObject(workbook);
    Marshal.ReleaseComObject(workbooks);
    Marshal.ReleaseComObject(xls);
    Marshal.FinalReleaseComObject(xls);

    return SaveFilePath;
}

",Volearix,https://codereview.stackexchange.com/users/38632,"Comments

Your code has way too many comments, mostly redundant ones - some are even obsolete!

Good comments should say why, not what.


// Create our new excel application and add our workbooks/worksheets
Workbooks workbooks = xls.Workbooks;
Workbook workbook = workbooks.Add();



This comment says what the code is doing, and it's lying - you're not creating a new Excel application, you're using an existing instance. Remove it.


// Hide our excel object if it's visible.
xls.Visible = false;



This comment adds no value, and is lying to a certain extent: you don't actually care whether it's already visible or not. Better just remove it.


// Turn off calculations if set to automatic; this can help prevent memory leaks.
xls.Calculation = xls.Calculation == XlCalculation.xlCalculationAutomatic ? XlCalculation.xlCalculationManual : XlCalculation.xlCalculationManual;



This one is accurate and informative - it says why you're turning off automatic calculations.. but it also says what the code is doing. Better rephrase it:

// turning off automatic calculations improves performance and can help prevent memory leaks.
xls.Calculation = (xls.Calculation == XlCalculation.xlCalculationAutomatic) 
                                    ? XlCalculation.xlCalculationManual 
                                    : XlCalculation.xlCalculationManual;


Notice how readability is improved by splitting the ternary operation into 3 lines. It appears the condition is moot, since both ends produce the same assignation. The instruction should be rewritten as simply:

xls.Calculation = XlCalculation.xlCalculationManual;



// Turn off screen updating so our export will process more quickly.
xls.ScreenUpdating = false;



Again, says what - the why makes it closely related to the previous statement. Thus:

// turning off automatic calculations and screen updating 
// improves performance and can help prevent memory leaks.
xls.Calculation = XlCalculation.xlCalculationManual;
xls.ScreenUpdating = false;



// Create an excel table and fill it will our query table.



Remove. This one adds no value.


for (int i = 0; i &lt;= iterator; i++)
{
    // Turn off calculations if set to automatic; this can help prevent memory leaks.
    Worksheet worksheet = (Worksheet)xls.Worksheets[i + 1];
    worksheet.Name = excelWorksheetName[i];
    worksheet.Select();



Apparently the code under that comment was moved, but the comment remained.



As for performance, @Will's comment is accurate - COM interop is hurting you here. What's slowing it down is the many calls to the Excel object model (COM interop in itself incurs a performance penalty, but Excel interop somehow makes it even worse). The only way is to limit the number of times you're accessing the Excel object model.

An alternative approach could be to write the data in a .csv file, and use the Excel object model to import the .csv data all in one shot (rather than looping into rows and columns to write the data ""manually""), and then to format the workbook and save it in .xlsx format.
",Mat's Mug,https://codereview.stackexchange.com/users/23788,http://codereview.stackexchange.com/questions/44169/creating-excel-document-is-very-slow,TECHNOLOGY,codereview.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,Creating EXCEL documents is very slow,"Attached is a generic code I wrote to create an Excel file with x number of worksheets.

The problem I am having is that it's pretty slow, like 5 seconds a sheet. It was my understanding that using a for loop when creating the tables was ideal, but the issue seems to be with tables containing over a thousand or so records... still wouldn't think it should take this long.

Any pointers would be appreciated, also, if I am completely left field with this code let me know, up-to-date Excel code resources seem to be hard to find.

public static string Export(string excelFileName, 
                            string[] excelWorksheetName, 
                            string tableStyle, 
                            params System.Data.DataTable[] dt)
{
    Application xls = new Application();
    xls.SheetsInNewWorkbook = dt.Length;

    // Create our new excel application and add our workbooks/worksheets
    Workbooks workbooks = xls.Workbooks;
    Workbook workbook = workbooks.Add();
    // Hide our excel object if it's visible.
    xls.Visible = false;
    // Turn off calculations if set to automatic; this can help prevent memory leaks.
    xls.Calculation = xls.Calculation == XlCalculation.xlCalculationAutomatic ? XlCalculation.xlCalculationManual : XlCalculation.xlCalculationManual;
    // Turn off screen updating so our export will process more quickly.
    xls.ScreenUpdating = false;
    // Create an excel table and fill it will our query table.

    int iterator = dt.Length - 1;
    for (int i = 0; i &lt;= iterator; i++)
    {
        // Turn off calculations if set to automatic; this can help prevent memory leaks.
        Worksheet worksheet = (Worksheet)xls.Worksheets[i + 1];
        worksheet.Name = excelWorksheetName[i];
        worksheet.Select();
        if (dt[i].Rows.Count &gt; 0)
        {
            // Format this information as a table.
            Range tblRange = worksheet.get_Range(""$A$1"");//string.Format(""$A$1"", dt[i].Rows.Count + 1));
            tblRange.Worksheet.ListObjects.Add(XlListObjectSourceType.xlSrcRange,
                                               tblRange,
                                               System.Type.Missing,
                                               XlYesNoGuess.xlYes,
                                               System.Type.Missing).Name = excelWorksheetName[i];
            tblRange.Select();
            tblRange.Worksheet.ListObjects[excelWorksheetName[i]].TableStyle = tableStyle;
            // Create a row with our column headers.
            for (int column = 0; column &lt; dt[i].Columns.Count; column++)
            {
                worksheet.Cells[1, column + 1] = dt[i].Columns[column].ColumnName;
            }

            // Export our data table information to excel.
            for (int row = 0; row &lt; dt[i].Rows.Count; row++)
            {
                for (int column = 0; column &lt; dt[i].Columns.Count; column++)
                {
                    worksheet.Cells[row + 2, column + 1] = (dt[i].Rows[row][column].ToString());
                }
            }
        }
        // Freeze our column headers.
        xls.Application.Range[""2:2""].Select();
        xls.ActiveWindow.FreezePanes = true;

        xls.ActiveWindow.DisplayGridlines = false;

        // Auto fit our rows and columns.
        xls.Application.Cells.EntireColumn.AutoFit();
        xls.Application.Cells.EntireRow.AutoFit();

        // Select the first cell in the worksheet.
        xls.Application.Range[""$A$2""].Select();

        // Turn off alerts to prevent asking for 'overwrite existing' and 'save changes' messages.
        xls.DisplayAlerts = false;
    }
    string SaveFilePath = string.Format(@""{0}.xls"", excelFileName);
    workbook.SaveAs(SaveFilePath, XlFileFormat.xlWorkbookNormal, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlExclusive, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);
    workbook.Close();

    // Release our resources.
    Marshal.ReleaseComObject(workbook);
    Marshal.ReleaseComObject(workbooks);
    Marshal.ReleaseComObject(xls);
    Marshal.FinalReleaseComObject(xls);

    return SaveFilePath;
}

","Comments

Your code has way too many comments, mostly redundant ones - some are even obsolete!

Good comments should say why, not what.


// Create our new excel application and add our workbooks/worksheets
Workbooks workbooks = xls.Workbooks;
Workbook workbook = workbooks.Add();



This comment says what the code is doing, and it's lying - you're not creating a new Excel application, you're using an existing instance. Remove it.


// Hide our excel object if it's visible.
xls.Visible = false;



This comment adds no value, and is lying to a certain extent: you don't actually care whether it's already visible or not. Better just remove it.


// Turn off calculations if set to automatic; this can help prevent memory leaks.
xls.Calculation = xls.Calculation == XlCalculation.xlCalculationAutomatic ? XlCalculation.xlCalculationManual : XlCalculation.xlCalculationManual;



This one is accurate and informative - it says why you're turning off automatic calculations.. but it also says what the code is doing. Better rephrase it:

// turning off automatic calculations improves performance and can help prevent memory leaks.
xls.Calculation = (xls.Calculation == XlCalculation.xlCalculationAutomatic) 
                                    ? XlCalculation.xlCalculationManual 
                                    : XlCalculation.xlCalculationManual;


Notice how readability is improved by splitting the ternary operation into 3 lines. It appears the condition is moot, since both ends produce the same assignation. The instruction should be rewritten as simply:

xls.Calculation = XlCalculation.xlCalculationManual;



// Turn off screen updating so our export will process more quickly.
xls.ScreenUpdating = false;



Again, says what - the why makes it closely related to the previous statement. Thus:

// turning off automatic calculations and screen updating 
// improves performance and can help prevent memory leaks.
xls.Calculation = XlCalculation.xlCalculationManual;
xls.ScreenUpdating = false;



// Create an excel table and fill it will our query table.



Remove. This one adds no value.


for (int i = 0; i &lt;= iterator; i++)
{
    // Turn off calculations if set to automatic; this can help prevent memory leaks.
    Worksheet worksheet = (Worksheet)xls.Worksheets[i + 1];
    worksheet.Name = excelWorksheetName[i];
    worksheet.Select();



Apparently the code under that comment was moved, but the comment remained.



As for performance, @Will's comment is accurate - COM interop is hurting you here. What's slowing it down is the many calls to the Excel object model (COM interop in itself incurs a performance penalty, but Excel interop somehow makes it even worse). The only way is to limit the number of times you're accessing the Excel object model.

An alternative approach could be to write the data in a .csv file, and use the Excel object model to import the .csv data all in one shot (rather than looping into rows and columns to write the data ""manually""), and then to format the workbook and save it in .xlsx format.
"
4951,4951,7885,How can I use an SVG image as a map marker in OpenLayers-3?,"I am trying to create map ""pin-drops"" (ie. map markers) in OpenLayers-3 (OL3) using SVG images.

Currently, I am using PNG images as the pindrops that reference the ol.style.Icon source (âsrcâ) property attribute just fine. However, this fails using an SVG image. Is there some other way to use an SVG in the same manner? Maybe by using a reference besides ol.style.Icon even? There is already a lot of built-in SVG in Open Layers so this should be possible, but I haven't found a way to get this working in OL3. Is there some other way to do this in OL3 that I should consider?

Please note: we already tried using an ol.Vector layer, however when the user zooms in/out, the size of the SVG image grows/shrinks which is an inadequate workaround.



OL3 (fails): 

var createMapMarkerImage = function() {
    return function(feature, resolution) {
        var iconStyle = new ol.style.Style({
            image: new ol.style.Icon( ({
                src: 'img/map_pindrop.svg'   // OL3 doesnât like this, but accepts a .PNG just fine
            }))
        });
        return [iconStyle];
    };
};


Very similar functionality, is the below example I found online, is almost perfect if it werenât for the fact that the example uses OpenLayers-2 (OL2) functionality which calls openlayers.js library (instead of OL3âs ol.js library). Sadly, swapping these javascript files out fails.



OL2 (works -but is the old OL library):

http://dev.openlayers.org/sandbox/camptocamp/tipi/examples/vector-symbols.html



Searching online for a solution to this seems to produce only other confused people searching for a solution.

Please help,

FreeBeer
",FreeBeer,https://stackoverflow.com/users/4691155,"I also had issues to show the icon image, ahocevar answer helped me to 
solve my problem but I had also to search for the php header, for SVG
In case you are or others who see this answer are using php to generate the SVG you have to use header function to identify the content-type

header('Content-type: image/svg+xml'); /* this line will do the magic */
echo '&lt;?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?&gt;
&lt;svg width=""100%"" height=""100%"" version=""1.1"" xmlns=""http://www.w3.org/2000/svg""&gt;
&lt;circle cx=""100"" cy=""50"" r=""40"" stroke=""black"" stroke-width=""2"" fill=""red""/&gt;
&lt;/svg&gt;';

",talsibony,https://stackoverflow.com/users/1220652,http://stackoverflow.com/questions/29152405/how-can-i-use-an-svg-image-as-a-map-marker-in-openlayers-3,STACKOVERFLOW,stackoverflow.com,1.0,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.7777777777777778,How to use SVG image as map marker in openlayers-3?,"I am trying to create map ""pin-drops"" (ie. map markers) in OpenLayers-3 (OL3) using SVG images.

Currently, I am using PNG images as the pindrops that reference the ol.style.Icon source (âsrcâ) property attribute just fine. However, this fails using an SVG image. Is there some other way to use an SVG in the same manner? Maybe by using a reference besides ol.style.Icon even? There is already a lot of built-in SVG in Open Layers so this should be possible, but I haven't found a way to get this working in OL3. Is there some other way to do this in OL3 that I should consider?

Please note: we already tried using an ol.Vector layer, however when the user zooms in/out, the size of the SVG image grows/shrinks which is an inadequate workaround.



OL3 (fails): 

var createMapMarkerImage = function() {
    return function(feature, resolution) {
        var iconStyle = new ol.style.Style({
            image: new ol.style.Icon( ({
                src: 'img/map_pindrop.svg'   // OL3 doesnât like this, but accepts a .PNG just fine
            }))
        });
        return [iconStyle];
    };
};


Very similar functionality, is the below example I found online, is almost perfect if it werenât for the fact that the example uses OpenLayers-2 (OL2) functionality which calls openlayers.js library (instead of OL3âs ol.js library). Sadly, swapping these javascript files out fails.



OL2 (works -but is the old OL library):

http://dev.openlayers.org/sandbox/camptocamp/tipi/examples/vector-symbols.html



Searching online for a solution to this seems to produce only other confused people searching for a solution.

Please help,

FreeBeer
","I also had issues to show the icon image, ahocevar answer helped me to 
solve my problem but I had also to search for the php header, for SVG
In case you are or others who see this answer are using php to generate the SVG you have to use header function to identify the content-type

header('Content-type: image/svg+xml'); /* this line will do the magic */
echo '&lt;?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?&gt;
&lt;svg width=""100%"" height=""100%"" version=""1.1"" xmlns=""http://www.w3.org/2000/svg""&gt;
&lt;circle cx=""100"" cy=""50"" r=""40"" stroke=""black"" stroke-width=""2"" fill=""red""/&gt;
&lt;/svg&gt;';

"
2864,2864,4560,"Solubility, pressure and Henry's law","Im trying to do my chem homework and I'm stumped. 


  Determine the solubility of $\ce{N2}$ in water exposed to air at 25Â°C, if the
  atmospheric pressure is 1.2 atm, assume that the mole fraction of
  nitrogen is 0.78 in air and the Henry's Law constant for nitrogen in
  water at this temperature is $6.1 Ã 10^{-4} M/atm$.



I have the answer, but i want to know how to solve for it. I've been reading through my notes and the book trying to find a reference through which to approach this problem and i have found none. If anyone can guide me in the right direction that would suffice

",Brandon,https://chemistry.stackexchange.com/users/4312,"What are the units of your answer? You need a solubility, which is an amount per volume. If your amount is moles, the your solubility is in moles/liter: $\text{M}$. 

That unit appears in the Henry's Law constant! $6.1\times 10^{-4} \frac{\text{M}}{\text{atm}}$. What can you do to get rid of the atmospheres in the denominator? You probably need the pressure and the mole fraction.
",Ben Norris,https://chemistry.stackexchange.com/users/275,http://chemistry.stackexchange.com/questions/8088/solubility-pressure-and-henrys-law,SCIENCE,chemistry.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.5555555555555556,1.0,1.0,0.6666666666666667,1.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,"Solubility, pressure and Henry's law","Im trying to do my chem homework and I'm stumped. 


  Determine the solubility of $\ce{N2}$ in water exposed to air at 25Â°C, if the
  atmospheric pressure is 1.2 atm, assume that the mole fraction of
  nitrogen is 0.78 in air and the Henry's Law constant for nitrogen in
  water at this temperature is $6.1 Ã 10^{-4} M/atm$.



I have the answer, but i want to know how to solve for it. I've been reading through my notes and the book trying to find a reference through which to approach this problem and i have found none. If anyone can guide me in the right direction that would suffice

","What are the units of your answer? You need a solubility, which is an amount per volume. If your amount is moles, the your solubility is in moles/liter: $\text{M}$. 

That unit appears in the Henry's Law constant! $6.1\times 10^{-4} \frac{\text{M}}{\text{atm}}$. What can you do to get rid of the atmospheres in the denominator? You probably need the pressure and the mole fraction.
"
1648,1648,2593,How many fans can I control?,"I'm running a Phenom X6 on an ASUS M4A88TD-V EVO/USB3 motherboard. I just recently realized that I can quiet the otherwise noisy fan(s) with the ASUS Fan Xpert program they have. I'm loving it now since 50% fan speed changed it from noisy to almost silent.

Two questions


How do I know which fan(s) I'm slowing down? I have the CPU fan and 1 rear 120mm case fan, and I'm not sure which one's I'm slowing.
I was thinking of getting an Antec 1200 or Coolermaster 932 case with more room and more fans. How do I find out how many of those fans I can control with software? Does it slow them all down equally or can I pick and choose?


thanks for any advice
",LoveMeSomeCode,https://superuser.com/users/10393,"120mm fans tend to be quiet, so i'm guessing its the CPU fan. I'd check a few things - what's the 120mm fan connected to? if its a molex connector only then its prolly running at a fixed speed. CPU fans are definately motherboard controllable

Also many cases have their own fan speed selectors, or there's optional addons for that. Chances are though they won't be software controllable.
",Journeyman Geek,https://superuser.com/users/10165,http://superuser.com/questions/300891,TECHNOLOGY,superuser.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,1.0,0.8888888888888888,0.6666666666666667,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,How many fans can I control?,"I'm running a Phenom X6 on an ASUS M4A88TD-V EVO/USB3 motherboard. I just recently realized that I can quiet the otherwise noisy fan(s) with the ASUS Fan Xpert program they have. I'm loving it now since 50% fan speed changed it from noisy to almost silent.

Two questions


How do I know which fan(s) I'm slowing down? I have the CPU fan and 1 rear 120mm case fan, and I'm not sure which one's I'm slowing.
I was thinking of getting an Antec 1200 or Coolermaster 932 case with more room and more fans. How do I find out how many of those fans I can control with software? Does it slow them all down equally or can I pick and choose?


thanks for any advice
","120mm fans tend to be quiet, so i'm guessing its the CPU fan. I'd check a few things - what's the 120mm fan connected to? if its a molex connector only then its prolly running at a fixed speed. CPU fans are definately motherboard controllable

Also many cases have their own fan speed selectors, or there's optional addons for that. Chances are though they won't be software controllable.
"
83,83,138,Tcolorbox: force labelling to take on specific number,"Using tcolorbox, how can I label a box and give the box whatever number I want?

\documentclass{memoir}
\usepackage[breakable]{tcolorbox}
\newtcolorbox[use counter=table,number within=chapter]{MijnOtherBox}[2][]{breakable,coltitle=blue!20!black,colback=black!1!white,colframe=black!10!white,title={Box~\thetcbcounter: #2},#1}

\begin{document}
\begin{MijnOtherBox}[label=Boxone]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone}
\end{MijnOtherBox}

\end{document}


In fact my problem is that in my document there is an issue with the numbering of the boxes: in some chapters the numbering jump, e.g. Box 3.1, Box 3.2 and (!) Box 3.4, skipping 3.3...
",Anne O'Nyme,https://tex.stackexchange.com/users/36633,"I'm not sure if the problem is skipping some values or setting them. This answer can help in the first case.

If you just want to skip one value, next code shows two possibilities: 


\stepcounter outside the box or 
step and label as tcolorbox option. 


If you need to jump more than one value, use \addtocounter before the box.

Remember that the new value will be the base for following boxes.

\documentclass{memoir}
\usepackage[breakable]{tcolorbox}
\newtcolorbox[use counter=table,number within=chapter]{MijnOtherBox}[2][]
    {breakable, coltitle=blue!20!black, colback=black!1!white, 
    colframe=black!10!white, title={Box~\thetcbcounter: #2}, #1}

\begin{document}
\begin{MijnOtherBox}[label=Boxone1]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone1}
\end{MijnOtherBox}

\stepcounter{table}
\begin{MijnOtherBox}[label=Boxone2]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone2}
\end{MijnOtherBox}

\begin{MijnOtherBox}[step and label={table}{Boxone3}]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone3}
\end{MijnOtherBox}

\addtocounter{table}{3}
\begin{MijnOtherBox}[label=Boxone4]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone4}
\end{MijnOtherBox}

\end{document}



",Ignasi,https://tex.stackexchange.com/users/1952,http://tex.stackexchange.com/questions/248525/tcolorbox-force-labelling-to-take-on-specific-number,TECHNOLOGY,tex.stackexchange.com,1.0,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Tcolorbox: force a specific number to be marked,"Using tcolorbox, how can I label a box and give the box whatever number I want?

\documentclass{memoir}
\usepackage[breakable]{tcolorbox}
\newtcolorbox[use counter=table,number within=chapter]{MijnOtherBox}[2][]{breakable,coltitle=blue!20!black,colback=black!1!white,colframe=black!10!white,title={Box~\thetcbcounter: #2},#1}

\begin{document}
\begin{MijnOtherBox}[label=Boxone]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone}
\end{MijnOtherBox}

\end{document}


In fact my problem is that in my document there is an issue with the numbering of the boxes: in some chapters the numbering jump, e.g. Box 3.1, Box 3.2 and (!) Box 3.4, skipping 3.3...
","I'm not sure if the problem is skipping some values or setting them. This answer can help in the first case.

If you just want to skip one value, next code shows two possibilities: 


\stepcounter outside the box or 
step and label as tcolorbox option. 


If you need to jump more than one value, use \addtocounter before the box.

Remember that the new value will be the base for following boxes.

\documentclass{memoir}
\usepackage[breakable]{tcolorbox}
\newtcolorbox[use counter=table,number within=chapter]{MijnOtherBox}[2][]
    {breakable, coltitle=blue!20!black, colback=black!1!white, 
    colframe=black!10!white, title={Box~\thetcbcounter: #2}, #1}

\begin{document}
\begin{MijnOtherBox}[label=Boxone1]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone1}
\end{MijnOtherBox}

\stepcounter{table}
\begin{MijnOtherBox}[label=Boxone2]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone2}
\end{MijnOtherBox}

\begin{MijnOtherBox}[step and label={table}{Boxone3}]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone3}
\end{MijnOtherBox}

\addtocounter{table}{3}
\begin{MijnOtherBox}[label=Boxone4]{Title for the box}
I want this box to be labelled with number 3.1 instead of \ref{Boxone4}
\end{MijnOtherBox}

\end{document}



"
876,876,1389,Why do people rewrite some libraries to many programming languages?,"There are some libraries, which are available in their versions written in many different programming languages, like for example Lucene, which is written in Java (as they say, 100% pure Java), but has also its versions in C++, C, Perl, Ruby, Lisp and some other languages. And I'm talking about implementations in these languages, not just FFI interfaces.

Why do people do that? I can see one obvious reason: deployment and distribution (and probably development as well) easier when a project has fewer dependencies. But is there anything else? In what situations is it worth it?
",mik01aj,https://programmers.stackexchange.com/users/25529,"Typically reimplementing a library to be ""native"" to a particular platform allows for:


Simpler deployment and distribution
Easier debugging
More idiomatic APIs suitable for your exact platform
Often better performance (platform interop can be a pain)
Fixing design issues which are still in the original for compatibility


For example, I started the Noda Time project as a port of Joda Time. It simply isn't practical to use Joda Time directly from within .NET... you really don't want to have to spin up a JVM just to do date and time calculations, as well as working out how to do the interop between the two. An automated port (a la J#) might have been feasible, but the end result wouldn't have been a pleasant and idiomatic API to use from C#.
",Jon Skeet,https://programmers.stackexchange.com/users/8958,http://programmers.stackexchange.com/questions/79169/why-do-people-rewrite-some-libraries-to-many-programming-languages,TECHNOLOGY,programmers.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.0,0.5555555555555556,0.4444444444444444,1.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8333333333333334,Why do people rewrite some libraries into multiple programming languages?,"There are libraries that can be written in many different programming languages in their versions, such as Lucene, which is written in Java (as they say, 100% pure Java), but it also has versions of C + +, C, Perl, ruby, LISP and other languages. I'm talking about the implementation of these languages, not just the FFI interface.","Typically reimplementing a library to be ""native"" to a particular platform allows for:


Simpler deployment and distribution
Easier debugging
More idiomatic APIs suitable for your exact platform
Often better performance (platform interop can be a pain)
Fixing design issues which are still in the original for compatibility


For example, I started the Noda Time project as a port of Joda Time. It simply isn't practical to use Joda Time directly from within .NET... you really don't want to have to spin up a JVM just to do date and time calculations, as well as working out how to do the interop between the two. An automated port (a la J#) might have been feasible, but the end result wouldn't have been a pleasant and idiomatic API to use from C#.
"
1451,1451,2285,MonoTouch: How to save a huge PDF downloaded from an URL incrementally?,"I need to download a huge PDF file from an URL in my MonoTouch iPhone/iPad newsstand app.

The PDF is too big to fit in memory, so I need to save it incrementally with NSData.

My idea is the following: instead of appending all the downloaded data in NSData and at the very end of the download, when I got all data, to store it to a file, I want to execute the download asynchronously in a separate thread and append to a file each received chunk and free my memory, but be certain that if the connection is dropped or the app crashes the download would resume automatically from the last chunk without corrupting the file.

What do you suggest? Is there a better method? How can I do it in MonoTouch? I did't find any documentation or code example about iOS incremental download/resume on the Xamarin website.
",Emanuele Sabetta,https://stackoverflow.com/users/959398,"You don't need NSData or anything from ObjC.
You can use WebClient (http://msdn.microsoft.com/en-us/library/system.net.webclient.aspx) to achieve this in plain C#.
For an example of a chunked download with progress bar, see here: http://devtoolshed.com/content/c-download-file-progress-bar
",Krumelur,https://stackoverflow.com/users/304870,http://stackoverflow.com/questions/8666648/monotouch-how-to-save-a-huge-pdf-downloaded-from-an-url-incrementally,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,Monotouch: how to save a huge PDF file downloaded from a URL incrementally?,"I need to download a huge PDF file from an URL in my MonoTouch iPhone/iPad newsstand app.

The PDF is too big to fit in memory, so I need to save it incrementally with NSData.

My idea is the following: instead of appending all the downloaded data in NSData and at the very end of the download, when I got all data, to store it to a file, I want to execute the download asynchronously in a separate thread and append to a file each received chunk and free my memory, but be certain that if the connection is dropped or the app crashes the download would resume automatically from the last chunk without corrupting the file.

What do you suggest? Is there a better method? How can I do it in MonoTouch? I did't find any documentation or code example about iOS incremental download/resume on the Xamarin website.
","You don't need NSData or anything from ObjC.
You can use WebClient (http://msdn.microsoft.com/en-us/library/system.net.webclient.aspx) to achieve this in plain C#.
For an example of a chunked download with progress bar, see here: http://devtoolshed.com/content/c-download-file-progress-bar
"
5398,5398,8575,What is a word for somebody who lies to themselves,"I feel like the fact that people lie to themselves about things can tell you a lot about that person but I just can't put my finger on a single word that I'd use to describe them. In fact, not just describe them, but truly convey that they lie to themselves.


  Example of a person who lies to themself: ""I will do all my work
  tomorrow, I swear.""

",Petar,https://english.stackexchange.com/users/64497,"In psychology this is known as denial and it is generally thought of as unhealthy (though it is very common).
Don't Even kNow I Am Lying.
It is generally a lie of negation (""my drinking isn't a problem"")
",user69617,https://english.stackexchange.com/users/69617,http://english.stackexchange.com/questions/158869/what-is-a-word-for-somebody-who-lies-to-themselves,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,What does it mean to a self Deceiver,"I think the fact that people lie to themselves can tell you a lot about that person, but I can't use one word to describe them. In fact, it's not just about describing them, it's about telling them that they lie to themselves.","In psychology this is known as denial and it is generally thought of as unhealthy (though it is very common).
Don't Even kNow I Am Lying.
It is generally a lie of negation (""my drinking isn't a problem"")
"
1527,1527,2401,"What conditions may cause ""The content on this page has either been modified by another user...""?","I'm working on a website which has multiple admins, some creating contents, some editing and some tagging...

I know editing one node at the same time will cause this error, is there anything else cause this error?

The content on this page has either been modified by another user, or you have already submitted modifications using this form. As a result, your changes cannot be saved.

",Mohammad Ali Akbari,https://drupal.stackexchange.com/users/1076,"Another cause might me the fact that you save a form, then hit the back button and try to save it again
",Marius Ilie,https://drupal.stackexchange.com/users/3790,http://drupal.stackexchange.com/questions/29954/what-conditions-may-cause-the-content-on-this-page-has-either-been-modified-by,TECHNOLOGY,drupal.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.6666666666666666,0.5,0.8888888888888888,0.7777777777777778,0.6,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,"What could cause ""content on this page has been modified by another user...""?","I'm working on a website which has multiple admins, some creating contents, some editing and some tagging...

I know editing one node at the same time will cause this error, is there anything else cause this error?

The content on this page has either been modified by another user, or you have already submitted modifications using this form. As a result, your changes cannot be saved.

","Another cause might me the fact that you save a form, then hit the back button and try to save it again
"
4136,4136,6600,How to remove a directory and its contents using NSFileManager,"New to Objective C. I have created a few directories which contain pdf files for an iPhone app. How can I delete a directory and its contents using NSFileManager?

Do I need to loop through and remove the contents first? Any code samples would be much appreciated.

Thanks in advance.
",booboo-a-choo,https://stackoverflow.com/users/393465,"Heres some code I use that Ive edited to suit the question

- (NSMutableString*)getUserDocumentDir {
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSMutableString *path = [NSMutableString stringWithString:[paths objectAtIndex:0]];
    return path;
}


- (BOOL) createMyDocsDirectory
{
    NSMutableString *path = [self getUserDocumentDir];
    [path appendString:@""/MyDocs""];
    NSLog(@""createpath:%@"",path);
    return [[NSFileManager defaultManager] createDirectoryAtPath:path                            withIntermediateDirectories:NO                                       attributes:nil                                            error:NULL];
}

- (BOOL) deleteMyDocsDirectory 
{
    NSMutableString *path = [self getUserDocumentDir];
    [path appendString:@""/MyDocs""];
    return [[NSFileManager defaultManager] removeItemAtPath:path error:nil];
}

",twerdster,https://stackoverflow.com/users/325494,http://stackoverflow.com/questions/3664694/how-to-remove-a-directory-and-its-contents-using-nsfilemanager,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to use nsfilemanager to delete directories and their contents,New target C. I've created several directories that contain a PDF file for an iPhone application. How do I use nsfilemanager to delete directories and their contents?,"Heres some code I use that Ive edited to suit the question

- (NSMutableString*)getUserDocumentDir {
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSMutableString *path = [NSMutableString stringWithString:[paths objectAtIndex:0]];
    return path;
}


- (BOOL) createMyDocsDirectory
{
    NSMutableString *path = [self getUserDocumentDir];
    [path appendString:@""/MyDocs""];
    NSLog(@""createpath:%@"",path);
    return [[NSFileManager defaultManager] createDirectoryAtPath:path                            withIntermediateDirectories:NO                                       attributes:nil                                            error:NULL];
}

- (BOOL) deleteMyDocsDirectory 
{
    NSMutableString *path = [self getUserDocumentDir];
    [path appendString:@""/MyDocs""];
    return [[NSFileManager defaultManager] removeItemAtPath:path error:nil];
}

"
4680,4680,7417,XNA 2D camera just part of screen,"Is it possible to use the 2D camera, but just for a part of the screen? Perhaps I want some info on the screen about score and other things, but I want that at a fixed place, just like when not using a 2D camera?
",3D-kreativ,https://gamedev.stackexchange.com/users/17921,"Create a Vector2 called Camera. Say you want to show an object with respect to the camera, i.e. a non-HUD object, draw it at a position given by:

DrawPosition = ObjectPosition - CameraPosition;

For the score and other HUD stuff, don't consider the camera vector.

DrawPosition = ObjectPosition;
",ApoorvaJ,https://gamedev.stackexchange.com/users/9881,http://gamedev.stackexchange.com/questions/33633/xna-2d-camera-just-part-of-screen,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,XNA 2D camera is just a part of the screen,"Is it possible to use a 2D camera, but only part of the screen? Maybe I want to see some information about scores and other things on the screen, but I want to see it in a fixed place, like not using a 2D camera?","Create a vector 2 called camera. Suppose you want to display camera related objects, that is, non heads up display objects, draw in the following locations:"
754,754,1192,Find cron jobs that run between given times,"Is it possible to find all entries in a crontab that run between time X and time Y without having to parse the cron time entries myself? I'm mainly concerned with time hour and  minute, not so much the other 3 time fields.
",frankc,https://stackoverflow.com/users/275455,"You could copy and paste the crontab file into Excel and then create a few functions that do this.  Since the time fields are always in the same place, your columns in Excel would correspond to the timeframe in which that command is executed.

You'll have to write your formula so that is accounts for single integer values and repeating values (like 10 versus */10).

If your crobtab file changes a lot and you have many entries, then you could probably write a php script to parse this information pretty quickly. 
",Scott Harwell,https://stackoverflow.com/users/489280,http://stackoverflow.com/questions/4053463/find-cron-jobs-that-run-between-given-times,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,1.0,Find cron jobs running between given times,"Can you find all the entries running between time x and time y in crontab without having to analyze the cron time entries yourself? My main concerns are time hours and minutes, not the other three time domains.","You could copy and paste the crontab file into Excel and then create a few functions that do this.  Since the time fields are always in the same place, your columns in Excel would correspond to the timeframe in which that command is executed.

You'll have to write your formula so that is accounts for single integer values and repeating values (like 10 versus */10).

If your crobtab file changes a lot and you have many entries, then you could probably write a php script to parse this information pretty quickly. 
"
4785,4785,7598,Is it better to go first or last in Vinci?,"My son is convinced that it's best to go last in Vinci because you have the more complete information of seeing where other players have started their civilizations and you always get last turn (like having home field advantage in baseball). I see these 2 advantages, but I wonder if these outweigh the disadvantages such as not having first pick on civilizations, not being the first to go into decline, and perhaps other factors I haven't even considered (we're all new to the game). So:

Is it better to go first, last, in between, or is the game so well balanced that it hardly matters?
",Joe Golton,https://boardgames.stackexchange.com/users/2260,"It will be difficult to measure, especially when you add in more than two players. Just examining two players for a moment here. It is usually more advantageous to go first during the first turn, because you get first race selection. After choosing your race, the new selection is revealed. If your opponent was only allowed a single turn, you could calculate the best move for every race before the revealed race, and determine the best move possible (after the new race is revealed, you can add it's best move into your calculations). If you only played one round, you will get the first attempt to take empty territory, and your opponent might have to attack you to take territory.

The exception to the above would be when a powerful race is revealed. This is less likely to happen when compared to the 6 starting revealed races.

An examination of the last turn is similar. The player who is going first has the opportunity to take any unclaimed regions (if any) before his opponent.

For the most part, this is a game of open information. Going first is an advantage in 2-player, because you could calculate your optimum move and your opponents optimum move that turn. In subsequent turns, you will get the first opportunity to go into decline. The only random events (race selection) favor the first player. In multiplayer though, who each person decides to attack has probably a greater effect on winning. If every player played optimally, I think the first player would still have the advantage most of the time, but that is a much more difficult question to solve.
",user1873,https://boardgames.stackexchange.com/users/1873,http://boardgames.stackexchange.com/questions/7413/is-it-better-to-go-first-or-last-in-vinci,CULTURE,boardgames.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"In Finch, is it better to go first or later?","My son is sure it's best to be last in Vince because you have more complete information about where other players started their civilization and you always get the last round (home advantage in baseball, for example). I see these two advantages, but I want to know whether these advantages outweigh the disadvantages. For example, there is no first choice for civilization, no first country to decline, and maybe there are other factors I haven't even considered (we are all novices). So:","It will be difficult to measure, especially when you add in more than two players. Just examining two players for a moment here. It is usually more advantageous to go first during the first turn, because you get first race selection. After choosing your race, the new selection is revealed. If your opponent was only allowed a single turn, you could calculate the best move for every race before the revealed race, and determine the best move possible (after the new race is revealed, you can add it's best move into your calculations). If you only played one round, you will get the first attempt to take empty territory, and your opponent might have to attack you to take territory.

The exception to the above would be when a powerful race is revealed. This is less likely to happen when compared to the 6 starting revealed races.

An examination of the last turn is similar. The player who is going first has the opportunity to take any unclaimed regions (if any) before his opponent.

For the most part, this is a game of open information. Going first is an advantage in 2-player, because you could calculate your optimum move and your opponents optimum move that turn. In subsequent turns, you will get the first opportunity to go into decline. The only random events (race selection) favor the first player. In multiplayer though, who each person decides to attack has probably a greater effect on winning. If every player played optimally, I think the first player would still have the advantage most of the time, but that is a much more difficult question to solve.
"
737,737,1170,What are the pitfalls of buying a used car after an accident?,"I have the option to buy a car that has been in an accident. There are alternatives, but within my budget the alternatives are usually older/have higher mileage. The seller is a local mechanic who did the restoration work and also showed pictures of the car before restoration. The damage was done to one of the front headlights and to the surrounding bits. The mechanic has convinced me that no damage was done to the internal carrying structure. He fixed the lights and did some paintwork restoration.

Problem: I read that people advice not to buy cars after the accident. This is my first car, so my experience is nonexistent.

Question: What are the cons against buying a car after the accident?

About the car: Opel Astra 2007 1.4 Petrol Manual Hatchback priced Â£2200, 1 prev owner, chain, 66K miles, 1 year MOT, 6 month tax
",JimD,https://mechanics.stackexchange.com/users/3196,"One indicator in this case could be the airbags. In a frontal accident they deploy if the impact was strong enough. So I'd consider the car if the airbags are still the originals. Too big of a chance of structural damage if the airbags deployed and were replaced. Better to steer clearâ¦
",Engin Kurutepe,https://mechanics.stackexchange.com/users/438,http://mechanics.stackexchange.com/questions/6177/what-are-the-pitfalls-of-buying-a-used-car-after-an-accident,SCIENCE,mechanics.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.5333333333333333,0.3333333333333333,0.0,1.0,0.7777777777777778,What are the pitfalls of buying a used car after an accident?,"I can choose to buy a car with an accident. There are other options, but within my budget, they are usually older / higher mileage. The seller is a local mechanic who did the repair work and showed pictures of the car before the repair. What was damaged was a headlight and surrounding debris. The mechanic has convinced me that the internal handling structure is not damaged. He fixed the light and did some paint work.","One indicator in this case could be the airbags. In a frontal accident they deploy if the impact was strong enough. So I'd consider the car if the airbags are still the originals. Too big of a chance of structural damage if the airbags deployed and were replaced. Better to steer clearâ¦
"
5928,5928,9390,How can I make my iPad apps retina in Xcode 5 iOS7,"Not long ago I started learning Objective-C with an interest of developing apps. I have just started my first app and I have no clue how to make my app retina. I made the design in photoshop and exported it as a png @ 2,048 x 1,536 but however the size of my storyboard is only 1,024 x 768. I have read somewhere on the internet that you need two story boards but I am not sure how to link everything together. I would really appreciate it if someone could help me.
",user2989426,https://stackoverflow.com/users/2989426,"No we don't need two storyboards for this. In storyboard, the view size will be 1024 x 768. You have to design the views for same sizes and keep images for these sizes only. Example, if you are making an UIImageView of size 100 x 100, then you will need to set its image of size 100 x 100 only. Now the extra effort required is:
If you named that image as test.png of size 100 x 100, then you have to add same image with name test@2x.png and size 200 x 200 to your project folder.

Now when the application will run on non retina divice, then it will by default take test.png and when the app will run on retina device, then test@2x.png will be used. This is default property you don't need to set this any where in code.

So make your views as usual and just keep images with @2x.png in project folder. Rest things will be managed automatically.
",Ashutosh,https://stackoverflow.com/users/1909299,http://stackoverflow.com/questions/21129482/how-can-i-make-my-ipad-apps-retina-in-xcode-5-ios7,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,How to make my iPad app retina in Xcode 5ios7,"Not long ago, I began to learn Objective-C, interested in developing applications. I've just started my first app, and I don't know how to make my app retina. I did this design in Photoshop and exported it as PNG @ 2048x 1536, but my storyboard is only 1024x768. I read on the Internet that you need a two-story blackboard, but I don't know how to connect everything. I would appreciate it if someone could help me.","No we don't need two storyboards for this. In storyboard, the view size will be 1024 x 768. You have to design the views for same sizes and keep images for these sizes only. Example, if you are making an UIImageView of size 100 x 100, then you will need to set its image of size 100 x 100 only. Now the extra effort required is:
If you named that image as test.png of size 100 x 100, then you have to add same image with name test@2x.png and size 200 x 200 to your project folder.

Now when the application will run on non retina divice, then it will by default take test.png and when the app will run on retina device, then test@2x.png will be used. This is default property you don't need to set this any where in code.

So make your views as usual and just keep images with @2x.png in project folder. Rest things will be managed automatically.
"
4753,4753,7539,EBS volume on AWS,"I had an EBS volume of 30GB that was mounted as the rootfs for a ubuntu server. Due to space concerns I had to increase the size of the volume to 50. So I carried out the following steps:


  
  Take a snapshot of the EBS volume.
  Created a new EBS volume of 50GB.
  Restored the snapshot to the new volume.
  Power off my EC2 instance.
  Unmounted my old volume and mounted my new volume.
  


Every thing works fine. But when I do a df -h I get this:

Filesystem Size Used Avail Use% Mounted on
rootfs 30G 27G 1.1G 97% /
devtmpfs 1.9G 112K 1.9G 1% /dev
tmpfs 1.9G 0 1.9G 0% /dev/shm
/dev/xvde1 30G 27G 1.1G 97% /


And when I do fdisk -l I get this:

Disk /dev/xvde1: 53.7 GB, 53687091200 bytes.


Could some one help me with this?
",Adithya,https://stackoverflow.com/users/3488138,"Run this line to fix this issue! 

resize2fs /dev/xvde1

",Adithya,https://stackoverflow.com/users/3488138,http://stackoverflow.com/questions/22803687/ebs-volume-on-aws,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,EBS volume on AWS,"I had an EBS volume of 30GB that was mounted as the rootfs for a ubuntu server. Due to space concerns I had to increase the size of the volume to 50. So I carried out the following steps:


  
  Take a snapshot of the EBS volume.
  Created a new EBS volume of 50GB.
  Restored the snapshot to the new volume.
  Power off my EC2 instance.
  Unmounted my old volume and mounted my new volume.
  


Every thing works fine. But when I do a df -h I get this:

Filesystem Size Used Avail Use% Mounted on
rootfs 30G 27G 1.1G 97% /
devtmpfs 1.9G 112K 1.9G 1% /dev
tmpfs 1.9G 0 1.9G 0% /dev/shm
/dev/xvde1 30G 27G 1.1G 97% /


And when I do fdisk -l I get this:

Disk /dev/xvde1: 53.7 GB, 53687091200 bytes.


Could some one help me with this?
",Run this line to fix this problem!
4652,4652,7375,SonicWall TZ 200 Network bandwidth or usage monitoring,"I was using Pfsense for a while and recently replaced it with SonicWall TZ200.

What I miss now is a Bandwidth or usage monitoring like BandwidthD to monitor IP wise traffic. 
How can I do this through SonicWall TZ200 or some other software?
I installed BandwidthD on my local machine. It works perfect, but I doubt that it shows only the traffic from and to my system.
",user37143,https://serverfault.com/users/37143,"I looked up the specs for the SonicWall TZ200 and it says that it can create Netflow accounting packets. Consequently, any netflow collector. Personally, I've used nTop before and I know it does IP based bandwidth usage , but there are tons of alternatives out there if that doesn't fit your requirements.
",Seanny123,https://serverfault.com/users/124759,http://serverfault.com/questions/185763,TECHNOLOGY,serverfault.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.3333333333333333,1.0,SonicWALL TZ 200 network bandwidth or usage monitoring,"I was using Pfsense for a while and recently replaced it with SonicWall TZ200.

What I miss now is a Bandwidth or usage monitoring like BandwidthD to monitor IP wise traffic. 
How can I do this through SonicWall TZ200 or some other software?
I installed BandwidthD on my local machine. It works perfect, but I doubt that it shows only the traffic from and to my system.
","I checked the specifications of SonicWALL TZ200, which said that it can create NetFlow accounting packets. Therefore, any NetFlow collector. Personally, I've used ntop before. I know it uses IP based bandwidth, but if it doesn't meet your requirements, there are many other options."
3087,3087,4917,does re-encrypting the same value with multiple keys reduce security,"I found myself wondering today, how much security is lost if you take a plaintext - assume that its content, including any metadata is unknown to an attacker, for example it may be random data - and encrypt it with multiple keys (not chained) and give all resulting ciphertexts to an attacker, how much higher is the probability of an attacker discovering the plaintext, vs only having a single ciphertext. 

An example:

Take plaintext $P_1$ and encrypt it with $K_1$, and send the resulting ciphertext $C_1$ to attacker $A_1$.

In addition: take the same plaintext $P_1$ and, and encrypt it with $K_1$, giving $C_1$. Then take $P_1$ and encrypt it with $K_2$ giving $C_2$, then $K_n$ giving $C_n$ and send all $n$ ciphertexts to attacker $A_2$.

How much more likely is attacker $A_2$ to discover the value of $P_1$, than $A_1$?
",Zack Newsham,https://crypto.stackexchange.com/users/13023,"
  Does re-encrypting the same value with multiple keys reduce security?


The answer is ""it depends""; there are some attack models and encryption methods where the security is reduced, there are other cases where there appears to be no security reduction.

Let us go through some models where we actually see a security reduction:

Plaintext guessing attack and deterministic encryption


In this attack model, the attacker has a guess to the plaintext $P_{guess}$ and wants to confirm whether $P_1 \stackrel{?}{=} P_{guess}$.  What he can do is guess random keys $K_{guess}$ and compute $E_{K_{guess}}(P_{guess})$ and he if that appears in one of the ciphertexts he's been given.  If he happens to guess a key $K_i$, then ciphertext $C_i$ will match, and he will get confirmation that his guess is likely to be correct - that's because we assume that the encryption is deterministic and so if the keys and the plaintext match, the ciphertext will as well.  Obviously, using more keys means that there are more targets the attacker can stumble into.

Deterministic stream ciphers, and plaintext with known linear relations.


Here, we assume we don't know the plaintext, however we do know certain linear relations between the bits of the plaintext; for example, we may know that the parity of each byte is even.  We also assume that the cipher works by generating a keystream (as a function of the key), and then exclusive-or the keystream with the plaintext to form the ciphertext.

So, what the attacker can do is examine each ciphertext; by assuming that the linear relationships hold in the original plaintext, he can evaluate the corresponding linear functions on the keystream; in the example, he can compute the parity of each byte of the keystream.

Then, he can pick random keys, and generate the corresponding keystream (here, we assume that this is determanistic).  Then, he can compute the linear function of that keystream (in the example, the parity of each byte), and see if it matches one of the keystreams that correspond to the known ciphertexts.

Like the first example, having more targets makes it more likely that the attacker will guess the correct key.

(Also, if you think that the example of ""parity of each byte is even"" is contrived, a more realistic example is ""the msbit of each byte is 0"").

Deterministic RSA encryption


If the encrypt the exact same message (without padding, or using determanistic padding) to $n$ different keys, and $n \ge e$ (where $e$ is the common public exponent), then it's easy to recover the message.  This is typically used as an example why you need to add randomness to your RSA encryption, even if you don't care about plaintext guessing attacks.



The above are three examples where encrypting with multiple keys can reduce security; in other cases (such as CBC-mode encryption), there is no obvious way to use multiple ciphertexts.

Now, the obvious thing about all three examples are that they are deterministic encryption; it would appear to be wise to add randomness if you are encrypting with multiple keys.
",poncho,https://crypto.stackexchange.com/users/452,http://crypto.stackexchange.com/questions/15590/does-re-encrypting-the-same-value-with-multiple-keys-reduce-security,TECHNOLOGY,crypto.stackexchange.com,0.8333333333333334,0.6666666666666666,0.0,0.5,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Whether re encrypting the same value with multiple keys will reduce security,"I found myself wondering today, how much security is lost if you take a plaintext - assume that its content, including any metadata is unknown to an attacker, for example it may be random data - and encrypt it with multiple keys (not chained) and give all resulting ciphertexts to an attacker, how much higher is the probability of an attacker discovering the plaintext, vs only having a single ciphertext. 

An example:

Take plaintext $P_1$ and encrypt it with $K_1$, and send the resulting ciphertext $C_1$ to attacker $A_1$.

In addition: take the same plaintext $P_1$ and, and encrypt it with $K_1$, giving $C_1$. Then take $P_1$ and encrypt it with $K_2$ giving $C_2$, then $K_n$ giving $C_n$ and send all $n$ ciphertexts to attacker $A_2$.

How much more likely is attacker $A_2$ to discover the value of $P_1$, than $A_1$?
","
  Does re-encrypting the same value with multiple keys reduce security?


The answer is ""it depends""; there are some attack models and encryption methods where the security is reduced, there are other cases where there appears to be no security reduction.

Let us go through some models where we actually see a security reduction:

Plaintext guessing attack and deterministic encryption


In this attack model, the attacker has a guess to the plaintext $P_{guess}$ and wants to confirm whether $P_1 \stackrel{?}{=} P_{guess}$.  What he can do is guess random keys $K_{guess}$ and compute $E_{K_{guess}}(P_{guess})$ and he if that appears in one of the ciphertexts he's been given.  If he happens to guess a key $K_i$, then ciphertext $C_i$ will match, and he will get confirmation that his guess is likely to be correct - that's because we assume that the encryption is deterministic and so if the keys and the plaintext match, the ciphertext will as well.  Obviously, using more keys means that there are more targets the attacker can stumble into.

Deterministic stream ciphers, and plaintext with known linear relations.


Here, we assume we don't know the plaintext, however we do know certain linear relations between the bits of the plaintext; for example, we may know that the parity of each byte is even.  We also assume that the cipher works by generating a keystream (as a function of the key), and then exclusive-or the keystream with the plaintext to form the ciphertext.

So, what the attacker can do is examine each ciphertext; by assuming that the linear relationships hold in the original plaintext, he can evaluate the corresponding linear functions on the keystream; in the example, he can compute the parity of each byte of the keystream.

Then, he can pick random keys, and generate the corresponding keystream (here, we assume that this is determanistic).  Then, he can compute the linear function of that keystream (in the example, the parity of each byte), and see if it matches one of the keystreams that correspond to the known ciphertexts.

Like the first example, having more targets makes it more likely that the attacker will guess the correct key.

(Also, if you think that the example of ""parity of each byte is even"" is contrived, a more realistic example is ""the msbit of each byte is 0"").

Deterministic RSA encryption


If the encrypt the exact same message (without padding, or using determanistic padding) to $n$ different keys, and $n \ge e$ (where $e$ is the common public exponent), then it's easy to recover the message.  This is typically used as an example why you need to add randomness to your RSA encryption, even if you don't care about plaintext guessing attacks.



The above are three examples where encrypting with multiple keys can reduce security; in other cases (such as CBC-mode encryption), there is no obvious way to use multiple ciphertexts.

Now, the obvious thing about all three examples are that they are deterministic encryption; it would appear to be wise to add randomness if you are encrypting with multiple keys.
"
4543,4543,7197,how to lock object face a certain distance away from another object face?,"i tried searching for this on google but i came up empty. i want to know how to lock object 2 5 inches away from the corner of object 1? i want it to stay 5 inches away even if i re-scale.

can someone please help me? how do i lock cube 2 5 inches away from the edge of objects 1?

here is an image of what i want to do:



EDIT:
i want to offset ""cube 2"" 5 inches away from the bottom right vertex of ""cube 1"" no matter where ""cube 1"" is?

so if i move or scale ""cube 1"", ""cube 2"" would still be offset 5 inches from the bottom right vertex of ""cube 1""
",Ismaeel,https://blender.stackexchange.com/users/7501,"Set object2 origin point to its right bottom corner and you are free to scale in object mode.

Select object2, go to edit mode, select right bottom vertex, Shift+S > Cursor to selected.
Return to object mode Shift+Ctrl+Alt+C > Origin to 3D cursor.  
",JuhaW,https://blender.stackexchange.com/users/7474,http://blender.stackexchange.com/questions/17803/how-to-lock-object-face-a-certain-distance-away-from-another-object-face,TECHNOLOGY,blender.stackexchange.com,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,1.0,0.0,1.0,How to lock a certain distance between an object's face and another object's face?,"i tried searching for this on google but i came up empty. i want to know how to lock object 2 5 inches away from the corner of object 1? i want it to stay 5 inches away even if i re-scale.

can someone please help me? how do i lock cube 2 5 inches away from the edge of objects 1?

here is an image of what i want to do:



EDIT:
i want to offset ""cube 2"" 5 inches away from the bottom right vertex of ""cube 1"" no matter where ""cube 1"" is?

so if i move or scale ""cube 1"", ""cube 2"" would still be offset 5 inches from the bottom right vertex of ""cube 1""
","Set object2 origin point to its right bottom corner and you are free to scale in object mode.

Select object2, go to edit mode, select right bottom vertex, Shift+S > Cursor to selected.
Return to object mode Shift+Ctrl+Alt+C > Origin to 3D cursor.  
"
1306,1306,2056,custom form validation class for a module I am building,"I am building a module for EE2 and I want to extend CI's form validation library. I also want a separate language file too, kept within my module's directory so it's separate from future EE updates.

I created a libraries folder within my module's folder within the third_party folder.

I named the file: My_Form_validation.php

&lt;?php defined('BASEPATH') OR exit('No direct script access allowed');

class MY_Form_validation extends CI_Form_validation {

    /**
     * Constructor
     *
     * @access  public
     */ 
    function __construct($rules = array())
    {   
        parent::__construct($rules);
    }

    public function is_valid($value)
    {
        $this-&gt;form_validation-&gt;set_message('is_valid', 'The %s field can not contain any spaces');
        return FALSE;
    }
}

$this-&gt;EE-&gt;form_validation-&gt;set_rules('short_name', 'Short name', 'required|max_length[30]|is_valid');


I set the rule in the mcp.module_name.php file, I also swapped out $this->EE->form_validation... with $this->CI->form_validation and nothing.

it is not erroring out, it just doesn't seem like it is loading it correctly.

I tried loading the my form validation library in the mcp.module_name.php constructor and it returns this error: Fatal error: Class 'CI_Form_validation' not found

I shouldn't have to load it since it should load along with the default form validation library.

Below is my constructor for the mcp.module_name.php file

public function __construct()
{
    $this-&gt;EE =&amp; get_instance();
    $this-&gt;CI =&amp; get_instance();
    $this-&gt;EE-&gt;config-&gt;load('config');
    $this-&gt;conf = $this-&gt;EE-&gt;config-&gt;item('restaurant_menu_defaults');
    $this-&gt;CI-&gt;load-&gt;helper('file');
    $this-&gt;EE-&gt;load-&gt;helper('html');
    $this-&gt;EE-&gt;load-&gt;model('restaurant_menu_model');
    $this-&gt;base = BASE.AMP.'C=addons_modules'.AMP.'M=show_module_cp'.AMP.'module=restaurant_menu';
    $this-&gt;base_url = BASE.AMP.'C=addons_modules'.AMP.'M=show_module_cp'.AMP.'module=restaurant_menu';
    $this-&gt;EE-&gt;cp-&gt;add_to_head('&lt;link rel=""stylesheet"" href=""/themes/third_party/restaurant_menu/css/restaurant_menu.css"" type=""text/css"" media=""print, projection, screen"" /&gt;');
    $this-&gt;base_short = 'C=addons_modules'.AMP.'M=show_module_cp'.AMP.'module=restaurant_menu';
    $this-&gt;data['base_url_short'] = $this-&gt;base_short;
    $this-&gt;data['base_url'] = $this-&gt;base;
    $this-&gt;site_id = $this-&gt;EE-&gt;config-&gt;item('site_id');
    $this-&gt;EE-&gt;cp-&gt;set_breadcrumb($this-&gt;base, $this-&gt;EE-&gt;lang-&gt;line('Restaurant Menu'));

    // setup navigation
    $this-&gt;EE-&gt;cp-&gt;set_right_nav(array(
        'module_nav_home' =&gt; $this-&gt;base_url.AMP.'method=index',
        //'module_nav_settings' =&gt; $this-&gt;base_url.AMP.'method=settings',
    ));
}


UPDATE:

added this to my construct on mcp.module_name

$this->EE->load->library('form_validation');
$this->EE->load->library('MY_Form_validation');

then in my methods, I run the form validation using: if($this->EE->my_form_validation->run() === FALSE)

Then I set my form field rules:

$this->EE->my_form_validation->set_rules('title', 'title', 'required|max_length[75]');
$this->EE->my_form_validation->set_rules('short_name', 'Short name', 'required|is_valid|max_length[30]');
$this->EE->my_form_validation->set_error_delimiters('', '');

MY_Form_validation.php

&lt;?php defined('BASEPATH') OR exit('No direct script access allowed');

class MY_Form_validation extends EE_Form_validation {

    /**
     * Constructor
     *
     * @access  public
     */ 
    function __construct($rules = array())
    {   
        parent::__construct($rules);
        $this-&gt;EE =&amp; get_instance();
    }

    public function is_valid($value)
    {
        $this-&gt;EE-&gt;form_validation-&gt;set_message('is_valid', 'The %s field can not contain any spaces');
        return false;
    }

}


It won't post the form unless all the rules are met, but it won't display the form error messages, why do you think that is?
",Brad,https://expressionengine.stackexchange.com/users/13,"First, no need to ever load directly from CI - you can always use EE. (So, $this-&gt;EE-&gt;load-&gt;helper('file').)

Same with your validation class - I'd extend Form_validation, not CI_Form_validation.

(Generally, EE should serve as your path to anything CI-related to avoid any conflicts.)

You'll need to load your custom validation library, and call it by its unique name as well. You may also have to load the form validation class before loading your custom library.

$this-&gt;EE-&gt;load-&gt;library('form_validation');
$this-&gt;EE-&gt;load-&gt;library('my_form_validation');
// $this-&gt;EE-&gt;my_form_validation-&gt;run();

",Derek Hogue,https://expressionengine.stackexchange.com/users/55,http://expressionengine.stackexchange.com/questions/13597/custom-form-validation-class-for-a-module-i-am-building,TECHNOLOGY,expressionengine.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.5555555555555556,1.0,0.8888888888888888,0.9,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Custom form validation class for the module being built,"I am building a module for EE2 and I want to extend CI's form validation library. I also want a separate language file too, kept within my module's directory so it's separate from future EE updates.

I created a libraries folder within my module's folder within the third_party folder.

I named the file: My_Form_validation.php

&lt;?php defined('BASEPATH') OR exit('No direct script access allowed');

class MY_Form_validation extends CI_Form_validation {

    /**
     * Constructor
     *
     * @access  public
     */ 
    function __construct($rules = array())
    {   
        parent::__construct($rules);
    }

    public function is_valid($value)
    {
        $this-&gt;form_validation-&gt;set_message('is_valid', 'The %s field can not contain any spaces');
        return FALSE;
    }
}

$this-&gt;EE-&gt;form_validation-&gt;set_rules('short_name', 'Short name', 'required|max_length[30]|is_valid');


I set the rule in the mcp.module_name.php file, I also swapped out $this->EE->form_validation... with $this->CI->form_validation and nothing.

it is not erroring out, it just doesn't seem like it is loading it correctly.

I tried loading the my form validation library in the mcp.module_name.php constructor and it returns this error: Fatal error: Class 'CI_Form_validation' not found

I shouldn't have to load it since it should load along with the default form validation library.

Below is my constructor for the mcp.module_name.php file

public function __construct()
{
    $this-&gt;EE =&amp; get_instance();
    $this-&gt;CI =&amp; get_instance();
    $this-&gt;EE-&gt;config-&gt;load('config');
    $this-&gt;conf = $this-&gt;EE-&gt;config-&gt;item('restaurant_menu_defaults');
    $this-&gt;CI-&gt;load-&gt;helper('file');
    $this-&gt;EE-&gt;load-&gt;helper('html');
    $this-&gt;EE-&gt;load-&gt;model('restaurant_menu_model');
    $this-&gt;base = BASE.AMP.'C=addons_modules'.AMP.'M=show_module_cp'.AMP.'module=restaurant_menu';
    $this-&gt;base_url = BASE.AMP.'C=addons_modules'.AMP.'M=show_module_cp'.AMP.'module=restaurant_menu';
    $this-&gt;EE-&gt;cp-&gt;add_to_head('&lt;link rel=""stylesheet"" href=""/themes/third_party/restaurant_menu/css/restaurant_menu.css"" type=""text/css"" media=""print, projection, screen"" /&gt;');
    $this-&gt;base_short = 'C=addons_modules'.AMP.'M=show_module_cp'.AMP.'module=restaurant_menu';
    $this-&gt;data['base_url_short'] = $this-&gt;base_short;
    $this-&gt;data['base_url'] = $this-&gt;base;
    $this-&gt;site_id = $this-&gt;EE-&gt;config-&gt;item('site_id');
    $this-&gt;EE-&gt;cp-&gt;set_breadcrumb($this-&gt;base, $this-&gt;EE-&gt;lang-&gt;line('Restaurant Menu'));

    // setup navigation
    $this-&gt;EE-&gt;cp-&gt;set_right_nav(array(
        'module_nav_home' =&gt; $this-&gt;base_url.AMP.'method=index',
        //'module_nav_settings' =&gt; $this-&gt;base_url.AMP.'method=settings',
    ));
}


UPDATE:

added this to my construct on mcp.module_name

$this->EE->load->library('form_validation');
$this->EE->load->library('MY_Form_validation');

then in my methods, I run the form validation using: if($this->EE->my_form_validation->run() === FALSE)

Then I set my form field rules:

$this->EE->my_form_validation->set_rules('title', 'title', 'required|max_length[75]');
$this->EE->my_form_validation->set_rules('short_name', 'Short name', 'required|is_valid|max_length[30]');
$this->EE->my_form_validation->set_error_delimiters('', '');

MY_Form_validation.php

&lt;?php defined('BASEPATH') OR exit('No direct script access allowed');

class MY_Form_validation extends EE_Form_validation {

    /**
     * Constructor
     *
     * @access  public
     */ 
    function __construct($rules = array())
    {   
        parent::__construct($rules);
        $this-&gt;EE =&amp; get_instance();
    }

    public function is_valid($value)
    {
        $this-&gt;EE-&gt;form_validation-&gt;set_message('is_valid', 'The %s field can not contain any spaces');
        return false;
    }

}


It won't post the form unless all the rules are met, but it won't display the form error messages, why do you think that is?
","First, no need to ever load directly from CI - you can always use EE. (So, $this-&gt;EE-&gt;load-&gt;helper('file').)

Same with your validation class - I'd extend Form_validation, not CI_Form_validation.

(Generally, EE should serve as your path to anything CI-related to avoid any conflicts.)

You'll need to load your custom validation library, and call it by its unique name as well. You may also have to load the form validation class before loading your custom library.

$this-&gt;EE-&gt;load-&gt;library('form_validation');
$this-&gt;EE-&gt;load-&gt;library('my_form_validation');
// $this-&gt;EE-&gt;my_form_validation-&gt;run();

"
356,356,565,Adding seconds to mysql DateTime via php,"Im trying to add 12 seconds to a mysql datetime object via php.

My php code generates the following query: ""UPDATE Stats SET Usage = 1970-01-01 00:00:12"" however the query fails.

My php code is as follows:

public function UpdateTime($diffrence)
{
    $seconds = $diffrence / 1000;

    mysql_connect('localhost','user','pass') or die(""Unable to select host"");

    mysql_select_db('StatDB') or die(""Unable to select database"");

    $query  = ""SELECT * FROM Stats"";

    $result=mysql_query($query);

    $retVal = mysql_result($result,0,""Usage"");

    $oldTime = new DateTime($retVal);

    $oldTime-&gt;modify('+'. $seconds .' seconds');

    $from = date(""Y-m-d H:i:s"", strtotime($oldTime-&gt;format('Y-m-d H:i:s')));

    $query2  = ""UPDATE Stats SET Usage = $from"";
    echo $query2;

    $result2=mysql_query($query2);

    mysql_close();
}


Does anyone how I can fix this?

Thanks
",Ryuk,https://stackoverflow.com/users/1211548,"You can do all of that using one single query:

UPDATE Stats SET Usage = Usage + INTERVAL $seconds SECOND

",Bojan DeviÄ,https://stackoverflow.com/users/393865,http://stackoverflow.com/questions/15317063/adding-seconds-to-mysql-datetime-via-php,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,Add seconds to MySQL datetime through PHP,"Im trying to add 12 seconds to a mysql datetime object via php.

My php code generates the following query: ""UPDATE Stats SET Usage = 1970-01-01 00:00:12"" however the query fails.

My php code is as follows:

public function UpdateTime($diffrence)
{
    $seconds = $diffrence / 1000;

    mysql_connect('localhost','user','pass') or die(""Unable to select host"");

    mysql_select_db('StatDB') or die(""Unable to select database"");

    $query  = ""SELECT * FROM Stats"";

    $result=mysql_query($query);

    $retVal = mysql_result($result,0,""Usage"");

    $oldTime = new DateTime($retVal);

    $oldTime-&gt;modify('+'. $seconds .' seconds');

    $from = date(""Y-m-d H:i:s"", strtotime($oldTime-&gt;format('Y-m-d H:i:s')));

    $query2  = ""UPDATE Stats SET Usage = $from"";
    echo $query2;

    $result2=mysql_query($query2);

    mysql_close();
}


Does anyone how I can fix this?

Thanks
","You can do all of that using one single query:

UPDATE Stats SET Usage = Usage + INTERVAL $seconds SECOND

"
3452,3452,5493,Are programming books in other languages useful for Python?,"I'm a self-taught intermediate Python programmer; I frequently come across popular books on software development and programming written in other languages (often Java). 

Typical examples:


Refactoring: Improving the Design of Existing Code
Design Patterns, Gang of Four
Test Driven Development: By Example
The Art of Unit Testing: With Examples in .NET


Generally speaking, how useful is it to read a book written for another language? Specifically, what about Python? Should one stick to language specific books? 

For example, a lot of people praise Design Patterns by the GOF, I've never read it because the model applies to other languages (after all Python is about anti-patterns, right?) yet I feel the urge to because of it's place in the CS literature cannon. 

Likewise, would The Art of Unit Testing: With Examples in .NET help a Python programmer learn unit testing even though the examples are in .Net? 
",Jason Wirth,https://programmers.stackexchange.com/users/21104,"First of all, some of the books you mentioned are written with examples in multiple programming languages. For example, GOF's DP is written with C++ and, if fewer, Smalltalk examples, and TDD is written with Java and Python examples.

If you are well trained in picking up what's useful, dropping what's not, and translating what you've picked up, you'll benefit from reading most of generally recommended books for programmers. However, if you have little experience in doing this, you could start from ""near-transfer"" books. Otherwise, you will learn very little, or even you will learn bad ideas and habits -- some of the practices are language-paradigm dependent. I have seen a good deal of Python programmers with all the hassles for implementing GOF's DP in C++.

Transfer is psychological and educational term for applying what you have learned in a different context. They differentiate between near and far transfer. Usually near-transfer is easier and more effective, which means you need to put more effort for far-transfer.

For near-transfer learning, I highly recommend learning from similar languages, in terms of its paradigm, to your target language -- siblings in the language typology. For Python, that would be something like Smalltalk -- or nowadays Ruby but Smalltalk's legacy is greater.

For instance, you will learn a lot more from reading DPSC than from solely reading GOF's DP. (BTW, reading both DPSC and GOF's DP at the same time with careful contrasting and comparing is a very rewarding learning experience)

From my near-transfer experiences, I remember leaps of improvement in my Python programming from reading books(articles, papers, and etc) for Smalltalk, APL, Io, and ICON, all of which are dynamic in nature.
",June Kim,https://programmers.stackexchange.com/users/88860,http://programmers.stackexchange.com/questions/195625/are-programming-books-in-other-languages-useful-for-python,TECHNOLOGY,programmers.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.5,0.3333333333333333,0.5,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,0.7777777777777778,Are programming books in other languages useful for Python?,"I'm a self-taught intermediate Python programmer; I frequently come across popular books on software development and programming written in other languages (often Java). 

Typical examples:


Refactoring: Improving the Design of Existing Code
Design Patterns, Gang of Four
Test Driven Development: By Example
The Art of Unit Testing: With Examples in .NET


Generally speaking, how useful is it to read a book written for another language? Specifically, what about Python? Should one stick to language specific books? 

For example, a lot of people praise Design Patterns by the GOF, I've never read it because the model applies to other languages (after all Python is about anti-patterns, right?) yet I feel the urge to because of it's place in the CS literature cannon. 

Likewise, would The Art of Unit Testing: With Examples in .NET help a Python programmer learn unit testing even though the examples are in .Net? 
","First of all, some of the books you mentioned are written with examples in multiple programming languages. For example, GOF's DP is written with C++ and, if fewer, Smalltalk examples, and TDD is written with Java and Python examples.

If you are well trained in picking up what's useful, dropping what's not, and translating what you've picked up, you'll benefit from reading most of generally recommended books for programmers. However, if you have little experience in doing this, you could start from ""near-transfer"" books. Otherwise, you will learn very little, or even you will learn bad ideas and habits -- some of the practices are language-paradigm dependent. I have seen a good deal of Python programmers with all the hassles for implementing GOF's DP in C++.

Transfer is psychological and educational term for applying what you have learned in a different context. They differentiate between near and far transfer. Usually near-transfer is easier and more effective, which means you need to put more effort for far-transfer.

For near-transfer learning, I highly recommend learning from similar languages, in terms of its paradigm, to your target language -- siblings in the language typology. For Python, that would be something like Smalltalk -- or nowadays Ruby but Smalltalk's legacy is greater.

For instance, you will learn a lot more from reading DPSC than from solely reading GOF's DP. (BTW, reading both DPSC and GOF's DP at the same time with careful contrasting and comparing is a very rewarding learning experience)

From my near-transfer experiences, I remember leaps of improvement in my Python programming from reading books(articles, papers, and etc) for Smalltalk, APL, Io, and ICON, all of which are dynamic in nature.
"
998,998,1576,Is pretending to want to trade before playing a monopoly card objectionable?,"In Settlers of Catan, I sometimes try to ask people if they want to trade a certain resource, tricking them into revealing the approximate amount of that resource in everyone's hand. After this I play the monopoly card. This has on some occasions not been received very well.

Is this fair play?
",Matthijs Wessels,https://boardgames.stackexchange.com/users/117,"There's no rule about it, so I'd say it's fair play.

However, it's a social game so if you keep 'crying wolf' then you might find your game-mates less likely to trade with you!
",Joe Zack,https://boardgames.stackexchange.com/users/102,http://boardgames.stackexchange.com/questions/577/is-pretending-to-want-to-trade-before-playing-a-monopoly-card-objectionable,CULTURE,boardgames.stackexchange.com,1.0,0.7777777777777778,1.0,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,Is it offensive to pretend to trade before playing Monopoly?,"Among the settlers in katan, I sometimes try to ask people if they want to exchange certain resources and cheat them to reveal the approximate amount of resources in each person's hands. After that, I played Monopoly. This is not well accepted in some cases.","There's no rule about it, so I'd say it's fair play.

However, it's a social game so if you keep 'crying wolf' then you might find your game-mates less likely to trade with you!
"
3420,3420,5444,"What conditions may cause ""The content on this page has either been modified by another user...""?","I'm working on a website which has multiple admins, some creating contents, some editing and some tagging...

I know editing one node at the same time will cause this error, is there anything else cause this error?

The content on this page has either been modified by another user, or you have already submitted modifications using this form. As a result, your changes cannot be saved.

",Mohammad Ali Akbari,https://drupal.stackexchange.com/users/1076,"I just managed to create this error with a FireFox setting.  I told FF never to save history and cleared my browser cache and then could not submit changes to nodes.  When I turned 'save history' back on, the issue resolved.  Probably related to a change in how FF was handling cookies.  

Site is Drupal 7 with OpenPublish, IDK much more than that as I'm new to the project.
",andy boyd,https://drupal.stackexchange.com/users/19865,http://drupal.stackexchange.com/questions/29954/what-conditions-may-cause-the-content-on-this-page-has-either-been-modified-by,TECHNOLOGY,drupal.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,1.0,"What could cause ""content on this page has been modified by another user...""?","I'm working on a website which has multiple admins, some creating contents, some editing and some tagging...

I know editing one node at the same time will cause this error, is there anything else cause this error?

The content on this page has either been modified by another user, or you have already submitted modifications using this form. As a result, your changes cannot be saved.

","I just managed to create this error with a FireFox setting.  I told FF never to save history and cleared my browser cache and then could not submit changes to nodes.  When I turned 'save history' back on, the issue resolved.  Probably related to a change in how FF was handling cookies.  

Site is Drupal 7 with OpenPublish, IDK much more than that as I'm new to the project.
"
3305,3305,5272,E_COMPILE_ERROR when enabling Magento compilation,"I'm trying to enable compilation on Magento via the control panel and while compilation is enabled the main page fails to display properly and I find that index.php has repeatedly raised the following error in logs:

E_Â­COMPILE_Â­ERROR: require_Â­onceÂ­(Â­)Â­: Failed opening required 'Â­ConfigÂ­FileÂ­ManagerÂ­Model.Â­php' Â­(include_Â­path='/Â­var/Â­www/Â­vhosts/Â­&lt;domain_name_redacted&gt;/Â­httpdocs/Â­includes/Â­srcÂ­:.Â­:'Â­)Â­

The site returns to normal immediately after disabling compilation but I'd really like to have the performance benefits. Does anyone know how to fix this?
",David Perry,https://magento.stackexchange.com/users/2075,"It sounds like one of your extensions, or some custom code in your system, is incompatible with Magento's compilation mode.  The exact solution will vary depending on your PHP system.  Here's an explanation of the problem and some troubleshooting tips that should help you.

A file in your system contains a line that looks something like this

//the string 'ConfigFileManager-Model.php' may be 
//a constant or variable as well

require_once 'ConfigFileManager-Model.php';


The file ConfigFileManager-Model.php is not part of Magento, or any publicly distributed package as far as I can tell.    

It sounds like when you're running in ""non-compiled mode"", Magento can find this file without issue.  That means it's somewhere in the normal Magento include paths

/path/to/magento/app/code/core/ConfigFileManager-Model.php    
/path/to/magento/app/code/community/ConfigFileManager-Model.php
/path/to/magento/app/code/local/ConfigFileManager-Model.php
/path/to/magento/path/to/calling/files/own/folder/ConfigFileManager-Model.php

#possibly more, depending on your system's default include path


However, when Magento runs in compiled mode, the core, local, and community code pool paths are not added as include paths.  Only the folder

/path/to/magento/includes/src


is added as an include path.  Additionally, what compilation mode does is make copies of all the class files and drops them into the includes/src folder.  That means the file's own original folder is no longer in the include path.  Because of this, when Magento runs the require code in compilation mode, it can't find the ConfigFileManager-Model.php file, and fails.

The best thing to do would be recode the module and/or custom code such that the functionality of ConfigFileManager-Model.php is incorporated into a standard Magento helper of model class.

The less good, but quicker thing would be to identify all the places ConfigFileManager-Model.php is required and change the path so it's absolute instead of relative. 
",Alan Storm,https://magento.stackexchange.com/users/4,http://magento.stackexchange.com/questions/3493/e-compile-error-when-enabling-magento-compilation,TECHNOLOGY,magento.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,1.0,Error enabling Magento compilation,"I'm trying to enable compilation on Magento via the control panel and while compilation is enabled the main page fails to display properly and I find that index.php has repeatedly raised the following error in logs:

E_Â­COMPILE_Â­ERROR: require_Â­onceÂ­(Â­)Â­: Failed opening required 'Â­ConfigÂ­FileÂ­ManagerÂ­Model.Â­php' Â­(include_Â­path='/Â­var/Â­www/Â­vhosts/Â­&lt;domain_name_redacted&gt;/Â­httpdocs/Â­includes/Â­srcÂ­:.Â­:'Â­)Â­

The site returns to normal immediately after disabling compilation but I'd really like to have the performance benefits. Does anyone know how to fix this?
","It sounds like one of your extensions, or some custom code in your system, is incompatible with Magento's compilation mode.  The exact solution will vary depending on your PHP system.  Here's an explanation of the problem and some troubleshooting tips that should help you.

A file in your system contains a line that looks something like this

//the string 'ConfigFileManager-Model.php' may be 
//a constant or variable as well

require_once 'ConfigFileManager-Model.php';


The file ConfigFileManager-Model.php is not part of Magento, or any publicly distributed package as far as I can tell.    

It sounds like when you're running in ""non-compiled mode"", Magento can find this file without issue.  That means it's somewhere in the normal Magento include paths

/path/to/magento/app/code/core/ConfigFileManager-Model.php    
/path/to/magento/app/code/community/ConfigFileManager-Model.php
/path/to/magento/app/code/local/ConfigFileManager-Model.php
/path/to/magento/path/to/calling/files/own/folder/ConfigFileManager-Model.php

#possibly more, depending on your system's default include path


However, when Magento runs in compiled mode, the core, local, and community code pool paths are not added as include paths.  Only the folder

/path/to/magento/includes/src


is added as an include path.  Additionally, what compilation mode does is make copies of all the class files and drops them into the includes/src folder.  That means the file's own original folder is no longer in the include path.  Because of this, when Magento runs the require code in compilation mode, it can't find the ConfigFileManager-Model.php file, and fails.

The best thing to do would be recode the module and/or custom code such that the functionality of ConfigFileManager-Model.php is incorporated into a standard Magento helper of model class.

The less good, but quicker thing would be to identify all the places ConfigFileManager-Model.php is required and change the path so it's absolute instead of relative. 
"
4091,4091,6527,How are potions made?,"Where does majority of the energy for the magical effect of a potion comes from? 

Does it all comes from the brewer? Or does most of it comes from the ingredients? 

I know JKR said that you have to use magic at some part of the process of brewing (hence no muggle potion brewers) [what about a squib?]

If brewer provides all of the energy then why aren't NEWT students magically exhausted after every potion class? Hermione successfully brewed batch of Polyjuice Potion (a very potent NEWT level potion) in first semester of her second year, and while brewing it was very time-consuming and required a lot of concentration she never showed any signs of exhaustion as far as I remember.
",Fen1ks,https://scifi.stackexchange.com/users/23010,"
  Where does majority of the energy for the magical effect of a potion
  comes from?
  
  Does it all comes from the brewer? Or does most of it comes from the ingredients?


I don't know where does the majority of the effect come from, but at least we do know that spells are usually required. I suppose that it really depends on the potion you're working on - I don't think a spell is required for all potions.


  I know JKR said that you have to use magic at some part of the process of brewing (hence no muggle potion brewers) [what about a
  squib?]


I think it is clear, then, that it simply sucks for squibs. Which makes sense. This may contribute to explain why is Filch so inefficient identifying potions.


  If brewer provides all of the energy then why aren't NEWT students magically exhausted after every potion class?


I don't think they explicitly mention whether students were tired or not after their potion classes. They probably were, but that would most likely be because of, uh, studying hard? XD


  Hermione successfully brewed batch of Polyjuice Potion (a very potent NEWT level potion) in first semester of her second year, and
  while brewing it was very time-consuming and required a lot of
  concentration she never showed any signs of exhaustion as far as I
  remember.


Brewing that potion takes several weeks/months/whatever. She had plenty of time to rest. I think that this proves that the longer a potion takes to be made, the least exhausting it is, because most of the time it consumes is, well, waiting rather than casting spells on it too frequently. For this kind of potions, the highest requirement would probably be patience and intelligence - Hermione should do fine.
",Voldemort,https://scifi.stackexchange.com/users/1660,http://scifi.stackexchange.com/questions/32947/how-are-potions-made,LIFE_ARTS,scifi.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8333333333333334,1.0,0.0,0.6666666666666666,0.3333333333333333,0.5555555555555556,How is the liquid medicine made?,"Where does majority of the energy for the magical effect of a potion comes from? 

Does it all comes from the brewer? Or does most of it comes from the ingredients? 

I know JKR said that you have to use magic at some part of the process of brewing (hence no muggle potion brewers) [what about a squib?]

If brewer provides all of the energy then why aren't NEWT students magically exhausted after every potion class? Hermione successfully brewed batch of Polyjuice Potion (a very potent NEWT level potion) in first semester of her second year, and while brewing it was very time-consuming and required a lot of concentration she never showed any signs of exhaustion as far as I remember.
","
  Where does majority of the energy for the magical effect of a potion
  comes from?
  
  Does it all comes from the brewer? Or does most of it comes from the ingredients?


I don't know where does the majority of the effect come from, but at least we do know that spells are usually required. I suppose that it really depends on the potion you're working on - I don't think a spell is required for all potions.


  I know JKR said that you have to use magic at some part of the process of brewing (hence no muggle potion brewers) [what about a
  squib?]


I think it is clear, then, that it simply sucks for squibs. Which makes sense. This may contribute to explain why is Filch so inefficient identifying potions.


  If brewer provides all of the energy then why aren't NEWT students magically exhausted after every potion class?


I don't think they explicitly mention whether students were tired or not after their potion classes. They probably were, but that would most likely be because of, uh, studying hard? XD


  Hermione successfully brewed batch of Polyjuice Potion (a very potent NEWT level potion) in first semester of her second year, and
  while brewing it was very time-consuming and required a lot of
  concentration she never showed any signs of exhaustion as far as I
  remember.


Brewing that potion takes several weeks/months/whatever. She had plenty of time to rest. I think that this proves that the longer a potion takes to be made, the least exhausting it is, because most of the time it consumes is, well, waiting rather than casting spells on it too frequently. For this kind of potions, the highest requirement would probably be patience and intelligence - Hermione should do fine.
"
5884,5884,9320,"What is the Goal of ""Hot Network Questions""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
",jmac,https://meta.stackexchange.com/users/209637,"Pity the poor community members of Workplace. They already have to deal with an endless supply of questions from the clueless who think that the rest of the world owes them a job and pats on the head. These are not necessarily bad questions, but they attract awful answers. Well, maybe they are not bad questions. They are made up of grammatical sentences. They seem to narrate reality as the OP sees it. Sometimes they even offer an opportunity for a really good answer, giving the OP a dose of much-needed reality. However, for every sensible answer offered by a person who has a clue, it seems like there are two or three from the orbit of Jupiter. Does this make them bad questions? Or does it just mean that a community that has taken on the job of TWP has a whole lot of work to do.

These questions are the reality TV of Stack Exchange. Broadcasting them creates work for the community, because it attracts an extra crop of drive-by dweeb answers. So I don't think that Shog9's notion that these questions are the entire fault of the community for failing to police questions is, in fact, entirely fair.
",Rosinante,https://meta.stackexchange.com/users/138822,http://meta.stackexchange.com/questions/219922/what-is-the-goal-of-hot-network-questions,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.5,0.4,0.0,0.0,0.0,0.7777777777777778,"What is the goal of ""network hot issues""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
","Pity the poor community workers. They have had to deal with countless problems from the ignorant who think the rest of the world owes them a job and pat them on the head. These questions are not necessarily bad questions, but they attract bad answers. Well, maybe they're not a bad problem. They are made up of grammatical sentences. They seem to be narrating the reality that OP sees. Sometimes, they even offer an opportunity, a really good answer, to the much-needed reality of operating doses. However, for every reasonable answer given by someone with a clue, it seems that there are two or three from Jupiter's orbit. Will it make them ask bad questions? Or it just means that there's a lot of work to do in a community that's doing twp work."
2806,2806,4471,Which is better extrusion or assembly for creating blueprints?,"When creating a a model of something that will be assembled, in particular furniture blueprints, which is a better approach?

To do many extrusions of the object or the create the pieces separately and join them in parent child relationships?
",chotchki,https://blender.stackexchange.com/users/1010,"I would create the pieces separately and then join them later. Here are some reasons why:


It allows you to preserve separation of concerns. This in itself has many benefits; for example, you could have different team members working on different parts.
It allows you to easily animate assembly instructions by simply moving the objects.
Logically, it makes more sense: the pieces are physically separate; in the real world, they are separate objects, so they should be in Blender as well.
You can join the pieces together at any time by selecting them and pressing CtrlJ or 3D View &rarr; Tool Shelf (T) &rarr; Join, and you can separate them again with Separate (P) &rarr; By Loose Parts while in edit mode.

",wchargin,https://blender.stackexchange.com/users/372,http://blender.stackexchange.com/questions/2288/which-is-better-extrusion-or-assembly-for-creating-blueprints,TECHNOLOGY,blender.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Which is a better extrusion or assembly for creating blueprints?,"When creating a a model of something that will be assembled, in particular furniture blueprints, which is a better approach?

To do many extrusions of the object or the create the pieces separately and join them in parent child relationships?
","I would create the pieces separately and then join them later. Here are some reasons why:


It allows you to preserve separation of concerns. This in itself has many benefits; for example, you could have different team members working on different parts.
It allows you to easily animate assembly instructions by simply moving the objects.
Logically, it makes more sense: the pieces are physically separate; in the real world, they are separate objects, so they should be in Blender as well.
You can join the pieces together at any time by selecting them and pressing CtrlJ or 3D View &rarr; Tool Shelf (T) &rarr; Join, and you can separate them again with Separate (P) &rarr; By Loose Parts while in edit mode.

"
5086,5086,8092,Would magic 'weapons' make the monk more balanced?,"The monk in D&amp;D 3.5 (and, to a lesser extent, in Pathfinder) is generally considered underpowered. 

Would adding magic 'weapons' that could add enhancement bonuses and magic weapon effects to a monk's unarmed strikes be sufficient to re-balance them? Would they then be over-balanced?

To be specific I'm thinking of something like hand wraps that are a zero-cost weapon having no mundane effect on combat (the wielder counts as unarmed) but  that can be enchanted in the same way and at the same cost as a normal magic weapon.

Update: 

Thanks to @mxyzplk, I see that Gauntlets would effectively fulfill this effect. Odd that I haven't seen this in any of the discussions on monk optimisation!

Regarding assessing balance, I'll judge this based on how well it addresses the issues in @KRyan's answer in the above-linked question. Obviously if anyone doesn't agree with his analysis then this question is moot, although I would like to see those competing opinions.
",Paul Hutton,https://rpg.stackexchange.com/users/2689,"Necessary but insufficient

It would help. It would more than help; I have a hard time imagining them being functional without it. The necklace of natural attacks or scorpion kama are generally necessary for Monks. That said, the necklace of natural attacks does exist (as do similar items in Pathfinder), and it&rsquo;s not nearly enough to make the Monks good.

The Monk&rsquo;s problems are problems of design: the people who wrote it evidently had no clear idea of what a Monk was or should do. Thus it receives a mish-mash of random abilities that do not synergize (and frequently contradict one another, see Flurry of Blows and Fast Movement).

To &ldquo;fix&rdquo; the Monk, one must first come up with a clear vision of what the Monk is supposed to be and do, and then most likely rebuild it from the ground up focused on that vision.

Or simply use one of the many classes that can effectively model one or more possible visions of what a &ldquo;monk&rdquo; should do, without any levels in the &ldquo;Monk&rdquo; class. The Cleric and Psychic Warrior are both Open Game Content and quite capable of fulfilling most roles you could imagine for the Monk, for instance. I&rsquo;d argue that it&rsquo;s entirely reasonable to treat a Barbarian&rsquo;s Rage as &ldquo;Zen Focus&rdquo; and waive the non-lawful requirement (which I&rsquo;d further argue is dumb to begin with). Such a &ldquo;Barbarian&rdquo; multiclassed with Fighter for combat maneuver mastery and perhaps taking Improved Unarmed Strike would make a decent monk. And if you have Tome of Battle, the Swordsage also does an excellent job.
",KRyan,https://rpg.stackexchange.com/users/4563,http://rpg.stackexchange.com/questions/22452/would-magic-weapons-make-the-monk-more-balanced,CULTURE,rpg.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Will magic weapons make monks more balanced?,"The monk in D&amp;D 3.5 (and, to a lesser extent, in Pathfinder) is generally considered underpowered. 

Would adding magic 'weapons' that could add enhancement bonuses and magic weapon effects to a monk's unarmed strikes be sufficient to re-balance them? Would they then be over-balanced?

To be specific I'm thinking of something like hand wraps that are a zero-cost weapon having no mundane effect on combat (the wielder counts as unarmed) but  that can be enchanted in the same way and at the same cost as a normal magic weapon.

Update: 

Thanks to @mxyzplk, I see that Gauntlets would effectively fulfill this effect. Odd that I haven't seen this in any of the discussions on monk optimisation!

Regarding assessing balance, I'll judge this based on how well it addresses the issues in @KRyan's answer in the above-linked question. Obviously if anyone doesn't agree with his analysis then this question is moot, although I would like to see those competing opinions.
","Necessary but insufficient

It would help. It would more than help; I have a hard time imagining them being functional without it. The necklace of natural attacks or scorpion kama are generally necessary for Monks. That said, the necklace of natural attacks does exist (as do similar items in Pathfinder), and it&rsquo;s not nearly enough to make the Monks good.

The Monk&rsquo;s problems are problems of design: the people who wrote it evidently had no clear idea of what a Monk was or should do. Thus it receives a mish-mash of random abilities that do not synergize (and frequently contradict one another, see Flurry of Blows and Fast Movement).

To &ldquo;fix&rdquo; the Monk, one must first come up with a clear vision of what the Monk is supposed to be and do, and then most likely rebuild it from the ground up focused on that vision.

Or simply use one of the many classes that can effectively model one or more possible visions of what a &ldquo;monk&rdquo; should do, without any levels in the &ldquo;Monk&rdquo; class. The Cleric and Psychic Warrior are both Open Game Content and quite capable of fulfilling most roles you could imagine for the Monk, for instance. I&rsquo;d argue that it&rsquo;s entirely reasonable to treat a Barbarian&rsquo;s Rage as &ldquo;Zen Focus&rdquo; and waive the non-lawful requirement (which I&rsquo;d further argue is dumb to begin with). Such a &ldquo;Barbarian&rdquo; multiclassed with Fighter for combat maneuver mastery and perhaps taking Improved Unarmed Strike would make a decent monk. And if you have Tome of Battle, the Swordsage also does an excellent job.
"
452,452,705,"3.5"" FDD to SATA / USB","Motherboards these days don't tend to have floppy cable/bus pins. It's a bit ""old hat"" I suppose.

I have such a motherboard, but would like to connect an internal floppy drive to it. It's the sort of drive that's usualy sold as a 7 in 1 floppy and media card drive.

It has a USB connector, but also the old fashioned floppy bus connector and a power connector.

I would like to know if such an adapter exists that I can convert the floppy bus connector, either to a SATA port, or to an internal USB pinout?
",series0ne,https://superuser.com/users/166563,"You'll need a floppy drive controller (you can't simple convert a floppy cable to USB), but they basically just don't exist anymore.

You'll probably just have to get a USB floppy drive and a USB card reader, and live with two separate devices.
",Æ¬á´cÊÎ¹á´007,https://superuser.com/users/23133,http://superuser.com/questions/890180,TECHNOLOGY,superuser.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,0.3333333333333333,0.7777777777777778,3.5-inch FDD to SATA / USB,"Motherboards these days don't tend to have floppy cable/bus pins. It's a bit ""old hat"" I suppose.

I have such a motherboard, but would like to connect an internal floppy drive to it. It's the sort of drive that's usualy sold as a 7 in 1 floppy and media card drive.

It has a USB connector, but also the old fashioned floppy bus connector and a power connector.

I would like to know if such an adapter exists that I can convert the floppy bus connector, either to a SATA port, or to an internal USB pinout?
","You'll need a floppy drive controller (you can't simple convert a floppy cable to USB), but they basically just don't exist anymore.

You'll probably just have to get a USB floppy drive and a USB card reader, and live with two separate devices.
"
2986,2986,4761,"Are DSLRs a dying breed, making now the time to switch to a mirrorless camera system?","I came across this thought provoking article on Stuck in Customs today that makes a strong case to hold off too much investment in DSLR gear, and instead switch to mirror-less cameras like the Sony NEX. The author prefers to call such cameras 3rd generation cameras to prevent any bias.

The crux of the argument lies in the smaller size and faster shooting speeds of the new cameras, while the sensor size is an area where they seem to be lacking (Sony &amp; Samsung cameras are APS-C sized though). Currently the big makers - Nikon &amp; Canon - have practically no presence in this market (Nikon seems to be doing something with the V1). However, they seem to have slowed down the introduction of new entry level DSLR models over the last year as well.

So, as DSLR users looking to build and enhance their kit (there are many like me who've jumped the bandwagon over the last couple of years, and are just starting to build their kit), what are the advantages of sticking with the DSLR system rather than switching to the 3rd gen cameras?

IMO, one point that could cause a massive switch in the DSLR base would be if Nikon &amp; Canon announced mirror-less models compatible with their current lens lineups, but that is a hypothetical scenario.

P.S. There is a similar question on mirror-less cameras, but that seems to be from the perspective of a person starting out rather than a person already invested in the DSLR system.
",ab.aditya,https://photo.stackexchange.com/users/1977,"they said rangefinders were going to go the way of the dodo when SLRs were introduced.
They said SLRs were going away when point and shoot cameras were introduced.
They said black and white was dead when colour film was invented.
All are still with us today.
",jwenting,https://photo.stackexchange.com/users/4000,http://photo.stackexchange.com/questions/18940/are-dslrs-a-dying-breed-making-now-the-time-to-switch-to-a-mirrorless-camera-sy,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,1.0,0.3333333333333333,0.6666666666666666,1.0,1.0,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,0.6666666666666666,0.5555555555555556,0.8888888888888888,0.7777777777777778,0.6666666666666667,0.0,0.0,0.6666666666666666,0.8888888888888888,SLR is a dying breed that makes the current time switch to a mirror less camera system?,"I came across this thought provoking article on Stuck in Customs today that makes a strong case to hold off too much investment in DSLR gear, and instead switch to mirror-less cameras like the Sony NEX. The author prefers to call such cameras 3rd generation cameras to prevent any bias.

The crux of the argument lies in the smaller size and faster shooting speeds of the new cameras, while the sensor size is an area where they seem to be lacking (Sony &amp; Samsung cameras are APS-C sized though). Currently the big makers - Nikon &amp; Canon - have practically no presence in this market (Nikon seems to be doing something with the V1). However, they seem to have slowed down the introduction of new entry level DSLR models over the last year as well.

So, as DSLR users looking to build and enhance their kit (there are many like me who've jumped the bandwagon over the last couple of years, and are just starting to build their kit), what are the advantages of sticking with the DSLR system rather than switching to the 3rd gen cameras?

IMO, one point that could cause a massive switch in the DSLR base would be if Nikon &amp; Canon announced mirror-less models compatible with their current lens lineups, but that is a hypothetical scenario.

P.S. There is a similar question on mirror-less cameras, but that seems to be from the perspective of a person starting out rather than a person already invested in the DSLR system.
","they said rangefinders were going to go the way of the dodo when SLRs were introduced.
They said SLRs were going away when point and shoot cameras were introduced.
They said black and white was dead when colour film was invented.
All are still with us today.
"
4794,4794,7613,1990s VHS Movie Identification,"Trying to find out which movie from approximately the 1990s contained this plot:  A woman sees a beast murder a man in an alley or street near her home.  She is terrorized and promises the beast if he lets her live she will never tell anyone about seeing the beast.  Then the movie switches from ""scary"" to ""romantic"" as she meets the man of her dreams and hooks up with him.  It appears to be a ""they lived happily ever after"" but she has disturbing dreams of the murder and is an artist.  She draws or sketches the beast from the alley.  Eventually she tells her hubby what she promised not to tell and he turns into the beast to destroy her.  Can't remember fully but the beast might have possibly fallen from the sky (crashing like a meteor or alien landing in the opening scene).  
",WonderingJew,https://scifi.stackexchange.com/users/41555,"This could be the final segment of the Tales From the Darkside movie;


  Lover's Vow : A despondent artist named Preston (played by James
  Remar) witnesses a gruesome murder committed by a gargoyle-like
  monster. The monster agrees to spare Preston's life as long as he
  swears never to speak of what he saw and heard or describe the
  monster's appearance to anyone. The monster vanishes, leaving Preston
  traumatized and confused, but bound by his oath never to talk about
  the incident.
  
  After that night, Preston's life takes many turns for the better. He
  meets a beautiful woman named Carola (played by Rae Dawn Chong), and
  they fall in love, marry, and have two children. Preston's struggling
  art career becomes wildly successful, and life seems promising, but he
  is tormented by memories of his encounter with the monster, and his
  vow of silence weighs on him. One night he breaks down and tells
  Carola about the monster, even showing her a statue he sculpted of it.
  She appears upset; at first Preston assumes she thinks he's lying, but
  then she lets out a heartbroken screech and reveals herself to be the
  very same creature he met that night.


Admittedly it's a male artist, not a female one but everything else in the story fits exactly.



Warning : Videos contain NSFW content (Creature effects)


            
                
                    
                    
                    
                    
                    
                
            


            
                
                    
                    
                    
                    
                    
                
            


            
                
                    
                    
                    
                    
                    
                
            
",Valorum,https://scifi.stackexchange.com/users/20774,http://scifi.stackexchange.com/questions/81115/1990s-vhs-movie-identification,LIFE_ARTS,scifi.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,0.3333333333333333,0.7777777777777778,Vhs Movie recognition in 1990s,"Trying to find out about the 1990s movies contain this plot: a woman sees a beast murdering a man in an alley or street near her home. Frightened, she assured the beast that if he let her live, she would not tell anyone about seeing the beast. Then the movie changed from ""horror"" to ""Romance"" because she met the man of her dreams and hooked up with him. It seems to be a ""happy life they have ever lived"", but she has a disturbing dream of murder and is an artist. She painted or painted wild animals in the alley. At last she told her husband what she promised not to say, and he became a wild animal to destroy her. I can't remember, but the beast may have fallen from the sky (like a meteor, or an alien landing at the beginning).","This could be the final segment of the Tales From the Darkside movie;


  Lover's Vow : A despondent artist named Preston (played by James
  Remar) witnesses a gruesome murder committed by a gargoyle-like
  monster. The monster agrees to spare Preston's life as long as he
  swears never to speak of what he saw and heard or describe the
  monster's appearance to anyone. The monster vanishes, leaving Preston
  traumatized and confused, but bound by his oath never to talk about
  the incident.
  
  After that night, Preston's life takes many turns for the better. He
  meets a beautiful woman named Carola (played by Rae Dawn Chong), and
  they fall in love, marry, and have two children. Preston's struggling
  art career becomes wildly successful, and life seems promising, but he
  is tormented by memories of his encounter with the monster, and his
  vow of silence weighs on him. One night he breaks down and tells
  Carola about the monster, even showing her a statue he sculpted of it.
  She appears upset; at first Preston assumes she thinks he's lying, but
  then she lets out a heartbroken screech and reveals herself to be the
  very same creature he met that night.


Admittedly it's a male artist, not a female one but everything else in the story fits exactly.



Warning : Videos contain NSFW content (Creature effects)


            
                
                    
                    
                    
                    
                    
                
            


            
                
                    
                    
                    
                    
                    
                
            


            
                
                    
                    
                    
                    
                    
                
            
"
1729,1729,2735,Adding Data to Multiple Tables Using Single Query,"I want to add data to multiple tables using a single INSERT INTO query, can I do this?

Please guide me and provide me syntax if this is possible.
",butt,https://dba.stackexchange.com/users/41629,"This is not possible.  The INSERT statement takes a single destination object as per the syntax (BOL reference):

[ WITH &lt;common_table_expression&gt; [ ,...n ] ]
INSERT 
{
        [ TOP ( expression ) [ PERCENT ] ] 
        [ INTO ] 
        { &lt;object&gt; | rowset_function_limited 
          [ WITH ( &lt;Table_Hint_Limited&gt; [ ...n ] ) ]
        }
    {
        [ ( column_list ) ] 
        [ &lt;OUTPUT Clause&gt; ]
        { VALUES ( { DEFAULT | NULL | expression } [ ,...n ] ) [ ,...n     ] 
        | derived_table 
        | execute_statement
        | &lt;dml_table_source&gt;
        | DEFAULT VALUES 
        }
    }
}
[;]


Take note of the &lt;object&gt; placeholder on the 6th line of the syntax snippet.

Is there a particular reason why you want to insert into two tables in one statement?  Perhaps you are looking for both inserts to either succeed or fail as one?  In that case, you would be looking at explicit transactions:

begin tran;
    insert into dbo.YourTable1 ...
    insert into dbo.YourTable2 ...
commit tran;


Besides code brevity and atomicity, I wouldn't see any other reason that you'd want to combine multiple destination tables into a single INSERT statement.
",Thomas Stringer,https://dba.stackexchange.com/users/2241,http://dba.stackexchange.com/questions/69006/adding-data-to-multiple-tables-using-single-query,TECHNOLOGY,dba.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,Adding data to multiple tables using a single query,I want to use an insert into query to add data to multiple tables. Can I do this?,"This is not possible.  The INSERT statement takes a single destination object as per the syntax (BOL reference):

[ WITH &lt;common_table_expression&gt; [ ,...n ] ]
INSERT 
{
        [ TOP ( expression ) [ PERCENT ] ] 
        [ INTO ] 
        { &lt;object&gt; | rowset_function_limited 
          [ WITH ( &lt;Table_Hint_Limited&gt; [ ...n ] ) ]
        }
    {
        [ ( column_list ) ] 
        [ &lt;OUTPUT Clause&gt; ]
        { VALUES ( { DEFAULT | NULL | expression } [ ,...n ] ) [ ,...n     ] 
        | derived_table 
        | execute_statement
        | &lt;dml_table_source&gt;
        | DEFAULT VALUES 
        }
    }
}
[;]


Take note of the &lt;object&gt; placeholder on the 6th line of the syntax snippet.

Is there a particular reason why you want to insert into two tables in one statement?  Perhaps you are looking for both inserts to either succeed or fail as one?  In that case, you would be looking at explicit transactions:

begin tran;
    insert into dbo.YourTable1 ...
    insert into dbo.YourTable2 ...
commit tran;


Besides code brevity and atomicity, I wouldn't see any other reason that you'd want to combine multiple destination tables into a single INSERT statement.
"
178,178,277,Change top's sorting back to CPU,"A former coworker did something to top that whenever it runs as root the data is sorted by MEM usage instead of the default CPU usage. According to multiple searches, the man page and even the options within the top console itself (O), just pressing k it should be sorted by CPU, but instead when I hit k it asks me for a pid to kill.

So how can I get back default sorting to CPU?  
",yzT,https://unix.stackexchange.com/users/27807,"I know it's not a direct answer to your question, but there's a wonderful tool called htop which I'd like to recommend.
It's like an advanced version of the original top tool which allows you to sort the output in a much easier way and appearance.
For example, if you want to sort by CPU, you simply hit F6 and choose your sorting.

Here's how htop looks like:
http://lel.xyz/htop.jpg

Here's how it looks when you press F6:
http://lel.xyz/htopsort.jpg

In order to install it on CentOS/RHEL machines you will have to add the EPEL repo and then simply run:

yum install -y htop

or on Debian machines simply run:

sudo apt-get install htop without adding any repo's.
",Itai Ganot,https://unix.stackexchange.com/users/36757,http://unix.stackexchange.com/questions/158584/change-tops-sorting-back-to-cpu,TECHNOLOGY,unix.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.7,1.0,0.0,0.0,1.0,Change top sorting back to CPU,"A former colleague did something, and whenever it ran as root, the data was sorted by MEM usage rather than the default CPU usage. Based on multiple searches, the man page or even the options in the top console itself (O), as long as you press K, it should be sorted by CPU, but when I press K, it will ask me to kill a PID.","I know it's not a direct answer to your question, but there's a wonderful tool called htop which I'd like to recommend.
It's like an advanced version of the original top tool which allows you to sort the output in a much easier way and appearance.
For example, if you want to sort by CPU, you simply hit F6 and choose your sorting.

Here's how htop looks like:
http://lel.xyz/htop.jpg

Here's how it looks when you press F6:
http://lel.xyz/htopsort.jpg

In order to install it on CentOS/RHEL machines you will have to add the EPEL repo and then simply run:

yum install -y htop

or on Debian machines simply run:

sudo apt-get install htop without adding any repo's.
"
937,937,1487,can i make an outlined path thicker in illustrator?,"i have downloaded some svg icons form the web which are all outlined paths. In illustrator i would like to make those paths thicker. Is there a way to do this? I know when a line is still in stroke-mode you can just adjust the size of the stroke, but once this has been converted to outlines i don't know if this is still possible?

thx
",Justin Othername,https://graphicdesign.stackexchange.com/users/34188,"Since the outlined art consists simply of filled objects, the intuitive solution would be to add an exterior stroke of the weight of half the amount you wanted to increase the initial stroke. For example, if the outlined stroke was 1pt, and you want to change it to a 2pt line, you would add a 0.5pt exterior stroke to the outline. However, some caveats I can think of off the top of my head:


Adding strokes to unjoined outlines will add weight to the ends, while with path stroke behaviour, the stroke is capped at the endpoints by default
It's a lot harder to reduce the weight of the stroke after it's outlined. Luckily, you want only to thicken it, so you don't really have to worry about this.


There's probably others â working with outlines when you want paths is never ideal. Nonetheless, the short answer is yes, it is entirely possible. You just have to be a little craftier.
",concat,https://graphicdesign.stackexchange.com/users/34190,http://graphicdesign.stackexchange.com/questions/42839/can-i-make-an-outlined-path-thicker-in-illustrator,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Can I make a rougher path in illustrator?,"I've downloaded some SVG icons from the Internet, which are the paths of the overview. In illustrator, I want to make these paths thicker. Is there a way? I know that when a line is still in stroke mode, you can resize the stroke, but once it's converted to a contour, I don't know if it's still possible?","Since the outlined art consists simply of filled objects, the intuitive solution would be to add an exterior stroke of the weight of half the amount you wanted to increase the initial stroke. For example, if the outlined stroke was 1pt, and you want to change it to a 2pt line, you would add a 0.5pt exterior stroke to the outline. However, some caveats I can think of off the top of my head:


Adding strokes to unjoined outlines will add weight to the ends, while with path stroke behaviour, the stroke is capped at the endpoints by default
It's a lot harder to reduce the weight of the stroke after it's outlined. Luckily, you want only to thicken it, so you don't really have to worry about this.


There's probably others â working with outlines when you want paths is never ideal. Nonetheless, the short answer is yes, it is entirely possible. You just have to be a little craftier.
"
3079,3079,4900,Macro that follows a link and downloads the table into a new sheet,"I am a geologist working for a small oil company in Louisiana. I constitute our tech department, and unfortunately my experience with coding is quite limited. I have used very basic vba coding in the past, but I dont code that much in my daily job, so I have forgotten most of it.

The louisiana dnr keeps amazing records for every single oil well drilled in the state and all of these records are located at www.Sonris.com. Part of these records are the production records for each well. I would like to create a macro that follows a given url and downloads the table found on the URL (aka the production records). After it downloads the file, I would like it to put the table in a new sheet and then to name this sheet based on the well name. 

I have fooled around with the retrieve data from web function, however I cannot make the function dynamic enough. I need the code to copy the hyperlink data found in a cell. Currently, the code just follows the hyperlink that I copy and paste while recording the macro. 

Any help would be appreciated

Sincerely,
Josiah

Below is the code generated;

    Sub Macro2()
'
'     Macro2 Macro
' attempt with multiple well to look at code instead of 1 well
'

'
    Range(""E27"").Select
    ActiveWorkbook.Worksheets.Add
    With ActiveSheet.QueryTables.Add(Connection:= _
        ""URL;http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=159392"" _
        , Destination:=Range(""$A$1""))
        .Name = ""cart_con_wellinfo2?p_WSN=159392""
        .FieldNames = True
        .RowNumbers = False
        .FillAdjacentFormulas = False
        .PreserveFormatting = True
        .RefreshOnFileOpen = False
        .BackgroundQuery = True
        .RefreshStyle = xlInsertDeleteCells
        .SavePassword = False
        .SaveData = True
        .AdjustColumnWidth = True
        .RefreshPeriod = 0
        .WebSelectionType = xlSpecifiedTables
        .WebFormatting = xlWebFormattingNone
        .WebTables = ""1,11""
        .WebPreFormattedTextToColumns = True
        .WebConsecutiveDelimitersAsOne = True
        .WebSingleBlockTextImport = False
        .WebDisableDateRecognition = False
        .WebDisableRedirections = False
        .Refresh BackgroundQuery:=False
    End With
    Sheets(""Sheet1"").Select
End Sub

",Josiah Hulsey,https://stackoverflow.com/users/4390183,"With all of the methods available to scrub external data, many users forget that you can open a web page full of tables with nothing more than a valid URL and File âº Open. I'm posting the code here but I will also supply a link to a working sample workbook that took ~ 2 minutes to gather the full web page data from 14 sequentially numbered WSN (web serial number) pages. Your own results may vary.

Option Explicit

Public Const csURL As String = ""http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=ÃWSNÃ""

Sub Gather_Well_Data()
    Dim rw As Long, lr As Long, w As Long, wsn As String, wb As Workbook
    On Error GoTo FÃ¬n
    Application.ScreenUpdating = False
    Application.DisplayAlerts = False
    With ThisWorkbook.Sheets(""WSNs"")
        lr = .Cells(Rows.Count, 1).End(xlUp).Row
        For rw = 2 To lr
            .Cells(rw, 2) = 0
            For w = 1 To .Parent.Sheets.Count
                If .Parent.Sheets(w).Name = CStr(.Cells(rw, 1).Value) Then
                    .Parent.Sheets(w).Delete
                    Exit For
                End If
            Next w
            wsn = Replace(csURL, ""ÃWSNÃ"", .Cells(rw, 1).Value)
            Set wb = Workbooks.Open(Filename:=wsn, ReadOnly:=True, addtomru:=False)
            wb.Sheets(1).Range(""A1:A3"").Font.Size = 12
            wb.Sheets(1).Copy After:=.Parent.Sheets(.Parent.Sheets.Count)
            .Parent.Sheets(.Parent.Sheets.Count).Name = .Cells(rw, 1).Value
            wb.Close savechanges:=False
            Set wb = Nothing
            .Cells(rw, 2) = 1
            Application.ScreenUpdating = True
            Application.ScreenUpdating = False
            .Parent.Save
        Next rw
        .Activate
    End With
FÃ¬n:
    Application.DisplayAlerts = True
    Application.ScreenUpdating = True
End Sub


The list of WSN identifiers are in the WSNs worksheet starting in column 2. Run the macro by tapping Alt+F8 to open the Macros dialog and Run the Gather_Well_Data macro. When it is complete, you will have a workbook filled with worksheets identified by the WSNs similar to below.

Â Â Â Â Â Â Â Â Â 

The sample workbook is on my public DropBox at:

LA_WSN_Data.xlsb
",Jeeped,https://stackoverflow.com/users/4039065,http://stackoverflow.com/questions/27690443/macro-that-follows-a-link-and-downloads-the-table-into-a-new-sheet,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Track links and download tables to macros in new worksheets,"I am a geologist working for a small oil company in Louisiana. I constitute our tech department, and unfortunately my experience with coding is quite limited. I have used very basic vba coding in the past, but I dont code that much in my daily job, so I have forgotten most of it.

The louisiana dnr keeps amazing records for every single oil well drilled in the state and all of these records are located at www.Sonris.com. Part of these records are the production records for each well. I would like to create a macro that follows a given url and downloads the table found on the URL (aka the production records). After it downloads the file, I would like it to put the table in a new sheet and then to name this sheet based on the well name. 

I have fooled around with the retrieve data from web function, however I cannot make the function dynamic enough. I need the code to copy the hyperlink data found in a cell. Currently, the code just follows the hyperlink that I copy and paste while recording the macro. 

Any help would be appreciated

Sincerely,
Josiah

Below is the code generated;

    Sub Macro2()
'
'     Macro2 Macro
' attempt with multiple well to look at code instead of 1 well
'

'
    Range(""E27"").Select
    ActiveWorkbook.Worksheets.Add
    With ActiveSheet.QueryTables.Add(Connection:= _
        ""URL;http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=159392"" _
        , Destination:=Range(""$A$1""))
        .Name = ""cart_con_wellinfo2?p_WSN=159392""
        .FieldNames = True
        .RowNumbers = False
        .FillAdjacentFormulas = False
        .PreserveFormatting = True
        .RefreshOnFileOpen = False
        .BackgroundQuery = True
        .RefreshStyle = xlInsertDeleteCells
        .SavePassword = False
        .SaveData = True
        .AdjustColumnWidth = True
        .RefreshPeriod = 0
        .WebSelectionType = xlSpecifiedTables
        .WebFormatting = xlWebFormattingNone
        .WebTables = ""1,11""
        .WebPreFormattedTextToColumns = True
        .WebConsecutiveDelimitersAsOne = True
        .WebSingleBlockTextImport = False
        .WebDisableDateRecognition = False
        .WebDisableRedirections = False
        .Refresh BackgroundQuery:=False
    End With
    Sheets(""Sheet1"").Select
End Sub

","With all of the methods available to scrub external data, many users forget that you can open a web page full of tables with nothing more than a valid URL and File âº Open. I'm posting the code here but I will also supply a link to a working sample workbook that took ~ 2 minutes to gather the full web page data from 14 sequentially numbered WSN (web serial number) pages. Your own results may vary.

Option Explicit

Public Const csURL As String = ""http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=ÃWSNÃ""

Sub Gather_Well_Data()
    Dim rw As Long, lr As Long, w As Long, wsn As String, wb As Workbook
    On Error GoTo FÃ¬n
    Application.ScreenUpdating = False
    Application.DisplayAlerts = False
    With ThisWorkbook.Sheets(""WSNs"")
        lr = .Cells(Rows.Count, 1).End(xlUp).Row
        For rw = 2 To lr
            .Cells(rw, 2) = 0
            For w = 1 To .Parent.Sheets.Count
                If .Parent.Sheets(w).Name = CStr(.Cells(rw, 1).Value) Then
                    .Parent.Sheets(w).Delete
                    Exit For
                End If
            Next w
            wsn = Replace(csURL, ""ÃWSNÃ"", .Cells(rw, 1).Value)
            Set wb = Workbooks.Open(Filename:=wsn, ReadOnly:=True, addtomru:=False)
            wb.Sheets(1).Range(""A1:A3"").Font.Size = 12
            wb.Sheets(1).Copy After:=.Parent.Sheets(.Parent.Sheets.Count)
            .Parent.Sheets(.Parent.Sheets.Count).Name = .Cells(rw, 1).Value
            wb.Close savechanges:=False
            Set wb = Nothing
            .Cells(rw, 2) = 1
            Application.ScreenUpdating = True
            Application.ScreenUpdating = False
            .Parent.Save
        Next rw
        .Activate
    End With
FÃ¬n:
    Application.DisplayAlerts = True
    Application.ScreenUpdating = True
End Sub


The list of WSN identifiers are in the WSNs worksheet starting in column 2. Run the macro by tapping Alt+F8 to open the Macros dialog and Run the Gather_Well_Data macro. When it is complete, you will have a workbook filled with worksheets identified by the WSNs similar to below.

Â Â Â Â Â Â Â Â Â 

The sample workbook is on my public DropBox at:

LA_WSN_Data.xlsb
"
140,140,223,Adding seconds to mysql DateTime via php,"Im trying to add 12 seconds to a mysql datetime object via php.

My php code generates the following query: ""UPDATE Stats SET Usage = 1970-01-01 00:00:12"" however the query fails.

My php code is as follows:

public function UpdateTime($diffrence)
{
    $seconds = $diffrence / 1000;

    mysql_connect('localhost','user','pass') or die(""Unable to select host"");

    mysql_select_db('StatDB') or die(""Unable to select database"");

    $query  = ""SELECT * FROM Stats"";

    $result=mysql_query($query);

    $retVal = mysql_result($result,0,""Usage"");

    $oldTime = new DateTime($retVal);

    $oldTime-&gt;modify('+'. $seconds .' seconds');

    $from = date(""Y-m-d H:i:s"", strtotime($oldTime-&gt;format('Y-m-d H:i:s')));

    $query2  = ""UPDATE Stats SET Usage = $from"";
    echo $query2;

    $result2=mysql_query($query2);

    mysql_close();
}


Does anyone how I can fix this?

Thanks
",Ryuk,https://stackoverflow.com/users/1211548,"Try:

$query2  = ""UPDATE `Stats` SET `Usage` = '$from'"";


'Usage' is a reserved word in MySQL:

http://dev.mysql.com/doc/refman/5.0/en/reserved-words.html
",DiscoInfiltrator,https://stackoverflow.com/users/2029085,http://stackoverflow.com/questions/15317063/adding-seconds-to-mysql-datetime-via-php,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Add seconds to MySQL datetime through PHP,"Im trying to add 12 seconds to a mysql datetime object via php.

My php code generates the following query: ""UPDATE Stats SET Usage = 1970-01-01 00:00:12"" however the query fails.

My php code is as follows:

public function UpdateTime($diffrence)
{
    $seconds = $diffrence / 1000;

    mysql_connect('localhost','user','pass') or die(""Unable to select host"");

    mysql_select_db('StatDB') or die(""Unable to select database"");

    $query  = ""SELECT * FROM Stats"";

    $result=mysql_query($query);

    $retVal = mysql_result($result,0,""Usage"");

    $oldTime = new DateTime($retVal);

    $oldTime-&gt;modify('+'. $seconds .' seconds');

    $from = date(""Y-m-d H:i:s"", strtotime($oldTime-&gt;format('Y-m-d H:i:s')));

    $query2  = ""UPDATE Stats SET Usage = $from"";
    echo $query2;

    $result2=mysql_query($query2);

    mysql_close();
}


Does anyone how I can fix this?

Thanks
","Try:

$query2  = ""UPDATE `Stats` SET `Usage` = '$from'"";


'Usage' is a reserved word in MySQL:

http://dev.mysql.com/doc/refman/5.0/en/reserved-words.html
"
1267,1267,1996,How to add additional photos to a status update,"I created a Facebook status update with three photos. I'd like to add one more. Note that I did not create an album, I simply uploaded all three photos at the time of creating the Facebook status update. I can delete photos... but don't see a way to add one.


",Bryce,https://webapps.stackexchange.com/users/17204,"Once you posted it, you canât add a new photo to a status update. The only moment when you can add more photos to a status update is between the time one or more photos are uploaded and the one you click Post (see picture below).



The only thing you can do is to delete the first pictures and re-upload them together with the fourth.

(FYI: the photos you upload directly (as status updates) are grouped in the album called Timeline Photos.)
",Alex,https://webapps.stackexchange.com/users/1512,http://webapps.stackexchange.com/questions/41379/how-to-add-additional-photos-to-a-status-update,TECHNOLOGY,webapps.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,How to add other photos to status updates,"I created a Facebook status update with three photos. I want to add another one. Note that I didn't create an album, just uploaded all three photos when I created a Facebook status update. I can delete photos... But there's no way to add another one.","Once you posted it, you canât add a new photo to a status update. The only moment when you can add more photos to a status update is between the time one or more photos are uploaded and the one you click Post (see picture below).



The only thing you can do is to delete the first pictures and re-upload them together with the fourth.

(FYI: the photos you upload directly (as status updates) are grouped in the album called Timeline Photos.)
"
1917,1917,3051,Hide microphone button Android virtual keyboard,"I wanted to know if is it possible to hide the microphone button (speech-to-text) in Android Virtual Keyboard programatically.

I know I can disable this option through device settings, but I don't want the user to use this feature in my application independently of his/her settings. 
I mean i want to force this behaviour inside my app.

Thanks in advance,
Demian
",Demian,https://stackoverflow.com/users/943009,"Here's how you do it: android:privateImeOptions=""nm"" - nm stands for No Microphone.
",markostamcar,https://stackoverflow.com/users/748430,http://stackoverflow.com/questions/7405500/hide-microphone-button-android-virtual-keyboard,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Hide microphone button Android virtual keyboard,"I wanted to know if is it possible to hide the microphone button (speech-to-text) in Android Virtual Keyboard programatically.

I know I can disable this option through device settings, but I don't want the user to use this feature in my application independently of his/her settings. 
I mean i want to force this behaviour inside my app.

Thanks in advance,
Demian
","Here's how you do it: android:privateImeOptions=""nm"" - nm stands for No Microphone.
"
3545,3545,5655,Can't install Pantheon desktop environment,"I've tried to install Pantheon desktop environment several times. I tried sudo apt-get update and sudo apt-get upgrade, but it's no use. Iâm just a very new beginner. This is what Iâve done:

quanglong@ubuntu:~$ sudo add-apt-repository ppa:elementary-os/daily
[sudo] password for quanglong: 
You are about to add the following PPA to your system:
 ATTENTION!
Do NOT install this PPA if you want a tested running system, this PPA contains the newest and most unstable development of elementary, it's useful only if you are a developer and are not afraid to encounter CRITICAL BUGS.
Also this PPA may overwrite already installed packages you don't want it to!
 More info: https://launchpad.net/~elementary-os/+archive/daily
Press [ENTER] to continue or ctrl-c to cancel adding it

gpg: keyring `/tmp/tmpkz5d_z/secring.gpg' created
gpg: keyring `/tmp/tmpkz5d_z/pubring.gpg' created
gpg: requesting key 4E1F8A59 from hkp server keyserver.ubuntu.com
gpg: /tmp/tmpkz5d_z/trustdb.gpg: trustdb created
gpg: key 4E1F8A59: public key ""Launchpad PPA for elementary OS team"" imported
gpg: Total number processed: 1
gpg:               imported: 1  (RSA: 1)
OK
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get update
Hit http://ppa.launchpad.net quantal Release.gpg                               
Get:1 http://security.ubuntu.com quantal-security Release.gpg [933 B]          
Hit http://us.archive.ubuntu.com quantal Release.gpg                           
Hit http://ppa.launchpad.net quantal Release.gpg
Get:2 http://security.ubuntu.com quantal-security Release [49.6 kB]
Get:3 http://us.archive.ubuntu.com quantal-updates Release.gpg [933 B]       
Hit http://us.archive.ubuntu.com quantal-backports Release.gpg                 
Hit http://ppa.launchpad.net quantal Release             
Hit http://us.archive.ubuntu.com quantal Release                               
Hit http://ppa.launchpad.net quantal Release                                   
Get:4 http://us.archive.ubuntu.com quantal-updates Release [49.6 kB]           
Hit http://ppa.launchpad.net quantal/main Sources                             
Get:5 http://security.ubuntu.com quantal-security/main Sources [74.3 kB]      
Hit http://ppa.launchpad.net quantal/main amd64 Packages                       
Hit http://ppa.launchpad.net quantal/main i386 Packages                        
Hit http://us.archive.ubuntu.com quantal-backports Release                     
Hit http://us.archive.ubuntu.com quantal/main Sources                          
Hit http://us.archive.ubuntu.com quantal/restricted Sources                    
Hit http://us.archive.ubuntu.com quantal/universe Sources
Hit http://ppa.launchpad.net quantal/main Sources                              
Hit http://us.archive.ubuntu.com quantal/multiverse Sources           
Get:6 http://security.ubuntu.com quantal-security/restricted Sources [1,833 B]
Hit http://us.archive.ubuntu.com quantal/main amd64 Packages                   
Hit http://ppa.launchpad.net quantal/main amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/restricted amd64 Packages
Get:7 http://security.ubuntu.com quantal-security/universe Sources [23.8 kB]
Hit http://ppa.launchpad.net quantal/main i386 Packages                       
Hit http://us.archive.ubuntu.com quantal/universe amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/multiverse amd64 Packages             
Get:8 http://security.ubuntu.com quantal-security/multiverse Sources [1,169 B]
Hit http://us.archive.ubuntu.com quantal/main i386 Packages                    
Hit http://us.archive.ubuntu.com quantal/restricted i386 Packages     
Get:9 http://security.ubuntu.com quantal-security/main amd64 Packages [207 kB]
Hit http://us.archive.ubuntu.com quantal/universe i386 Packages               
Hit http://us.archive.ubuntu.com quantal/multiverse i386 Packages              
Hit http://us.archive.ubuntu.com quantal/main Translation-en                   
Hit http://us.archive.ubuntu.com quantal/multiverse Translation-en             
Hit http://us.archive.ubuntu.com quantal/restricted Translation-en             
Hit http://us.archive.ubuntu.com quantal/universe Translation-en               
Get:10 http://us.archive.ubuntu.com quantal-updates/main Sources [134 kB]      
Get:11 http://security.ubuntu.com quantal-security/restricted amd64 Packages [3,469 B]
Get:12 http://security.ubuntu.com quantal-security/universe amd64 Packages [72.4 kB]
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:13 http://us.archive.ubuntu.com quantal-updates/restricted Sources [2,564 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:14 http://us.archive.ubuntu.com quantal-updates/universe Sources [96.7 kB] 
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:15 http://security.ubuntu.com quantal-security/multiverse amd64 Packages [1,488 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:16 http://security.ubuntu.com quantal-security/main i386 Packages [205 kB] 
Get:17 http://us.archive.ubuntu.com quantal-updates/multiverse Sources [5,269 B]
Get:18 http://us.archive.ubuntu.com quantal-updates/main amd64 Packages [337 kB]
Get:19 http://us.archive.ubuntu.com quantal-updates/restricted amd64 Packages [4,804 B]
Get:20 http://us.archive.ubuntu.com quantal-updates/universe amd64 Packages [218 kB]
Get:21 http://security.ubuntu.com quantal-security/restricted i386 Packages [3,531 B]
Get:22 http://security.ubuntu.com quantal-security/universe i386 Packages [73.0 kB]
Get:23 http://us.archive.ubuntu.com quantal-updates/multiverse amd64 Packages [12.1 kB]
Get:24 http://security.ubuntu.com quantal-security/multiverse i386 Packages [1,726 B]
Hit http://security.ubuntu.com quantal-security/main Translation-en            
Get:25 http://us.archive.ubuntu.com quantal-updates/main i386 Packages [334 kB]
Hit http://security.ubuntu.com quantal-security/multiverse Translation-en      
Hit http://security.ubuntu.com quantal-security/restricted Translation-en      
Hit http://security.ubuntu.com quantal-security/universe Translation-en        
Get:26 http://us.archive.ubuntu.com quantal-updates/restricted i386 Packages [4,841 B]
Get:27 http://us.archive.ubuntu.com quantal-updates/universe i386 Packages [219 kB]
Get:28 http://us.archive.ubuntu.com quantal-updates/multiverse i386 Packages [12.3 kB]
Hit http://us.archive.ubuntu.com quantal-updates/main Translation-en           
Hit http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/restricted Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/universe Translation-en       
Hit http://us.archive.ubuntu.com quantal-backports/main Sources                
Hit http://us.archive.ubuntu.com quantal-backports/restricted Sources          
Ign http://security.ubuntu.com quantal-security/main Translation-en_US         
Hit http://us.archive.ubuntu.com quantal-backports/universe Sources            
Ign http://security.ubuntu.com quantal-security/multiverse Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Sources          
Ign http://security.ubuntu.com quantal-security/restricted Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/main amd64 Packages         
Ign http://security.ubuntu.com quantal-security/universe Translation-en_US     
Hit http://us.archive.ubuntu.com quantal-backports/restricted amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/universe amd64 Packages     
Hit http://us.archive.ubuntu.com quantal-backports/multiverse amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/main i386 Packages          
Hit http://us.archive.ubuntu.com quantal-backports/restricted i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/universe i386 Packages      
Hit http://us.archive.ubuntu.com quantal-backports/multiverse i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/main Translation-en         
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/restricted Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/universe Translation-en     
Ign http://us.archive.ubuntu.com quantal/main Translation-en_US                
Ign http://us.archive.ubuntu.com quantal/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/universe Translation-en_US
Fetched 2,151 kB in 45s (47.7 kB/s)
Reading package lists... Done
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get install elementary-desktop
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package elementary-desktop
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ 

",user275846,https://askubuntu.com/users/275846,"Okay I got build errors. Haven't got time to test it at the moment :(.

Also: ""After this operation, 1779 MB of additional disk space will be used.""
So make sure you have a few GB's set aside if you're going to do this.



Okay so I got it working by following this: How to install the Pantheon desktop environment? Basically the PPA everyone is suggesting works, is 404-ing for me (and presumably you) when I try and access it.

1) This is syslinux-themes-elementary-isis, and the .sh script apparently requires it. Sudo apt-get didn't find it for me. You could probably test removing this dependency from the .sh if you are feeling bold. I installed amd64 version of this (as I am on 64 bit, if you are on 32 bit obviously don't), just use a .deb installer on Ubuntu:

https://launchpad.net/~elementary-os/+archive/daily/+files/syslinux-themes-elementary-isis_2-0%7E4%7Esaucy1_amd64.deb


2) This is required by the elementary os install script:

sudo apt-get install dctrl-tools dpkg-dev 
    genisoimage gfxboot-theme-ubuntu live-build squashfs-tools syslinux zsync


3) The script uses this to determine what files to download (obviously don't do both, amd64 is for 64bit and i386 is for 32 bit) (you'll want to put this in .bashrc or somewhere else for it to be permanent, not 100% anyone will ever need this again though):

export ARCH=amd64
export ARCH=i386


4) From the previous question/answer thread:

sudo apt-get install bzr
bzr branch lp:elementaryos
cd elementaryos
sudo congrego.sh


On my machine I didn't specify $ARCH so I got 90% of the way through a 970 M .iso file for i386 before I realised -_-.

Currently running through the amd64 installation.



As an aside:

# load config
source etc/congrego.conf

if [[ ""$ARCH"" == ""all"" ]]; then
        $(dirname ""$0"")/bin/download.sh i386
        $(dirname ""$0"")/bin/download.sh amd64
        $(dirname ""$0"")/bin/build.sh i386
        $(dirname ""$0"")/bin/build.sh amd64
        if [[ ""$SOURCEFORGE"" != """" ]]; then
            $(dirname ""$0"")/bin/sourceforge.sh i386
            $(dirname ""$0"")/bin/sourceforge.sh amd64
        fi
else
        $(dirname ""$0"")/bin/download.sh ""$ARCH""
        $(dirname ""$0"")/bin/build.sh ""$ARCH""
        $(dirname ""$0"")/bin/sourceforge.sh ""$ARCH""
fi


It is a bit presumptuous that users would have that environment variable set. Unless I am reading it wrong, it seems like it will download iso's for i386 AND amd64 and then build both of them, which sounds like a bad idea. I'm noob at bash script though so it could be fine for all I know.

Just in case this is irrelevant to your machine:

Linux mikeydesknix 3.11.0-19-generic #33-Ubuntu SMP Tue Mar 11 18:48:34 UTC 2014 
x86_64 x86_64 x86_64 GNU/Linux

[ mikey ][ 02:22:59 ]$lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 13.10
Release:    13.10
Codename:   saucy


--

Build Errors:

[2014-05-01 03:31:40] lb_chroot_hooks 
P: Begin executing hooks...
ERROR:root:DebFileApplication import
Traceback (most recent call last):
  File ""/usr/share/software-center/softwarecenter/db/__init__.py"", line 4, in &lt;module&gt;
    from debfile import DebFileApplication, DebFileOpenError
  File ""/usr/share/software-center/softwarecenter/db/debfile.py"", line 25, in &lt;module&gt;
    from softwarecenter.db.application import Application, AppDetails
  File ""/usr/share/software-center/softwarecenter/db/application.py"", line 28, in &lt;module&gt;
    import softwarecenter.distro
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 199, in &lt;module&gt;
    distro_instance = _get_distro()
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 174, in _get_distro
    module = __import__(distro_module_name, globals(), locals(), [], -1)
ImportError: No module named ""elementary os""
Traceback (most recent call last):
  File ""/usr/sbin/update-apt-xapian-index"", line 101, in &lt;module&gt;
    if not indexer.setupIndexing(force=opts.force, system=opts.pkgfile is None):
  File ""/usr/lib/python2.7/dist-packages/axi/indexer.py"", line 471, in setupIndexing
    self.plugins = Plugins(progress=self.progress, system=system)
  File ""/usr/lib/python2.7/dist-packages/axi/indexer.py"", line 94, in __init__
    addon = Addon(fullname, **kw)
  File ""/usr/lib/python2.7/dist-packages/axi/indexer.py"", line 49, in __init__
    self.module = imp.load_source(""axi.plugin_"" + self.name, fname)
  File ""/usr/share/apt-xapian-index/plugins/software_center.py"", line 13, in &lt;module&gt;
    from softwarecenter.db.update import (
  File ""/usr/share/software-center/softwarecenter/db/update.py"", line 33, in &lt;module&gt;
    from softwarecenter.backend.scagent import SoftwareCenterAgent
  File ""/usr/share/software-center/softwarecenter/backend/scagent.py"", line 28, in &lt;module&gt;
    from softwarecenter.distro import get_distro, get_current_arch
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 199, in &lt;module&gt;
    distro_instance = _get_distro()
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 174, in _get_distro
    module = __import__(distro_module_name, globals(), locals(), [], -1)
ImportError: No module named ""elementary os""
E: chroot/root/lb_chroot_hooks/002-update-apt-xapian-index.chroot failed (exit non-zero). You should check for errors.
P: Begin unmounting filesystems...
P: Saving caches...
Reading package lists...
Building dependency tree...
Reading state information...
md5sum: binary.hybrid.iso: No such file or directory

",mikeyjk,https://askubuntu.com/users/193732,http://askubuntu.com/questions/457673/cant-install-pantheon-desktop-environment,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.6666666666666666,Unable to install Pantheon desktop environment,"I've tried to install Pantheon desktop environment several times. I tried sudo apt-get update and sudo apt-get upgrade, but it's no use. Iâm just a very new beginner. This is what Iâve done:

quanglong@ubuntu:~$ sudo add-apt-repository ppa:elementary-os/daily
[sudo] password for quanglong: 
You are about to add the following PPA to your system:
 ATTENTION!
Do NOT install this PPA if you want a tested running system, this PPA contains the newest and most unstable development of elementary, it's useful only if you are a developer and are not afraid to encounter CRITICAL BUGS.
Also this PPA may overwrite already installed packages you don't want it to!
 More info: https://launchpad.net/~elementary-os/+archive/daily
Press [ENTER] to continue or ctrl-c to cancel adding it

gpg: keyring `/tmp/tmpkz5d_z/secring.gpg' created
gpg: keyring `/tmp/tmpkz5d_z/pubring.gpg' created
gpg: requesting key 4E1F8A59 from hkp server keyserver.ubuntu.com
gpg: /tmp/tmpkz5d_z/trustdb.gpg: trustdb created
gpg: key 4E1F8A59: public key ""Launchpad PPA for elementary OS team"" imported
gpg: Total number processed: 1
gpg:               imported: 1  (RSA: 1)
OK
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get update
Hit http://ppa.launchpad.net quantal Release.gpg                               
Get:1 http://security.ubuntu.com quantal-security Release.gpg [933 B]          
Hit http://us.archive.ubuntu.com quantal Release.gpg                           
Hit http://ppa.launchpad.net quantal Release.gpg
Get:2 http://security.ubuntu.com quantal-security Release [49.6 kB]
Get:3 http://us.archive.ubuntu.com quantal-updates Release.gpg [933 B]       
Hit http://us.archive.ubuntu.com quantal-backports Release.gpg                 
Hit http://ppa.launchpad.net quantal Release             
Hit http://us.archive.ubuntu.com quantal Release                               
Hit http://ppa.launchpad.net quantal Release                                   
Get:4 http://us.archive.ubuntu.com quantal-updates Release [49.6 kB]           
Hit http://ppa.launchpad.net quantal/main Sources                             
Get:5 http://security.ubuntu.com quantal-security/main Sources [74.3 kB]      
Hit http://ppa.launchpad.net quantal/main amd64 Packages                       
Hit http://ppa.launchpad.net quantal/main i386 Packages                        
Hit http://us.archive.ubuntu.com quantal-backports Release                     
Hit http://us.archive.ubuntu.com quantal/main Sources                          
Hit http://us.archive.ubuntu.com quantal/restricted Sources                    
Hit http://us.archive.ubuntu.com quantal/universe Sources
Hit http://ppa.launchpad.net quantal/main Sources                              
Hit http://us.archive.ubuntu.com quantal/multiverse Sources           
Get:6 http://security.ubuntu.com quantal-security/restricted Sources [1,833 B]
Hit http://us.archive.ubuntu.com quantal/main amd64 Packages                   
Hit http://ppa.launchpad.net quantal/main amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/restricted amd64 Packages
Get:7 http://security.ubuntu.com quantal-security/universe Sources [23.8 kB]
Hit http://ppa.launchpad.net quantal/main i386 Packages                       
Hit http://us.archive.ubuntu.com quantal/universe amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/multiverse amd64 Packages             
Get:8 http://security.ubuntu.com quantal-security/multiverse Sources [1,169 B]
Hit http://us.archive.ubuntu.com quantal/main i386 Packages                    
Hit http://us.archive.ubuntu.com quantal/restricted i386 Packages     
Get:9 http://security.ubuntu.com quantal-security/main amd64 Packages [207 kB]
Hit http://us.archive.ubuntu.com quantal/universe i386 Packages               
Hit http://us.archive.ubuntu.com quantal/multiverse i386 Packages              
Hit http://us.archive.ubuntu.com quantal/main Translation-en                   
Hit http://us.archive.ubuntu.com quantal/multiverse Translation-en             
Hit http://us.archive.ubuntu.com quantal/restricted Translation-en             
Hit http://us.archive.ubuntu.com quantal/universe Translation-en               
Get:10 http://us.archive.ubuntu.com quantal-updates/main Sources [134 kB]      
Get:11 http://security.ubuntu.com quantal-security/restricted amd64 Packages [3,469 B]
Get:12 http://security.ubuntu.com quantal-security/universe amd64 Packages [72.4 kB]
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:13 http://us.archive.ubuntu.com quantal-updates/restricted Sources [2,564 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:14 http://us.archive.ubuntu.com quantal-updates/universe Sources [96.7 kB] 
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:15 http://security.ubuntu.com quantal-security/multiverse amd64 Packages [1,488 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:16 http://security.ubuntu.com quantal-security/main i386 Packages [205 kB] 
Get:17 http://us.archive.ubuntu.com quantal-updates/multiverse Sources [5,269 B]
Get:18 http://us.archive.ubuntu.com quantal-updates/main amd64 Packages [337 kB]
Get:19 http://us.archive.ubuntu.com quantal-updates/restricted amd64 Packages [4,804 B]
Get:20 http://us.archive.ubuntu.com quantal-updates/universe amd64 Packages [218 kB]
Get:21 http://security.ubuntu.com quantal-security/restricted i386 Packages [3,531 B]
Get:22 http://security.ubuntu.com quantal-security/universe i386 Packages [73.0 kB]
Get:23 http://us.archive.ubuntu.com quantal-updates/multiverse amd64 Packages [12.1 kB]
Get:24 http://security.ubuntu.com quantal-security/multiverse i386 Packages [1,726 B]
Hit http://security.ubuntu.com quantal-security/main Translation-en            
Get:25 http://us.archive.ubuntu.com quantal-updates/main i386 Packages [334 kB]
Hit http://security.ubuntu.com quantal-security/multiverse Translation-en      
Hit http://security.ubuntu.com quantal-security/restricted Translation-en      
Hit http://security.ubuntu.com quantal-security/universe Translation-en        
Get:26 http://us.archive.ubuntu.com quantal-updates/restricted i386 Packages [4,841 B]
Get:27 http://us.archive.ubuntu.com quantal-updates/universe i386 Packages [219 kB]
Get:28 http://us.archive.ubuntu.com quantal-updates/multiverse i386 Packages [12.3 kB]
Hit http://us.archive.ubuntu.com quantal-updates/main Translation-en           
Hit http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/restricted Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/universe Translation-en       
Hit http://us.archive.ubuntu.com quantal-backports/main Sources                
Hit http://us.archive.ubuntu.com quantal-backports/restricted Sources          
Ign http://security.ubuntu.com quantal-security/main Translation-en_US         
Hit http://us.archive.ubuntu.com quantal-backports/universe Sources            
Ign http://security.ubuntu.com quantal-security/multiverse Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Sources          
Ign http://security.ubuntu.com quantal-security/restricted Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/main amd64 Packages         
Ign http://security.ubuntu.com quantal-security/universe Translation-en_US     
Hit http://us.archive.ubuntu.com quantal-backports/restricted amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/universe amd64 Packages     
Hit http://us.archive.ubuntu.com quantal-backports/multiverse amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/main i386 Packages          
Hit http://us.archive.ubuntu.com quantal-backports/restricted i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/universe i386 Packages      
Hit http://us.archive.ubuntu.com quantal-backports/multiverse i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/main Translation-en         
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/restricted Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/universe Translation-en     
Ign http://us.archive.ubuntu.com quantal/main Translation-en_US                
Ign http://us.archive.ubuntu.com quantal/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/universe Translation-en_US
Fetched 2,151 kB in 45s (47.7 kB/s)
Reading package lists... Done
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get install elementary-desktop
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package elementary-desktop
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ 

","Okay I got build errors. Haven't got time to test it at the moment :(.

Also: ""After this operation, 1779 MB of additional disk space will be used.""
So make sure you have a few GB's set aside if you're going to do this.



Okay so I got it working by following this: How to install the Pantheon desktop environment? Basically the PPA everyone is suggesting works, is 404-ing for me (and presumably you) when I try and access it.

1) This is syslinux-themes-elementary-isis, and the .sh script apparently requires it. Sudo apt-get didn't find it for me. You could probably test removing this dependency from the .sh if you are feeling bold. I installed amd64 version of this (as I am on 64 bit, if you are on 32 bit obviously don't), just use a .deb installer on Ubuntu:

https://launchpad.net/~elementary-os/+archive/daily/+files/syslinux-themes-elementary-isis_2-0%7E4%7Esaucy1_amd64.deb


2) This is required by the elementary os install script:

sudo apt-get install dctrl-tools dpkg-dev 
    genisoimage gfxboot-theme-ubuntu live-build squashfs-tools syslinux zsync


3) The script uses this to determine what files to download (obviously don't do both, amd64 is for 64bit and i386 is for 32 bit) (you'll want to put this in .bashrc or somewhere else for it to be permanent, not 100% anyone will ever need this again though):

export ARCH=amd64
export ARCH=i386


4) From the previous question/answer thread:

sudo apt-get install bzr
bzr branch lp:elementaryos
cd elementaryos
sudo congrego.sh


On my machine I didn't specify $ARCH so I got 90% of the way through a 970 M .iso file for i386 before I realised -_-.

Currently running through the amd64 installation.



As an aside:

# load config
source etc/congrego.conf

if [[ ""$ARCH"" == ""all"" ]]; then
        $(dirname ""$0"")/bin/download.sh i386
        $(dirname ""$0"")/bin/download.sh amd64
        $(dirname ""$0"")/bin/build.sh i386
        $(dirname ""$0"")/bin/build.sh amd64
        if [[ ""$SOURCEFORGE"" != """" ]]; then
            $(dirname ""$0"")/bin/sourceforge.sh i386
            $(dirname ""$0"")/bin/sourceforge.sh amd64
        fi
else
        $(dirname ""$0"")/bin/download.sh ""$ARCH""
        $(dirname ""$0"")/bin/build.sh ""$ARCH""
        $(dirname ""$0"")/bin/sourceforge.sh ""$ARCH""
fi


It is a bit presumptuous that users would have that environment variable set. Unless I am reading it wrong, it seems like it will download iso's for i386 AND amd64 and then build both of them, which sounds like a bad idea. I'm noob at bash script though so it could be fine for all I know.

Just in case this is irrelevant to your machine:

Linux mikeydesknix 3.11.0-19-generic #33-Ubuntu SMP Tue Mar 11 18:48:34 UTC 2014 
x86_64 x86_64 x86_64 GNU/Linux

[ mikey ][ 02:22:59 ]$lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 13.10
Release:    13.10
Codename:   saucy


--

Build Errors:

[2014-05-01 03:31:40] lb_chroot_hooks 
P: Begin executing hooks...
ERROR:root:DebFileApplication import
Traceback (most recent call last):
  File ""/usr/share/software-center/softwarecenter/db/__init__.py"", line 4, in &lt;module&gt;
    from debfile import DebFileApplication, DebFileOpenError
  File ""/usr/share/software-center/softwarecenter/db/debfile.py"", line 25, in &lt;module&gt;
    from softwarecenter.db.application import Application, AppDetails
  File ""/usr/share/software-center/softwarecenter/db/application.py"", line 28, in &lt;module&gt;
    import softwarecenter.distro
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 199, in &lt;module&gt;
    distro_instance = _get_distro()
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 174, in _get_distro
    module = __import__(distro_module_name, globals(), locals(), [], -1)
ImportError: No module named ""elementary os""
Traceback (most recent call last):
  File ""/usr/sbin/update-apt-xapian-index"", line 101, in &lt;module&gt;
    if not indexer.setupIndexing(force=opts.force, system=opts.pkgfile is None):
  File ""/usr/lib/python2.7/dist-packages/axi/indexer.py"", line 471, in setupIndexing
    self.plugins = Plugins(progress=self.progress, system=system)
  File ""/usr/lib/python2.7/dist-packages/axi/indexer.py"", line 94, in __init__
    addon = Addon(fullname, **kw)
  File ""/usr/lib/python2.7/dist-packages/axi/indexer.py"", line 49, in __init__
    self.module = imp.load_source(""axi.plugin_"" + self.name, fname)
  File ""/usr/share/apt-xapian-index/plugins/software_center.py"", line 13, in &lt;module&gt;
    from softwarecenter.db.update import (
  File ""/usr/share/software-center/softwarecenter/db/update.py"", line 33, in &lt;module&gt;
    from softwarecenter.backend.scagent import SoftwareCenterAgent
  File ""/usr/share/software-center/softwarecenter/backend/scagent.py"", line 28, in &lt;module&gt;
    from softwarecenter.distro import get_distro, get_current_arch
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 199, in &lt;module&gt;
    distro_instance = _get_distro()
  File ""/usr/share/software-center/softwarecenter/distro/__init__.py"", line 174, in _get_distro
    module = __import__(distro_module_name, globals(), locals(), [], -1)
ImportError: No module named ""elementary os""
E: chroot/root/lb_chroot_hooks/002-update-apt-xapian-index.chroot failed (exit non-zero). You should check for errors.
P: Begin unmounting filesystems...
P: Saving caches...
Reading package lists...
Building dependency tree...
Reading state information...
md5sum: binary.hybrid.iso: No such file or directory

"
2054,2054,3274,What is a sci-fi system that would feel familiar to reluctant Pathfinder players?,"For the last few months I've been running a Pathfinder campaign, and recently I told my players that I needed a break and they agreed on switching games for a few months. I'm a fan of the works of Isaac Asimov, Larry Niven and so on, and science fiction would be a great change of pace. So here is my opportunity! At last! Or not?

My problem is my players have never liked anything that isn't D&amp;D or Pathfinder. We're all well into the thirties, and the majority have a taste for long campaigns (they really enjoy character development) and some big differences about what we want in a game. The one player who's also a regular GM has a greater appreciation for new games, but the rest is usually scared off by words like ""indie"", and ""FATE"".

I ran a Traveller campaign years ago using GURPS. They hated GURPS. I took off the GURPS part and added ""Mongoose"". They hated Mongoose. I tried Diaspora. They hate FATE. I talked about Ringworld, but I found BRP is not a good system for sci-fi. Jovian Chronicles? ""It has to be as bad as Tribe 8."" (Their words, not mine). Every time I suggest anything that's not Pathfinder it's the same song.

Though I find Traveller good enough, obviously now it's not an option. My latest reading has been a game based on FUDGE (far enough from FATE) inspired by movies like Alien, Predator and alike. I fear a one-session campaign and new ""hate"". It has to be a game that fits my group. Right?

Of course it may be that there's no such game and I have to deal with my players instead, so ""There is no such game"" is an answer I'll reluctantly accept.
",Cazacurdas,https://rpg.stackexchange.com/users/7885,"The best way is to get buy-in from your players. One way of doing that is giving them a selection of games that you would enjoy and asking them to decide amongst themselves which to play. This leverages a bit of human psychology where we will invest in something more if we have a hand in choosing it, especially if, in the process of choosing it, we ever argue for its merits to a peer. Giving your players a choice of sci-fi games means that the one they pick will have at least a little bit of support from at least some of your players already built-in.

Pick three or four games and present them to your players. Say you're running one of these, but which is up to them. Don't defend the games if they disparage them, just ask them to pick the one they think they'll enjoy the most. (By not allowing them to make you a target of arguments, you prevent them from digging in their heels and deciding preemptively they'll hate it.) If they hate it, well, they chose it. Which specific games you present them is up to you, but if I were doing this and trying hard to keep them all as appealing to dedicated Pathfinder players as possible, I would include at least one of these three if not all of them:


Stars Without Number is based on an older edition of D&amp;D, so it's as close as you will come to the feel of Pathfinder, mechanically, as a science-fiction system can get. As a bonus, it's free, and if your players like it, it's very well supported with for-pay supplements and print books.

As a fan of Traveller, you should find the GM's side of SWN to be pleasantly familiar too. It's built to accommodate a system-hopping game or a campaign that stays on one world, and the ""tags"" system for setting development means you have a constant supply of new ideas at the roll of a die. It will work for a one-shot as well as Pathfinder would â possibly better, because new characters are not quite as complicated, and it gives you tools for quickly ""statting up"" a world.
Thousand Suns is exactly aimed at re-creating the genre of Isaac Aasimov, Niven, Pournelle, and their kindred in classic science fiction. Written by a luminary of classic D&amp;D blogging, James Maliszewski of Grognardia, it's a straightforward system that still has its roots in D&amp;D, so it doesn't ask players coming from a d20 background to make a paradigm shift in ""how RPGs work"" like Fate does, and it doesn't have the explosion of complexity (compared to d20) that GURPS or BRP does. It has stats with unfamiliar names but familiar function, and a skill system that should feel familiar enough to them.
d20 Future is going to be very familiar to your players. It's a bit more generic in that it's aimed at creating all kinds of sci-fi, not just the sort written by the authors you mention, but it will do the job. Being a supplement to d20 Modern it does require more books, but the breadth of character options will probably be welcome to your players, since lots of ""chunky"" character build options (as opposed to the fine-grained ones of GURPS, et. al.) is one of the big draws of d20 for its dedicated fans. d20 Future and Modern both have SRDs online, which somewhat makes up for the extra materials you need by making them free.


I strongly suggestion one of those, but the most important part is to give them a shortlist of games you're willing to run and then make the decision theirs. They've already agreed to a change of game, and it's only for a short time, so they should at least be able to agree on one they think they won't hate.

And if they do hate it, all is not lost: you've played a bit of a game you want to play, and you've burned only one of thousands of games that you could try. Really, you could keep trying one-shots of strange new games regularly, and it would take you decades to go through even a fraction of the RPGs currently published, and there are more every year; so don't worry too much if they hate it. Enjoy it yourself, and give them some agency in the choice, and it will all turn out in the end.
",SevenSidedDie,https://rpg.stackexchange.com/users/321,http://rpg.stackexchange.com/questions/24444/what-is-a-sci-fi-system-that-would-feel-familiar-to-reluctant-pathfinder-players,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.5,0.0,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.6666666666666666,1.0,What is the familiar science fiction system for reluctant Pathfinder players?,"For the last few months I've been running a Pathfinder campaign, and recently I told my players that I needed a break and they agreed on switching games for a few months. I'm a fan of the works of Isaac Asimov, Larry Niven and so on, and science fiction would be a great change of pace. So here is my opportunity! At last! Or not?

My problem is my players have never liked anything that isn't D&amp;D or Pathfinder. We're all well into the thirties, and the majority have a taste for long campaigns (they really enjoy character development) and some big differences about what we want in a game. The one player who's also a regular GM has a greater appreciation for new games, but the rest is usually scared off by words like ""indie"", and ""FATE"".

I ran a Traveller campaign years ago using GURPS. They hated GURPS. I took off the GURPS part and added ""Mongoose"". They hated Mongoose. I tried Diaspora. They hate FATE. I talked about Ringworld, but I found BRP is not a good system for sci-fi. Jovian Chronicles? ""It has to be as bad as Tribe 8."" (Their words, not mine). Every time I suggest anything that's not Pathfinder it's the same song.

Though I find Traveller good enough, obviously now it's not an option. My latest reading has been a game based on FUDGE (far enough from FATE) inspired by movies like Alien, Predator and alike. I fear a one-session campaign and new ""hate"". It has to be a game that fits my group. Right?

Of course it may be that there's no such game and I have to deal with my players instead, so ""There is no such game"" is an answer I'll reluctantly accept.
","The best way is to get buy-in from your players. One way of doing that is giving them a selection of games that you would enjoy and asking them to decide amongst themselves which to play. This leverages a bit of human psychology where we will invest in something more if we have a hand in choosing it, especially if, in the process of choosing it, we ever argue for its merits to a peer. Giving your players a choice of sci-fi games means that the one they pick will have at least a little bit of support from at least some of your players already built-in.

Pick three or four games and present them to your players. Say you're running one of these, but which is up to them. Don't defend the games if they disparage them, just ask them to pick the one they think they'll enjoy the most. (By not allowing them to make you a target of arguments, you prevent them from digging in their heels and deciding preemptively they'll hate it.) If they hate it, well, they chose it. Which specific games you present them is up to you, but if I were doing this and trying hard to keep them all as appealing to dedicated Pathfinder players as possible, I would include at least one of these three if not all of them:


Stars Without Number is based on an older edition of D&amp;D, so it's as close as you will come to the feel of Pathfinder, mechanically, as a science-fiction system can get. As a bonus, it's free, and if your players like it, it's very well supported with for-pay supplements and print books.

As a fan of Traveller, you should find the GM's side of SWN to be pleasantly familiar too. It's built to accommodate a system-hopping game or a campaign that stays on one world, and the ""tags"" system for setting development means you have a constant supply of new ideas at the roll of a die. It will work for a one-shot as well as Pathfinder would â possibly better, because new characters are not quite as complicated, and it gives you tools for quickly ""statting up"" a world.
Thousand Suns is exactly aimed at re-creating the genre of Isaac Aasimov, Niven, Pournelle, and their kindred in classic science fiction. Written by a luminary of classic D&amp;D blogging, James Maliszewski of Grognardia, it's a straightforward system that still has its roots in D&amp;D, so it doesn't ask players coming from a d20 background to make a paradigm shift in ""how RPGs work"" like Fate does, and it doesn't have the explosion of complexity (compared to d20) that GURPS or BRP does. It has stats with unfamiliar names but familiar function, and a skill system that should feel familiar enough to them.
d20 Future is going to be very familiar to your players. It's a bit more generic in that it's aimed at creating all kinds of sci-fi, not just the sort written by the authors you mention, but it will do the job. Being a supplement to d20 Modern it does require more books, but the breadth of character options will probably be welcome to your players, since lots of ""chunky"" character build options (as opposed to the fine-grained ones of GURPS, et. al.) is one of the big draws of d20 for its dedicated fans. d20 Future and Modern both have SRDs online, which somewhat makes up for the extra materials you need by making them free.


I strongly suggestion one of those, but the most important part is to give them a shortlist of games you're willing to run and then make the decision theirs. They've already agreed to a change of game, and it's only for a short time, so they should at least be able to agree on one they think they won't hate.

And if they do hate it, all is not lost: you've played a bit of a game you want to play, and you've burned only one of thousands of games that you could try. Really, you could keep trying one-shots of strange new games regularly, and it would take you decades to go through even a fraction of the RPGs currently published, and there are more every year; so don't worry too much if they hate it. Enjoy it yourself, and give them some agency in the choice, and it will all turn out in the end.
"
2127,2127,3387,How can I make my iPad apps retina in Xcode 5 iOS7,"Not long ago I started learning Objective-C with an interest of developing apps. I have just started my first app and I have no clue how to make my app retina. I made the design in photoshop and exported it as a png @ 2,048 x 1,536 but however the size of my storyboard is only 1,024 x 768. I have read somewhere on the internet that you need two story boards but I am not sure how to link everything together. I would really appreciate it if someone could help me.
",user2989426,https://stackoverflow.com/users/2989426,"What is Retina Display

@1X is a resolution (or rather, a process) in which many designers still design apps. Why? Because (and as many would have to agree) designing at such is much more tangible. I find it hard to explain why itâs so, but all I can say is that the content feels much more 1 on 1, it feels right so to speak, and the design is much more flexible to deal with, because of our âlowâ resolution computer displays that weâre designing them on.
Though that doesnât mean we all like designing @1X. Iâve seen many others who build wonderful, beautiful apps designing at both processes (the other would have to be @2X â resolution of that of the Retina Display) and some say it feels much more comfortable for them having to have their content match perfectly without having to scale things up and tweak things around on the display.

More Dtails 2x-the-retina-dilemma

How identify the retina display

#define IS_RETINA_DISPLAY ([[UIScreen mainScreen] respondsToSelector:@selector(displayLinkWithTarget:selector:)] &amp;&amp; ([UIScreen mainScreen].scale == 2.0))

if(IS_RETINA_DISPLAY)
{
   // RETINA_DISPLAY 
}else{
  // NON_RETINA_DISPLAY 
}


Now, that the iPad has been released, Iâm sure you are all scrambling for ideas on how to snag a piece of the market in the imminent gold rush. some of below links is going to help you on your journey with a series of iPad tutorials to come.

ipad-programming-tutorial-hello-world

How-To-Develop-iPad-Apps
",codercat,https://stackoverflow.com/users/1650785,http://stackoverflow.com/questions/21129482/how-can-i-make-my-ipad-apps-retina-in-xcode-5-ios7,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.5,0.3333333333333333,0.5,0.5,0.3,0.6666666666666666,0.0,0.3333333333333333,0.5,How to make my iPad app retina in Xcode 5ios7,"Not long ago, I began to learn Objective-C, interested in developing applications. I've just started my first app, and I don't know how to make my app retina. I did this design in Photoshop and exported it as PNG @ 2048x 1536, but my storyboard is only 1024x768. I read on the Internet that you need a two-story blackboard, but I don't know how to connect everything. I would appreciate it if someone could help me.","What is Retina Display

@1X is a resolution (or rather, a process) in which many designers still design apps. Why? Because (and as many would have to agree) designing at such is much more tangible. I find it hard to explain why itâs so, but all I can say is that the content feels much more 1 on 1, it feels right so to speak, and the design is much more flexible to deal with, because of our âlowâ resolution computer displays that weâre designing them on.
Though that doesnât mean we all like designing @1X. Iâve seen many others who build wonderful, beautiful apps designing at both processes (the other would have to be @2X â resolution of that of the Retina Display) and some say it feels much more comfortable for them having to have their content match perfectly without having to scale things up and tweak things around on the display.

More Dtails 2x-the-retina-dilemma

How identify the retina display

#define IS_RETINA_DISPLAY ([[UIScreen mainScreen] respondsToSelector:@selector(displayLinkWithTarget:selector:)] &amp;&amp; ([UIScreen mainScreen].scale == 2.0))

if(IS_RETINA_DISPLAY)
{
   // RETINA_DISPLAY 
}else{
  // NON_RETINA_DISPLAY 
}


Now, that the iPad has been released, Iâm sure you are all scrambling for ideas on how to snag a piece of the market in the imminent gold rush. some of below links is going to help you on your journey with a series of iPad tutorials to come.

ipad-programming-tutorial-hello-world

How-To-Develop-iPad-Apps
"
2395,2395,3824,"Are DSLRs a dying breed, making now the time to switch to a mirrorless camera system?","I came across this thought provoking article on Stuck in Customs today that makes a strong case to hold off too much investment in DSLR gear, and instead switch to mirror-less cameras like the Sony NEX. The author prefers to call such cameras 3rd generation cameras to prevent any bias.

The crux of the argument lies in the smaller size and faster shooting speeds of the new cameras, while the sensor size is an area where they seem to be lacking (Sony &amp; Samsung cameras are APS-C sized though). Currently the big makers - Nikon &amp; Canon - have practically no presence in this market (Nikon seems to be doing something with the V1). However, they seem to have slowed down the introduction of new entry level DSLR models over the last year as well.

So, as DSLR users looking to build and enhance their kit (there are many like me who've jumped the bandwagon over the last couple of years, and are just starting to build their kit), what are the advantages of sticking with the DSLR system rather than switching to the 3rd gen cameras?

IMO, one point that could cause a massive switch in the DSLR base would be if Nikon &amp; Canon announced mirror-less models compatible with their current lens lineups, but that is a hypothetical scenario.

P.S. There is a similar question on mirror-less cameras, but that seems to be from the perspective of a person starting out rather than a person already invested in the DSLR system.
",ab.aditya,https://photo.stackexchange.com/users/1977,"The advantages of DSLR are going to be usage specific as well as product line specific.  It depends on what you are doing with your photographing.  It also depends on the state of the market in terms of what products will be available, in the new systems that will eventually replace the current DSLR systems (specifically the mount size, focal plane distance, and sensor size).  Premium cameras with a larger focal plane exist because there is an advantage to that which mean photographers want and can work with.  Others are not even DSLR and are considered high-end Pro.  Look at cameras by Hasselblad, Leica, and Mamiya.  You can see both formats larger than ""full frame"" and lens mounts that don't need to make room for a mirror.  They have their advantages, too.

I think a new format will eventually emerge that does not exist today.  It will be larger than the 4/3rds system because of the advantages of a larger sensor regarding noise.  But it might not dominate because digital sensors have fairly well leveled the playing field as phone cameras clearly prove.  I hope this new format is just the same 35mm based full frame related sizing, with a closer lens mount which can support an extender adapter to accept ""older reflex style"" lenses.
",Skaperen,https://photo.stackexchange.com/users/6964,http://photo.stackexchange.com/questions/18940/are-dslrs-a-dying-breed-making-now-the-time-to-switch-to-a-mirrorless-camera-sy,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,1.0,0.8888888888888888,SLR is a dying breed that makes the current time switch to a mirror less camera system?,"I came across this thought provoking article on Stuck in Customs today that makes a strong case to hold off too much investment in DSLR gear, and instead switch to mirror-less cameras like the Sony NEX. The author prefers to call such cameras 3rd generation cameras to prevent any bias.

The crux of the argument lies in the smaller size and faster shooting speeds of the new cameras, while the sensor size is an area where they seem to be lacking (Sony &amp; Samsung cameras are APS-C sized though). Currently the big makers - Nikon &amp; Canon - have practically no presence in this market (Nikon seems to be doing something with the V1). However, they seem to have slowed down the introduction of new entry level DSLR models over the last year as well.

So, as DSLR users looking to build and enhance their kit (there are many like me who've jumped the bandwagon over the last couple of years, and are just starting to build their kit), what are the advantages of sticking with the DSLR system rather than switching to the 3rd gen cameras?

IMO, one point that could cause a massive switch in the DSLR base would be if Nikon &amp; Canon announced mirror-less models compatible with their current lens lineups, but that is a hypothetical scenario.

P.S. There is a similar question on mirror-less cameras, but that seems to be from the perspective of a person starting out rather than a person already invested in the DSLR system.
","The advantages of DSLR are going to be usage specific as well as product line specific.  It depends on what you are doing with your photographing.  It also depends on the state of the market in terms of what products will be available, in the new systems that will eventually replace the current DSLR systems (specifically the mount size, focal plane distance, and sensor size).  Premium cameras with a larger focal plane exist because there is an advantage to that which mean photographers want and can work with.  Others are not even DSLR and are considered high-end Pro.  Look at cameras by Hasselblad, Leica, and Mamiya.  You can see both formats larger than ""full frame"" and lens mounts that don't need to make room for a mirror.  They have their advantages, too.

I think a new format will eventually emerge that does not exist today.  It will be larger than the 4/3rds system because of the advantages of a larger sensor regarding noise.  But it might not dominate because digital sensors have fairly well leveled the playing field as phone cameras clearly prove.  I hope this new format is just the same 35mm based full frame related sizing, with a closer lens mount which can support an extender adapter to accept ""older reflex style"" lenses.
"
970,970,1536,How to configure ssh tunneling with Putty between two RHEL servers?,"I'm trying to allow ssh access from a remote RHEL server to a local RHEL box via Win/Putty gateway. Basically, I'd like to be able to do 'ssh localhost -p 512' on a remote server so that it would connect to the RHEL server in the local network. The local network is beyond a firewall so I can connect from my Win PC to the remote server with Putty/ssh but not vice verse.

LclSrv----WinXP/Putty-----||-----RmtSrv

So, I've added the following tunneling settings to the current RmtSrv session in Putty (actually I use Kitty but doesn't matter):

R512 LclSrv:22

I expect that this would create a process on the remote server that listens port 512 and transfers the connections to a local network/LclSrv port 22.

After pressing start button, Putty opens a regular ssh terminal session successfully but nothing happens. (options show active port forwarding). I've checked with netstat -l that port 512 is not listening on RmtSrv. ssh on this port returns 'connection refused'. What am I doing wrong? May be there is something in the sshd_config that needs to be changed in order to allow the tunneling? Could it be user privileges on RmtSrv that prevents me from creating tunnels? I have sudo btw.

Cheers, Vlad.
",spoonboy,https://serverfault.com/users/201265,"On the left side of the Putty window you have a Menu. On it, SSH has a + to its left. Click there. Go to Tunnels. Configure them. VoilÃ .
",Envite,https://serverfault.com/users/199641,http://serverfault.com/questions/558831,TECHNOLOGY,serverfault.com,0.7777777777777778,0.7777777777777778,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,How to use putty to configure SSH tunnel between two RHEL servers?,"I'm trying to allow ssh access from a remote RHEL server to a local RHEL box via Win/Putty gateway. Basically, I'd like to be able to do 'ssh localhost -p 512' on a remote server so that it would connect to the RHEL server in the local network. The local network is beyond a firewall so I can connect from my Win PC to the remote server with Putty/ssh but not vice verse.

LclSrv----WinXP/Putty-----||-----RmtSrv

So, I've added the following tunneling settings to the current RmtSrv session in Putty (actually I use Kitty but doesn't matter):

R512 LclSrv:22

I expect that this would create a process on the remote server that listens port 512 and transfers the connections to a local network/LclSrv port 22.

After pressing start button, Putty opens a regular ssh terminal session successfully but nothing happens. (options show active port forwarding). I've checked with netstat -l that port 512 is not listening on RmtSrv. ssh on this port returns 'connection refused'. What am I doing wrong? May be there is something in the sshd_config that needs to be changed in order to allow the tunneling? Could it be user privileges on RmtSrv that prevents me from creating tunnels? I have sudo btw.

Cheers, Vlad.
","On the left side of the Putty window you have a Menu. On it, SSH has a + to its left. Click there. Go to Tunnels. Configure them. VoilÃ .
"
4219,4219,6730,What lightweight telephoto lens are available for Nikon bodies?,"I'm looking for a lightweight telephoto lens for my Nikon D700 body, with a focal length around 300mm, good sharpness and AF. After several days with the 70-200 vrII handheld, I found this lens too big and heavy. I usually prefer the prime lenses, but all the good ~300mm prime I know weight 1.5kg or more.

I will use it mostly for sport, wildlife and landscape. A bonus point if it is bright enough for a use in dark concert stages :)

The only two lightweight options I considered for now are


Nikon 70-300mm VR (750g, F5.6@300mm)
Nikon 180mm (760g) + 1.4x TC (F4@250mm)


Have you any recommandation on these possibilities ? e.g. with third party lenses.
I'm in love with my 85mm 1.4G, but I have the feeling that I won't be able to get the same quality at 300mm without carrying expensive kilos of glasses.
",Emile,https://photo.stackexchange.com/users/13738,"This 300mm seems to be lightweight (755g), but definitely not cheap! http://www.bhphotovideo.com/c/product/1111442-REG/nikon_2223_af_s_nikkor_300mm_f_4e.html
",gatoatigrado,https://photo.stackexchange.com/users/35576,http://photo.stackexchange.com/questions/31099/what-lightweight-telephoto-lens-are-available-for-nikon-bodies,LIFE_ARTS,photo.stackexchange.com,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.7777777777777778,0.7333333333333333,0.0,0.0,0.0,0.7777777777777778,What kind of light telephoto lens does Nikon have?,"I'm looking for a lightweight telephoto lens for my Nikon D700 body, with a focal length around 300mm, good sharpness and AF. After several days with the 70-200 vrII handheld, I found this lens too big and heavy. I usually prefer the prime lenses, but all the good ~300mm prime I know weight 1.5kg or more.

I will use it mostly for sport, wildlife and landscape. A bonus point if it is bright enough for a use in dark concert stages :)

The only two lightweight options I considered for now are


Nikon 70-300mm VR (750g, F5.6@300mm)
Nikon 180mm (760g) + 1.4x TC (F4@250mm)


Have you any recommandation on these possibilities ? e.g. with third party lenses.
I'm in love with my 85mm 1.4G, but I have the feeling that I won't be able to get the same quality at 300mm without carrying expensive kilos of glasses.
","This 300 mm looks light (755g), but it's definitely not cheap! http://www.bhphotovideo.com/c/product/1111442-REG/nikon_Ã´u afÃ´u nikkorÃ´u 300Ã´u fÃ´e.html"
794,794,1260,"Can I delete my fork of a BitBucket repository, after the owner has accepted and merged my pull request?","I created a fork of a public repository on BitBucket, with the sole purpose of committing a pull request that fixed some bug. The pull request was accepted and merged. Now, I want to delete the repository, that has outlived its purpose. If I do that, will the changes be lost?

There is already a question about this same issue, but for GitHub. Apparently, on GitHub you can delete the repository before the request has been even merged, as it gets automatically saved in the target repository. I guess that on BitBucket, things will be similar, but I wanted to be sure.
",user8792354,https://stackoverflow.com/users/3497081,"I'm not sure if you could do it before it's merged, but you certainly should be able to afterwards.
",Peter O'Callaghan,https://stackoverflow.com/users/401446,http://stackoverflow.com/questions/22857212/can-i-delete-my-fork-of-a-bitbucket-repository-after-the-owner-has-accepted-and,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.0,0.0,1.0,Can I delete the fork of my bitbucket repository after the owner accepts and merges my pull request?,"I created a fork of a public repository on BitBucket, with the sole purpose of committing a pull request that fixed some bug. The pull request was accepted and merged. Now, I want to delete the repository, that has outlived its purpose. If I do that, will the changes be lost?

There is already a question about this same issue, but for GitHub. Apparently, on GitHub you can delete the repository before the request has been even merged, as it gets automatically saved in the target repository. I guess that on BitBucket, things will be similar, but I wanted to be sure.
","I'm not sure if you could do it before it's merged, but you certainly should be able to afterwards.
"
5972,5972,9470,Declaring a globally-visible array in CodeIgniter for routing,"(Totally new to CodeIgniter and php, not new to programming)

In CodeIgniter, how or where can I declare an array that will be accessible in the router (CI_Router), in my custom controller and in the view loader (CI_Loader)? I want to avoid hard-coding data in the router and specifying the same data more than once (in the router and in the controller and/or view).

(Explanation follows; perhaps there is a better way to do what I'm trying to do.)

I have a site where I publish my freeware apps. The site is all static, but maintaining plain html by hand is a nightmare, so I'm trying to use CodeIgniter to generate the pages dynamically. Apart from a few loose ends like 'welcome' or 'contact info', the bulk of the site consists of highly structured application sections. Each app has the same set of pages: about, download, screenshots, etc. These pages all have the same exact layout and only differ in contents.

My main concern is maintainability and the amount of work that required to add a new app (or a new page for all apps). I see no reason to use multiple controllers (or even multiple views), because the only difference is in data (application identifiers), not in behavior or page layout.

My problem is with routing. I could do something like

$route['app1'] = 'main/apps/app1';
$route['app2'] = 'main/apps/app2';


...or loop over an array of app identifiers, but that seems really bad. When I add an application, I should not have to modify the router, since it's just another identifier added to a list, that will be used to pick page contents from an appropriate file.

What I would like to do instead is (pseudocode):

foreach (app in list_of_apps) {
  foreach (app_page in list_of_pages) {
    route['app/app_page'] = 'main/index/app/app_page'
  }
}


This would take care of all requests for 'app1/download' or 'app2/screenshots', etc. So where can I declare the arrays $list_of_apps and $list_of_pages so that they are visible in the router, in the controller, and later in view as well?
",Marek JedliÅski,https://stackoverflow.com/users/9226,"This should be a simple regular expressions solution:

// set this to whatever controller/method you want as the index for the app
$route['([^/])']      = 'main/apps/$1';

// this is a sample ""subpage"" handler
$route['([^/])/(.*)'] = 'main/index/$1/$2';


If all ""apps"" follow the same URL structure, it shouldn't be too hard to make this very modular.
",landons,https://stackoverflow.com/users/206881,http://stackoverflow.com/questions/8766536/declaring-a-globally-visible-array-in-codeigniter-for-routing,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Declare a globally visible array for routing in CodeIgniter,"(Totally new to CodeIgniter and php, not new to programming)

In CodeIgniter, how or where can I declare an array that will be accessible in the router (CI_Router), in my custom controller and in the view loader (CI_Loader)? I want to avoid hard-coding data in the router and specifying the same data more than once (in the router and in the controller and/or view).

(Explanation follows; perhaps there is a better way to do what I'm trying to do.)

I have a site where I publish my freeware apps. The site is all static, but maintaining plain html by hand is a nightmare, so I'm trying to use CodeIgniter to generate the pages dynamically. Apart from a few loose ends like 'welcome' or 'contact info', the bulk of the site consists of highly structured application sections. Each app has the same set of pages: about, download, screenshots, etc. These pages all have the same exact layout and only differ in contents.

My main concern is maintainability and the amount of work that required to add a new app (or a new page for all apps). I see no reason to use multiple controllers (or even multiple views), because the only difference is in data (application identifiers), not in behavior or page layout.

My problem is with routing. I could do something like

$route['app1'] = 'main/apps/app1';
$route['app2'] = 'main/apps/app2';


...or loop over an array of app identifiers, but that seems really bad. When I add an application, I should not have to modify the router, since it's just another identifier added to a list, that will be used to pick page contents from an appropriate file.

What I would like to do instead is (pseudocode):

foreach (app in list_of_apps) {
  foreach (app_page in list_of_pages) {
    route['app/app_page'] = 'main/index/app/app_page'
  }
}


This would take care of all requests for 'app1/download' or 'app2/screenshots', etc. So where can I declare the arrays $list_of_apps and $list_of_pages so that they are visible in the router, in the controller, and later in view as well?
","This should be a simple regular expressions solution:

// set this to whatever controller/method you want as the index for the app
$route['([^/])']      = 'main/apps/$1';

// this is a sample ""subpage"" handler
$route['([^/])/(.*)'] = 'main/index/$1/$2';


If all ""apps"" follow the same URL structure, it shouldn't be too hard to make this very modular.
"
1015,1015,1602,What is the purpose of iron bars in concrete?,"What purpose do iron rods in concrete serve? 
Do these iron rods impart any strength to the concrete apart from defining the framework for the concrete to solidify upon initially?
",Everyone,https://physics.stackexchange.com/users/5265,"To expand a bit on Ignacio's answer: he's refering to pre-stressed concrete. The idea is to put the metal rods (rebars) under tension then allow the concrete to set around them. Once the concrete has set you release the tension on the rebars and the rebars then exert a compression force on the concrete. This allows the concrete to deal better with stretching forces. As Ignacio says, un-prestressed concrete is weak under tension.

You also see unstressed metal grids being used when concrete is being poured. I'm not sure what benefit you get from these except that they stop cracks in the concrete from compromising the whole structure.
",John Rennie,https://physics.stackexchange.com/users/1325,http://physics.stackexchange.com/questions/31357/what-is-the-purpose-of-iron-bars-in-concrete,SCIENCE,physics.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,What is the role of reinforcement in concrete?,"What purpose do iron rods in concrete serve? 
Do these iron rods impart any strength to the concrete apart from defining the framework for the concrete to solidify upon initially?
","To expand a bit on Ignacio's answer: he's refering to pre-stressed concrete. The idea is to put the metal rods (rebars) under tension then allow the concrete to set around them. Once the concrete has set you release the tension on the rebars and the rebars then exert a compression force on the concrete. This allows the concrete to deal better with stretching forces. As Ignacio says, un-prestressed concrete is weak under tension.

You also see unstressed metal grids being used when concrete is being poured. I'm not sure what benefit you get from these except that they stop cracks in the concrete from compromising the whole structure.
"
1349,1349,2125,Controlling smoke/fire emision amount,"It is possible to animate the emission of the smoke in smoke sim? I tried to insert keyframes in the fuelAmmount propierty in the flow object but it didn't work.
Thanks.
",Hikaru Ai,https://blender.stackexchange.com/users/384,"Controlling the amount of fire by keyframing the Flame Rate works for me:



However it doesn't affect the smoke.

To affect the smoke as well, you could try animating the Volume Factor:


",gandalf3,https://blender.stackexchange.com/users/599,http://blender.stackexchange.com/questions/7409/controlling-smoke-fire-emision-amount,TECHNOLOGY,blender.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Control smoke / fire emission,"Is it possible to animate smoke emission in smoke SIM? I tried to insert a key in the fuelamount propeller in the flow object, but it didn't work.","Controlling the amount of fire by keyframing the Flame Rate works for me:



However it doesn't affect the smoke.

To affect the smoke as well, you could try animating the Volume Factor:


"
4918,4918,7830,"Is there any way to customize vmware's ""Easy Install"" of ubuntu?","VMWare has a feature when creating new VMs called Easy Install, that will show you a small wizard asking you the minimum things needed and then will install the entire OS without you needing to do anything.

When installing Ubuntu server, it only asks you the details of the default user (Full name, username, password and repeat password) and then installs ubuntu with the default options and packages.

I'd like to know if I can tell it to install some extra packages, run custom commands before finishing the installation or using another apt repository than the default one.

BTW if it matters, I'm using VMware Player 5.0.0 on Ubuntu 11.10 amd64, and I'm planning to install Ubuntu 11.10 amd64 server as a guest.
",Carlos CampderrÃ³s,https://superuser.com/users/126729,"I'm totally pasting this so its probably wrong-ish but you can find the location of the easy install iso and modify it.
VMware has a command 

C:\Program Files (x86)\VMware\VMware Workstation\mkisofs.exe


or

/usr/lib/vmware/bin/mkisofs


Apparently Linux system versions of the command may not do the right job

mount -o loop  /apps/vmware/a1/autoinst.iso /mnt/vmtest
cp -Rf /mnt/vmtest/* /where/ever

# On windows just use 7zip or something to extract iso.


Modify ks.cfg, google for more help here.

cd into /where/ever

/&lt;pathto VMware's&gt;/mkisofs -o 'autoinst.iso' -b 'isolinux/isolinux.bin' -c 'isolinux/boot.cat' -no-emul-boot  -boot-load-size 4 -boot-info-table 'boot'


I knew about this cause I tried it ages ago but this is a shameless paste/hack of https://communities.vmware.com/thread/292368

It may be all wrong but they said to use the VMware mkisofs.

I'm making this a wiki so someone can make right any mistakes but read the link if for real world example.
",sabgenton,https://superuser.com/users/85034,http://superuser.com/questions/495295,TECHNOLOGY,superuser.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,"Is there any way to customize Ubuntu ""easy install"" for VMware?","VMWare has a feature when creating new VMs called Easy Install, that will show you a small wizard asking you the minimum things needed and then will install the entire OS without you needing to do anything.

When installing Ubuntu server, it only asks you the details of the default user (Full name, username, password and repeat password) and then installs ubuntu with the default options and packages.

I'd like to know if I can tell it to install some extra packages, run custom commands before finishing the installation or using another apt repository than the default one.

BTW if it matters, I'm using VMware Player 5.0.0 on Ubuntu 11.10 amd64, and I'm planning to install Ubuntu 11.10 amd64 server as a guest.
","I'm totally pasting this so its probably wrong-ish but you can find the location of the easy install iso and modify it.
VMware has a command 

C:\Program Files (x86)\VMware\VMware Workstation\mkisofs.exe


or

/usr/lib/vmware/bin/mkisofs


Apparently Linux system versions of the command may not do the right job

mount -o loop  /apps/vmware/a1/autoinst.iso /mnt/vmtest
cp -Rf /mnt/vmtest/* /where/ever

# On windows just use 7zip or something to extract iso.


Modify ks.cfg, google for more help here.

cd into /where/ever

/&lt;pathto VMware's&gt;/mkisofs -o 'autoinst.iso' -b 'isolinux/isolinux.bin' -c 'isolinux/boot.cat' -no-emul-boot  -boot-load-size 4 -boot-info-table 'boot'


I knew about this cause I tried it ages ago but this is a shameless paste/hack of https://communities.vmware.com/thread/292368

It may be all wrong but they said to use the VMware mkisofs.

I'm making this a wiki so someone can make right any mistakes but read the link if for real world example.
"
5018,5018,7992,When to Use WCF / REST,"I am new to REST. I was reading many article about REST. Still I am confused and do not know exact reason when we should go for REST rather than WCF traditional services.
",Shailesh,https://stackoverflow.com/users/673039,"I don't think the two are mutually exclusive, see this question which has pointers to many other interesting posts on WCF and REST. In terms of whether or not you need to expose a RESTful service at all, that depends on your application.

If you are building a public API, using REST with JSON or XML is popular in part because it's a very generic way to expose an API since clients don't generally need to generate code to use your API. Whereas with something like SOAP, code generation for the client is a lot more standard. If your clients are javascript, for instance, it's quite easy to use a RESTful service. If your API is only for internal consumption (i.e. you own the client and the server), then the benefits of REST are somewhat diminished, and it may be easier to use something like WCF.

In general, REST is a good choice when you don't mind being limited to HTTP, your service endpoints can be described well using RESTful concepts, you don't need a contract (like a WSDL), and when you don't want to worry that a client of your service won't be supported for technical reasons.

I've used RESTful web services as a reference in the past, it's a great book.
",Paul Sanwald,https://stackoverflow.com/users/344155,http://stackoverflow.com/questions/5405533/when-to-use-wcf-rest,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,When to use WCF / rest,"I'm new here to rest. I read a lot about rest. However, I'm still confused about when we should take a rest, rather than the exact reason for WCF's traditional services.","I don't think the two are mutually exclusive, see this question which has pointers to many other interesting posts on WCF and REST. In terms of whether or not you need to expose a RESTful service at all, that depends on your application.

If you are building a public API, using REST with JSON or XML is popular in part because it's a very generic way to expose an API since clients don't generally need to generate code to use your API. Whereas with something like SOAP, code generation for the client is a lot more standard. If your clients are javascript, for instance, it's quite easy to use a RESTful service. If your API is only for internal consumption (i.e. you own the client and the server), then the benefits of REST are somewhat diminished, and it may be easier to use something like WCF.

In general, REST is a good choice when you don't mind being limited to HTTP, your service endpoints can be described well using RESTful concepts, you don't need a contract (like a WSDL), and when you don't want to worry that a client of your service won't be supported for technical reasons.

I've used RESTful web services as a reference in the past, it's a great book.
"
3931,3931,6270,How to Investigate Wi-Fi Intrusion and where to look for evidence?,"I'm trying to figure out how to configure a network so that I can tell what an intruder did (in the past) while on the network after they are detected. 
eg. If someone with a wi-fi enabled laptop parked outside my home and connected to my home network because he was able to crack my weak encryption. and if he were to do some fraudulent activity from my network, how can I configure my network and where would I have to look on the network to see what he was up to?
What devices would be able to log valuable information and how would I make sense of this information?
",Tony,https://security.stackexchange.com/users/18344,"Since I now know your question is theoretical, I can answer it better about how you can setup your network so you would be able to tell.  The exact way of setting it up will vary from device to device, but there are a lot of options available.  The key is that you need a device capable of logging that is in a location on the network that everything the person does will go through it.

For an average home network, this could be either the Wireless Access Point, the Router or if applicable, the gateway or firewall.  The wireless access point will get the information right as they get on to the network and will ensure that all activity coming in on the wireless network is logged, but if they were to use their wireless connection to compromise a wired system and then use the wired system, you would have an incomplete log.

Most likely the Router also serves as the gateway and firewall (the device that gives the rest of the network access to the Internet and ensures the Internet doesn't have unintended access to the private network).  Logging at the gateway and/or firewall ensures that all outbound traffic is logged, but won't tell you anything about what the intruder did internally on your network.

In most home networks, since there is only one router and it also generally serves as wireless access point, gateway and firewall, it will end up being privy to all connections flowing across the network.  It may not have access to all the contents of the packets it routes (if encryption is used) but it at least (by necessity) has access to the routing information (ie, where it is coming from and where it is going).  This is likely the best place in a home network to log.

Most consumer routers do not have this kind of logging by default, however third party firmwares such as DD-WRT often add logging capability to the routers that can either write to an internal store (limited space) or a network share.  Exactly what information can be stored and how it is formatted varies from device to device, but in general information like the IP and MAC Address of the client as well as the requested destination IP, Port and protocol (such as TCP or UDP) as well as a timestamp can give you a lot of what you need to get at least a general idea of what was going on.

If space is no object, it may even be possible to log the content of every packet sent across the network, but that will be a huge amount of space and it may not be safe to exclude ""known"" MAC addresses from the logging to try and reduce the amount since MAC spoofing is fairly easy on a wireless network.  (IE, the intruder can make themselves look like a valid machine)  Of course, if you are going to this kind of length, you could also do a per machine certificate and/or not use a weak key at which point the problem would likely be avoided in the first place.
",AJ Henderson,https://security.stackexchange.com/users/12578,http://security.stackexchange.com/questions/26467/how-to-investigate-wi-fi-intrusion-and-where-to-look-for-evidence,TECHNOLOGY,security.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,How to investigate Wi Fi intrusion and where to find evidence?,"I'm trying to figure out how to configure a network so that I can tell what an intruder did (in the past) while on the network after they are detected. 
eg. If someone with a wi-fi enabled laptop parked outside my home and connected to my home network because he was able to crack my weak encryption. and if he were to do some fraudulent activity from my network, how can I configure my network and where would I have to look on the network to see what he was up to?
What devices would be able to log valuable information and how would I make sense of this information?
","Since I now know your question is theoretical, I can answer it better about how you can setup your network so you would be able to tell.  The exact way of setting it up will vary from device to device, but there are a lot of options available.  The key is that you need a device capable of logging that is in a location on the network that everything the person does will go through it.

For an average home network, this could be either the Wireless Access Point, the Router or if applicable, the gateway or firewall.  The wireless access point will get the information right as they get on to the network and will ensure that all activity coming in on the wireless network is logged, but if they were to use their wireless connection to compromise a wired system and then use the wired system, you would have an incomplete log.

Most likely the Router also serves as the gateway and firewall (the device that gives the rest of the network access to the Internet and ensures the Internet doesn't have unintended access to the private network).  Logging at the gateway and/or firewall ensures that all outbound traffic is logged, but won't tell you anything about what the intruder did internally on your network.

In most home networks, since there is only one router and it also generally serves as wireless access point, gateway and firewall, it will end up being privy to all connections flowing across the network.  It may not have access to all the contents of the packets it routes (if encryption is used) but it at least (by necessity) has access to the routing information (ie, where it is coming from and where it is going).  This is likely the best place in a home network to log.

Most consumer routers do not have this kind of logging by default, however third party firmwares such as DD-WRT often add logging capability to the routers that can either write to an internal store (limited space) or a network share.  Exactly what information can be stored and how it is formatted varies from device to device, but in general information like the IP and MAC Address of the client as well as the requested destination IP, Port and protocol (such as TCP or UDP) as well as a timestamp can give you a lot of what you need to get at least a general idea of what was going on.

If space is no object, it may even be possible to log the content of every packet sent across the network, but that will be a huge amount of space and it may not be safe to exclude ""known"" MAC addresses from the logging to try and reduce the amount since MAC spoofing is fairly easy on a wireless network.  (IE, the intruder can make themselves look like a valid machine)  Of course, if you are going to this kind of length, you could also do a per machine certificate and/or not use a weak key at which point the problem would likely be avoided in the first place.
"
3188,3188,5080,Would magic 'weapons' make the monk more balanced?,"The monk in D&amp;D 3.5 (and, to a lesser extent, in Pathfinder) is generally considered underpowered. 

Would adding magic 'weapons' that could add enhancement bonuses and magic weapon effects to a monk's unarmed strikes be sufficient to re-balance them? Would they then be over-balanced?

To be specific I'm thinking of something like hand wraps that are a zero-cost weapon having no mundane effect on combat (the wielder counts as unarmed) but  that can be enchanted in the same way and at the same cost as a normal magic weapon.

Update: 

Thanks to @mxyzplk, I see that Gauntlets would effectively fulfill this effect. Odd that I haven't seen this in any of the discussions on monk optimisation!

Regarding assessing balance, I'll judge this based on how well it addresses the issues in @KRyan's answer in the above-linked question. Obviously if anyone doesn't agree with his analysis then this question is moot, although I would like to see those competing opinions.
",Paul Hutton,https://rpg.stackexchange.com/users/2689,"No.

From the PhB (which system?  Both.  Well, the CRB from Pathfinder, to be technical): ""A monkâs unarmed strike is treated both as a manufactured weapon and a natural weapon for the purpose of spells and effects that enhance or improve either manufactured weapons or natural weapons.""

Id, Craft Magic Arms and Armor: ""The weapon, armor, or shield to be enhanced must be a masterwork item that you provide. Its cost is not included in the above cost.""

Ultimate Magic (pathfinder only), Masterwork Transformation spell: ""Target: one weapon...""

You can, and should, already do this.  In 3.5 this requires that the GM rule that a Monk has a Masterwork body (pretty reasonable).  In pathfinder this requires a level 2 spell, or GM discretion.  I have a player who likes to play monks and this is usually something he puts a fair amount of money in.  I have run into issues doing this with less RAW-friendly groups, as reforging one's hands into the Fists of Fire and Thunder can upset people who have got it in their heads somehow that monks don't get magic weapon upgrades.  In fact, monks benefit from magic upgrades to their weaponry more than any other class, since they both can gain both natural-weapon-only benefits and manufactured-weapon-only benefits, and can have a great variety of specialized enchantments available pretty much all the time.

In both systems monks can make Unarmed Attacks with ""either fist interchangeably... elbows, knees, and feet"" (PHB, cf. CRB).  Enchanting each of these body parts separately allows an unburdened monk access to what are effectively 8 different magic weapons.  Her number of attacks doesn't change, but on each attack she can choose, as normal, which weapon she is employing.  This allows monks to make better use of energy damage and bane abilities than most other melee classes.  In campaigns where WBL is preserved by GM fiat the monk will never have the cash to do this, but in campaigns where spells and social abilities are allowed to generate their stated wealth without WBL limitations the party wizard should be able to provide the monk with a fairly kitted out set of enchantments around level 9.

Even with all this, however, the monk is still a spell-less melee fighter and so very underpowered.  The monk will be much better than a fellow student who for some reason refused magical augmentation, and, in fact, a decent melee build if the game is limited to the Core classes, since the monk's class abilities help somewhat compensate for most non-casters' lack of battlefield mobility (i.e. teleportation), but the monk is still a weak class.



N.B.: 

The benefit of doing your enchantments this way is, in order of importance 1) It's cooler.  You can have Hands of Justice and Feet of Law. 2) You save a magic item slot.  This is a big deal, as that slot can now be used to hold something like a Scarab of Protection or a Necklace of Netted Stars.  You can also keep your Amulet of Mighty Fists +5 and use that in place of your enhancement bonus on your body parts, saving room for more special abilities 2) Your enchantments can't be stolen the way external gear can.  It's always on your person and you can never permanently loose it without some very high level magic. 3) You can utilize all the defensive portions of the enchantments at once, and choose between the offensive portions as 'not an action' when making your attacks. 4) Technically, you save 300 gp.  Actually, if 300 gp matters most of your benefits are moot.

You do not uniquely gain the ability to use weapon enhancements by doing this.  You could do that already, via a Necklace of Natural Weapons or a Scorpion Kama, among other options.
",the dark wanderer,https://rpg.stackexchange.com/users/14848,http://rpg.stackexchange.com/questions/22452/would-magic-weapons-make-the-monk-more-balanced,CULTURE,rpg.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Will magic weapons make monks more balanced?,"The monk in D&amp;D 3.5 (and, to a lesser extent, in Pathfinder) is generally considered underpowered. 

Would adding magic 'weapons' that could add enhancement bonuses and magic weapon effects to a monk's unarmed strikes be sufficient to re-balance them? Would they then be over-balanced?

To be specific I'm thinking of something like hand wraps that are a zero-cost weapon having no mundane effect on combat (the wielder counts as unarmed) but  that can be enchanted in the same way and at the same cost as a normal magic weapon.

Update: 

Thanks to @mxyzplk, I see that Gauntlets would effectively fulfill this effect. Odd that I haven't seen this in any of the discussions on monk optimisation!

Regarding assessing balance, I'll judge this based on how well it addresses the issues in @KRyan's answer in the above-linked question. Obviously if anyone doesn't agree with his analysis then this question is moot, although I would like to see those competing opinions.
","No.

From the PhB (which system?  Both.  Well, the CRB from Pathfinder, to be technical): ""A monkâs unarmed strike is treated both as a manufactured weapon and a natural weapon for the purpose of spells and effects that enhance or improve either manufactured weapons or natural weapons.""

Id, Craft Magic Arms and Armor: ""The weapon, armor, or shield to be enhanced must be a masterwork item that you provide. Its cost is not included in the above cost.""

Ultimate Magic (pathfinder only), Masterwork Transformation spell: ""Target: one weapon...""

You can, and should, already do this.  In 3.5 this requires that the GM rule that a Monk has a Masterwork body (pretty reasonable).  In pathfinder this requires a level 2 spell, or GM discretion.  I have a player who likes to play monks and this is usually something he puts a fair amount of money in.  I have run into issues doing this with less RAW-friendly groups, as reforging one's hands into the Fists of Fire and Thunder can upset people who have got it in their heads somehow that monks don't get magic weapon upgrades.  In fact, monks benefit from magic upgrades to their weaponry more than any other class, since they both can gain both natural-weapon-only benefits and manufactured-weapon-only benefits, and can have a great variety of specialized enchantments available pretty much all the time.

In both systems monks can make Unarmed Attacks with ""either fist interchangeably... elbows, knees, and feet"" (PHB, cf. CRB).  Enchanting each of these body parts separately allows an unburdened monk access to what are effectively 8 different magic weapons.  Her number of attacks doesn't change, but on each attack she can choose, as normal, which weapon she is employing.  This allows monks to make better use of energy damage and bane abilities than most other melee classes.  In campaigns where WBL is preserved by GM fiat the monk will never have the cash to do this, but in campaigns where spells and social abilities are allowed to generate their stated wealth without WBL limitations the party wizard should be able to provide the monk with a fairly kitted out set of enchantments around level 9.

Even with all this, however, the monk is still a spell-less melee fighter and so very underpowered.  The monk will be much better than a fellow student who for some reason refused magical augmentation, and, in fact, a decent melee build if the game is limited to the Core classes, since the monk's class abilities help somewhat compensate for most non-casters' lack of battlefield mobility (i.e. teleportation), but the monk is still a weak class.



N.B.: 

The benefit of doing your enchantments this way is, in order of importance 1) It's cooler.  You can have Hands of Justice and Feet of Law. 2) You save a magic item slot.  This is a big deal, as that slot can now be used to hold something like a Scarab of Protection or a Necklace of Netted Stars.  You can also keep your Amulet of Mighty Fists +5 and use that in place of your enhancement bonus on your body parts, saving room for more special abilities 2) Your enchantments can't be stolen the way external gear can.  It's always on your person and you can never permanently loose it without some very high level magic. 3) You can utilize all the defensive portions of the enchantments at once, and choose between the offensive portions as 'not an action' when making your attacks. 4) Technically, you save 300 gp.  Actually, if 300 gp matters most of your benefits are moot.

You do not uniquely gain the ability to use weapon enhancements by doing this.  You could do that already, via a Necklace of Natural Weapons or a Scorpion Kama, among other options.
"
837,837,1333,Hydrophobia Outside of Rabies?,"
  RELATED: 
  
  Why does rabies cause hydrophobia? 
  
  Agony, Hydrophobia and viruses in the light of evolutionary principles


Has hydrophobia been found outside of rabies?

I have only seen it being mentioned as a symptom of rabies.
",user3306356,https://biology.stackexchange.com/users/6818,"Hydrophobia is mostly attributed to rabies, most of the sources refer rabies as hydrophobia. Technically Hydrophobia is the intense fear of water.




  Hydrophobia is an intense, irrational fear of water that can be commonly diagnosed at childhood and should be treated as soon as possible. Certain types of hydrophobia may also appear in later stages of contracting rabies, which would require treatment on an immediate basis.


Also the Wikipedia link for Rabies states that


  Signs and symptoms may soon expand to slight or partial paralysis, anxiety, insomnia, confusion, agitation, abnormal behavior, paranoia, terror, and hallucinations, progressing to delirium. The person may have hydrophobia.


So rabies and hydrophobia are distinct and hydrophobia is a symptom of rabies.


  Hydrophobia may, however, more readly be confronted with hysteria, acute mania and tetanus.


Hydrophobia is incidental to other diseases, it can be observed, occassionally, in tetanus,hysteria,cynanche,tonsillaris,tracheitis and certain inflammations in stomach. Tetanus is strongly believed to cause intense hydrophobia conditions.How ever, there is always a belief of hydrophobia linked with rabies.


  The pathology of Hydrophobia and Tetanus is found to have great similarities and there is a great similarity in the distribution of lesion in the central nervous system as well as a certain analogy in the kind of lesion. The special localization of symptoms of both disease, in the tongue,throat and neck was associated with the special prevalence of the lesions in the medulla oblongata and especially in the neighborhood of the nuclei in the fourth ventricle etc.
  
  Reference :THE Medical Times and Gazette - J &amp; A Churchill


So it is possible to cause hydrophobic conditions when Tetanus is affected and also hydrophobia can occur from mental disorders. 
",Jayachandran,https://biology.stackexchange.com/users/10294,http://biology.stackexchange.com/questions/24718/hydrophobia-outside-of-rabies,SCIENCE,biology.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.7777777777777778,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Other than rabies?,"
  RELATED: 
  
  Why does rabies cause hydrophobia? 
  
  Agony, Hydrophobia and viruses in the light of evolutionary principles


Has hydrophobia been found outside of rabies?

I have only seen it being mentioned as a symptom of rabies.
","Hydrophobia is mostly attributed to rabies, most of the sources refer rabies as hydrophobia. Technically Hydrophobia is the intense fear of water.




  Hydrophobia is an intense, irrational fear of water that can be commonly diagnosed at childhood and should be treated as soon as possible. Certain types of hydrophobia may also appear in later stages of contracting rabies, which would require treatment on an immediate basis.


Also the Wikipedia link for Rabies states that


  Signs and symptoms may soon expand to slight or partial paralysis, anxiety, insomnia, confusion, agitation, abnormal behavior, paranoia, terror, and hallucinations, progressing to delirium. The person may have hydrophobia.


So rabies and hydrophobia are distinct and hydrophobia is a symptom of rabies.


  Hydrophobia may, however, more readly be confronted with hysteria, acute mania and tetanus.


Hydrophobia is incidental to other diseases, it can be observed, occassionally, in tetanus,hysteria,cynanche,tonsillaris,tracheitis and certain inflammations in stomach. Tetanus is strongly believed to cause intense hydrophobia conditions.How ever, there is always a belief of hydrophobia linked with rabies.


  The pathology of Hydrophobia and Tetanus is found to have great similarities and there is a great similarity in the distribution of lesion in the central nervous system as well as a certain analogy in the kind of lesion. The special localization of symptoms of both disease, in the tongue,throat and neck was associated with the special prevalence of the lesions in the medulla oblongata and especially in the neighborhood of the nuclei in the fourth ventricle etc.
  
  Reference :THE Medical Times and Gazette - J &amp; A Churchill


So it is possible to cause hydrophobic conditions when Tetanus is affected and also hydrophobia can occur from mental disorders. 
"
1053,1053,1655,How to ask a question according to the specific sections?,"
  ï¼1ï¼I get up early in order to catch a bus. 
  
  ï¼2ï¼I get up early because I can catch a bus.


How to ask a question according to âin order to catch a bus â and ""because I can catch  a bus""?
",user48070,https://ell.stackexchange.com/users/2065,"
  Because of (or on account of) what circumstance do you get up early?


is a question that (2) can answer, but (1) cannot.  This takes advantage of the fact that in (2) you are indicating both a reason to get up early, and also a fact -- namely, that there is a bus to take (I 'can' catch a bus implies that there is a bus to take).

In (1) you might try to get up early to catch a bus, without expecting that one is very likely to be there.  You might think there's only a fifty-fifty chance.

By contrast, I don't think that there is any question that (1) answers that (2) doesn't also answer.  The reason is that (2) has 'extra information' but otherwise implicitly indicates a purpose, just like (1).
",Merk,https://ell.stackexchange.com/users/2826,http://ell.stackexchange.com/questions/22934/how-to-ask-a-question-according-to-the-specific-sections,CULTURE,ell.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,0.0,0.8888888888888888,How to ask questions according to specific chapters?,"
  ï¼1ï¼I get up early in order to catch a bus. 
  
  ï¼2ï¼I get up early because I can catch a bus.


How to ask a question according to âin order to catch a bus â and ""because I can catch  a bus""?
","
  Because of (or on account of) what circumstance do you get up early?


is a question that (2) can answer, but (1) cannot.  This takes advantage of the fact that in (2) you are indicating both a reason to get up early, and also a fact -- namely, that there is a bus to take (I 'can' catch a bus implies that there is a bus to take).

In (1) you might try to get up early to catch a bus, without expecting that one is very likely to be there.  You might think there's only a fifty-fifty chance.

By contrast, I don't think that there is any question that (1) answers that (2) doesn't also answer.  The reason is that (2) has 'extra information' but otherwise implicitly indicates a purpose, just like (1).
"
1183,1183,1859,"Set your journey to the wellness.. ""set"" used as ""begin"" , goes right here?","Using 'set' as 'begin' or closely similar way.

The sentence ""Set your journey to the wellness.."" is ok?

Set goes right here?

From definition, I want to use ""set"" for this purpose..
cause (someone or something) to start doing something.
""the incident set me thinking""
",user57406,https://english.stackexchange.com/users/57406,"Which ""wellness"" is this? I suspect you might mean ""Begin your journey to wellness"", but can't be sure.

Set does not have this meaning, but the idiom ""set out on"" is used specifically for journeys, so ""Set out on your journey to wellness"" works, though it focuses a bit more on the idea of a literal journey than a figurative one. I'd therefore advise against unless perhaps it was used with some visual imagery of journeys that would more strongly bring the imagery to mind. (Metaphors need to either be strong in the imagery or else quiet and let the figurative meaning dominate, ""set out on"" risks falling between the two).
",Jon Hanna,https://english.stackexchange.com/users/15770,http://english.stackexchange.com/questions/138933/set-your-journey-to-the-wellness-set-used-as-begin-goes-right-here,CULTURE,english.stackexchange.com,0.5555555555555556,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,0.6666666666666666,1.0,1.0,0.6,0.6666666666666666,0.0,1.0,0.8888888888888888,"Make your journey healthy... "" Set to start, right here?","Using 'set' as 'begin' or closely similar way.

The sentence ""Set your journey to the wellness.."" is ok?

Set goes right here?

From definition, I want to use ""set"" for this purpose..
cause (someone or something) to start doing something.
""the incident set me thinking""
","Which ""wellness"" is this? I suspect you might mean ""Begin your journey to wellness"", but can't be sure.

Set does not have this meaning, but the idiom ""set out on"" is used specifically for journeys, so ""Set out on your journey to wellness"" works, though it focuses a bit more on the idea of a literal journey than a figurative one. I'd therefore advise against unless perhaps it was used with some visual imagery of journeys that would more strongly bring the imagery to mind. (Metaphors need to either be strong in the imagery or else quiet and let the figurative meaning dominate, ""set out on"" risks falling between the two).
"
2738,2738,4367,"Learning the musical concepts in the book ""GÃ¶del, Escher, Bach""","I am reading the book ""GÃ¶del, Escher, Bach"", in which the author tries to present concepts in mathematics, drawings and music as instances of a certain ""pattern"", that he calls ""strange loops"". He makes several comments about Bach's music, in particular, as the title suggests. So, he talks about the fugues, sonatas and partitas, modulation, themes played against themselves, how Bach manages to get two or more musical lines going simultaneously and so on.

But I don't understand a thing about these musical concepts. I have tried to listen on YouTube to some of the compositions he mentions in the book, but my stupid brain only hears a stream of notes flowing. I can't recognize the patterns he talks about, nor can I grasp, for example, the fact the the ""Canon per Tonos"" rises successively until it reaches the key C again. 

So how can I learn more about these musical concepts, so as to better follow the book's main ideas? To make this question narrower, I'm not asking for general references to learn about music, but something very specific to the content of the book, so that I don't miss important information (and fun) from his exposition.
",Otavio Macedo,https://music.stackexchange.com/users/12666,"I agree with luser droog's answer.

My understanding of the book (which I did not finish) was that there is an overall theme of language, which is then illustrated through the three artists. While the letters in each of these languages are based on natural, measurable, physical phenomena (projections to 2 dimensions in the visual language of Escher, mathematical elements in the metaphysics of GÃ¶del, and musical tones in the language of Bach), the languages themselves (ie. the ""grammars"") are artificial. 

The specific artists are not drawn out merely to indulge in a cult of personality, but because each were innovators in developing the modern features of their respective language. I suspect you may have guessed where I'm going with this.

To get the deeper understanding that you're after, you have to read the scores. If you don't read staff notation, learn it. I don't mean to be curt or rude, but there is to my knowledge no other way.
",luser droog,https://music.stackexchange.com/users/1344,http://music.stackexchange.com/questions/22216/learning-the-musical-concepts-in-the-book-g%C3%B6del-escher-bach,LIFE_ARTS,music.stackexchange.com,0.6666666666666666,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,0.5,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,"Learning the concept of music in Godel, Escher and Bach","I am reading the book ""GÃ¶del, Escher, Bach"", in which the author tries to present concepts in mathematics, drawings and music as instances of a certain ""pattern"", that he calls ""strange loops"". He makes several comments about Bach's music, in particular, as the title suggests. So, he talks about the fugues, sonatas and partitas, modulation, themes played against themselves, how Bach manages to get two or more musical lines going simultaneously and so on.

But I don't understand a thing about these musical concepts. I have tried to listen on YouTube to some of the compositions he mentions in the book, but my stupid brain only hears a stream of notes flowing. I can't recognize the patterns he talks about, nor can I grasp, for example, the fact the the ""Canon per Tonos"" rises successively until it reaches the key C again. 

So how can I learn more about these musical concepts, so as to better follow the book's main ideas? To make this question narrower, I'm not asking for general references to learn about music, but something very specific to the content of the book, so that I don't miss important information (and fun) from his exposition.
","I agree with luser droog's answer.

My understanding of the book (which I did not finish) was that there is an overall theme of language, which is then illustrated through the three artists. While the letters in each of these languages are based on natural, measurable, physical phenomena (projections to 2 dimensions in the visual language of Escher, mathematical elements in the metaphysics of GÃ¶del, and musical tones in the language of Bach), the languages themselves (ie. the ""grammars"") are artificial. 

The specific artists are not drawn out merely to indulge in a cult of personality, but because each were innovators in developing the modern features of their respective language. I suspect you may have guessed where I'm going with this.

To get the deeper understanding that you're after, you have to read the scores. If you don't read staff notation, learn it. I don't mean to be curt or rude, but there is to my knowledge no other way.
"
4942,4942,7870,How can I surface TFS 2010 project associated Information with SharePoint2010,"How can I surface TFS 2010 project associated Information with  SharePoint2010, i.e. work items etc. from TFS.

Has anyone surfaced that data in SP 2010 so that the users can access all that info from their team portal? Are there any neat web parts that will let you do that?

Would BCS be requried to surface data from TFS?!
Any insights/thoughts/suggestions welcome.
",Ybbest,https://sharepoint.stackexchange.com/users/309,"You have a whole set of TFS webparts that you can deploy and activate in SP2010. They come with the TFS installation files.

See Extensions for SharePoint Products or Add Integration with SharePoint Products to a Deployment of Team Foundation Server

And this YouTube video for a visual overview of what they provide.
",Louis,https://sharepoint.stackexchange.com/users/6551,http://sharepoint.stackexchange.com/questions/31894/how-can-i-surface-tfs-2010-project-associated-information-with-sharepoint2010,TECHNOLOGY,sharepoint.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.6,0.0,0.0,1.0,0.6666666666666666,How to use sharepoint2010 to display TFs 2010 project related information,"How can I surface TFS 2010 project associated Information with  SharePoint2010, i.e. work items etc. from TFS.

Has anyone surfaced that data in SP 2010 so that the users can access all that info from their team portal? Are there any neat web parts that will let you do that?

Would BCS be requried to surface data from TFS?!
Any insights/thoughts/suggestions welcome.
","You have a whole set of TFS webparts that you can deploy and activate in SP2010. They come with the TFS installation files.

See Extensions for SharePoint Products or Add Integration with SharePoint Products to a Deployment of Team Foundation Server

And this YouTube video for a visual overview of what they provide.
"
1468,1468,2311,"Can I wire 2 ceiling fans, 5 ceiling spot lights, and 3 closet lights on a singe 15 amp circuit?","Can I wire 2 ceiling fans and 5 ceiling spot lights and 3 closet ligthts on a singe circuit with 12 ga wire and a 15 amp breaker?
Or should I wire the 2 ceiling fans on a separate circuit?
",Mike B,https://diy.stackexchange.com/users/37651,"There should be no problem putting it all on a single 15 ampere circuit. Likely in the worst case scenario, each fixture would consume ~100 watts. That would be using large 52"" fans, and 100 watt bulbs in each fixture. With the 10 fixtures, that would be 1000 watts (10 * 100 = 1000). A 15 ampere 120 volt circuit can provide 1800 watts of power (15A * 120V). 

More realistically, you're going to be using lower wattage fixtures, especially nowadays with CFL and LED bulbs becoming more common. Here's some calculations based on various wattage devices. 


10 devices @ 75 watts each = 750 watts.
10 devices @ 60 watts each = 600 watts.
2 fans @ 100 watts, and 8 lights @ 60 watts = 680 watts.
2 fans @ 75 watts with 3 60 watt blub light kits, and 8 lights @ 100 watts = 1310 watts.
2 fans @ 100 watts with 3 100 watt bulb light kits, and 8 lights @ 100 watts = 1600 watts.


Since it's a 15 ampere circuit, you'll only need 14 AWG conductors. Unless there's a specific reason you're using 12 AWG instead, which is also fine.
",Tester101,https://diy.stackexchange.com/users/33,http://diy.stackexchange.com/questions/66264/can-i-wire-2-ceiling-fans-5-ceiling-spot-lights-and-3-closet-lights-on-a-singe,LIFE_ARTS,diy.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.7777777777777778,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,"Can I connect 2 ceiling fans, 5 ceiling lights and 3 closet lights on a 15 amp circuit?","Can I connect 2 ceiling fans, 5 ceiling lights and 3 closet lights in one circuit with 12 GA wire and 15 amp circuit breaker?","There should be no problem putting it all on a single 15 ampere circuit. Likely in the worst case scenario, each fixture would consume ~100 watts. That would be using large 52"" fans, and 100 watt bulbs in each fixture. With the 10 fixtures, that would be 1000 watts (10 * 100 = 1000). A 15 ampere 120 volt circuit can provide 1800 watts of power (15A * 120V). 

More realistically, you're going to be using lower wattage fixtures, especially nowadays with CFL and LED bulbs becoming more common. Here's some calculations based on various wattage devices. 


10 devices @ 75 watts each = 750 watts.
10 devices @ 60 watts each = 600 watts.
2 fans @ 100 watts, and 8 lights @ 60 watts = 680 watts.
2 fans @ 75 watts with 3 60 watt blub light kits, and 8 lights @ 100 watts = 1310 watts.
2 fans @ 100 watts with 3 100 watt bulb light kits, and 8 lights @ 100 watts = 1600 watts.


Since it's a 15 ampere circuit, you'll only need 14 AWG conductors. Unless there's a specific reason you're using 12 AWG instead, which is also fine.
"
3530,3530,5627,Problems Binding MouseDoubleClick via M-V-MV Design Pattern,"I have the following snippet of code in an .xaml file:

&lt;TreeView MouseDoubleClick=""TreeView_MouseDoubleClick"" ItemsSource=""{Binding MyList}""&gt;
  &lt;TreeView.ItemContainerStyle&gt;
    &lt;Style TargetType=""{x:Type TreeViewItem}""&gt;
      &lt;Setter Property=""IsExpanded"" Value=""{Binding IsExpanded, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""IsSelected"" Value=""{Binding IsSelected, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""FontWeight"" Value=""Normal"" /&gt;
      &lt;Style.Triggers&gt;
        &lt;Trigger Property=""IsSelected"" Value=""True""&gt;
          &lt;Setter Property=""FontWeight"" Value=""Bold"" /&gt;
        &lt;/Trigger&gt;
      &lt;/Style.Triggers&gt;
    &lt;/Style&gt;
  &lt;/TreeView.ItemContainerStyle&gt;


As you can see, when you ""MouseDoubleClick"" on an item in the TreeView it will execute the code in the code behind...namely...

private void TreeView_MouseDoubleClick(object sender, System.Windows.Input.MouseButtonEventArgs e)
{
    try
    {
        MessageBox.Show(((TreeViewWithViewModelDemo.LoadOnDemand.HtmlFileViewModel)(((System.Windows.Controls.TreeView)(sender)).SelectedValue)).HtmlFileName);
    }
    catch
    {
    }
}


I'm trying to follow the Model-View-ViewModel Design Pattern and would like to move the implementation of this MouseDoubleClick event away from the View and into the ViewModel.

I understand that if I was using a command I would use {Binding Command=""Select""} (or something similar that implements the ICommand interface) but I cannot seem to find the syntax for this particular issue since it is not a command button.

Can someone help me out?

Thanks
",Ann Sanderson,https://stackoverflow.com/users/1161283,"I actually posted an answer to someone about this very topic a few days ago. Here is what I posted

Obviously that is for a listviewitem, not a treeviewitem but it will still work, with some minor changes.
",Jason Ridge,https://stackoverflow.com/users/978083,http://stackoverflow.com/questions/9811538/problems-binding-mousedoubleclick-via-m-v-mv-design-pattern,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,Binding mousedoubleclick with m-v-mv design pattern,"I have the following snippet of code in an .xaml file:

&lt;TreeView MouseDoubleClick=""TreeView_MouseDoubleClick"" ItemsSource=""{Binding MyList}""&gt;
  &lt;TreeView.ItemContainerStyle&gt;
    &lt;Style TargetType=""{x:Type TreeViewItem}""&gt;
      &lt;Setter Property=""IsExpanded"" Value=""{Binding IsExpanded, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""IsSelected"" Value=""{Binding IsSelected, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""FontWeight"" Value=""Normal"" /&gt;
      &lt;Style.Triggers&gt;
        &lt;Trigger Property=""IsSelected"" Value=""True""&gt;
          &lt;Setter Property=""FontWeight"" Value=""Bold"" /&gt;
        &lt;/Trigger&gt;
      &lt;/Style.Triggers&gt;
    &lt;/Style&gt;
  &lt;/TreeView.ItemContainerStyle&gt;


As you can see, when you ""MouseDoubleClick"" on an item in the TreeView it will execute the code in the code behind...namely...

private void TreeView_MouseDoubleClick(object sender, System.Windows.Input.MouseButtonEventArgs e)
{
    try
    {
        MessageBox.Show(((TreeViewWithViewModelDemo.LoadOnDemand.HtmlFileViewModel)(((System.Windows.Controls.TreeView)(sender)).SelectedValue)).HtmlFileName);
    }
    catch
    {
    }
}


I'm trying to follow the Model-View-ViewModel Design Pattern and would like to move the implementation of this MouseDoubleClick event away from the View and into the ViewModel.

I understand that if I was using a command I would use {Binding Command=""Select""} (or something similar that implements the ICommand interface) but I cannot seem to find the syntax for this particular issue since it is not a command button.

Can someone help me out?

Thanks
","I actually posted an answer to someone about this very topic a few days ago. Here is what I posted

Obviously that is for a listviewitem, not a treeviewitem but it will still work, with some minor changes.
"
5984,5984,9487,how to map users and group with sshfs,"As you can see below I'm able to map the user from kevcoder00 to kevcoder01 but the group gets mapped to marigold although that group does not exists on kevcoder01

l00py@kevcoder00:~$ sshfs -o idmap=user l00py@kevcoder01:/home/l00py ~/kevcoder01/
l00py@kevcoder01's password: 
l00py@kevcoder00:~$ ls -hl kevcoder01/
total 0
-rw-r--r-- 1 l00py marigold 0 Jul  4 00:34 I_LIVE
-rw-r--r-- 1 l00py marigold 0 Jul  4 00:59 I_LIVE_AGAIN


What do I need to do to map both user and group?
",kevcoder,https://unix.stackexchange.com/users/10651,"I don't think it's mapping to marigold. The GID that marigold is using on your local system is the same number as the default group of 100py on the remote server devcoder01.

For example

On my laptop my default group is GID 501, saml.

$ id -a
uid=500(saml) gid=501(saml) groups=501(saml),502(vboxusers),503(jupiter)


On my remote server skinner the user sam uses the following:

$ id -a sam
uid=5060(sam) gid=1000(users) groups=1000(users),1060(pics),1050(mp3s),1070(mock)


Now when I connect:

$ sshfs -o idmap=user sam@skinner:/home/sam /home/saml/mnt

$ ls -l ~/mnt
drwxr-xr-x 1 saml users     4096 May 27  2011 projects
drwxr-xr-x 1 saml users     4096 Mar 11 22:53 public_html
-rw-r--r-- 1 root root   1992744 Apr 18  2012 rest.war
-rw-r--r-- 1 saml  1000      136 Sep  4  2012 scott_jay_addresses.txt
drwxr-xr-x 1 saml  1000     4096 Jun 27  2012 SparkleShare


If you look in this directory it would appear that I have access to other groups but it's just the way that sshfs works. It's presenting the shared directory using the UIDs/GIDs of the remote and you happen to have the same UIDs/GIDs in use on your local system.

If you use the -n switch to ls -l you can see the actual UIDs/GIDs:

$ ls -ln
drwxr-xr-x 1 500  100     4096 Mar 11 22:53 public_html
-rw-r--r-- 1   0    0  1992744 Apr 18  2012 rest.war
-rw-r--r-- 1 500 1000      136 Sep  4  2012 scott_jay_addresses.txt
drwxr-xr-x 1 500 1000     4096 Jun 27  2012 SparkleShare


If I had an entry in my local system's /etc/group file for 1000 it would've been shown when doing the ls -l. In the above output you can see that the group ""user"" is using GID 100, and I just happen to have an entry in my local system's for that:

users:x:100:

",slm,https://unix.stackexchange.com/users/7453,http://unix.stackexchange.com/questions/81707/how-to-map-users-and-group-with-sshfs,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.5,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.7777777777777778,1.0,0.8,0.6666666666666666,0.0,1.0,1.0,How to use sshfs to map users and groups,"As you can see below I'm able to map the user from kevcoder00 to kevcoder01 but the group gets mapped to marigold although that group does not exists on kevcoder01

l00py@kevcoder00:~$ sshfs -o idmap=user l00py@kevcoder01:/home/l00py ~/kevcoder01/
l00py@kevcoder01's password: 
l00py@kevcoder00:~$ ls -hl kevcoder01/
total 0
-rw-r--r-- 1 l00py marigold 0 Jul  4 00:34 I_LIVE
-rw-r--r-- 1 l00py marigold 0 Jul  4 00:59 I_LIVE_AGAIN


What do I need to do to map both user and group?
","I don't think it's mapping to marigold. The GID that marigold is using on your local system is the same number as the default group of 100py on the remote server devcoder01.

For example

On my laptop my default group is GID 501, saml.

$ id -a
uid=500(saml) gid=501(saml) groups=501(saml),502(vboxusers),503(jupiter)


On my remote server skinner the user sam uses the following:

$ id -a sam
uid=5060(sam) gid=1000(users) groups=1000(users),1060(pics),1050(mp3s),1070(mock)


Now when I connect:

$ sshfs -o idmap=user sam@skinner:/home/sam /home/saml/mnt

$ ls -l ~/mnt
drwxr-xr-x 1 saml users     4096 May 27  2011 projects
drwxr-xr-x 1 saml users     4096 Mar 11 22:53 public_html
-rw-r--r-- 1 root root   1992744 Apr 18  2012 rest.war
-rw-r--r-- 1 saml  1000      136 Sep  4  2012 scott_jay_addresses.txt
drwxr-xr-x 1 saml  1000     4096 Jun 27  2012 SparkleShare


If you look in this directory it would appear that I have access to other groups but it's just the way that sshfs works. It's presenting the shared directory using the UIDs/GIDs of the remote and you happen to have the same UIDs/GIDs in use on your local system.

If you use the -n switch to ls -l you can see the actual UIDs/GIDs:

$ ls -ln
drwxr-xr-x 1 500  100     4096 Mar 11 22:53 public_html
-rw-r--r-- 1   0    0  1992744 Apr 18  2012 rest.war
-rw-r--r-- 1 500 1000      136 Sep  4  2012 scott_jay_addresses.txt
drwxr-xr-x 1 500 1000     4096 Jun 27  2012 SparkleShare


If I had an entry in my local system's /etc/group file for 1000 it would've been shown when doing the ls -l. In the above output you can see that the group ""user"" is using GID 100, and I just happen to have an entry in my local system's for that:

users:x:100:

"
5758,5758,9126,Tomcat uses BASIC auth instead of FORM auth,"I've run into a very weird problem with Tomcat: My Webapp running on Tomcat 6 works just fine with BASIC auth. However I would like to switch to FORM based auth. But when I change my web.xml from:

&lt;login-config&gt;
    &lt;auth-method&gt;BASIC&lt;/auth-method&gt;
    &lt;realm-name&gt;my realm&lt;/realm-name&gt;
&lt;/login-config&gt;


to this here

&lt;login-config&gt;
    &lt;auth-method&gt;FORM&lt;/auth-method&gt;
    &lt;form-login-config&gt;
      &lt;form-login-page&gt;/login.html&lt;/form-login-page&gt;
      &lt;form-error-page&gt;/loginfail.html&lt;/form-error-page&gt;
    &lt;/form-login-config&gt;
    &lt;realm-name&gt;my realm&lt;/realm-name&gt;
&lt;/login-config&gt;


Tomcat still uses BASIC auth.


Both login files exist.
There are no errors in catalina.err/out.
Leaving out the realm element makes the browser show ""Authentication
required"" instead of the realm name (still uses BASIC)


Are there any conditions under which FORM based auth is not being used?
",Meriadox,https://stackoverflow.com/users/2867589,"It seems that reloading the webapp was not enough in my case.

After restarting tomcat by FORM Authentication is being used.

ADD: FORM authentication is using a different digest algorithm than BASIC/DIGEST. Hence my old user auth database is not reusable. But this is a different topic. :)
",Meriadox,https://stackoverflow.com/users/2867589,http://stackoverflow.com/questions/19299469/tomcat-uses-basic-auth-instead-of-form-auth,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8333333333333334,0.5,1.0,0.8333333333333334,0.7,0.0,0.5,0.5,0.6666666666666666,Tomcat uses basic auth instead of form auth,"I've run into a very weird problem with Tomcat: My Webapp running on Tomcat 6 works just fine with BASIC auth. However I would like to switch to FORM based auth. But when I change my web.xml from:

&lt;login-config&gt;
    &lt;auth-method&gt;BASIC&lt;/auth-method&gt;
    &lt;realm-name&gt;my realm&lt;/realm-name&gt;
&lt;/login-config&gt;


to this here

&lt;login-config&gt;
    &lt;auth-method&gt;FORM&lt;/auth-method&gt;
    &lt;form-login-config&gt;
      &lt;form-login-page&gt;/login.html&lt;/form-login-page&gt;
      &lt;form-error-page&gt;/loginfail.html&lt;/form-error-page&gt;
    &lt;/form-login-config&gt;
    &lt;realm-name&gt;my realm&lt;/realm-name&gt;
&lt;/login-config&gt;


Tomcat still uses BASIC auth.


Both login files exist.
There are no errors in catalina.err/out.
Leaving out the realm element makes the browser show ""Authentication
required"" instead of the realm name (still uses BASIC)


Are there any conditions under which FORM based auth is not being used?
","It seems that reloading the webapp was not enough in my case.

After restarting tomcat by FORM Authentication is being used.

ADD: FORM authentication is using a different digest algorithm than BASIC/DIGEST. Hence my old user auth database is not reusable. But this is a different topic. :)
"
1583,1583,2491,Find cron jobs that run between given times,"Is it possible to find all entries in a crontab that run between time X and time Y without having to parse the cron time entries myself? I'm mainly concerned with time hour and  minute, not so much the other 3 time fields.
",frankc,https://stackoverflow.com/users/275455,"You can use the Ruby 1.8.7 gem ""crontab-parser"" to parse a crontab, and then iterate through each minute between the two timestamps, calling should_run? on every crontab entry:

require 'rubygems'
require 'crontab-parser'

start_time = Time.parse(ARGV[0])
end_time   = Time.parse(ARGV[1])

# CrontabParser barfs on env variable setting in a crontab, so just skip them
cron_data = File.readlines(ARGV[2]).select {|line| line =~ /^[0-9*]/}
cron  = CrontabParser.new(cron_data.join(""\n""))
(start_time..end_time).each do |timestamp|
  next unless timestamp.sec.to_i == 0
  cron.each do |cron_entry|
    if cron_entry.should_run?(timestamp)
      puts ""#{timestamp}\t#{cron_entry.cmd}""
    end
  end
end


So, if you have a crontab.txt that looks like this:

*   *   *   *   *   foo
18  15  *   *   *   bar


Then call the script with output from date or similar and a file containing a crontab:

ruby cron_report.rb ""Sat Mar 3 02:07:32 UTC 2012"" ""Sat Mar 3 02:21:32 UTC 2012"" crontab.txt


You'll get output like this:

Sat Mar 03 15:17:00 UTC 2012    *   *   *   *   *   foo
Sat Mar 03 15:18:00 UTC 2012    *   *   *   *   *   foo
Sat Mar 03 15:18:00 UTC 2012    18  15  *   *   *   bar
Sat Mar 03 15:19:00 UTC 2012    *   *   *   *   *   foo
Sat Mar 03 15:20:00 UTC 2012    *   *   *   *   *   foo

",nohat,https://stackoverflow.com/users/3101,http://stackoverflow.com/questions/4053463/find-cron-jobs-that-run-between-given-times,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,Find cron jobs running between given times,"Can you find all the entries running between time x and time y in crontab without having to analyze the cron time entries yourself? My main concerns are time hours and minutes, not the other three time domains.","You can use the Ruby 1.8.7 gem ""crontab-parser"" to parse a crontab, and then iterate through each minute between the two timestamps, calling should_run? on every crontab entry:

require 'rubygems'
require 'crontab-parser'

start_time = Time.parse(ARGV[0])
end_time   = Time.parse(ARGV[1])

# CrontabParser barfs on env variable setting in a crontab, so just skip them
cron_data = File.readlines(ARGV[2]).select {|line| line =~ /^[0-9*]/}
cron  = CrontabParser.new(cron_data.join(""\n""))
(start_time..end_time).each do |timestamp|
  next unless timestamp.sec.to_i == 0
  cron.each do |cron_entry|
    if cron_entry.should_run?(timestamp)
      puts ""#{timestamp}\t#{cron_entry.cmd}""
    end
  end
end


So, if you have a crontab.txt that looks like this:

*   *   *   *   *   foo
18  15  *   *   *   bar


Then call the script with output from date or similar and a file containing a crontab:

ruby cron_report.rb ""Sat Mar 3 02:07:32 UTC 2012"" ""Sat Mar 3 02:21:32 UTC 2012"" crontab.txt


You'll get output like this:

Sat Mar 03 15:17:00 UTC 2012    *   *   *   *   *   foo
Sat Mar 03 15:18:00 UTC 2012    *   *   *   *   *   foo
Sat Mar 03 15:18:00 UTC 2012    18  15  *   *   *   bar
Sat Mar 03 15:19:00 UTC 2012    *   *   *   *   *   foo
Sat Mar 03 15:20:00 UTC 2012    *   *   *   *   *   foo

"
2672,2672,4257,How do I deal with a slow and undedicated colleague in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
",HOT,https://programmers.stackexchange.com/users/34092,"As others have mentioned, behaving professionally is the single most important thing for your long-term career.  And honestly, as long as you behave professionally, you'll be in pretty good shape, no matter how those around you behave.  

In this situation, there are a couple of considerations you need to take into account.

First, you need to understand that you are responsible for your program working to the desired specifications, by the given deadline.  If your program interoperates with someone else's program, you are also responsible for making sure that that other program also works by the same deadline.  To put this differently:  If the other person misses their deadline, then you have also missed your deadline, even if your own part of the project was on time.  In management terms, this is called owning the inputs.

You have correctly noted that when your colleague declares in a meeting that his program's bugs are fixed, that you can't immediately declare him as incorrect to the manager (your manager would see that as ""throwing your co-worker under the bus"";  a very bad career move).  Others, on the other hand, have pointed out that it is unprofessional not to declare the true state of the project to the manager.  Both sides are completely correct.

So if it's bad to contradict your colleague in front of the manager, and it's also bad to not contradict him, then what do you do?

The answer is actually pretty simple:  You need to talk to your colleague well before the meeting with the manager, and let them know that at the upcoming meeting you're going to need to tell the manager about the troubles you've been having with their program, and that it's impacting your ability to deliver your side of the project on time, and whether there's anything you can do to help them address the troubles you've been having.  You need to have this conversation at least two full days before the meeting where you will tell the manager, and preferably a full week in advance.

In most cases, just telling your colleague that you're going to have to list their program as a risk at a particular meeting will get them motivated to address the problems you're having, and you never have to talk to the manager at all.  In others, where the problems are more schedule-driven, the colleague will often agree with you, and the two of you can go to the manager together.

I've never had a colleague who didn't either fix things up for me quickly or else agree with my concerns, when expressed this way.  But if it did happen, by giving your colleague advance warning you'd still be in a better position when talking to the manager.  Since you talked to your colleague and tried to work out a solution on your own, and warned them well in advance that you would need to raise the issue at this meeting, your colleague won't be surprised when they do, and the manager won't think that you're simply trying to shift the blame.

Do please remember that when you express your concerns, either to the colleague or to the manager, that your concerns are about your colleague's program which is returning bad data (or whatever else it's doing);  these are measurable things which can be verified and fixed.  Your concerns are not about your colleague being slow or undedicated;  these are not measurable things, which may or may not be true, and which are unlikely to be fixed by bringing them up in a meeting in front of the boss.
",Trevor Powell,https://programmers.stackexchange.com/users/34454,http://programmers.stackexchange.com/questions/101528/how-do-i-deal-with-a-slow-and-undedicated-colleague-in-the-team,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,1.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.7777777777777778,0.8888888888888888,1.0,0.8666666666666666,0.3333333333333333,1.0,0.0,0.8888888888888888,How can I deal with a colleague who is slow-moving and lacks dedication in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
","As others have mentioned, behaving professionally is the single most important thing for your long-term career.  And honestly, as long as you behave professionally, you'll be in pretty good shape, no matter how those around you behave.  

In this situation, there are a couple of considerations you need to take into account.

First, you need to understand that you are responsible for your program working to the desired specifications, by the given deadline.  If your program interoperates with someone else's program, you are also responsible for making sure that that other program also works by the same deadline.  To put this differently:  If the other person misses their deadline, then you have also missed your deadline, even if your own part of the project was on time.  In management terms, this is called owning the inputs.

You have correctly noted that when your colleague declares in a meeting that his program's bugs are fixed, that you can't immediately declare him as incorrect to the manager (your manager would see that as ""throwing your co-worker under the bus"";  a very bad career move).  Others, on the other hand, have pointed out that it is unprofessional not to declare the true state of the project to the manager.  Both sides are completely correct.

So if it's bad to contradict your colleague in front of the manager, and it's also bad to not contradict him, then what do you do?

The answer is actually pretty simple:  You need to talk to your colleague well before the meeting with the manager, and let them know that at the upcoming meeting you're going to need to tell the manager about the troubles you've been having with their program, and that it's impacting your ability to deliver your side of the project on time, and whether there's anything you can do to help them address the troubles you've been having.  You need to have this conversation at least two full days before the meeting where you will tell the manager, and preferably a full week in advance.

In most cases, just telling your colleague that you're going to have to list their program as a risk at a particular meeting will get them motivated to address the problems you're having, and you never have to talk to the manager at all.  In others, where the problems are more schedule-driven, the colleague will often agree with you, and the two of you can go to the manager together.

I've never had a colleague who didn't either fix things up for me quickly or else agree with my concerns, when expressed this way.  But if it did happen, by giving your colleague advance warning you'd still be in a better position when talking to the manager.  Since you talked to your colleague and tried to work out a solution on your own, and warned them well in advance that you would need to raise the issue at this meeting, your colleague won't be surprised when they do, and the manager won't think that you're simply trying to shift the blame.

Do please remember that when you express your concerns, either to the colleague or to the manager, that your concerns are about your colleague's program which is returning bad data (or whatever else it's doing);  these are measurable things which can be verified and fixed.  Your concerns are not about your colleague being slow or undedicated;  these are not measurable things, which may or may not be true, and which are unlikely to be fixed by bringing them up in a meeting in front of the boss.
"
5054,5054,8039,Piezo as a switch to flash an led when disturbed,"An LED embedded in a small translucent item (say half the size of a pack of cards) that would flash on briefly if the object was disturbed or tipped over.
I immediately responded that a piezoelectric sensor/generator inside the object wired to an LED would do it.
However, when I tried to demonstrate this concept using a piezo buzzer I liberated from an old phone, I could only get the LED to register a dim blip when I smashed the piezo buzzer with a blunt object.
How would I ensure that a piezo sensor/generator would actually light up the LED adequately without the application of blunt force trauma.
As I mentioned, space would be an issue so no large parts, breadboards, or really complex circuitry.
I'm just trying to figure out the easiest and smallest way to accomplish this simple task.
Thanks a lot for any help you can give me!
",Rory O'Hare,https://electronics.stackexchange.com/users/6179,"A tilt sensor would probably do. All the large component vendors stock varying types of these.

A simple DIY solution might be something like a small spring (from a pen?) placed around a stiff wire so any disturbance causes the spring to contact the wire and close the circuit (connections at bottom of spring and wire like a SPST switch) 

The above would obviously need a small battery/solar cell/energy harvesting solution of some sort. If you are trying to do this without a battery then I don't think it's possible with a piezo, as they only produce tiny amounts of current. A shake to charge torch type circuit might be made to work (e.g. magnet slides through coil on tilt)  

EDIT - With the requirement of no battery now confirmed, I think I would try the coil idea mentioned above. If all you need is a brief flash then when the thing is tilted and the magnet slides through the coil it should work, You can downsize as necessary (within reason)
Couple of links:
DIY Shake flashlight
Shake Flashlights - how they work
This will likely be pretty difficult to do well with no ""intelligence"" or energy reserve (e.g. cap charged very slowly with something like a tiny solar cell, discharged through LED on spring sensor closing) 
",Oli Glaser,https://electronics.stackexchange.com/users/5372,http://electronics.stackexchange.com/questions/22736/piezo-as-a-switch-to-flash-an-led-when-disturbed,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.3333333333333333,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,Piezoelectric as a switch flashes led when disturbed,"An LED embedded in a small translucent item (say half the size of a pack of cards) that would flash on briefly if the object was disturbed or tipped over.
I immediately responded that a piezoelectric sensor/generator inside the object wired to an LED would do it.
However, when I tried to demonstrate this concept using a piezo buzzer I liberated from an old phone, I could only get the LED to register a dim blip when I smashed the piezo buzzer with a blunt object.
How would I ensure that a piezo sensor/generator would actually light up the LED adequately without the application of blunt force trauma.
As I mentioned, space would be an issue so no large parts, breadboards, or really complex circuitry.
I'm just trying to figure out the easiest and smallest way to accomplish this simple task.
Thanks a lot for any help you can give me!
","A tilt sensor would probably do. All the large component vendors stock varying types of these.

A simple DIY solution might be something like a small spring (from a pen?) placed around a stiff wire so any disturbance causes the spring to contact the wire and close the circuit (connections at bottom of spring and wire like a SPST switch) 

The above would obviously need a small battery/solar cell/energy harvesting solution of some sort. If you are trying to do this without a battery then I don't think it's possible with a piezo, as they only produce tiny amounts of current. A shake to charge torch type circuit might be made to work (e.g. magnet slides through coil on tilt)  

EDIT - With the requirement of no battery now confirmed, I think I would try the coil idea mentioned above. If all you need is a brief flash then when the thing is tilted and the magnet slides through the coil it should work, You can downsize as necessary (within reason)
Couple of links:
DIY Shake flashlight
Shake Flashlights - how they work
This will likely be pretty difficult to do well with no ""intelligence"" or energy reserve (e.g. cap charged very slowly with something like a tiny solar cell, discharged through LED on spring sensor closing) 
"
332,332,532,Is pretending to want to trade before playing a monopoly card objectionable?,"In Settlers of Catan, I sometimes try to ask people if they want to trade a certain resource, tricking them into revealing the approximate amount of that resource in everyone's hand. After this I play the monopoly card. This has on some occasions not been received very well.

Is this fair play?
",Matthijs Wessels,https://boardgames.stackexchange.com/users/117,"If you are simply trying to determine which resource is the most abundant, can't you just count the remaining resource cards? Isn't that public knowledge?

If so, that would make this tactic unnecessary.
",BradC,https://boardgames.stackexchange.com/users/608,http://boardgames.stackexchange.com/questions/577/is-pretending-to-want-to-trade-before-playing-a-monopoly-card-objectionable,CULTURE,boardgames.stackexchange.com,0.8888888888888888,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.5555555555555556,0.7777777777777778,1.0,0.7333333333333333,0.0,0.3333333333333333,0.3333333333333333,1.0,Is it offensive to pretend to trade before playing Monopoly?,"Among the settlers in katan, I sometimes try to ask people if they want to exchange certain resources and cheat them to reveal the approximate amount of resources in each person's hands. After that, I played Monopoly. This is not well accepted in some cases.","If you just want to determine which resource is the most abundant, can't you count the remaining resource cards? Isn't this public knowledge?"
3090,3090,4920,"SQL agent job, why is the job history showing that a step is still running even though the job has completed","I have a sql agent job that runs Powershell as its first step (there are 3 steps in total).

I have set this step to have 2 retries, with a 3 minute retry interval.
When I look into the job history, the step_1 states that it is still running, and also that it has completed. It has done this for every time that it has run (at least the last year).
Am I missing something from my powershell? Or is this something to do with sql agent itself?

Details of querying the sysjobhistory table (Pipe seperated):

Step_name|step_id|run_date|run_time|run_duration|run_status

(Job outcome)|0|2014/02/12|01:20:00|5|Succeded

Record volume space to file|1|2014/02/12|01:20:00|2|In Progress

Record volume space to file|1|2014/02/12|01:20:00|2|Succeded

Load Volume Space|2|2014/02/12|01:20:02|1|Succeded

Record database data file space|3|2014/02/12|01:20:03|2|Succeded


Step 1 runs the following Powershell:

gwmi win32_volume | select name, capacity, freespace | Export-Csv c:\temp.tmp

",Jake,https://dba.stackexchange.com/users/36309,"On the Hey Scripting Guy! blog at Technet, Chad Miller reports that if you run a Windows Powershell command as a SQL Agent job, and there are no syntax errors yet, the command produces an error (for example, attempting to get operating system information from an unavailable server). The SQL Server Agent job will report success.
Check tip #10 in the post for instructions on how to implement error handling with different options so that you can, for instance, have SQL Agent continue on error or halt the Agent job. The reported ""succeeded"" may not in fact have succeeded.

10-tips-for-the-sql-server-powershell-scripter
",huckleseed,https://dba.stackexchange.com/users/38334,http://dba.stackexchange.com/questions/65089/sql-agent-job-why-is-the-job-history-showing-that-a-step-is-still-running-even,TECHNOLOGY,dba.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.6,1.0,0.0,0.0,0.7777777777777778,"SQL agent job, why the job history shows that the step is still running even if the job has completed","I have a sql agent job that runs Powershell as its first step (there are 3 steps in total).

I have set this step to have 2 retries, with a 3 minute retry interval.
When I look into the job history, the step_1 states that it is still running, and also that it has completed. It has done this for every time that it has run (at least the last year).
Am I missing something from my powershell? Or is this something to do with sql agent itself?

Details of querying the sysjobhistory table (Pipe seperated):

Step_name|step_id|run_date|run_time|run_duration|run_status

(Job outcome)|0|2014/02/12|01:20:00|5|Succeded

Record volume space to file|1|2014/02/12|01:20:00|2|In Progress

Record volume space to file|1|2014/02/12|01:20:00|2|Succeded

Load Volume Space|2|2014/02/12|01:20:02|1|Succeded

Record database data file space|3|2014/02/12|01:20:03|2|Succeded


Step 1 runs the following Powershell:

gwmi win32_volume | select name, capacity, freespace | Export-Csv c:\temp.tmp

","On the Hey Scripting Guy! blog at Technet, Chad Miller reports that if you run a Windows Powershell command as a SQL Agent job, and there are no syntax errors yet, the command produces an error (for example, attempting to get operating system information from an unavailable server). The SQL Server Agent job will report success.
Check tip #10 in the post for instructions on how to implement error handling with different options so that you can, for instance, have SQL Agent continue on error or halt the Agent job. The reported ""succeeded"" may not in fact have succeeded.

10-tips-for-the-sql-server-powershell-scripter
"
3945,3945,6295,Counter-warding: how to know where wards are?,"Pro players seem to have some sixth sense when counter-warding, but I always seem to fail. For observer wards, you can try the usual ward spots (runes/rosh/hills).... however, if your five-man push fails because the enemy saw you coming, there are a lot of possible ward spots you may have walked by. And how about countering sentry wards to protect a riki/gondar/brood?
",Robert Fraser,https://gaming.stackexchange.com/users/3074,"The true answer is not to guess, but to know. Watch your minimap and your opponents' inventories constantly. In most games, it will be the enemy support heroes placing the majority if not all of the wards so you'll know where to focus your attention. If they are carrying wards you need to monitor their hero as much as possible and notice when that ward count drops by 1. When it does, you should know where they've been and where the common ward spots in that area are. If you've kept Observer Wards up yourself, you can determine exactly where they've placed it because doing so causes an animation. If you don't see this, you can usually narrow it down to one of a few spots and counterward appropriately. Most good counterwarding locations will reveal multiple frequently warded spots in an area- the reveal range of 950 is much larger than the vision range.

It's also worth noting that many of the common support heroes have spells that reveal high ground (allowing you to counter wards on hills or high ground that you couldn't otherwise see). AA's slow, Dazzle's ultimate, VS's howl, and others.

The other way to counterward requires a lot of experience and an expectation of high level opposition. Judging from how your opponents react to movement and gank attempts by your own team, you can tell when they've spotted someone moving between lanes and thus where they've warded. This is much more difficult and really only applicable if you're playing against competent opponents, weaker players are usally too sporadic for their reactions to be of much use. For example, I know that after a successful teamfight win in midgame by a good opposing team their supports will probably be spending the downtime placing offensive wards. With a combination of everything you've read above, I can make the chances of succesfully counterwarding worth the 100 gold chance to possibly catch a ward even if I don't know exactly where one has been placed.

As for the second part of your question, you will never really deliberately counter Sentry Wards unless it's to protect your own Observer Wards since doing so requires that the area be clear of opponents and thus their Sentry wards are unlikely to be used again anyway, they only last 3 minutes. If you really want to do so because your team is relying heavily on invisibility, a Gem is preferable because it will allow you to both reveal Sentries as you move around the map and also allow you to counter Observer Wards. This is only viable if carried by a hard to kill member of your team or the invisible hero they're countering, however. You don't want to die and give the other team the gem.
",Decency,https://gaming.stackexchange.com/users/11047,http://gaming.stackexchange.com/questions/47787/counter-warding-how-to-know-where-wards-are,CULTURE,gaming.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.0,0.6666666666666666,0.5,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.5555555555555556,1.0,1.0,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,1.0,1.0,How to know where the ward is?,"The pros seem to have a sixth sense on the counter attack, but I always seem to fail. For the observer ward, you can try the usual ward point (Rune / Rose / Hill).... However, if your 5-man push fails because the enemy sees you coming, there are many possible ward locations that you may have passed. So, how to protect a Ricky / gonda / cub against the sentry?","The true answer is not to guess, but to know. Watch your minimap and your opponents' inventories constantly. In most games, it will be the enemy support heroes placing the majority if not all of the wards so you'll know where to focus your attention. If they are carrying wards you need to monitor their hero as much as possible and notice when that ward count drops by 1. When it does, you should know where they've been and where the common ward spots in that area are. If you've kept Observer Wards up yourself, you can determine exactly where they've placed it because doing so causes an animation. If you don't see this, you can usually narrow it down to one of a few spots and counterward appropriately. Most good counterwarding locations will reveal multiple frequently warded spots in an area- the reveal range of 950 is much larger than the vision range.

It's also worth noting that many of the common support heroes have spells that reveal high ground (allowing you to counter wards on hills or high ground that you couldn't otherwise see). AA's slow, Dazzle's ultimate, VS's howl, and others.

The other way to counterward requires a lot of experience and an expectation of high level opposition. Judging from how your opponents react to movement and gank attempts by your own team, you can tell when they've spotted someone moving between lanes and thus where they've warded. This is much more difficult and really only applicable if you're playing against competent opponents, weaker players are usally too sporadic for their reactions to be of much use. For example, I know that after a successful teamfight win in midgame by a good opposing team their supports will probably be spending the downtime placing offensive wards. With a combination of everything you've read above, I can make the chances of succesfully counterwarding worth the 100 gold chance to possibly catch a ward even if I don't know exactly where one has been placed.

As for the second part of your question, you will never really deliberately counter Sentry Wards unless it's to protect your own Observer Wards since doing so requires that the area be clear of opponents and thus their Sentry wards are unlikely to be used again anyway, they only last 3 minutes. If you really want to do so because your team is relying heavily on invisibility, a Gem is preferable because it will allow you to both reveal Sentries as you move around the map and also allow you to counter Observer Wards. This is only viable if carried by a hard to kill member of your team or the invisible hero they're countering, however. You don't want to die and give the other team the gem.
"
1396,1396,2200,What is output impedance of a pin?,"When a datasheet mentions the output impedance of a pin so and so ohms. What exactly does it mean? Can anybody explain through a diagram how does it look like?
",Durgaprasad,https://electronics.stackexchange.com/users/20352,"Simplified, its just the internal resistance of the output. An equivalent circuit would be just a resistor in series with the sourcing output pin.   

Any non-ideal source has some (parasitic/unwanted) internal resistance due to the physical layout of the source. In general it needs to be low compared to the load, because with increasing current, the voltage drop on the internal resistance increases and thus, the output voltage decreases.

I keep talking about resistance but you asked about output impedance. 

Impedance = resistance + reactance

Reactance is the opposition of a circuit element to a change of electric current or voltage, due to its inductance or capacitance. Since the output behavior is not entirely resistive, we talk about ""output impedance"".
",Rev1.0,https://electronics.stackexchange.com/users/16051,http://electronics.stackexchange.com/questions/127046/what-is-output-impedance-of-a-pin,TECHNOLOGY,electronics.stackexchange.com,0.8333333333333334,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,0.0,0.6666666666666666,0.8333333333333334,0.8333333333333334,1.0,1.0,0.7,0.5,0.0,0.0,0.6666666666666666,What is the output impedance of the pin?,When the data sheet mentions the output impedance of a pin so ohm. What does that mean? Can anyone use a chart to explain what it looks like?,"Simplified, its just the internal resistance of the output. An equivalent circuit would be just a resistor in series with the sourcing output pin.   

Any non-ideal source has some (parasitic/unwanted) internal resistance due to the physical layout of the source. In general it needs to be low compared to the load, because with increasing current, the voltage drop on the internal resistance increases and thus, the output voltage decreases.

I keep talking about resistance but you asked about output impedance. 

Impedance = resistance + reactance

Reactance is the opposition of a circuit element to a change of electric current or voltage, due to its inductance or capacitance. Since the output behavior is not entirely resistive, we talk about ""output impedance"".
"
3740,3740,5957,Structure for nitrate ion?,"

Why is the above structure not considered a valid structure for the nitrate ion? Is it because adding a double bond reduces the formal charges present on the nitrogen? Does the above form exist anywhere?
",1110101001,https://chemistry.stackexchange.com/users/2142,"Nitrate actually exists as a superposition of these three resonance forms:



Essentially, a lone pair from an oxygen with a negative formal change forms a double bond to nitrogen. However, as nitrogen is a period II element, and hence must obey the octet rule, it can not have 5 bonds to other atoms. The already-present double bond then turns into a single bond and the pair of electrons moves onto the oxygen. This ""movement"" can happen with all three of the oxygen atoms and all three of the bonds. This is called ""resonance"".

Due to resonance, the energy of the system is minimised making it more stable.

Your Lewis structure is not far off. The ""true"" structure of nitrate is:



Approximately, each oxygen atom contributes one third of a bond with the nitrogen, lowering the formal charge on each atom from what you have written, which does not exist in nature.

The true structure is sort of an average of the properties of each possibility for where the electrons could be located, including the three resonance forms above, your structure, and any other configuration. However, these other forms are of minuscule probability to be formed (perhaps read up on wavefunctions and electron distributions if you're interested), and so the main contributors to the ""real"" structure are the three resonance forms.

Note that none of these structures ever exist in isolation for more than the most infinitesimal of time periods.
",Michael Scholz,https://chemistry.stackexchange.com/users/4860,http://chemistry.stackexchange.com/questions/9304/is-this-a-valid-structure-for-the-nitrate-ion,SCIENCE,chemistry.stackexchange.com,0.6666666666666666,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.8,0.0,0.0,1.0,0.6666666666666666,Structure of nitrate ions?,Why is the above structure not considered as the effective structure of nitrate? Is it because adding double bonds reduces the formal charge of nitrogen? Does the above form exist anywhere?,"Nitrate actually exists as a superposition of these three resonance forms:



Essentially, a lone pair from an oxygen with a negative formal change forms a double bond to nitrogen. However, as nitrogen is a period II element, and hence must obey the octet rule, it can not have 5 bonds to other atoms. The already-present double bond then turns into a single bond and the pair of electrons moves onto the oxygen. This ""movement"" can happen with all three of the oxygen atoms and all three of the bonds. This is called ""resonance"".

Due to resonance, the energy of the system is minimised making it more stable.

Your Lewis structure is not far off. The ""true"" structure of nitrate is:



Approximately, each oxygen atom contributes one third of a bond with the nitrogen, lowering the formal charge on each atom from what you have written, which does not exist in nature.

The true structure is sort of an average of the properties of each possibility for where the electrons could be located, including the three resonance forms above, your structure, and any other configuration. However, these other forms are of minuscule probability to be formed (perhaps read up on wavefunctions and electron distributions if you're interested), and so the main contributors to the ""real"" structure are the three resonance forms.

Note that none of these structures ever exist in isolation for more than the most infinitesimal of time periods.
"
4726,4726,7500,Roguelike Class Structure Makes Everything Effectively Global,"A brief rundown of the hierarchy of the game data objects:

Configuration - loaded from XML files, has Descriptors, among other things

Atlas - has a Configuration, has a CreatureInstance(represents the player's creature instance), is an associative array of AtlasColumns

AtlasColumn - has an Atlas(parent), is an associative array of AtlasCells

AtlasCell - has an AtlasColumn(parent), is an associative array of Layers

Layer - has an AtlasCell(parent), is an associative array of LayerColumns

LayerColumn - has a Layer(parent), is an associative array of LayerCells

LayerCell - has a LayerColumn(parent), has a CreatureInstance, a array of ItemInstances, and a TerrainInstance

CreatureInstance/ItemInstance/TerrainInstance - has a LayerCell(parent), has a Descriptor

Descriptor - has an associative array of properties needed by an instance to do its particular function

The most important thing in the Configuration are the Descriptors.  A Descriptor has all of the properties that are needed by the various types of instances. It has properties that drive behavior, what it looks like on screen, and so on.

So here's the part that bothers me:

Everything... EVERYTHING, from Atlas to TerrainInstance can talk up and down the entire chain, the reason being that if, for example, the TerrainInstance is a square upon which a player steps and suddenly a number of monsters are conjured around him, the TerrainInstance needs to have access to the neighboring LayerCells.  Or for another example if a CreatureInstance when attacking the player's CreatureInstance is able to take items from the player's inventory, and relocate them somewhere else in the dungeon, it needs access to a different Layer or AtlasCell in order to put the item where it needs to go.

An alternative that would appear to be ""better encapsulated"" might be a messaging system that sends little message objects up and down the chain and handles things at the appropriate level, but is that really any BETTER than just having the objects be aware of one another?

The game I'm writing started out with mostly hardcoded item and creature types, and gradually morphed its way into something similar to the more flexible roguelike framework that I've detailed above. I'm finally switching from C# to Java for it(the language is immaterial, however), and I'd like to not have missed something glaringly obvious that will cause great pains later when I need to refactor it.

So, the question: is the apparent lack of encapsulation within the data/business objects of the game demonstrate a fatal flaw in the architecture?  And if so, what is that flaw and how can I correct it before I get too far along?
",PlayDeezGames,https://gamedev.stackexchange.com/users/12875,"There's nothing wrong with objects knowing about other objects. That doesn't defy encapsulation.

However, I don't think anything is gained by having CreatureInstance actually store a reference to it's LayerCell. That's a needless coupling of data. It should have a ""location"" type, and Atlas should have a FindCell function that takes this location type.


  Or for another example if a CreatureInstance when attacking the player's CreatureInstance is able to take items from the player's inventory, and relocate them somewhere else in the dungeon, it needs access to a different Layer or AtlasCell in order to put the item where it needs to go.


What you're saying is that the CreatureInstance itself needs to directly do the following:


Detect that it's attack hit the target.
Look in the inventory of the target.
Remove some items form it.
Place those items in the world.


This is highly unnecessary. Why does the CreatureInstance have to do this? Yes, conceptually, it is the creature's attack that causes items to be removed. But why does the CreatureInstance object have to deal with that?

Here's how I would do it.

The CreatureInstance would have one or more Attacks. An Attack is an object that, when successful, can cause one or more effects. Effects include:


Dealing damage, possibly with damage types.
Removing items from the target and placing them on the map.
etc.


All the CreatureInstance has to know is what Attacks it can perform and who it can perform them on. When it decides to use the DrainItemsAttack, it simply says, ""I'm using DrainItemsAttack on this target.""

The DrainItemsAttack would invoke the ""RemoveAndDropItems"" effect. That's not a class; that's a free function (or a static member of some class, since you're using languages that don't allow free functions). It doesn't have to have state, so it doesn't need to be a type. It's just a function that takes some number of inventory items from a CreatureInstance and places them on the ground.

It is that function which needs to be able to inspect inventory, remove items, find suitable terrain to place them on, etc. Each of these operations should be its own function. So your ""RemoveAndDropItems"" effect would be implemented like this (pseudo-code):

bool RemoveAndDropItems(int numToRemove, CreatureInstance target, Atlas world)
{
  for(numToRemove)
  {
    ItemInstance item = target.FindSuitableItemToRemove();
    if(!item)
      return false;
    target.RemoveItem(item);
    LayerCell loc = world.FindSuitableLocationToPlaceItem(item, target.loc());
    world.PlaceItem(item, loc);
  }
  return true;
}


This way, CreatureInstance isn't responsible for finding places to put stuff. You have functions for that. Nor does it have to have knowledge of ItemInstance or other types; that's all taken care of elsewhere.
",Nicol Bolas,https://gamedev.stackexchange.com/users/8240,http://gamedev.stackexchange.com/questions/24023/roguelike-class-structure-makes-everything-effectively-global,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.5555555555555556,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,1.0,1.0,Roguelike class structure effectively globalizes all content,"A brief rundown of the hierarchy of the game data objects:

Configuration - loaded from XML files, has Descriptors, among other things

Atlas - has a Configuration, has a CreatureInstance(represents the player's creature instance), is an associative array of AtlasColumns

AtlasColumn - has an Atlas(parent), is an associative array of AtlasCells

AtlasCell - has an AtlasColumn(parent), is an associative array of Layers

Layer - has an AtlasCell(parent), is an associative array of LayerColumns

LayerColumn - has a Layer(parent), is an associative array of LayerCells

LayerCell - has a LayerColumn(parent), has a CreatureInstance, a array of ItemInstances, and a TerrainInstance

CreatureInstance/ItemInstance/TerrainInstance - has a LayerCell(parent), has a Descriptor

Descriptor - has an associative array of properties needed by an instance to do its particular function

The most important thing in the Configuration are the Descriptors.  A Descriptor has all of the properties that are needed by the various types of instances. It has properties that drive behavior, what it looks like on screen, and so on.

So here's the part that bothers me:

Everything... EVERYTHING, from Atlas to TerrainInstance can talk up and down the entire chain, the reason being that if, for example, the TerrainInstance is a square upon which a player steps and suddenly a number of monsters are conjured around him, the TerrainInstance needs to have access to the neighboring LayerCells.  Or for another example if a CreatureInstance when attacking the player's CreatureInstance is able to take items from the player's inventory, and relocate them somewhere else in the dungeon, it needs access to a different Layer or AtlasCell in order to put the item where it needs to go.

An alternative that would appear to be ""better encapsulated"" might be a messaging system that sends little message objects up and down the chain and handles things at the appropriate level, but is that really any BETTER than just having the objects be aware of one another?

The game I'm writing started out with mostly hardcoded item and creature types, and gradually morphed its way into something similar to the more flexible roguelike framework that I've detailed above. I'm finally switching from C# to Java for it(the language is immaterial, however), and I'd like to not have missed something glaringly obvious that will cause great pains later when I need to refactor it.

So, the question: is the apparent lack of encapsulation within the data/business objects of the game demonstrate a fatal flaw in the architecture?  And if so, what is that flaw and how can I correct it before I get too far along?
","There's nothing wrong with objects knowing about other objects. That doesn't defy encapsulation.

However, I don't think anything is gained by having CreatureInstance actually store a reference to it's LayerCell. That's a needless coupling of data. It should have a ""location"" type, and Atlas should have a FindCell function that takes this location type.


  Or for another example if a CreatureInstance when attacking the player's CreatureInstance is able to take items from the player's inventory, and relocate them somewhere else in the dungeon, it needs access to a different Layer or AtlasCell in order to put the item where it needs to go.


What you're saying is that the CreatureInstance itself needs to directly do the following:


Detect that it's attack hit the target.
Look in the inventory of the target.
Remove some items form it.
Place those items in the world.


This is highly unnecessary. Why does the CreatureInstance have to do this? Yes, conceptually, it is the creature's attack that causes items to be removed. But why does the CreatureInstance object have to deal with that?

Here's how I would do it.

The CreatureInstance would have one or more Attacks. An Attack is an object that, when successful, can cause one or more effects. Effects include:


Dealing damage, possibly with damage types.
Removing items from the target and placing them on the map.
etc.


All the CreatureInstance has to know is what Attacks it can perform and who it can perform them on. When it decides to use the DrainItemsAttack, it simply says, ""I'm using DrainItemsAttack on this target.""

The DrainItemsAttack would invoke the ""RemoveAndDropItems"" effect. That's not a class; that's a free function (or a static member of some class, since you're using languages that don't allow free functions). It doesn't have to have state, so it doesn't need to be a type. It's just a function that takes some number of inventory items from a CreatureInstance and places them on the ground.

It is that function which needs to be able to inspect inventory, remove items, find suitable terrain to place them on, etc. Each of these operations should be its own function. So your ""RemoveAndDropItems"" effect would be implemented like this (pseudo-code):

bool RemoveAndDropItems(int numToRemove, CreatureInstance target, Atlas world)
{
  for(numToRemove)
  {
    ItemInstance item = target.FindSuitableItemToRemove();
    if(!item)
      return false;
    target.RemoveItem(item);
    LayerCell loc = world.FindSuitableLocationToPlaceItem(item, target.loc());
    world.PlaceItem(item, loc);
  }
  return true;
}


This way, CreatureInstance isn't responsible for finding places to put stuff. You have functions for that. Nor does it have to have knowledge of ItemInstance or other types; that's all taken care of elsewhere.
"
2166,2166,3454,High-Tech Dungeon Crawling in Hard Sci-Fi,"I've started playing Eclipse Phase with a group of friends. Most of them have a Dungeons and Dragon history, and love getting magic items and such. I've already made up my mind to take the party on more dungeon raids, but what specifically can I do in the way of loot? It is a hard science fiction setting; no magic. It's noted in the core book that some brand-name weapons and items will have special features, and there is something called Psi that is basically watered-down psychic abilities. What are some recommendations you would make for drops and treasure caches?
",Tasuret,https://rpg.stackexchange.com/users/1598,"Treasures?


Self-mobile plot-hook - NPC similar to Princess Leia in SW Ep IV in role. In distress, but of use down the road
Illegal goods of use to the party
Better weapons than the party has... if they can take them from the current owners.
Rescue a trainer who can provide them esoteric skills training
maps to other places to raid
Entry Tokens to Eroticon 6 (HHGTTG reference...)
repair parts
almost untraceable bulk cargo of high value
Readily traceable very high value cargo worth black marketing (ADVENTURE HOOK FROM H***)
parts for improving their gear
manuals for various bits of gear
objects d'arte

",aramis,https://rpg.stackexchange.com/users/407,http://rpg.stackexchange.com/questions/6974/high-tech-dungeon-crawling-in-hard-sci-fi,CULTURE,rpg.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,1.0,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.0,0.6666666666666666,High tech dungeons crawling in hard science fiction,"I've started the eclipse phase with a group of friends. Most of them have a history of dungeons and dragons, like to get magic items and so on. I have made up my mind to let the party make more raids in the dungeons, but what can I do to rob? It's a hard science fiction scene; there's no magic. As mentioned in the core book, some famous brand weapons and articles will have special functions. There is also something called psi, which basically weakens the psychological ability. What advice would you give to drips and treasures?","Treasures?


Self-mobile plot-hook - NPC similar to Princess Leia in SW Ep IV in role. In distress, but of use down the road
Illegal goods of use to the party
Better weapons than the party has... if they can take them from the current owners.
Rescue a trainer who can provide them esoteric skills training
maps to other places to raid
Entry Tokens to Eroticon 6 (HHGTTG reference...)
repair parts
almost untraceable bulk cargo of high value
Readily traceable very high value cargo worth black marketing (ADVENTURE HOOK FROM H***)
parts for improving their gear
manuals for various bits of gear
objects d'arte

"
5119,5119,8139,How to stop SQL server restore from overwriting database?,"I have a ELMAH database that I want to script the restore of using the following:

RESTORE DATABASE [Elmah] 
FROM DISK = N'E:\Elmah_backup_2012_11_02_030003_1700702.bak' 
WITH FILE = 1,  
MOVE N'Elmah' TO N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah.mdf',  
MOVE N'Elmah_log' TO N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah.ldf',  
NOUNLOAD, STATS = 10
GO


Even though I am not including WITH REPLACE each time I execute this statement it restores over the existing database.

I will always drop all databases before this operation and I never want this code to accidentally restore a database over one in production.

How do I change this code so that it will never overwrite an existing database?

I am actually doing this through SMO objects but the principle and results are the same so I am hoping to keep this simplified to just the TSQL necessary in the hopes that I can generalize that information to what needs to be set on the appropriate SMO.Restore object.
",Chris Magnuson,https://stackoverflow.com/users/101679,"You need to (a) give the restored database a new logical name, and (b) you need to define new physical file names, so the existing ones won't be overwritten. Try something like this:

RESTORE DATABASE [Elmah_Restored]       &lt;== new (and unique) logical database name
FROM DISK = N'E:\Elmah_backup_2012_11_02_030003_1700702.bak' 
WITH FILE = 1,  
MOVE N'Elmah' TO 
     N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah_restored.mdf',   &lt;== new (and unique) physical file name
MOVE N'Elmah_log' TO 
     N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah_restored_log.ldf',   &lt;== new (and unique) physical file name
NOUNLOAD, STATS = 10
GO

",marc_s,https://stackoverflow.com/users/13302,http://stackoverflow.com/questions/13200464/how-to-stop-sql-server-restore-from-overwriting-database,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,How to prevent SQL server from restoring the overwriting database?,"I have a ELMAH database that I want to script the restore of using the following:

RESTORE DATABASE [Elmah] 
FROM DISK = N'E:\Elmah_backup_2012_11_02_030003_1700702.bak' 
WITH FILE = 1,  
MOVE N'Elmah' TO N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah.mdf',  
MOVE N'Elmah_log' TO N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah.ldf',  
NOUNLOAD, STATS = 10
GO


Even though I am not including WITH REPLACE each time I execute this statement it restores over the existing database.

I will always drop all databases before this operation and I never want this code to accidentally restore a database over one in production.

How do I change this code so that it will never overwrite an existing database?

I am actually doing this through SMO objects but the principle and results are the same so I am hoping to keep this simplified to just the TSQL necessary in the hopes that I can generalize that information to what needs to be set on the appropriate SMO.Restore object.
","You need to (a) give the restored database a new logical name, and (b) you need to define new physical file names, so the existing ones won't be overwritten. Try something like this:

RESTORE DATABASE [Elmah_Restored]       &lt;== new (and unique) logical database name
FROM DISK = N'E:\Elmah_backup_2012_11_02_030003_1700702.bak' 
WITH FILE = 1,  
MOVE N'Elmah' TO 
     N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah_restored.mdf',   &lt;== new (and unique) physical file name
MOVE N'Elmah_log' TO 
     N'C:\Program Files\Microsoft SQL Server\MSSQL10_50.MSSQLSERVER\MSSQL\DATA\Elmah_restored_log.ldf',   &lt;== new (and unique) physical file name
NOUNLOAD, STATS = 10
GO

"
1718,1718,2720,Is research a viable business model?,"I have had the suspicion that it may be for a while and apparently not all is a product of my mind. Let me quote from an answer:


  In my experience, in UK and other European countries, the research
  funding comes from successful proposals to the relevant funding
  bodies. There are research centres that were established and keep
  going only because the staff there constantly submits project
  proposals (somebody told me that the success rate is 1 out of 5 or
  maybe even lower).


There are two questions here.


Can a company feasibly focus on obtaining funds in publicly funded research (as a business model) successfully enough to ""survive""?
Can such a company be started (nearly) from scratch?


In short, the company would be exactly like a research institute (or institution) except that it would be private.

Reasons why question 1 may not be feasible:


I don't see any company doing this kind of thing, i.e. there may be some, but there are not many, which means that it may be hard. It's a bad sign.
Public funds seem to be assigned to public entities, while companies can benefit from the collaboration and synergy, but they are expected to get their funding from their work as companies (searching for customers, etc.) In this case the customers would be the partners in the projects and the society itself, but again, this seems to be an ""innovative"" (maybe naÃ¯ve, or even plain stupid) idea.
Research is a means for something, not an end on itself, that's why the business model should be on something else (point two) and that's why such a company would raise eyebrows on the mere idea of its existence. It may even be against some kind of tacit rule or even written laws.


Reasons why question 2 may not be feasible:


No previous history of success of the company, or products or anything means zero (or negative) trustworthiness and no projects assigned to the company.
No partners would like to associate with the company in a project for the reasons in point 1.
The most similar case I can think of are spin-off companies that are created from successful research labs, not from scratch.
OMG so much communism! Go to kickstarter you hippie!


As an example, a possible scenario that could be close to this: Someone writes a paper about a software system that does something not very novel in the state of the art but in a way that is very different from an architectural point of view, leading to good results in practical terms. In short: in theory nothing is new, in practice what was just a dream is now a reality. What is done remains the same in theory, but how it is done is completely different in practice (and now it works). Unfortunately only a proof of concept (PoC) can reasonably be implemented.

Would it be feasible to request funds to continue the development of this PoC (still very far from a commercial product) as a start-up or that simply doesn't make sense?
",Trylks,https://academia.stackexchange.com/users/7571,"From the perspective of the US, there are many research institutes that operate as a private business entity.  These research institutes can apply for some federal funding in the same capacity as a research at an educational institution.  I see it being possible to start a private company without a lot of capital, although you will need to have a very strong skill set that is in demand.  Whether this is a sustainable model really seems to depend on the specialized skills that the business would offer and the infrastructure that would allow it to efficiently prepare grants. Research-I educational institutions in the US have an incredible infrastructure to prepare and apply for grants that would be difficult to replicate in the private sector.  
",Brian P,https://academia.stackexchange.com/users/17232,http://academia.stackexchange.com/questions/23676/is-research-a-viable-business-model,LIFE_ARTS,academia.stackexchange.com,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.4444444444444444,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,0.6666666666666666,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.7777777777777778,Is research a viable business model?,"I have had the suspicion that it may be for a while and apparently not all is a product of my mind. Let me quote from an answer:


  In my experience, in UK and other European countries, the research
  funding comes from successful proposals to the relevant funding
  bodies. There are research centres that were established and keep
  going only because the staff there constantly submits project
  proposals (somebody told me that the success rate is 1 out of 5 or
  maybe even lower).


There are two questions here.


Can a company feasibly focus on obtaining funds in publicly funded research (as a business model) successfully enough to ""survive""?
Can such a company be started (nearly) from scratch?


In short, the company would be exactly like a research institute (or institution) except that it would be private.

Reasons why question 1 may not be feasible:


I don't see any company doing this kind of thing, i.e. there may be some, but there are not many, which means that it may be hard. It's a bad sign.
Public funds seem to be assigned to public entities, while companies can benefit from the collaboration and synergy, but they are expected to get their funding from their work as companies (searching for customers, etc.) In this case the customers would be the partners in the projects and the society itself, but again, this seems to be an ""innovative"" (maybe naÃ¯ve, or even plain stupid) idea.
Research is a means for something, not an end on itself, that's why the business model should be on something else (point two) and that's why such a company would raise eyebrows on the mere idea of its existence. It may even be against some kind of tacit rule or even written laws.


Reasons why question 2 may not be feasible:


No previous history of success of the company, or products or anything means zero (or negative) trustworthiness and no projects assigned to the company.
No partners would like to associate with the company in a project for the reasons in point 1.
The most similar case I can think of are spin-off companies that are created from successful research labs, not from scratch.
OMG so much communism! Go to kickstarter you hippie!


As an example, a possible scenario that could be close to this: Someone writes a paper about a software system that does something not very novel in the state of the art but in a way that is very different from an architectural point of view, leading to good results in practical terms. In short: in theory nothing is new, in practice what was just a dream is now a reality. What is done remains the same in theory, but how it is done is completely different in practice (and now it works). Unfortunately only a proof of concept (PoC) can reasonably be implemented.

Would it be feasible to request funds to continue the development of this PoC (still very far from a commercial product) as a start-up or that simply doesn't make sense?
","From the perspective of the US, there are many research institutes that operate as a private business entity.  These research institutes can apply for some federal funding in the same capacity as a research at an educational institution.  I see it being possible to start a private company without a lot of capital, although you will need to have a very strong skill set that is in demand.  Whether this is a sustainable model really seems to depend on the specialized skills that the business would offer and the infrastructure that would allow it to efficiently prepare grants. Research-I educational institutions in the US have an incredible infrastructure to prepare and apply for grants that would be difficult to replicate in the private sector.  
"
1534,1534,2409,Find cron jobs that run between given times,"Is it possible to find all entries in a crontab that run between time X and time Y without having to parse the cron time entries myself? I'm mainly concerned with time hour and  minute, not so much the other 3 time fields.
",frankc,https://stackoverflow.com/users/275455,"Since this doesn't seem possible without parsing cron, I decided to write it myself in perl:
(not sure why the formatting is fubar)

#!/usr/bin/perl -w
use strict;
use Set::CrossProduct;

my $begin;
my $end;

if($ARGV[0] &amp;&amp; $ARGV[0] =~ /before/i){
    $begin = 0;
    $end = $ARGV[1];
}
elsif($ARGV[0] &amp;&amp; $ARGV[0] =~ /after/i){
    $end = 2400;
    $begin = $ARGV[1]; 
}
else{
    $begin = $ARGV[0];
    $end = $ARGV[1];
}

if(!defined($begin) || !defined($end)){
    print STDERR ""Invalid Arguments\n"";
    exit 1;
}

my @crontab = `crontab -l`;

foreach my $cronjob (@crontab){
    chomp $cronjob;

next if $cronjob =~ /^ *\#/ ||$cronjob =~ /^ *$/  ;

#print ""in: $cronjob\n"";

my ($min,$hour,$day_of_month,$month,$day_of_week, @cmd) = split(/ /, $cronjob);

my @mins = expandRange($min,0,59);
my @hours = expandRange($hour,0,23);

my $cp = Set::CrossProduct-&gt;new([\@hours,\@mins]);

my $combos = $cp-&gt;combinations();

foreach my $time ( map { $_-&gt;[0]*100 + $_-&gt;[1] } @$combos){
if($time &gt;= $begin &amp;&amp; $time &lt;= $end){
    print $cronjob,""\n"";
    last; #don't print the job n times, just once
}
}


}

sub expandRange{

my ($in,$begin,$end) = @_;
#print ""in: ($in)[$begin:$end]\n"";
my @range;

my @vals = split(/,/,$in);
foreach my $val (@vals){
my $mult = 1;
if($val =~ /\/(.+)$/){
    $mult = $1;
    $val =~ s/\/(.+)//;
}

if($in =~ /\*/){
    @range = grep { $_ % $mult == 0 &amp;&amp; $_ &gt;= $begin &amp;&amp;  $_ &lt;= $end  } $begin..$end;
}
elsif($val =~ /[\-:]/){
    my ($first, $last) = split(/[\-:]/,$val);
    push(@range, grep {  $_ % $mult == 0 &amp;&amp; $_ &gt;= $begin &amp;&amp;  $_ &lt;= $end } $first..$last);
}
elsif($val &gt;= $begin &amp;&amp;  $val &lt;= $end) {
    push(@range, $val);
}
}

my %unique;
@unique{@range} = 1;

return sort keys %unique;


}

",frankc,https://stackoverflow.com/users/275455,http://stackoverflow.com/questions/4053463/find-cron-jobs-that-run-between-given-times,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.0,0.0,1.0,Find cron jobs running between given times,"Can you find all the entries running between time x and time y in crontab without having to analyze the cron time entries yourself? My main concerns are time hours and minutes, not the other three time domains.","Since this doesn't seem possible without parsing cron, I decided to write it myself in perl:
(not sure why the formatting is fubar)

#!/usr/bin/perl -w
use strict;
use Set::CrossProduct;

my $begin;
my $end;

if($ARGV[0] &amp;&amp; $ARGV[0] =~ /before/i){
    $begin = 0;
    $end = $ARGV[1];
}
elsif($ARGV[0] &amp;&amp; $ARGV[0] =~ /after/i){
    $end = 2400;
    $begin = $ARGV[1]; 
}
else{
    $begin = $ARGV[0];
    $end = $ARGV[1];
}

if(!defined($begin) || !defined($end)){
    print STDERR ""Invalid Arguments\n"";
    exit 1;
}

my @crontab = `crontab -l`;

foreach my $cronjob (@crontab){
    chomp $cronjob;

next if $cronjob =~ /^ *\#/ ||$cronjob =~ /^ *$/  ;

#print ""in: $cronjob\n"";

my ($min,$hour,$day_of_month,$month,$day_of_week, @cmd) = split(/ /, $cronjob);

my @mins = expandRange($min,0,59);
my @hours = expandRange($hour,0,23);

my $cp = Set::CrossProduct-&gt;new([\@hours,\@mins]);

my $combos = $cp-&gt;combinations();

foreach my $time ( map { $_-&gt;[0]*100 + $_-&gt;[1] } @$combos){
if($time &gt;= $begin &amp;&amp; $time &lt;= $end){
    print $cronjob,""\n"";
    last; #don't print the job n times, just once
}
}


}

sub expandRange{

my ($in,$begin,$end) = @_;
#print ""in: ($in)[$begin:$end]\n"";
my @range;

my @vals = split(/,/,$in);
foreach my $val (@vals){
my $mult = 1;
if($val =~ /\/(.+)$/){
    $mult = $1;
    $val =~ s/\/(.+)//;
}

if($in =~ /\*/){
    @range = grep { $_ % $mult == 0 &amp;&amp; $_ &gt;= $begin &amp;&amp;  $_ &lt;= $end  } $begin..$end;
}
elsif($val =~ /[\-:]/){
    my ($first, $last) = split(/[\-:]/,$val);
    push(@range, grep {  $_ % $mult == 0 &amp;&amp; $_ &gt;= $begin &amp;&amp;  $_ &lt;= $end } $first..$last);
}
elsif($val &gt;= $begin &amp;&amp;  $val &lt;= $end) {
    push(@range, $val);
}
}

my %unique;
@unique{@range} = 1;

return sort keys %unique;


}

"
5710,5710,9049,Weird jquery 302 error in Firebug,"I am posting data to servlet using jquery .post() method. The data is being posted and servlet is able to catch the data. But in my firebug I see 302 once the post request is done.

Also I am redirecting the user to success page in my servlet. But the redirect is not happening!!

Should'nt I be getting 200 on the post request?

And why is a simple response.sendRedirect(""success.jsp"") not happening?



When I click on the response tab I can see the success.jsp html tags.

Please throw light on what is happening? How do I correct it?
",enthusiastic,https://stackoverflow.com/users/584003,"That is not wierd. because you have called sendRedirect method in the server, server send back the response with 302 for informing the client browser to redirect to another url (which is also sent in the response header).

You can use forward method instead of redirect method if you want to do the redirection from the server side.
",Manjula Weerasinge,https://stackoverflow.com/users/201986,http://stackoverflow.com/questions/8613350/weird-jquery-302-error-in-firebug,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.6666666666666666,0.7777777777777778,Strange jQuery 302 error in firebug,"I am posting data to servlet using jquery .post() method. The data is being posted and servlet is able to catch the data. But in my firebug I see 302 once the post request is done.

Also I am redirecting the user to success page in my servlet. But the redirect is not happening!!

Should'nt I be getting 200 on the post request?

And why is a simple response.sendRedirect(""success.jsp"") not happening?



When I click on the response tab I can see the success.jsp html tags.

Please throw light on what is happening? How do I correct it?
","That's not wierd. Because you invoke the sendRedirect method in the server, the server sends a response in 302 to notify the client browser to redirect to another URL (also in the response header)."
634,634,1000,Is it better to go first or last in Vinci?,"My son is convinced that it's best to go last in Vinci because you have the more complete information of seeing where other players have started their civilizations and you always get last turn (like having home field advantage in baseball). I see these 2 advantages, but I wonder if these outweigh the disadvantages such as not having first pick on civilizations, not being the first to go into decline, and perhaps other factors I haven't even considered (we're all new to the game). So:

Is it better to go first, last, in between, or is the game so well balanced that it hardly matters?
",Joe Golton,https://boardgames.stackexchange.com/users/2260,"This is very difficult question to answer because so much of it depends on your experience, play-style, and how the random elements of the game turn out.  These games have sufficient complexity that, based on how they are played by humans, going either first or last might be an advantage.

It's certain that one's play-style preferences will affect this decision.  If you are one who more often likes to find a best response to your opponent's moves, then going later will be 'better' since it suits your play-style, this you'll win more often going later than going earlier.  However, if you're one who prefers to be more strategic, going earlier might yield you more wins.

Two things to note:


If you have the choice of consistently going in a certain order, keep choosing the one you have the most experience with.  This will enable you to remove one variable of the game, and allow you to improve your skill in the game faster.
There ARE certain combinations of races and powers that are clearly better, especially in terms of how they interact, than others.  This means that in certain games, it will be more advantageous to grab them, thus go earlier.  However, it's not at all clear that these situations happen often enough to offset any advantages (if they exist) from going later.

",Neal Tibrewala,https://boardgames.stackexchange.com/users/587,http://boardgames.stackexchange.com/questions/7413/is-it-better-to-go-first-or-last-in-vinci,CULTURE,boardgames.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,"In Finch, is it better to go first or later?","My son is sure it's best to be last in Vince because you have more complete information about where other players started their civilization and you always get the last round (home advantage in baseball, for example). I have seen these two advantages, but I want to know if they exceed the disadvantages, such as no first choice of civilization, no first decline, and perhaps other factors I have not even considered (we are all novices). So:","This is very difficult question to answer because so much of it depends on your experience, play-style, and how the random elements of the game turn out.  These games have sufficient complexity that, based on how they are played by humans, going either first or last might be an advantage.

It's certain that one's play-style preferences will affect this decision.  If you are one who more often likes to find a best response to your opponent's moves, then going later will be 'better' since it suits your play-style, this you'll win more often going later than going earlier.  However, if you're one who prefers to be more strategic, going earlier might yield you more wins.

Two things to note:


If you have the choice of consistently going in a certain order, keep choosing the one you have the most experience with.  This will enable you to remove one variable of the game, and allow you to improve your skill in the game faster.
There ARE certain combinations of races and powers that are clearly better, especially in terms of how they interact, than others.  This means that in certain games, it will be more advantageous to grab them, thus go earlier.  However, it's not at all clear that these situations happen often enough to offset any advantages (if they exist) from going later.

"
427,427,662,Change top's sorting back to CPU,"A former coworker did something to top that whenever it runs as root the data is sorted by MEM usage instead of the default CPU usage. According to multiple searches, the man page and even the options within the top console itself (O), just pressing k it should be sorted by CPU, but instead when I hit k it asks me for a pid to kill.

So how can I get back default sorting to CPU?  
",yzT,https://unix.stackexchange.com/users/27807,"To add to the answers already P (upper case P) makes top order by CPU, Then hit W (again upper case W) to save. 

M goes back to memory
",exussum,https://unix.stackexchange.com/users/29498,http://unix.stackexchange.com/questions/158584/change-tops-sorting-back-to-cpu,TECHNOLOGY,unix.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Change top sorting back to CPU,"A former colleague did something, and whenever it ran as root, the data was sorted by MEM usage rather than the default CPU usage. Based on multiple searches, the man page or even the options in the top console itself (O), as long as you press K, it should be sorted by CPU, but when I press K, it will ask me to kill a PID.","To add to the answers already P (upper case P) makes top order by CPU, Then hit W (again upper case W) to save. 

M goes back to memory
"
2011,2011,3208,Cordova - Trying to execute a function inside a webview,"I have a webview from my website working very well in my app. What I'm trying to do now is asking users when they hit Android Back Button if they really want to leave the app.
I'm using the InAppBrowser plugin. Here's my code.

document.addEventListener(""deviceready"", onDeviceReady, false);

        // Cordova is ready
        function onDeviceReady() {
            navigator.splashscreen.show();
            var ref = window.open(""http://m.estadao.com.br"", ""_self"", ""location=no"");

            ref.addEventListener('loadstop', function(){
                ref.executeScript({
                    code:  
                        document.addEventListener(""backbutton"", onBackKeyDown, false);
                        function onBackKeyDown() {
                            navigator.notification.confirm(
                                ""Tem certeza que deseja sair?"",
                                function(buttonIndex){
                                    confirmExit(buttonIndex);
                                },
                                ""Aviso"",
                                ""Ok, Cancel""
                            );
                        }
                        function confirmExit(stat){
                            if (stat == ""1""){
                                navigator.app.exitApp();
                            } else {
                                window.open(""http://m.estadao.com.br"", ""_self"", ""location=no"", ""zoom=no"");
                            }
                        };
                });
            });
        }


And here is the link of plugin
http://cordova.apache.org/docs/en/2.7.0/cordova_inappbrowser_inappbrowser.md.html#executeScript

Any idea what can i do to make it work ? Thanks!
",vbotio,https://stackoverflow.com/users/3025104,"I am assuming that your problem is back-button event is not getting triggered once the webview loads. This is a common problem with using in-appbrowser plugin for webview. It loads page but we loose control over the page. Use the following plugin
    https://github.com/Wizcorp/phonegap-plugin-wizViewManager/ for webView. It creates a custom webview inside your phonegap app and you still have control over back button and you can also define the size of the webView
",ShinyJos,https://stackoverflow.com/users/3477701,http://stackoverflow.com/questions/31466037/cordova-trying-to-execute-a-function-inside-a-webview,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.5,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,0.8333333333333334,Cordova - try to execute functions in WebView,"I have a webview from my website working very well in my app. What I'm trying to do now is asking users when they hit Android Back Button if they really want to leave the app.
I'm using the InAppBrowser plugin. Here's my code.

document.addEventListener(""deviceready"", onDeviceReady, false);

        // Cordova is ready
        function onDeviceReady() {
            navigator.splashscreen.show();
            var ref = window.open(""http://m.estadao.com.br"", ""_self"", ""location=no"");

            ref.addEventListener('loadstop', function(){
                ref.executeScript({
                    code:  
                        document.addEventListener(""backbutton"", onBackKeyDown, false);
                        function onBackKeyDown() {
                            navigator.notification.confirm(
                                ""Tem certeza que deseja sair?"",
                                function(buttonIndex){
                                    confirmExit(buttonIndex);
                                },
                                ""Aviso"",
                                ""Ok, Cancel""
                            );
                        }
                        function confirmExit(stat){
                            if (stat == ""1""){
                                navigator.app.exitApp();
                            } else {
                                window.open(""http://m.estadao.com.br"", ""_self"", ""location=no"", ""zoom=no"");
                            }
                        };
                });
            });
        }


And here is the link of plugin
http://cordova.apache.org/docs/en/2.7.0/cordova_inappbrowser_inappbrowser.md.html#executeScript

Any idea what can i do to make it work ? Thanks!
","I am assuming that your problem is back-button event is not getting triggered once the webview loads. This is a common problem with using in-appbrowser plugin for webview. It loads page but we loose control over the page. Use the following plugin
    https://github.com/Wizcorp/phonegap-plugin-wizViewManager/ for webView. It creates a custom webview inside your phonegap app and you still have control over back button and you can also define the size of the webView
"
4220,4220,6732,Examples of RESTful Web Services for Browser Games,"Can anyone point me towards examples of Browser Games / Browser Game Sites that use RESTful web services?

I have been convinced time and again that building web sites using RESTful principles is a good idea. And I agree.  But I just can't wrap my head around what RESTful means when the service you're providing is just a single (or a few) games.

Any ideas or thoughts would be nice, but I'd also love to see some solid examples.
",theJollySin,https://gamedev.stackexchange.com/users/15684,"You would have REST services for all the moves one could make, or for the game information requests.

Something like:

POST /game/45093/move?x=3&amp;y=2

POST /game/45093/surrender

GET /game/45093/status

GET /games


etc...
",Wouter Lievens,https://gamedev.stackexchange.com/users/4857,http://gamedev.stackexchange.com/questions/28058/examples-of-restful-web-services-for-browser-games,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,0.5,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8333333333333334,0.5,0.8333333333333334,1.0,0.7,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,Example of restful web services for browser games,"Can anyone point me towards examples of Browser Games / Browser Game Sites that use RESTful web services?

I have been convinced time and again that building web sites using RESTful principles is a good idea. And I agree.  But I just can't wrap my head around what RESTful means when the service you're providing is just a single (or a few) games.

Any ideas or thoughts would be nice, but I'd also love to see some solid examples.
","You would have REST services for all the moves one could make, or for the game information requests.

Something like:

POST /game/45093/move?x=3&amp;y=2

POST /game/45093/surrender

GET /game/45093/status

GET /games


etc...
"
3951,3951,6305,What do you call a group of people that move a lot?,"I can't think of the word to describe it. Something similar to ""wanderer"" or ""roamer"". 

It's often used to describe people that don't stay in one place... not ""migratory""...
",Marty,https://english.stackexchange.com/users/9704,"Nomadic should work. But I would not go with words like pastoral. It seems to convey a more idyllic and peaceful stance. Also, pastoral might refer to continuous movement in search of rural grasslands to base your livelihood upon.

Also, gypsies, fugitives and migrants or bedouins would be discriminatory to use in a extended sense as they are particular to certain segments of people. The same is the case with a vagabond or a tramp.

The word which I would prefer over Nomadic is the word 'drifting'. It seems to convey more of the aimless movement that the question seemed to have in mind.
",Sri Atluru,https://english.stackexchange.com/users/9701,http://english.stackexchange.com/questions/29078/what-do-you-call-a-group-of-people-that-move-a-lot,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,What do you call people who move a lot?,"I can't think of the word to describe it. Something similar to ""wanderer"" or ""roamer"". 

It's often used to describe people that don't stay in one place... not ""migratory""...
","Nomadic should work. But I would not go with words like pastoral. It seems to convey a more idyllic and peaceful stance. Also, pastoral might refer to continuous movement in search of rural grasslands to base your livelihood upon.

Also, gypsies, fugitives and migrants or bedouins would be discriminatory to use in a extended sense as they are particular to certain segments of people. The same is the case with a vagabond or a tramp.

The word which I would prefer over Nomadic is the word 'drifting'. It seems to convey more of the aimless movement that the question seemed to have in mind.
"
2619,2619,4164,Android setOnItemClickListener,"I'm not able to initiate the ""OnItemClickListener"".

You can see my code snippet

 ListAdapter adapter = new SimpleAdapter(this, mylist , R.layout.main, new String[] { ""title""}, new int[] { R.id.item_title});
    setListAdapter(adapter);

    final ListView lv = getListView();
    lv.setTextFilterEnabled(true);

    lv.setOnItemClickListener(new OnItemClickListener() {
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) {              
            @SuppressWarnings(""unchecked"")
            HashMap&lt;String, String&gt; o = (HashMap&lt;String, String&gt;) lv.getItemAtPosition(position);                   
            Toast.makeText(TopNewsActivity.this, ""ID '"" + o.get(""id"") + ""' was clicked."", Toast.LENGTH_LONG).show(); 

        }
    });


after the setListAdapter my debugger goes to ""lv.setOnItemClickListener"" but then does not get into the loop and moves out.

I want to make the links Clickable kindly help.
",ReNa,https://stackoverflow.com/users/694260,"Maybe you forgot to write @Override before public void onItemClick?

Adapter.setOnItemClickListener(new OnItemClickListener() {
@Override
public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position,
                long id) {
        }
});

",Anton Derevyanko,https://stackoverflow.com/users/467750,http://stackoverflow.com/questions/5714522/android-setonitemclicklistener,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Android setonitemclicklistener,"I'm not able to initiate the ""OnItemClickListener"".

You can see my code snippet

 ListAdapter adapter = new SimpleAdapter(this, mylist , R.layout.main, new String[] { ""title""}, new int[] { R.id.item_title});
    setListAdapter(adapter);

    final ListView lv = getListView();
    lv.setTextFilterEnabled(true);

    lv.setOnItemClickListener(new OnItemClickListener() {
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) {              
            @SuppressWarnings(""unchecked"")
            HashMap&lt;String, String&gt; o = (HashMap&lt;String, String&gt;) lv.getItemAtPosition(position);                   
            Toast.makeText(TopNewsActivity.this, ""ID '"" + o.get(""id"") + ""' was clicked."", Toast.LENGTH_LONG).show(); 

        }
    });


after the setListAdapter my debugger goes to ""lv.setOnItemClickListener"" but then does not get into the loop and moves out.

I want to make the links Clickable kindly help.
","Maybe you forgot to write @Override before public void onItemClick?

Adapter.setOnItemClickListener(new OnItemClickListener() {
@Override
public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position,
                long id) {
        }
});

"
527,527,831,Are there any disadvantages to encrypting the password hash?,"Is encrypting the password hash in database more secure than storing only the hash?

Suppose we store encrypted SHA-256 result with AES instead of hash directly. Is this a good protection from a situation in the future when someone will break one of the algorithms?
",Piotr MÃ¼ller,https://security.stackexchange.com/users/61366,"Bob Brown has covered most of the salient points in his answer but I did want to point out that there is one significant disadvantage:  Complexity.   You are increasing the complexity of your application to some degree, lesser (in the case of adding a pepper to the hash where you need to think about key management as well as storage of password hashes and salts) or greater (in the case of implementing something more sophisticated like AES and needing to store IVs or Nonces and possibly tags/MACs as well as the output, the salt, and managing the key(s).) 

So, is the value you're going to add sufficient to justify the additional cost of complexity?  You'll have to answer that question for your application.  I'd would say that it generally doesn't, while there certainly are cases out there where it does.   

In any case, as Bob mentioned, you need to start with a strong foundation and move to a better hashing algorithm like Bcrypt regardless of whether you decide to encrypt or not.   
",Xander,https://security.stackexchange.com/users/12,http://security.stackexchange.com/questions/73586/are-there-any-disadvantages-to-encrypting-the-password-hash,TECHNOLOGY,security.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,1.0,What are the disadvantages of encrypted password hash?,"Is encrypting the password hash in database more secure than storing only the hash?

Suppose we store encrypted SHA-256 result with AES instead of hash directly. Is this a good protection from a situation in the future when someone will break one of the algorithms?
","Bob Brown has covered most of the salient points in his answer but I did want to point out that there is one significant disadvantage:  Complexity.   You are increasing the complexity of your application to some degree, lesser (in the case of adding a pepper to the hash where you need to think about key management as well as storage of password hashes and salts) or greater (in the case of implementing something more sophisticated like AES and needing to store IVs or Nonces and possibly tags/MACs as well as the output, the salt, and managing the key(s).) 

So, is the value you're going to add sufficient to justify the additional cost of complexity?  You'll have to answer that question for your application.  I'd would say that it generally doesn't, while there certainly are cases out there where it does.   

In any case, as Bob mentioned, you need to start with a strong foundation and move to a better hashing algorithm like Bcrypt regardless of whether you decide to encrypt or not.   
"
109,109,177,Facebook Connect Changed My User ID and Deleted Some Badges,"So this actually happened a long time ago I just never complained about it until now:

I was a beta user of SO and originally my account was located at: http://stackoverflow.com/users/871/andrew-g-johnson -- I used Google to login as soon as it was available

Then when you guys rolled out Facebook Connect and I clicked that.  Suddenly my account id was changed: http://stackoverflow.com/users/428190/andrew-g-johnson.

I liked my low user id and beta badge -- is it possible to get those back?
",Andrew G. Johnson,https://meta.stackexchange.com/users/871,"This isn't possible without hours of painful dev work manually manipulating the database, sorry -- your account was auto-merged into the higher ID way back in August 2010.
",Jeff Atwood,https://meta.stackexchange.com/users/1,http://meta.stackexchange.com/questions/87813/facebook-connect-changed-my-user-id-and-deleted-some-badges,TECHNOLOGY,meta.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.7777777777777778,1.0,0.4444444444444444,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,Facebook connect changed my user ID and removed some badges,"So this actually happened a long time ago I just never complained about it until now:

I was a beta user of SO and originally my account was located at: http://stackoverflow.com/users/871/andrew-g-johnson -- I used Google to login as soon as it was available

Then when you guys rolled out Facebook Connect and I clicked that.  Suddenly my account id was changed: http://stackoverflow.com/users/428190/andrew-g-johnson.

I liked my low user id and beta badge -- is it possible to get those back?
","It's impossible without a few hours of painstaking development work to manually operate the database, sorry - your account is automatically merged into a higher ID as early as August 2010."
5287,5287,8396,"Facebook - Music, Books, Interests.. are they all included in ""Likes""?","I am trying to retrieve a list of users' interests. So I am making calls to the graph api to retrieve things like books, music, etc. It seems everything under ""Likes"" also includes everything listed under books, music, etc. Are their any exceptions, or can I just make one call to retrieve Likes?
",Andy Hin,https://stackoverflow.com/users/396077,"The facebook Likes api for the graph includes: likes, share counts, comments and notes. You can make one call to retrieve all likes, but it is not just limited to likes, they could have put a comment on the page describing that they didn't like it, and it will still show up here.
",Russ Bradberry,https://stackoverflow.com/users/48450,http://stackoverflow.com/questions/4951995/facebook-music-books-interests-are-they-all-included-in-likes,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.8333333333333334,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,"Facebook - music, books, interests.. Are they all included in ""like""?","I'm trying to retrieve a list of users' interests. So I'm calling the graph API to retrieve books, music, and so on. It seems that all contents under ""likes"" also include all contents listed under books, music, etc. Do they have any exceptions, or can I just call once to retrieve likes?","The Facebook likes API of this figure includes: likes, share counts, comments and notes. You can make a call to retrieve all your likes, but it's not limited to likes. They can comment on the page and describe that they don't like it. It still appears here."
5300,5300,8418,How do I deal with a slow and undedicated colleague in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
",HOT,https://programmers.stackexchange.com/users/34092,"It's difficult and unreasonable to estimate the relative effort and complexity of another project if you aren't familiar with the code base. You say his code is error-prone, but it could be in great shape with all of the remaining issues at a very high level of abstraction... Problem is, that is the only code that your front end needs!

Or, maybe he's a bad employee and taking the company for a ride. I can't say, and you may not have all the information you need to know with confidence, either.

I'd suggest a midway tactic. Next time you meet, bring some details of a major bug in his code that is affecting you. When he says everything is fine, politely say there is one outstanding issue that's blocking your progress. 

Politically, saying it like that let's you assert that he's not quite correct, while still giving him an opening to play dumb and not be put on the defensive.

Your manager should ask at the next meeting if it's fixed. If not, the pressure falls on him to fix one bug. If it is fix, say thanks, it's working great now, and you found a new blocker. If you want to be especially nice, say you ran into it shortly before the meeting. 

You're not lying, per se, nor are you taking sides. You're playing politics by calling attention to problems and letting your colleague save face if things are really not proceeding all that well. 

It's tempting to just talk to your manager, but don't forget which one of them you have to work with the most.
",Stefan Mohr,https://programmers.stackexchange.com/users/27797,http://programmers.stackexchange.com/questions/101528/how-do-i-deal-with-a-slow-and-undedicated-colleague-in-the-team,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.6666666666666667,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,How can I deal with a colleague who is slow-moving and lacks dedication in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
","It's difficult and unreasonable to estimate the relative effort and complexity of another project if you aren't familiar with the code base. You say his code is error-prone, but it could be in great shape with all of the remaining issues at a very high level of abstraction... Problem is, that is the only code that your front end needs!

Or, maybe he's a bad employee and taking the company for a ride. I can't say, and you may not have all the information you need to know with confidence, either.

I'd suggest a midway tactic. Next time you meet, bring some details of a major bug in his code that is affecting you. When he says everything is fine, politely say there is one outstanding issue that's blocking your progress. 

Politically, saying it like that let's you assert that he's not quite correct, while still giving him an opening to play dumb and not be put on the defensive.

Your manager should ask at the next meeting if it's fixed. If not, the pressure falls on him to fix one bug. If it is fix, say thanks, it's working great now, and you found a new blocker. If you want to be especially nice, say you ran into it shortly before the meeting. 

You're not lying, per se, nor are you taking sides. You're playing politics by calling attention to problems and letting your colleague save face if things are really not proceeding all that well. 

It's tempting to just talk to your manager, but don't forget which one of them you have to work with the most.
"
3824,3824,6082,Twisted pair cable twists and unwanted signals issue,"I am confused about one point I have read the following paragraph from the networking book.
âthe twists in the twisted pair cable are used to avoid the unwanted signals. For example one twist, one wire is closer to the noise source and the other is farther; in the next twist the reverse is true. Twisting makes its probable that both wires are equally affected by the unwanted signal. This means that the receiver which calculate the difference between the two receives no unwanted signal.â

Now ok I understood the purpose of twists but I am confused about how receiver will calculate the difference when it will receive the signal?. How unwanted signal will be eliminated ? 
Another thing that I want to make clear is ,  I am beginner please provide such an answer that can be understood.
",Zia ur Rahman,https://serverfault.com/users/44270,"A 'voltage' as such, is very difficult to measure.  In fact, it's hard to even define it.  What's always used is a 'voltage difference'.  A typical 'AA' battery uses chemical energy to keep a voltage difference of 1.5V between its contact points.  A light bulb will light up when a voltage difference forces electric charges to flow through its filament.

Think of a waterfall, the energy of the fall depends only on the difference between the altitude at the top and the bottom of the fall.  it doesn't matter if it occurs on top of a mountain or at sea level, as long as the fall itself is the same length.

in old 'single ended' signals (like rs-232, a parallel port, old IDE), bits are represented by the voltage of individual wires.... and a 'reference point' (or ground connection).  it's always a voltage difference, but the reference is constant, so it's not always mentioned.

in 'differential signals' (ethernet, 'ultra scsi', any modern serial port (USB, SATA, SAS, FireWire, even PCI-ex!)), each signal is carried by two wires, usually twisted together (or very close traces on a printed board), and the receiver doesn't use a common reference point to measure the voltage difference, it uses the difference between the two signal wires.  This way, it doesn't matter if wire A is 22v and wire B is 25V, or A is -10v and B is -7V; it only matters that B is 3V higher than A.
",Javier,https://serverfault.com/users/6125,http://serverfault.com/questions/135421,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.8888888888888888,0.7777777777777778,0.7333333333333333,0.0,0.3333333333333333,1.0,0.8888888888888888,Twisted twisted twisted pair cables and unwanted signal problems,"I am confused about one point I have read the following paragraph from the networking book.
âthe twists in the twisted pair cable are used to avoid the unwanted signals. For example one twist, one wire is closer to the noise source and the other is farther; in the next twist the reverse is true. Twisting makes its probable that both wires are equally affected by the unwanted signal. This means that the receiver which calculate the difference between the two receives no unwanted signal.â

Now ok I understood the purpose of twists but I am confused about how receiver will calculate the difference when it will receive the signal?. How unwanted signal will be eliminated ? 
Another thing that I want to make clear is ,  I am beginner please provide such an answer that can be understood.
","A 'voltage' as such, is very difficult to measure.  In fact, it's hard to even define it.  What's always used is a 'voltage difference'.  A typical 'AA' battery uses chemical energy to keep a voltage difference of 1.5V between its contact points.  A light bulb will light up when a voltage difference forces electric charges to flow through its filament.

Think of a waterfall, the energy of the fall depends only on the difference between the altitude at the top and the bottom of the fall.  it doesn't matter if it occurs on top of a mountain or at sea level, as long as the fall itself is the same length.

in old 'single ended' signals (like rs-232, a parallel port, old IDE), bits are represented by the voltage of individual wires.... and a 'reference point' (or ground connection).  it's always a voltage difference, but the reference is constant, so it's not always mentioned.

in 'differential signals' (ethernet, 'ultra scsi', any modern serial port (USB, SATA, SAS, FireWire, even PCI-ex!)), each signal is carried by two wires, usually twisted together (or very close traces on a printed board), and the receiver doesn't use a common reference point to measure the voltage difference, it uses the difference between the two signal wires.  This way, it doesn't matter if wire A is 22v and wire B is 25V, or A is -10v and B is -7V; it only matters that B is 3V higher than A.
"
3388,3388,5401,Convert vector<int> to delimited string,"As I see here there is a fast and short way to Convert vector to string separated with a character in c#:

var result = string.Join("";"", data); 
var result = string.Join("";"", data.Select(x =&gt; x.ToString()).ToArray()); 


I wan to know is there a same way in c++ to do this?
",thirdDeveloper,https://stackoverflow.com/users/1578952,"#include &lt;sstream&gt;
#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;iterator&gt;
#include &lt;iostream&gt;

int main()
{
    std::vector&lt;int&gt; data = {42, 1, 2, 3, 4, 5};

    std::ostringstream oss;
    std::copy(data.begin(), data.end(), std::ostream_iterator&lt;int&gt;(oss, "";""));

    std::string result( oss.str() );
    std::cout &lt;&lt; result &lt;&lt; ""\n"";
}


N.B. In C++11, you can use the more general form

using std::begin;
using std::end;
std::copy(begin(data), end(data), std::ostream_iterator&lt;int&gt;(oss, "";""));


Where the using-declarations are not required if ADL can be used (like in the example above).



Also possible, but maybe a bit less efficient:

std::string s;
for(auto const&amp; e : v) s += std::to_string(e) + "";"";


which can be written via std::accumulate in &lt;algorithm&gt; as:

std::string s = std::accumulate(begin(v), end(v), std::string{},
    [](std::string r, int p){ return std::move(r) + std::to_string(p) + "";""; });


(IIRC there was some method to eliminate the copying, maybe by taking the lambda-parameter by reference std::string&amp; r.)



A version w/o the trailing semi-colon (thanks to Dietmar KÃ¼hl):

std::vector&lt;int&gt; data = {42, 1, 2, 3, 4, 5};

std::ostringstream out;
if (!v.empty())
{
    std::copy(v.begin(), v.end() - 1, std::ostream_iterator&lt;int&gt;(out, "";""));
    out &lt;&lt; v.back();
}

std::string result( out.str() );
std::cout &lt;&lt; result &lt;&lt; ""\n"";

",dyp,https://stackoverflow.com/users/420683,http://stackoverflow.com/questions/20817322/convert-vectorint-to-delimited-string,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,1.0,Convert vector < int > to delimited string,"As I see here there is a fast and short way to Convert vector to string separated with a character in c#:

var result = string.Join("";"", data); 
var result = string.Join("";"", data.Select(x =&gt; x.ToString()).ToArray()); 


I wan to know is there a same way in c++ to do this?
","#include &lt;sstream&gt;
#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;iterator&gt;
#include &lt;iostream&gt;

int main()
{
    std::vector&lt;int&gt; data = {42, 1, 2, 3, 4, 5};

    std::ostringstream oss;
    std::copy(data.begin(), data.end(), std::ostream_iterator&lt;int&gt;(oss, "";""));

    std::string result( oss.str() );
    std::cout &lt;&lt; result &lt;&lt; ""\n"";
}


N.B. In C++11, you can use the more general form

using std::begin;
using std::end;
std::copy(begin(data), end(data), std::ostream_iterator&lt;int&gt;(oss, "";""));


Where the using-declarations are not required if ADL can be used (like in the example above).



Also possible, but maybe a bit less efficient:

std::string s;
for(auto const&amp; e : v) s += std::to_string(e) + "";"";


which can be written via std::accumulate in &lt;algorithm&gt; as:

std::string s = std::accumulate(begin(v), end(v), std::string{},
    [](std::string r, int p){ return std::move(r) + std::to_string(p) + "";""; });


(IIRC there was some method to eliminate the copying, maybe by taking the lambda-parameter by reference std::string&amp; r.)



A version w/o the trailing semi-colon (thanks to Dietmar KÃ¼hl):

std::vector&lt;int&gt; data = {42, 1, 2, 3, 4, 5};

std::ostringstream out;
if (!v.empty())
{
    std::copy(v.begin(), v.end() - 1, std::ostream_iterator&lt;int&gt;(out, "";""));
    out &lt;&lt; v.back();
}

std::string result( out.str() );
std::cout &lt;&lt; result &lt;&lt; ""\n"";

"
4538,4538,7191,Please help me in changing layout of all products page,"

can anyone tell me where can I change layout of this page i think this page is now having 3columns.phtml layout but I need 2columns-left.phtml layout please help me.
",Abdul,https://magento.stackexchange.com/users/16312,"add the following code in your local.xml file

&lt;catalog_category_layered translate=""label""&gt;
  &lt;reference name=""root""&gt;
    &lt;action method=""setTemplate""&gt;
      &lt;template&gt;page/2columns-left.phtml&lt;/template&gt; 
    &lt;/action&gt;
  &lt;/reference&gt;
&lt;/catalog_category_layered&gt;

",Pradeep Sanku,https://magento.stackexchange.com/users/4556,http://magento.stackexchange.com/questions/44475/how-to-change-the-layout-of-the-all-products-page,TECHNOLOGY,magento.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,1.0,1.0,0.5,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Please help me change the layout of all product pages,"Who can tell me where I can change the layout of this page? I think this page now has three columns.phtml layouts, but I need two columns-left.phtml layouts. Please help me.","add the following code in your local.xml file

&lt;catalog_category_layered translate=""label""&gt;
  &lt;reference name=""root""&gt;
    &lt;action method=""setTemplate""&gt;
      &lt;template&gt;page/2columns-left.phtml&lt;/template&gt; 
    &lt;/action&gt;
  &lt;/reference&gt;
&lt;/catalog_category_layered&gt;

"
3374,3374,5382,WYSIWYG TinyMCE Editor Integration,"I have integrated WYSIWYG Editor using this tutorial. I can see it in my custom module, but when I try to insert variable it gives me following error in console

Error: ReferenceError: widgetTools is not defined
Source File: http://mywebsite.com/js/mage/adminhtml/wysiwyg/tiny_mce/plugins/magentowidget/editor_plugin.js
Line: 44


There is also another error when I try to insert widget,

Error: ReferenceError: widgetTools is not defined
Source File: http://mywebsite.com/js/mage/adminhtml/wysiwyg/tiny_mce/plugins/magentowidget/editor_plugin.js
Line: 44


Could anyone pls guide me on how to integrate WYSIWYG editor in backend custom module as well as frontend without having console errors.

Also how to add necessary WYSIWYG (TinyMCE) JS files to insert widgets, variables, images and other media types ?

Thanks.
",Mark,https://magento.stackexchange.com/users/9071,"You will need to include the wysiwyg javascript files.

I think the lines of code you need are.

&lt;script type=""text/javascript"" src=""&lt;?php echo $this-&gt;getJsUrl() ?&gt;tiny_mce/tiny_mce.js""&gt;&lt;/script&gt;


And

&lt;action method=""addItem""&gt;&lt;type&gt;js&lt;/type&gt;&lt;name&gt;mage/adminhtml/wysiwyg/tiny_mce/setup.js&lt;/name&gt;&lt;params/&gt;&lt;if/&gt;&lt;condition&gt;can_load_tiny_mce&lt;/condition&gt;&lt;/action&gt;


These should be set by default on normal adminhtml pages as long as you turn on the editor. To do this you can add the following to your block class in the _prepareLayout function.

$this-&gt;getLayout()-&gt;getBlock('head')-&gt;setCanLoadTinyMce(true);

",David Manners,https://magento.stackexchange.com/users/158,http://magento.stackexchange.com/questions/23756/wysiwyg-tinymce-editor-integration,TECHNOLOGY,magento.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.3333333333333333,0.0,0.8888888888888888,WYSIWYG TinyMCE editor integration,"I have integrated WYSIWYG Editor using this tutorial. I can see it in my custom module, but when I try to insert variable it gives me following error in console

Error: ReferenceError: widgetTools is not defined
Source File: http://mywebsite.com/js/mage/adminhtml/wysiwyg/tiny_mce/plugins/magentowidget/editor_plugin.js
Line: 44


There is also another error when I try to insert widget,

Error: ReferenceError: widgetTools is not defined
Source File: http://mywebsite.com/js/mage/adminhtml/wysiwyg/tiny_mce/plugins/magentowidget/editor_plugin.js
Line: 44


Could anyone pls guide me on how to integrate WYSIWYG editor in backend custom module as well as frontend without having console errors.

Also how to add necessary WYSIWYG (TinyMCE) JS files to insert widgets, variables, images and other media types ?

Thanks.
","You will need to include the wysiwyg javascript files.

I think the lines of code you need are.

&lt;script type=""text/javascript"" src=""&lt;?php echo $this-&gt;getJsUrl() ?&gt;tiny_mce/tiny_mce.js""&gt;&lt;/script&gt;


And

&lt;action method=""addItem""&gt;&lt;type&gt;js&lt;/type&gt;&lt;name&gt;mage/adminhtml/wysiwyg/tiny_mce/setup.js&lt;/name&gt;&lt;params/&gt;&lt;if/&gt;&lt;condition&gt;can_load_tiny_mce&lt;/condition&gt;&lt;/action&gt;


These should be set by default on normal adminhtml pages as long as you turn on the editor. To do this you can add the following to your block class in the _prepareLayout function.

$this-&gt;getLayout()-&gt;getBlock('head')-&gt;setCanLoadTinyMce(true);

"
239,239,384,How does arbitary code execution work?,"I'm unable to understand how arbitrary code execution vulnerabilities are supposed to work.

Wikipedia mentions:


  Arbitrary code execution is commonly achieved through control over the instruction pointer of a running process.


Say, the vulnerability is being triggered by some maliciously crafted file that said process is reading. How could it modify the instruction pointer, or, otherwise, corrupt the internal state of the application so as to cause it to execute the attacker's code?

Also, given that modern OSes implement DEP and ASLR, how is this even feasible? The data loaded from the application would not even be executable, and additionally, it's also difficult to determine the offset of the shellcode/payload.

Brownie points for showing a small snippet of code that would be vulnerable to such an exploit.
",user2064000,https://security.stackexchange.com/users/22260,"Code injection / Code execution is any attack that involves tricking a node in a distributed system into running code specified in a network message that was supposed to be treated as plain text/bytes.

The arbitrary part means that the vulnerability allows the attacker to make use of the full authority of the running process or of some privileged principle like root.




  given that modern OSes implement DEP and ASLR, how is this even feasible


Code injection relies on some other kind of vulnerability to inject the payload.  You're probably thinking of injection via buffer overflow but there are other ways to inject code that memory address space tricks don't help against.

Code injection doesn't necessarily mean injecting instructions in the processor's instruction set into a code/data segment.  It can mean injecting source code in a scripting language which the program foolishly interprets.  For example, shell injection involves injecting bytes that are passed to a shell.


  Shell injection (or Command Injection[10])is named after Unix shells, but applies to most systems which allow software to programmatically execute a command line. Typical shell injection-related functions include system(), StartProcess(), and System.Diagnostics.Process.Start().




Some systems have used string tainting * to try to mitigate code injections that aren't covered by DEP/ASLR and it does help but isn't foolproof:  taint bits aren't serialized when strings are serialized to files/DBs and, under maintenance, more untaint instructions are added to a program to fix high visibility non-security bugs than are removed to fix low-visibility security vulnerabilities.


  The concept behind taint checking is that any variable that can be modified by an outside user (for example a variable set by a field in a web form) poses a potential security risk. If that variable is used in an expression that sets a second variable, that second variable is now also suspicious. The taint checking tool proceeds variable by variable until it has a complete list of all variables which are potentially influenced by outside input.




Systems that label strings based on information flow have also been used to secure distributed systems that have to mix strings of different provenance, but information-flow is more of an all-or-nothing approach: harder to retrofit onto systems that were not designed around it.


  Information ï¬ow control protects information security
  by constraining how information is transmitted among
  objects and users of various security classes. These security classes are expressed as labels associated with the information or its containers.


Taint-checking, above, is a very simple kind of information flow analysis in which the labels are restricted to (tainted, untainted).
",Mike Samuel,https://security.stackexchange.com/users/227,http://security.stackexchange.com/questions/63315/how-does-arbitary-code-execution-work,TECHNOLOGY,security.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,How does arbitrary code execution work?,"I'm unable to understand how arbitrary code execution vulnerabilities are supposed to work.

Wikipedia mentions:


  Arbitrary code execution is commonly achieved through control over the instruction pointer of a running process.


Say, the vulnerability is being triggered by some maliciously crafted file that said process is reading. How could it modify the instruction pointer, or, otherwise, corrupt the internal state of the application so as to cause it to execute the attacker's code?

Also, given that modern OSes implement DEP and ASLR, how is this even feasible? The data loaded from the application would not even be executable, and additionally, it's also difficult to determine the offset of the shellcode/payload.

Brownie points for showing a small snippet of code that would be vulnerable to such an exploit.
","Code injection / Code execution is any attack that involves tricking a node in a distributed system into running code specified in a network message that was supposed to be treated as plain text/bytes.

The arbitrary part means that the vulnerability allows the attacker to make use of the full authority of the running process or of some privileged principle like root.




  given that modern OSes implement DEP and ASLR, how is this even feasible


Code injection relies on some other kind of vulnerability to inject the payload.  You're probably thinking of injection via buffer overflow but there are other ways to inject code that memory address space tricks don't help against.

Code injection doesn't necessarily mean injecting instructions in the processor's instruction set into a code/data segment.  It can mean injecting source code in a scripting language which the program foolishly interprets.  For example, shell injection involves injecting bytes that are passed to a shell.


  Shell injection (or Command Injection[10])is named after Unix shells, but applies to most systems which allow software to programmatically execute a command line. Typical shell injection-related functions include system(), StartProcess(), and System.Diagnostics.Process.Start().




Some systems have used string tainting * to try to mitigate code injections that aren't covered by DEP/ASLR and it does help but isn't foolproof:  taint bits aren't serialized when strings are serialized to files/DBs and, under maintenance, more untaint instructions are added to a program to fix high visibility non-security bugs than are removed to fix low-visibility security vulnerabilities.


  The concept behind taint checking is that any variable that can be modified by an outside user (for example a variable set by a field in a web form) poses a potential security risk. If that variable is used in an expression that sets a second variable, that second variable is now also suspicious. The taint checking tool proceeds variable by variable until it has a complete list of all variables which are potentially influenced by outside input.




Systems that label strings based on information flow have also been used to secure distributed systems that have to mix strings of different provenance, but information-flow is more of an all-or-nothing approach: harder to retrofit onto systems that were not designed around it.


  Information ï¬ow control protects information security
  by constraining how information is transmitted among
  objects and users of various security classes. These security classes are expressed as labels associated with the information or its containers.


Taint-checking, above, is a very simple kind of information flow analysis in which the labels are restricted to (tainted, untainted).
"
566,566,889,Tripod Head for GigaPan Epic Pro,"I get massively confused when it comes to tripod heads screw sizes blah de blah, so excuse the possible simplicity of this question. I have a GigaPan Epic Pro and a Manfrotto 475B Pro Geared Tripod. I also have a 2 way tilt head that came with my Monopod which I am currently using as the head for this tripod as well. 

Problem is that this head doesn't seem the most stable to place the massive GigaPan unit on with a Nikon D4 and a 400mm lens (all in all a damn heavy setup!). The GigaPan unit has what I call the 'normal' screw (or is it a thread?) which is the same one you get in the bottom of almost every camera known to man these days (like I said, I'm useless when it comes to this stuff). The tripod has the 'big' screw (thread?) that the heads screw in to. This is all pretty normal. Here are my questions;

1- What are these screws/threads actually called, I've seen 1/4 inch and 3/8 inch thrown around a lot and I'd guess that 1/4 inch is the 'normal' one and the 3/8 the 'big' one?

2 - For the GigaPan I'd ideally place it straight onto the 'big' screw, obviously this is not possible, but would this Manfrotto 120 3/8 to 1/4 inch Adaptor be pretty much what I am after.

These might seem very simple questions but trust me, I consider myself a pretty decent photographer but when it comes to this I really struggle to get my head around it.

Thanks!

(also I didn't have the rep to create the tag 'GigaPan', but I think it should be, so feel free to add it! )
",Rob Quincey,https://photo.stackexchange.com/users/6209,"The GigaPan Epic Pro itself weighs 7.25lbs with battery. Then once you add in a Nikon D4(2 lb 15.3 oz), and a Nikon 400mm f/2.8G ED AF-S (10.2lbs), you are talking about putting roughly 20lbs of gear on the tripod. This is significant, but certainly not unheard of.

The GigaPan Epic Pro has the standard 1/4-20 tripod screw at the bottom. You can read more about that here: Is there a standard tripod mount? 

My assumption is that GigaPan included this standard screw so you can mount the camera to a non proprietary setup. If they chose any other screw, they would either have to engage head manufacturers to develop custom quick release brackets, or create their own heads. 

I know that one option you brought up would be to mount legs directly to the GigaPan. I think that this might cause you issues. The reason is that without a proper head that locks into the legs, you might risk the connection between the legs and GigaPan loosening up. I cannot say this from experience, but I think you would be best suited with a very sturdy head.

For a head you might want to look at something like a Manfrotto Hydrostatic Ball head. They do an excellent job of making sure that the lock and ball aren't going anywhere.
",dpollitt,https://photo.stackexchange.com/users/4892,http://photo.stackexchange.com/questions/29289/tripod-head-for-gigapan-epic-pro,LIFE_ARTS,photo.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,1.0,Tripod head of GigaPan Epic Pro,"I get massively confused when it comes to tripod heads screw sizes blah de blah, so excuse the possible simplicity of this question. I have a GigaPan Epic Pro and a Manfrotto 475B Pro Geared Tripod. I also have a 2 way tilt head that came with my Monopod which I am currently using as the head for this tripod as well. 

Problem is that this head doesn't seem the most stable to place the massive GigaPan unit on with a Nikon D4 and a 400mm lens (all in all a damn heavy setup!). The GigaPan unit has what I call the 'normal' screw (or is it a thread?) which is the same one you get in the bottom of almost every camera known to man these days (like I said, I'm useless when it comes to this stuff). The tripod has the 'big' screw (thread?) that the heads screw in to. This is all pretty normal. Here are my questions;

1- What are these screws/threads actually called, I've seen 1/4 inch and 3/8 inch thrown around a lot and I'd guess that 1/4 inch is the 'normal' one and the 3/8 the 'big' one?

2 - For the GigaPan I'd ideally place it straight onto the 'big' screw, obviously this is not possible, but would this Manfrotto 120 3/8 to 1/4 inch Adaptor be pretty much what I am after.

These might seem very simple questions but trust me, I consider myself a pretty decent photographer but when it comes to this I really struggle to get my head around it.

Thanks!

(also I didn't have the rep to create the tag 'GigaPan', but I think it should be, so feel free to add it! )
","The GigaPan Epic Pro itself weighs 7.25lbs with battery. Then once you add in a Nikon D4(2 lb 15.3 oz), and a Nikon 400mm f/2.8G ED AF-S (10.2lbs), you are talking about putting roughly 20lbs of gear on the tripod. This is significant, but certainly not unheard of.

The GigaPan Epic Pro has the standard 1/4-20 tripod screw at the bottom. You can read more about that here: Is there a standard tripod mount? 

My assumption is that GigaPan included this standard screw so you can mount the camera to a non proprietary setup. If they chose any other screw, they would either have to engage head manufacturers to develop custom quick release brackets, or create their own heads. 

I know that one option you brought up would be to mount legs directly to the GigaPan. I think that this might cause you issues. The reason is that without a proper head that locks into the legs, you might risk the connection between the legs and GigaPan loosening up. I cannot say this from experience, but I think you would be best suited with a very sturdy head.

For a head you might want to look at something like a Manfrotto Hydrostatic Ball head. They do an excellent job of making sure that the lock and ball aren't going anywhere.
"
4294,4294,6845,Count consecutive null rows from a joined table,"I have the following tables:

members:
----------------------------------------------
| member_id | member_name | member_join_date |
----------------------------------------------  

events:
-------------------------
| event_id | event_name |
-------------------------

event_dates:
--------------------------------------
| event_id | event_date | event_week |
--------------------------------------

attendance:
------------------------------------------------------------
| member_id | event_id | attendance_date | attendance_week |
------------------------------------------------------------


So I have members who joined the organization at a certain time and they may attend weekly events (the occurrences of which are monitored by the event_dates table)

What I want to do is get all members that have at least 3-consecutive absences

I did all I could and I think I have each part of the query but don't know how to merge them together.

Get all events that they could've attended:

    SELECT
      m.member_id AS id,
      ed.event_id,
      ed.event_week
    FROM
      members AS m
      LEFT JOIN
        event_dates AS ed
        ON
          ed.event_date &gt;= m.member_join_date


Get all the events they actually attended:

    SELECT
      m.member_id AS id,
      a.event_id
    FROM
      members AS m
      LEFT JOIN
        attendance AS a
        ON
          a.member_id = m.member_id


And probably the answer to this question if I manage to merge the two queries into one:

http://stackoverflow.com/questions/1321670/count-of-consecutive-not-null-values

But this time I want to count NULL values
",Rolando Cruz,https://dba.stackexchange.com/users/10755,"(Assuming that the (event_id, event_date) is the primary or a unique key in event_dates table):

SELECT
  m.member_id AS id,
  ed_start.event_id,
  ed_start.event_date AS miss_start,
  ed_end.event_date AS miss_end,
  COUNT(*) AS consecutive_misses
FROM
  members AS m
  JOIN
    event_dates AS ed_start
    ON
      ed_start.event_date &gt;= m.member_join_date
  JOIN
    event_dates AS ed_end
    ON  ed_end.event_id = ed_start.event_id
    AND ed_end.event_date &gt;= ed_start.event_date
  JOIN
    event_dates AS ed_mid
    ON  ed_mid.event_id = ed_start.event_id
    AND ed_mid.event_date &gt;= ed_start.event_date
    AND ed_mid.event_date &lt;= ed_end.event_date
  LEFT JOIN
    attendance AS a
    ON  a.member_id = m.member_id
    AND a.event_id = ed_mid.event_id
    AND a.attendance_date = ed_mid.event_date
GROUP BY 
    m.member_id,
    ed_start.event_id,
    ed_start.event_date,
    ed_end.event_date
HAVING
    COUNT(*) &gt;= 3
   AND
    COUNT(a.attendance_date) = 0 ;


Test in SQL-Fiddle



The above may give (too many) multiple results if the consecutive misses are more than 3. So, If you want only the members and events they missed but not when they missed attendance, replace the SELECT with (test: SQL-Fiddle-2): 

SELECT DISTINCT
  m.member_id AS id,
  ed.event_id,
FROM
  ...


You could also wrap the query (as a derived table) inside an external query and do another grouping for this to work (test: SQL-Fiddle-3)



And if you want only the members and not the events they missed nor when they missed attendance:

SELECT DISTINCT
  m.member_id AS id
FROM
  ...

",ypercubeáµá´¹,https://dba.stackexchange.com/users/993,http://dba.stackexchange.com/questions/24852/count-consecutive-null-rows-from-a-joined-table,TECHNOLOGY,dba.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,Count consecutive empty rows in join table,"I have the following tables:

members:
----------------------------------------------
| member_id | member_name | member_join_date |
----------------------------------------------  

events:
-------------------------
| event_id | event_name |
-------------------------

event_dates:
--------------------------------------
| event_id | event_date | event_week |
--------------------------------------

attendance:
------------------------------------------------------------
| member_id | event_id | attendance_date | attendance_week |
------------------------------------------------------------


So I have members who joined the organization at a certain time and they may attend weekly events (the occurrences of which are monitored by the event_dates table)

What I want to do is get all members that have at least 3-consecutive absences

I did all I could and I think I have each part of the query but don't know how to merge them together.

Get all events that they could've attended:

    SELECT
      m.member_id AS id,
      ed.event_id,
      ed.event_week
    FROM
      members AS m
      LEFT JOIN
        event_dates AS ed
        ON
          ed.event_date &gt;= m.member_join_date


Get all the events they actually attended:

    SELECT
      m.member_id AS id,
      a.event_id
    FROM
      members AS m
      LEFT JOIN
        attendance AS a
        ON
          a.member_id = m.member_id


And probably the answer to this question if I manage to merge the two queries into one:

http://stackoverflow.com/questions/1321670/count-of-consecutive-not-null-values

But this time I want to count NULL values
","(Assuming that the (event_id, event_date) is the primary or a unique key in event_dates table):

SELECT
  m.member_id AS id,
  ed_start.event_id,
  ed_start.event_date AS miss_start,
  ed_end.event_date AS miss_end,
  COUNT(*) AS consecutive_misses
FROM
  members AS m
  JOIN
    event_dates AS ed_start
    ON
      ed_start.event_date &gt;= m.member_join_date
  JOIN
    event_dates AS ed_end
    ON  ed_end.event_id = ed_start.event_id
    AND ed_end.event_date &gt;= ed_start.event_date
  JOIN
    event_dates AS ed_mid
    ON  ed_mid.event_id = ed_start.event_id
    AND ed_mid.event_date &gt;= ed_start.event_date
    AND ed_mid.event_date &lt;= ed_end.event_date
  LEFT JOIN
    attendance AS a
    ON  a.member_id = m.member_id
    AND a.event_id = ed_mid.event_id
    AND a.attendance_date = ed_mid.event_date
GROUP BY 
    m.member_id,
    ed_start.event_id,
    ed_start.event_date,
    ed_end.event_date
HAVING
    COUNT(*) &gt;= 3
   AND
    COUNT(a.attendance_date) = 0 ;


Test in SQL-Fiddle



The above may give (too many) multiple results if the consecutive misses are more than 3. So, If you want only the members and events they missed but not when they missed attendance, replace the SELECT with (test: SQL-Fiddle-2): 

SELECT DISTINCT
  m.member_id AS id,
  ed.event_id,
FROM
  ...


You could also wrap the query (as a derived table) inside an external query and do another grouping for this to work (test: SQL-Fiddle-3)



And if you want only the members and not the events they missed nor when they missed attendance:

SELECT DISTINCT
  m.member_id AS id
FROM
  ...

"
1841,1841,2921,Why did they choose Barabbas?,"John 19:38 - 40 (NLT)


  38 âWhat is truth?â Pilate asked. Then he went out again to the people
  and told them, âHe is not guilty of any crime. 39 But you have a
  custom of asking me to release one prisoner each year at Passover.
  Would you like me to release this âKing of the Jewsâ?â
  
  40 But they shouted back, âNo! Not this man. We want Barabbas!â
  (Barabbas was a revolutionary.)


Why were they so messed up that they would choose the rebellious, murderous Barabbas over the innocent Son of God?
",Andrew,https://christianity.stackexchange.com/users/65,"They were persuaded by the chief priests and elders:


  But the chief priests and the elders persuaded the crowd to ask for Barabbas and to have Jesus executed. 


Matthew 27:20

They (chief priests and elders) had enormous power over the people since the synagogues and temple were the way people could stay in relations with other people (it was the heart of the community) and, they thought, with God. Perhaps the crowd felt threatened with losing their livelihoods and eternity with God.

But that is speculation - the text simply says that they persuaded the crowd.
",Wikis,https://christianity.stackexchange.com/users/62,http://christianity.stackexchange.com/questions/7043/why-did-they-choose-barabbas,CULTURE,christianity.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why did they choose Barabbas?,"John 19:38 - 40 (NLT)


  38 âWhat is truth?â Pilate asked. Then he went out again to the people
  and told them, âHe is not guilty of any crime. 39 But you have a
  custom of asking me to release one prisoner each year at Passover.
  Would you like me to release this âKing of the Jewsâ?â
  
  40 But they shouted back, âNo! Not this man. We want Barabbas!â
  (Barabbas was a revolutionary.)


Why were they so messed up that they would choose the rebellious, murderous Barabbas over the innocent Son of God?
","They were persuaded by the chief priests and elders:


  But the chief priests and the elders persuaded the crowd to ask for Barabbas and to have Jesus executed. 


Matthew 27:20

They (chief priests and elders) had enormous power over the people since the synagogues and temple were the way people could stay in relations with other people (it was the heart of the community) and, they thought, with God. Perhaps the crowd felt threatened with losing their livelihoods and eternity with God.

But that is speculation - the text simply says that they persuaded the crowd.
"
4162,4162,6633,Maximum magnetic strength achievable,"What will be the maximum magnetic strength to which a piece of ferromagnetic substance can be magnetised?

What will the maximum strength possible for a piece of iron?

How would the shape of the ferromagnetic substance affect this strength?

What would be the current needed in the solenoid if this strength is to be achieved?
",karthikeyan,https://physics.stackexchange.com/users/25735,"The effect you're describing is called magnetic saturation. This is the point where increasing the external magnetic field doesn't increase the magnetisation of your ferromagnet becaused all the domains are aligned and no further increase in the net alignment is possible. 

Iron saturates at around 2 Tesla. This is a property of the material so the shape of the piece of iron doesn't make any difference.

The field at the centre of  solenoid is $B = \mu n I$, and the graph in the linked article shows the required values of the product $nI$. For most materials it's some where in the range $nI = 50 - 100$ amp turns per inch.
",John Rennie,https://physics.stackexchange.com/users/1325,http://physics.stackexchange.com/questions/113578/maximum-magnetic-strength-achievable,SCIENCE,physics.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Maximum attainable magnetic strength,"What will be the maximum magnetic strength to which a piece of ferromagnetic substance can be magnetised?

What will the maximum strength possible for a piece of iron?

How would the shape of the ferromagnetic substance affect this strength?

What would be the current needed in the solenoid if this strength is to be achieved?
","The effect you're describing is called magnetic saturation. This is the point where increasing the external magnetic field doesn't increase the magnetisation of your ferromagnet becaused all the domains are aligned and no further increase in the net alignment is possible. 

Iron saturates at around 2 Tesla. This is a property of the material so the shape of the piece of iron doesn't make any difference.

The field at the centre of  solenoid is $B = \mu n I$, and the graph in the linked article shows the required values of the product $nI$. For most materials it's some where in the range $nI = 50 - 100$ amp turns per inch.
"
1899,1899,3023,Where to create a shared media folder?,"I'd like to place all my family's media in one shared folder for everyone to use from any computer.  Whether it's a PC or home server.

What is more appropriate:


Create it in my home folder (/home/lamcro/media/)
Create a new account called media (/home/media/)
or just Create a new folder  (/media/)


As far as I know, there is no ""Shared Folder"" in Ubuntu, like in Windows.

I'm just looking for the least cumbersome method, in case I ever want to do a full Linux re-install.
",lamcro,https://superuser.com/users/1237,"/media: Not such a good idea. You should find an existing folder in that location. This is where Ubuntu auto-mounts any external media. You'll find new folders mysteriously springing up within your share when you plug in some media e.g an external USB drive. You could instead place your files within a folder in /media, e.g /media/Lamcro-Media. 

/home/lamcro/media: A so-so choice. Chances of accidental deletion of a folder are high when they are in your home directory. You do not want to lose your photos and home videos due to an accidental click or a command that didn't go as planned.

/home/media: You could do this, if the new user 'media' will own all the files. If not, it'd be just a location, albeit one tied to a user account. I'd avoid this, just  because I don't get the logic behind a userid for my media.

My suggestion would be to create a new partition, mount it within /media, e.g. /media/Lamcro-Media and then place your files there. If you ever had to reinstall linux, you would be able to leave this partition untouched, and mount it again on the newly installed system. Failing that, I'd opt for /media/Lamcro-Media as a normal folder, but that's just personal choice.

Going by your question, I'd say the key is to create a new partition to keep all your media. You could then mount it at /media and, if dissatisfied, remount it elsewhere.
",nagul,https://superuser.com/users/4358,http://superuser.com/questions/22355,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.8888888888888888,Where do I create a shared media folder?,"I'd like to place all my family's media in one shared folder for everyone to use from any computer.  Whether it's a PC or home server.

What is more appropriate:


Create it in my home folder (/home/lamcro/media/)
Create a new account called media (/home/media/)
or just Create a new folder  (/media/)


As far as I know, there is no ""Shared Folder"" in Ubuntu, like in Windows.

I'm just looking for the least cumbersome method, in case I ever want to do a full Linux re-install.
","/media: Not such a good idea. You should find an existing folder in that location. This is where Ubuntu auto-mounts any external media. You'll find new folders mysteriously springing up within your share when you plug in some media e.g an external USB drive. You could instead place your files within a folder in /media, e.g /media/Lamcro-Media. 

/home/lamcro/media: A so-so choice. Chances of accidental deletion of a folder are high when they are in your home directory. You do not want to lose your photos and home videos due to an accidental click or a command that didn't go as planned.

/home/media: You could do this, if the new user 'media' will own all the files. If not, it'd be just a location, albeit one tied to a user account. I'd avoid this, just  because I don't get the logic behind a userid for my media.

My suggestion would be to create a new partition, mount it within /media, e.g. /media/Lamcro-Media and then place your files there. If you ever had to reinstall linux, you would be able to leave this partition untouched, and mount it again on the newly installed system. Failing that, I'd opt for /media/Lamcro-Media as a normal folder, but that's just personal choice.

Going by your question, I'd say the key is to create a new partition to keep all your media. You could then mount it at /media and, if dissatisfied, remount it elsewhere.
"
2520,2520,4020,Inventor of CRT?,"Let's cut to the chase. I've been researching through numerous, reliable and unreliable, resources. According to the CRT official site and wiki, the first CRT( cathode ray tube) was invented by Carl Ferdinand Braun, year 1897. Yet undeniable proofs of CRTs being used in experiments in 1860s have been collected.
So this leaves the question unanswered. Noting that one of the fundamental progresses in chemistry( discovery of electron) is based on this useful tube, I will be thankful to anyone willing to share some info.
",M.A.R.,https://chemistry.stackexchange.com/users/7448,"Invention of CRT

In the year 1855, German inventor Heinrich Geissler developed mercury pump which is later modified by Sir William Crookes who became the first to produce cathode rays.



Figure 1: Geissler's Vaccum tubes(1862)

Since, then vacuum tubes are being used to study cathode rays, Braun's tube was actually an improvement to the these.

Otherwise, all of them have used some kind of Vacuum tube which produces cathode rays.


  
  In 1858 Julius PlÃ¼cker showed that cathode rays bend under the influence of a magnet.
  In 1865 H. Sprengel improves the Geissler vacuum pump.
  In 1869 J.W. Hittorf establishes that ""rays"" from the cathode travel in straight lines.
  In 1871 C.F. Varley is first to publish suggestion that cathode rays are composed of particles.[Fig 2]
  In 1874 George Johnstone Stoney estimates the charge of the then unknown electron.
  In 1876 Eugen Goldstein introduces the term cathode ray to describe the light emitted.
  In 1881 Herman Ludwig von Helmholtz suggested the idea that there is a smallest unit of electricity.
  In 1890 Arthur Schuster calculates the ratio of charge to mass of the particles making up cathode rays (today known as electrons) by
  measuring the magnetic deflection of cathode rays.
  In 1894 J.J. Thomson announces that he has found that the velocity of cathode rays is much lower than that of light.
  


Source: 


http://www.chemteam.info/AtomicStructure/Disc-of-Electron-History.html
http://www.chemteam.info/AtomicStructure/Disc-of-Electron-Intro.html




Figure 2: First published paper on cathode rays.
",Devashish Das,https://chemistry.stackexchange.com/users/7120,http://chemistry.stackexchange.com/questions/15171/inventor-of-crt,SCIENCE,chemistry.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.7777777777777778,The inventor of CRT?,"Let's get to the point. I've been studying a lot of reliable and unreliable resources. According to the official website of CRT and Wiki, the first CRT (cathode ray tube) was invented by Carl Ferdinand Braun in 1897. However, there is undeniable evidence that CRT was used in experiments in the 1860s.","Invention of CRT

In the year 1855, German inventor Heinrich Geissler developed mercury pump which is later modified by Sir William Crookes who became the first to produce cathode rays.



Figure 1: Geissler's Vaccum tubes(1862)

Since, then vacuum tubes are being used to study cathode rays, Braun's tube was actually an improvement to the these.

Otherwise, all of them have used some kind of Vacuum tube which produces cathode rays.


  
  In 1858 Julius PlÃ¼cker showed that cathode rays bend under the influence of a magnet.
  In 1865 H. Sprengel improves the Geissler vacuum pump.
  In 1869 J.W. Hittorf establishes that ""rays"" from the cathode travel in straight lines.
  In 1871 C.F. Varley is first to publish suggestion that cathode rays are composed of particles.[Fig 2]
  In 1874 George Johnstone Stoney estimates the charge of the then unknown electron.
  In 1876 Eugen Goldstein introduces the term cathode ray to describe the light emitted.
  In 1881 Herman Ludwig von Helmholtz suggested the idea that there is a smallest unit of electricity.
  In 1890 Arthur Schuster calculates the ratio of charge to mass of the particles making up cathode rays (today known as electrons) by
  measuring the magnetic deflection of cathode rays.
  In 1894 J.J. Thomson announces that he has found that the velocity of cathode rays is much lower than that of light.
  


Source: 


http://www.chemteam.info/AtomicStructure/Disc-of-Electron-History.html
http://www.chemteam.info/AtomicStructure/Disc-of-Electron-Intro.html




Figure 2: First published paper on cathode rays.
"
4238,4238,6758,Is it wise (and common) to publish in a peer-reviewed journal without an impact factor to prevent impairement of one's own mean impact factor?,"I recently found out that a team of colleagues published in a journal without impact factor, though peer-reviewed. According to my supervisor this happens sometimes when the study cannot be published in a top journal, and then it could be better to do so than publish in a low profile journal whose impact factor would drag down the mean impact factor of the papers published by that team. 

Is this common? If so, which elements can specifically drive a research team to choose this option?
",Cobactan,https://academia.stackexchange.com/users/35445,"This reasoning is Wrong and Bad in several ways.


First, computing ""mean impact factor"" for a person or group is insane and should be resisted at all costs.  Even amongst IF-crazy groups, the metric is generally how many high-IF publications have been obtained (ignoring low-IF publications), not the fraction of high-IF publications.
Second, even if you're going to commit yourself to such insanity, the reasonable mathematical interpretation of ""no impact factor"" is ""IF = 0"", not ""omit from data.""  Thus, if you're using this crazy statistic, it should be worse to publish in a no-IF venue.
Finally, a journal with no IF generally falls into one of two categories: either it is good but very new (or just not yet covered by ISI), in which case it will likely have an IF in a couple of years and the strategy will be undone, or else is it complete trash and likely predatory, in which case it will be a worse stain on your record than a moderate-IF publication, even amongst the most IF-crazy communities.


My only possible conclusions are that either:


your supervisor is seriously distorted in their thinking, or
your supervisor is lying to you out of embarrassment to cover the fact that they published (intentionally or accidentally) in a trash/predatory journal.

",jakebeal,https://academia.stackexchange.com/users/22733,http://academia.stackexchange.com/questions/49719/is-it-wise-and-common-to-publish-in-a-peer-reviewed-journal-without-an-impact,LIFE_ARTS,academia.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Is it wise (and common) to publish in peer-reviewed journals without influencing factors to prevent their average influencing factors from being damaged?,"I recently found that a group of colleagues published in a journal without influencing factors, but only peer review. According to my tutor, sometimes this happens when a research cannot be published in a top-level journal, which may be better than publishing in a low-key journal where an influencing factor will drag down the average influencing factor of the team's published papers.","This reasoning is Wrong and Bad in several ways.


First, computing ""mean impact factor"" for a person or group is insane and should be resisted at all costs.  Even amongst IF-crazy groups, the metric is generally how many high-IF publications have been obtained (ignoring low-IF publications), not the fraction of high-IF publications.
Second, even if you're going to commit yourself to such insanity, the reasonable mathematical interpretation of ""no impact factor"" is ""IF = 0"", not ""omit from data.""  Thus, if you're using this crazy statistic, it should be worse to publish in a no-IF venue.
Finally, a journal with no IF generally falls into one of two categories: either it is good but very new (or just not yet covered by ISI), in which case it will likely have an IF in a couple of years and the strategy will be undone, or else is it complete trash and likely predatory, in which case it will be a worse stain on your record than a moderate-IF publication, even amongst the most IF-crazy communities.


My only possible conclusions are that either:


your supervisor is seriously distorted in their thinking, or
your supervisor is lying to you out of embarrassment to cover the fact that they published (intentionally or accidentally) in a trash/predatory journal.

"
4307,4307,6862,"If you attempt to predict a Roulette wheel $n$ times, what's the probability you'll get $5$ in a row at some point?","I'm talking about a Roulette wheel with $38$ equally probable outcomes. Someone mentioned that he guessed the correct number five times in a row, and said that this was surprising because the probability of this happening was $$\left(\frac{1}{38}\right)^5$$

This is true if you only play the game $5$ times. However, if you play it more than $5$ times there's a higher (should be much higher?) probability that you'll get $5$ in a row at some point. 

I was thinking about how surprised this person should be at their streak of $m$ correct guesses given that they play $n$ games, each with probability $p$ of success. It makes intuitive sense that their surprise should be proportional to $1/q$ (or maybe $\log(1/q)$ since $1$ in a billion doesn't surprise you $10$ times more than $1$ in $100$ million), where $q$ is the probability that they get at least one streak of $m$ correct guesses at some point in their $n$ games. 

So, with the Roulette example I was thinking about, $p=1/38$ and $m=5$. 

I tried to find an explicit formula for $q$ in terms of $n$, and encountered some difficulty, because of the non-independence of ""getting a streak in the first five tries"" and ""getting a streak in tries $2$ through $6$"" (if the first is a failure, it's much more  likely that the second will be too). 



In summary, two questions:


How do I find the probability that you get $5$ correct guesses in a row at some point if you play $n$ games of Roulette?
More generally, what is the probability that you get $m$ successes at some point in a series of $n$ events, each with probability $p$ of success? 


The variables satisfy $\,\,\,m,n \in \mathbb{N}$, $\,\,\,m\leq n$, $\,\,\,p \in \mathbb{R}$, $\,\,\,0 \leq p \leq 1$.



If we write the answer to the second question as a function $q(m,n,p)$, then we can say that $q$ should be increasing with $n$, decreasing with $m$, and increasing with $p$. It should equal $p^n$ when $m=n$ and should equal $1$ when $p=1$ and $0$ when $p=0$. 

I feel as though this should be a basic probability problem, but I'm having trouble solving it. Maybe some kind of recursive approach would work? Given $q(n,m,p)$, I think I could write $q(n+1,m,p)$ using the probability that the last $m-1$ results are all successes ...
",Zubin Mukerjee,https://math.stackexchange.com/users/111946,"Feller, ""An Introduction to Probability Theory and Its Applications"", Third Edition, gives a useful approximation on p. 325, equation 7.11.

Suppose we toss a possibly biased coin $n$ times, where the probability of a head is $p$ and $q = 1-p$.  Let $q_n$ be the probability there is no run of $r$ successive heads.  Then

$$q_n \sim \frac{1-px}{(r+1-rx)q} \cdot \frac{1}{x^{n+1}}  $$

where $x$ is the smallest positive root of $1 - x + q p^r x^{r+1} = 0$.

For your problem, we have $r = 5$, $p = 1/38$, and $q = 37/38$, from which we calculate $x \approx 1 + 1.228854 \times 10^{-8}$.  

It works out that $q_n = 1/2$ for $n \approx 5.64 \times 10^7$, i.e. it takes about 56 million trials to have a 50% chance of guessing correctly 5 times in a row.
",awkward,https://math.stackexchange.com/users/76172,http://math.stackexchange.com/questions/1081447/if-you-attempt-to-predict-a-roulette-wheel-n-times-whats-the-probability-you,SCIENCE,math.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,1.0,"If you try to predict that the number of times a roulette is n dollars, what is the probability that you will get 5 dollars in a row at a certain time?","I'm talking about a Roulette wheel with $38$ equally probable outcomes. Someone mentioned that he guessed the correct number five times in a row, and said that this was surprising because the probability of this happening was $$\left(\frac{1}{38}\right)^5$$

This is true if you only play the game $5$ times. However, if you play it more than $5$ times there's a higher (should be much higher?) probability that you'll get $5$ in a row at some point. 

I was thinking about how surprised this person should be at their streak of $m$ correct guesses given that they play $n$ games, each with probability $p$ of success. It makes intuitive sense that their surprise should be proportional to $1/q$ (or maybe $\log(1/q)$ since $1$ in a billion doesn't surprise you $10$ times more than $1$ in $100$ million), where $q$ is the probability that they get at least one streak of $m$ correct guesses at some point in their $n$ games. 

So, with the Roulette example I was thinking about, $p=1/38$ and $m=5$. 

I tried to find an explicit formula for $q$ in terms of $n$, and encountered some difficulty, because of the non-independence of ""getting a streak in the first five tries"" and ""getting a streak in tries $2$ through $6$"" (if the first is a failure, it's much more  likely that the second will be too). 



In summary, two questions:


How do I find the probability that you get $5$ correct guesses in a row at some point if you play $n$ games of Roulette?
More generally, what is the probability that you get $m$ successes at some point in a series of $n$ events, each with probability $p$ of success? 


The variables satisfy $\,\,\,m,n \in \mathbb{N}$, $\,\,\,m\leq n$, $\,\,\,p \in \mathbb{R}$, $\,\,\,0 \leq p \leq 1$.



If we write the answer to the second question as a function $q(m,n,p)$, then we can say that $q$ should be increasing with $n$, decreasing with $m$, and increasing with $p$. It should equal $p^n$ when $m=n$ and should equal $1$ when $p=1$ and $0$ when $p=0$. 

I feel as though this should be a basic probability problem, but I'm having trouble solving it. Maybe some kind of recursive approach would work? Given $q(n,m,p)$, I think I could write $q(n+1,m,p)$ using the probability that the last $m-1$ results are all successes ...
","Feller, ""An Introduction to Probability Theory and Its Applications"", Third Edition, gives a useful approximation on p. 325, equation 7.11.

Suppose we toss a possibly biased coin $n$ times, where the probability of a head is $p$ and $q = 1-p$.  Let $q_n$ be the probability there is no run of $r$ successive heads.  Then

$$q_n \sim \frac{1-px}{(r+1-rx)q} \cdot \frac{1}{x^{n+1}}  $$

where $x$ is the smallest positive root of $1 - x + q p^r x^{r+1} = 0$.

For your problem, we have $r = 5$, $p = 1/38$, and $q = 37/38$, from which we calculate $x \approx 1 + 1.228854 \times 10^{-8}$.  

It works out that $q_n = 1/2$ for $n \approx 5.64 \times 10^7$, i.e. it takes about 56 million trials to have a 50% chance of guessing correctly 5 times in a row.
"
415,415,645,Driving electric cars through large pools of water,"The state of California is expected to be hit by a large storm in the coming days and there are frequently clogged drains in my town. I have an electric vehicle that seemed to handle driving through large puddles during the last storm but I was curious if anyone could tell me what the potential hazards are of driving an EV through a large standing pool of water. 

I don't need to worry about getting water in the engine (I think) since there is no air intake. There are fans that cool the battery if it gets too hot but I don't think that will be a problem during this storm.

EDIT: I have a Ford Focus
",Chris.Stover,https://mechanics.stackexchange.com/users/7751,"The answer to this question is what was put into its design at the drawing board stage. Encapsulation and water proofing of components susceptable to being submerged in water being the main consideration. As an electric vehicle construction is usually decided by its weight, less weight means less drain on the battery means greater distance between charges, encapsulation would not be a consideration. So I would be reluctant to drive through puddles higher then the hubs of the wheel at any sort of speed.
",Allan Osborne,https://mechanics.stackexchange.com/users/3975,http://mechanics.stackexchange.com/questions/13505/driving-electric-cars-through-large-pools-of-water,CULTURE,mechanics.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,0.7777777777777778,Driving electric cars in a big pool,"California is expected to be hit by a major storm in the next few days, and my town is often clogged with sewers. I have an electric car that seems to be able to drive through a big puddle in the last storm, but I'm curious if anyone can tell me what the potential dangers of driving an electric car in a huge pool of water are.","The answer to this question is, in the drawing stage, how is its design carried out. The main consideration is the package and water resistance of components. Because the structure of electric vehicle is usually determined by its weight, the lighter the weight means the less power consumption of battery means the greater the distance between charging, so the encapsulation is not considered. So I don't want to drive at any speed in a puddle higher than the hub."
204,204,328,Does this C++ static analysis rule make sense as is?,"I'm implementing some C++ static analysis rules, and one of them prohibits a function from returning a reference or pointer to a reference parameter of the function, i.e. the following are all non-compliant:

int *f(int&amp; x) { return &amp;x; } // #1
const int *g(const int&amp; x) { return &amp;x; } // #2
int&amp; h(int&amp; x) { return x; } // #3
const int&amp; m(const int&amp; x) { return x; } // #4


The justification given for this is that ""It is implementation-defined behaviour whether the reference parameter is a temporary object or a reference to the parameter.""

I'm puzzled by this, however, because stream operators in C++ are written in this way, e.g.

std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const X&amp; x) {
    //...
    return os;
}


I think I'm pretty confident that stream operators in C++ do not in general exhibit implementation-defined behaviour, so what's going on?

According to my understanding as it is at present, I would expect #1 and #3 to be well-defined, on the basis that temporaries cannot be bound to non-const references, so int&amp; x refers to a real object that has lifetime beyond the scope of the function, hence returning a pointer or reference to that object is fine. I would expect #2 to be dodgy, because a temporary could have been bound to const int&amp; x, in which case trying to take its address would seem a bad plan. I'm not sure about #4 - my gut feeling is that that's also potentially dodgy, but I'm not sure. In particular, I'm not clear on what would happen in the following case:

const int&amp; m(const int&amp; x) { return x; }
//...
const int&amp; r = m(23);

",Stuart Golodetz,https://stackoverflow.com/users/499449,"In C++11, #2 and #4 can be made safe if there are also rvalue reference overloads. Thus:

const int *get( const int &amp;x ) { return &amp;x; }
const int *get( const int &amp;&amp;x ) { return nullptr; }

void test() {
    const int x = 0;
    const int *p1 = get( x ); // OK; p1 is &amp;x.
    const int *p2 = get( x+42 ); // OK; p2 is nullptr.
}


So although they are dodgy, they do have safe uses if the programmer knows what they are doing. It'd be draconian to forbid this.

(Perhaps safer would be if the const rvalue reference overload was made private, left undefined, or otherwise caused a compile-time or link-time error. This is especially true for the #4 case, where we return a reference but there is nothing good to return a reference to and the language doesn't allow references to null.)
",Brangdon,https://stackoverflow.com/users/1440351,http://stackoverflow.com/questions/11538478/does-this-c-static-analysis-rule-make-sense-as-is,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,1.0,0.7777777777777778,Does this C + + static analysis rule make sense?,"I'm implementing some C++ static analysis rules, and one of them prohibits a function from returning a reference or pointer to a reference parameter of the function, i.e. the following are all non-compliant:

int *f(int&amp; x) { return &amp;x; } // #1
const int *g(const int&amp; x) { return &amp;x; } // #2
int&amp; h(int&amp; x) { return x; } // #3
const int&amp; m(const int&amp; x) { return x; } // #4


The justification given for this is that ""It is implementation-defined behaviour whether the reference parameter is a temporary object or a reference to the parameter.""

I'm puzzled by this, however, because stream operators in C++ are written in this way, e.g.

std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const X&amp; x) {
    //...
    return os;
}


I think I'm pretty confident that stream operators in C++ do not in general exhibit implementation-defined behaviour, so what's going on?

According to my understanding as it is at present, I would expect #1 and #3 to be well-defined, on the basis that temporaries cannot be bound to non-const references, so int&amp; x refers to a real object that has lifetime beyond the scope of the function, hence returning a pointer or reference to that object is fine. I would expect #2 to be dodgy, because a temporary could have been bound to const int&amp; x, in which case trying to take its address would seem a bad plan. I'm not sure about #4 - my gut feeling is that that's also potentially dodgy, but I'm not sure. In particular, I'm not clear on what would happen in the following case:

const int&amp; m(const int&amp; x) { return x; }
//...
const int&amp; r = m(23);

","In C++11, #2 and #4 can be made safe if there are also rvalue reference overloads. Thus:

const int *get( const int &amp;x ) { return &amp;x; }
const int *get( const int &amp;&amp;x ) { return nullptr; }

void test() {
    const int x = 0;
    const int *p1 = get( x ); // OK; p1 is &amp;x.
    const int *p2 = get( x+42 ); // OK; p2 is nullptr.
}


So although they are dodgy, they do have safe uses if the programmer knows what they are doing. It'd be draconian to forbid this.

(Perhaps safer would be if the const rvalue reference overload was made private, left undefined, or otherwise caused a compile-time or link-time error. This is especially true for the #4 case, where we return a reference but there is nothing good to return a reference to and the language doesn't allow references to null.)
"
4919,4919,7831,Is there a name for the number of values a variable can take?,"For example, a bit or a boolean can be either 0 or 1 so the number 2 is associated with it. Similarly, for a byte which is 8 bits, the maximum number of different assignments would be 2^8.

Is there a name for this number?

When we pass everything through our system that has ECMAScript, Java and MySQL, then a boolean does not have only two possible assignments. For instance, a false boolean gets saved as a 0 and the boxed value could be null so a boolean suddenly can get true, false, 0, 1, null or even undefined or &lt;missing&gt;.

I think it could get problematic in tests to guarantee that the values are not inconsistent. For instance, a value boolean locked could become null and then when a script or a layout template evaluates it then it will evaluate to false somewhere if the real value was null and similar problems.

So why don't we always assert that a boolean has the same number of possible values (2 values) and similarly for other types?

There is a mathematical term named ""arity"" that is something similar but not exactly, and statistics and probability theory also has the concept of ""event space"" that would be almost exactly what I mean. For instance, the event space for a boolean would be the set {0,1} which has cardinality 2 and that cardinality doesn't get preserved throughout the system, especially when data is passed as polyglots and/or serialized (json, jsonp, xml, yaml).
",Niklas Rosencrantz,https://programmers.stackexchange.com/users/12893,"I would call it cardinality (and indeed I have used it in that sense). It is strictly the cardinality of the set of all values a variable can take.

Edit: for example, a 16-bit integer can take exactly 65536 values. The cardinality of the set of all values that the integer can take is 655536.

Once you start to consider variables that have a range of valid values and also a range of invalid values (like a boolean with a bitwise value of 17), then you have to extend the concept somewhat, but you can still describe those values with set notation and the concept of cardinality still applies.

Edit: Yes, this is the mathematical set, not programming Set. If you were to apply the concept to the C# type short and derive the type short?, this would not have 65537 values, represented by the union of the set of 65536 values mentioned previously and one additional value, null. 
",david.pfx,https://programmers.stackexchange.com/users/114930,http://programmers.stackexchange.com/questions/233316/is-there-a-name-for-the-number-of-values-a-variable-can-take,TECHNOLOGY,programmers.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.9,0.0,0.3333333333333333,1.0,0.7777777777777778,Is there a name for the number of values a variable can accept?,"For example, a bit or a boolean can be either 0 or 1 so the number 2 is associated with it. Similarly, for a byte which is 8 bits, the maximum number of different assignments would be 2^8.

Is there a name for this number?

When we pass everything through our system that has ECMAScript, Java and MySQL, then a boolean does not have only two possible assignments. For instance, a false boolean gets saved as a 0 and the boxed value could be null so a boolean suddenly can get true, false, 0, 1, null or even undefined or &lt;missing&gt;.

I think it could get problematic in tests to guarantee that the values are not inconsistent. For instance, a value boolean locked could become null and then when a script or a layout template evaluates it then it will evaluate to false somewhere if the real value was null and similar problems.

So why don't we always assert that a boolean has the same number of possible values (2 values) and similarly for other types?

There is a mathematical term named ""arity"" that is something similar but not exactly, and statistics and probability theory also has the concept of ""event space"" that would be almost exactly what I mean. For instance, the event space for a boolean would be the set {0,1} which has cardinality 2 and that cardinality doesn't get preserved throughout the system, especially when data is passed as polyglots and/or serialized (json, jsonp, xml, yaml).
","I would call it cardinality (and indeed I have used it in that sense). It is strictly the cardinality of the set of all values a variable can take.

Edit: for example, a 16-bit integer can take exactly 65536 values. The cardinality of the set of all values that the integer can take is 655536.

Once you start to consider variables that have a range of valid values and also a range of invalid values (like a boolean with a bitwise value of 17), then you have to extend the concept somewhat, but you can still describe those values with set notation and the concept of cardinality still applies.

Edit: Yes, this is the mathematical set, not programming Set. If you were to apply the concept to the C# type short and derive the type short?, this would not have 65537 values, represented by the union of the set of 65536 values mentioned previously and one additional value, null. 
"
4473,4473,7096,How many domains can you configure on a Sun M5000 system?,"We have a few Sun M5000 servers with the following configuration:


Each system has 2 system boards each containing 2 x 2.5Ghz quad core processors
Each system board has 16GB of RAM
Each system has 4 x 300GB disks


I would like to know how many hardware domains can I configure per system? Do I need one system board per domain (implying a total of 2 domains), or can I create 4 domains, each with one cpu each?
",Andre Miller,https://serverfault.com/users/5339,"Even though the maximum number of domains supported on the M5000 is four, that also requires 4 system boards.

So in this configuration (2 system boards), the max number of domains is 2. To get 4 domains two more system boards were required.
",Andre Miller,https://serverfault.com/users/5339,http://serverfault.com/questions/50465,TECHNOLOGY,serverfault.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,How many domains can be configured on a sun m5000 system?,"We have a few Sun M5000 servers with the following configuration:


Each system has 2 system boards each containing 2 x 2.5Ghz quad core processors
Each system board has 16GB of RAM
Each system has 4 x 300GB disks


I would like to know how many hardware domains can I configure per system? Do I need one system board per domain (implying a total of 2 domains), or can I create 4 domains, each with one cpu each?
","Even though the maximum number of domains supported on the M5000 is four, that also requires 4 system boards.

So in this configuration (2 system boards), the max number of domains is 2. To get 4 domains two more system boards were required.
"
6048,6048,9598,how to lock object face a certain distance away from another object face?,"i tried searching for this on google but i came up empty. i want to know how to lock object 2 5 inches away from the corner of object 1? i want it to stay 5 inches away even if i re-scale.

can someone please help me? how do i lock cube 2 5 inches away from the edge of objects 1?

here is an image of what i want to do:



EDIT:
i want to offset ""cube 2"" 5 inches away from the bottom right vertex of ""cube 1"" no matter where ""cube 1"" is?

so if i move or scale ""cube 1"", ""cube 2"" would still be offset 5 inches from the bottom right vertex of ""cube 1""
",Ismaeel,https://blender.stackexchange.com/users/7501,"There are always a few things you can do when trying to move things in exact increments.
the first is to enable increment snapping, noted by the magnet on the bottom of the 3D view-port.



Another way is to type the distance you want your object to move on your keyboard.

example. G>x>1

This will move your object one unit on the 'X' axis.

if you find you object does not line up with the grid Shift+S>'Selection to Grid' will realign your object to the nearest major intersection on the grid.

Hope this helps,

Vince
",Scalia,https://blender.stackexchange.com/users/6385,http://blender.stackexchange.com/questions/17803/how-to-lock-object-face-a-certain-distance-away-from-another-object-face,TECHNOLOGY,blender.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,How to lock a certain distance between an object's face and another object's face?,"i tried searching for this on google but i came up empty. i want to know how to lock object 2 5 inches away from the corner of object 1? i want it to stay 5 inches away even if i re-scale.

can someone please help me? how do i lock cube 2 5 inches away from the edge of objects 1?

here is an image of what i want to do:



EDIT:
i want to offset ""cube 2"" 5 inches away from the bottom right vertex of ""cube 1"" no matter where ""cube 1"" is?

so if i move or scale ""cube 1"", ""cube 2"" would still be offset 5 inches from the bottom right vertex of ""cube 1""
","There are always a few things you can do when trying to move things in exact increments.
the first is to enable increment snapping, noted by the magnet on the bottom of the 3D view-port.



Another way is to type the distance you want your object to move on your keyboard.

example. G>x>1

This will move your object one unit on the 'X' axis.

if you find you object does not line up with the grid Shift+S>'Selection to Grid' will realign your object to the nearest major intersection on the grid.

Hope this helps,

Vince
"
2588,2588,4117,.NET - VB - OOP - Partial Class - How to create Partial Constructors,"I have a Partial Class in a file MainFile.vb with a constructor like this:

Partial Class MyAwesomeClass

    ' The constructor - Name it MainConstructor
    Public Sub New(Dim x As Integer)
        ' Some awesome code here
        Line1_of_code()
        Line2_of_code()
        Line3_of_code()
    End Sub

End Class


Now I want to add some more lines of code in the same constructor i.e. MainConstructor but my problem(s) is/are:


I can't edit the file MainFile.vb
I can't create another constructor
All I can do is -- since the MyAwesomeClass is a Partial Class; I can create another file e.g. ExtendedFile.vb and write my lines of code


So I'm trying to do like this which is not allowed in .NET:

Partial Class MyAwesomeClass

    ' The extended constructor - Name it ExtConstructor
    Public Sub New(Dim x As Integer) ' Boom!!!! Error: Duplicate constructor with same kind of arguments
        ' my extended awesome code here
        Line4_of_code()
        Line5_of_code()
        Line6_of_code()
    End Sub

End Class


Ultimately I want to do something like - When I create an object of MyAwesomeClass; it should execute Line1_of_code() to Line6_of_code(). I.e.

Dim objAwesome As New MyAwesomeClass(5) ' Any Integer will do


should execute all the below lines for objAwesome (and in the same order, too)

Line1_of_code()
Line2_of_code()
Line3_of_code()
Line4_of_code()
Line5_of_code()
Line6_of_code()


I'm using .NET Fx 4.0 -- Is there any workaround or solution? Any help would be appreciated.
",Ruchir Gupta,https://stackoverflow.com/users/3832403,"You can think of a partial class as code in separate files. Then compiler will merge it in one class file.

One solution is to just make new inherited class and override constructor.

Second solution is to make Shared (static) method builder:

Partial Class MyAwesomeClass
    Public Shared Function Create() As MyAwesomeClass
    ' your code goes here
    ' calling base instance creation


Third solution is to make different signature for second constructor, because you cannot have two methods in class with same name and signature, e.g.

Partial Class MyAwesomeClass
    Public Sub New(Dim x As Integer, Dim buildWithNewAwesomeImplementation as Boolean) ' 
        Me.New(x) ' calling base constructor
        If(buildWithNewAwesomeImplementation)
          Line4_of_code()
          Line5_of_code()
          Line6_of_code()
        End if
    End Sub
End Class


First solution seems more reasonable. 
",Artru,https://stackoverflow.com/users/304371,http://stackoverflow.com/questions/25152230/net-vb-oop-partial-class-how-to-create-partial-constructors,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,1.0,. net-vb-oop-partial class - how to create partial constructor,"I have a Partial Class in a file MainFile.vb with a constructor like this:

Partial Class MyAwesomeClass

    ' The constructor - Name it MainConstructor
    Public Sub New(Dim x As Integer)
        ' Some awesome code here
        Line1_of_code()
        Line2_of_code()
        Line3_of_code()
    End Sub

End Class


Now I want to add some more lines of code in the same constructor i.e. MainConstructor but my problem(s) is/are:


I can't edit the file MainFile.vb
I can't create another constructor
All I can do is -- since the MyAwesomeClass is a Partial Class; I can create another file e.g. ExtendedFile.vb and write my lines of code


So I'm trying to do like this which is not allowed in .NET:

Partial Class MyAwesomeClass

    ' The extended constructor - Name it ExtConstructor
    Public Sub New(Dim x As Integer) ' Boom!!!! Error: Duplicate constructor with same kind of arguments
        ' my extended awesome code here
        Line4_of_code()
        Line5_of_code()
        Line6_of_code()
    End Sub

End Class


Ultimately I want to do something like - When I create an object of MyAwesomeClass; it should execute Line1_of_code() to Line6_of_code(). I.e.

Dim objAwesome As New MyAwesomeClass(5) ' Any Integer will do


should execute all the below lines for objAwesome (and in the same order, too)

Line1_of_code()
Line2_of_code()
Line3_of_code()
Line4_of_code()
Line5_of_code()
Line6_of_code()


I'm using .NET Fx 4.0 -- Is there any workaround or solution? Any help would be appreciated.
","You can think of a partial class as code in separate files. Then compiler will merge it in one class file.

One solution is to just make new inherited class and override constructor.

Second solution is to make Shared (static) method builder:

Partial Class MyAwesomeClass
    Public Shared Function Create() As MyAwesomeClass
    ' your code goes here
    ' calling base instance creation


Third solution is to make different signature for second constructor, because you cannot have two methods in class with same name and signature, e.g.

Partial Class MyAwesomeClass
    Public Sub New(Dim x As Integer, Dim buildWithNewAwesomeImplementation as Boolean) ' 
        Me.New(x) ' calling base constructor
        If(buildWithNewAwesomeImplementation)
          Line4_of_code()
          Line5_of_code()
          Line6_of_code()
        End if
    End Sub
End Class


First solution seems more reasonable. 
"
3176,3176,5060,How to know which edition a DotNetNuke site is,"This may be a silly question, but I recently inherited a DotNetNuke site.  Looking in the settings, I can see it's running version 4.09.00 of DNN. Looking at current DNN 5.0 information, there appears to be several editions available (Community, Professional, Enterprise, etc).

So my question is:


Were these editions also available in the 4.0 version of DNN?
If so, is there a way to tell which edition the site is running?  I didn't see any immediately obvious designation in the admin areas.


Thanks!
",mrdrbob,https://webmasters.stackexchange.com/users/1436,"From the DotNetNuke Wikipedia page:


  The DotNetNuke Professional Edition was introduced in February 2009 with version 5.0. The DotNetNuke Elite Edition was released in September 2009.


At least these editions were not available in version 4.
",Nick,https://webmasters.stackexchange.com/users/1470,http://webmasters.stackexchange.com/questions/2139/how-to-know-which-edition-a-dotnetnuke-site-is,TECHNOLOGY,webmasters.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.6666666666666666,0.5555555555555556,1.0,0.6666666666666666,0.5333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,How to know which version of DotNetNuke site is,"This may be a silly question, but I recently inherited a DotNetNuke website. In the setup, I can see that it is running version 4.09.00 of DNN. Looking at the current DNN 5.0 information, it appears that several versions are available (community, professional, enterprise, etc.).","From the DotNetNuke Wikipedia page:


  The DotNetNuke Professional Edition was introduced in February 2009 with version 5.0. The DotNetNuke Elite Edition was released in September 2009.


At least these editions were not available in version 4.
"
4621,4621,7324,Meaning of ladder points,"Last night, we had a discussion regarding promotions on the ladder.
One of the issues where whether the points have influence on promotion or not, and neither of us can find legit facts to the points on the ladder.
We couldn't find any facts regarding the points at all, besides the fact that it ranks you on the ladder.

Do the points on the ladder have any other meaning besides placing you from 1-100 on the ladder?
",AtlasEU,https://gaming.stackexchange.com/users/43767,"Ladder ranking (LR) is (presumably) like hidden Matchmaking Rating (MMR), but offset by an unknown amount, and inflated by Bonus Pool.

Ladder ranking changes similarly to MMR, rising and dropping depending on the relative strength of your opponents, but it becomes offset by following factors:


LR has different ""zero point"" in different leagues (and League ranges should not overlap much, theoretically).
LR cannot be negative, so if you keep losing, your MMR diverges from ladder points.
LR is inflated by Bonus Pool, so, assuming all players spend their bonus pool, everyone's Ladder points drift up from their MMR by some (same for everyone) amount.


There was also a nuance that when matching players, their relative strength was determined by subtracting MMR of one from LR of the other, so both players could turn out to be ""favored"". ""Favor"" indication was removed, though, so it may have no effect today.

Bottom line: while LR does correlate with MMR in some circumstances, strictly speaking, it does not mean anything but rank in a Division. It is (with all Bonus pool stuff) just a convenient way to rank players, while giving them sense of progression and ""catching up"".
",Orc JMR,https://gaming.stackexchange.com/users/33619,http://gaming.stackexchange.com/questions/126756/meaning-of-ladder-points,CULTURE,gaming.stackexchange.com,0.5555555555555556,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Meaning of step point,"Last night, we had a discussion regarding promotions on the ladder.
One of the issues where whether the points have influence on promotion or not, and neither of us can find legit facts to the points on the ladder.
We couldn't find any facts regarding the points at all, besides the fact that it ranks you on the ladder.

Do the points on the ladder have any other meaning besides placing you from 1-100 on the ladder?
","Ladder ranking (LR) is (presumably) like hidden Matchmaking Rating (MMR), but offset by an unknown amount, and inflated by Bonus Pool.

Ladder ranking changes similarly to MMR, rising and dropping depending on the relative strength of your opponents, but it becomes offset by following factors:


LR has different ""zero point"" in different leagues (and League ranges should not overlap much, theoretically).
LR cannot be negative, so if you keep losing, your MMR diverges from ladder points.
LR is inflated by Bonus Pool, so, assuming all players spend their bonus pool, everyone's Ladder points drift up from their MMR by some (same for everyone) amount.


There was also a nuance that when matching players, their relative strength was determined by subtracting MMR of one from LR of the other, so both players could turn out to be ""favored"". ""Favor"" indication was removed, though, so it may have no effect today.

Bottom line: while LR does correlate with MMR in some circumstances, strictly speaking, it does not mean anything but rank in a Division. It is (with all Bonus pool stuff) just a convenient way to rank players, while giving them sense of progression and ""catching up"".
"
5981,5981,9482,How do I deal with a slow and undedicated colleague in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
",HOT,https://programmers.stackexchange.com/users/34092,"I've just read ""The Clean Coder"" by R.C. Martin (Uncle Bob).  The main point of the book is that programmers in general don't get much respect because they are not behaving professionally.  That means mainly that they don't communicate effectively with management about the status of the project.  

Lying is certainly a very very bad form of communication.  Your colleague is being extremely unprofessional and so are you.  You both are doing nothing good to improve the perception of programmers.

I would advise you to go right away to management.  However, I have gotten in trouble in the past for having been too ""honest"" (in some unrelated situation), so I'm not sure you should take my advice.
Also, as many have pointed out, maybe your perception of the situation is not as accurate as you think.
",toto2,https://programmers.stackexchange.com/users/34506,http://programmers.stackexchange.com/questions/101528/how-do-i-deal-with-a-slow-and-undedicated-colleague-in-the-team,TECHNOLOGY,programmers.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.8,0.0,1.0,0.3333333333333333,0.7777777777777778,How can I deal with a colleague who is slow-moving and lacks dedication in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
","I've just read ""The Clean Coder"" by R.C. Martin (Uncle Bob).  The main point of the book is that programmers in general don't get much respect because they are not behaving professionally.  That means mainly that they don't communicate effectively with management about the status of the project.  

Lying is certainly a very very bad form of communication.  Your colleague is being extremely unprofessional and so are you.  You both are doing nothing good to improve the perception of programmers.

I would advise you to go right away to management.  However, I have gotten in trouble in the past for having been too ""honest"" (in some unrelated situation), so I'm not sure you should take my advice.
Also, as many have pointed out, maybe your perception of the situation is not as accurate as you think.
"
969,969,1535,EXcel Web Access - web part Error,"I asked this related question in stack overflow, Hence this forum is dedicated for sharepoint, Thought to ask here!!

I got to know how to get the Excel using sharepoint Excel web access webpart. However I am getting an error ""Excel Services is unable to process the request. Wait a few minutes and try performing this operation again!!"" Even If I directly access the Excel from the document library also getting the same error!!
",Jithu,https://sharepoint.stackexchange.com/users/5462,"Would be nice if you could provide some log information, but double check:


Excel Services is actually running on the farm.
Check if you can run Get-SPExcelServiceApplication 
Check the Trusted File Location for Excel Services
Check if your Web Application has a service connection to the Excel Services

",Anders Aune,https://sharepoint.stackexchange.com/users/4328,http://sharepoint.stackexchange.com/questions/22346/excel-web-access-web-part-error,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Excel web access web part error,"I asked this related question in stack overflow, Hence this forum is dedicated for sharepoint, Thought to ask here!!

I got to know how to get the Excel using sharepoint Excel web access webpart. However I am getting an error ""Excel Services is unable to process the request. Wait a few minutes and try performing this operation again!!"" Even If I directly access the Excel from the document library also getting the same error!!
","Would be nice if you could provide some log information, but double check:


Excel Services is actually running on the farm.
Check if you can run Get-SPExcelServiceApplication 
Check the Trusted File Location for Excel Services
Check if your Web Application has a service connection to the Excel Services

"
4725,4725,7499,"How can I learn how to lay out an ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
",xenoterracide,https://rpg.stackexchange.com/users/1015,"""Just the facts"" just isn't enough

Plan more flavor and context into your scenes, and your story.  WoD games often lend themselves to strong thematic overtones, so don't skimp.  Small side stories, or a growing tapestry of NPCs can both add a feeling of depth to the play experience.  As you write later scene, call back to those ""useless"" or ""flavor"" elements from earlier.  

These threads don't support the factual investigation story, but they support the emotional investment the players should develop.  Recurring NPCs, even if they are unimportant people, are characters the player can start to get attached to, or develop other feelings towards like pity, anger, or curiosity.  Less ""important"" people can also illustrate the human impact of what the antagonist(s) and PCs are doing in the world.

Add enough grit and detail to create a solid emotional journey, and the story will feel more meaty.

More facts don't hurt, either

That said, writing a good story/mystery can be ten times harder for most of us than telling it back during play.  I've fallen into the trap of carefully coming up with some scheme for the players to learn about, thinking it was great because I spent so long on it and put so much effort into it.  Then, they quickly gobbled it up and were ready for more... that I didn't have!

Try just adding more facets to the story and clue details to found.
",Jessa,https://rpg.stackexchange.com/users/17690,http://rpg.stackexchange.com/questions/50671/how-can-i-learn-how-to-lay-out-an-evidence-scene,CULTURE,rpg.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,"How can I learn to set up ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
","""Just the facts"" just isn't enough

Plan more flavor and context into your scenes, and your story.  WoD games often lend themselves to strong thematic overtones, so don't skimp.  Small side stories, or a growing tapestry of NPCs can both add a feeling of depth to the play experience.  As you write later scene, call back to those ""useless"" or ""flavor"" elements from earlier.  

These threads don't support the factual investigation story, but they support the emotional investment the players should develop.  Recurring NPCs, even if they are unimportant people, are characters the player can start to get attached to, or develop other feelings towards like pity, anger, or curiosity.  Less ""important"" people can also illustrate the human impact of what the antagonist(s) and PCs are doing in the world.

Add enough grit and detail to create a solid emotional journey, and the story will feel more meaty.

More facts don't hurt, either

That said, writing a good story/mystery can be ten times harder for most of us than telling it back during play.  I've fallen into the trap of carefully coming up with some scheme for the players to learn about, thinking it was great because I spent so long on it and put so much effort into it.  Then, they quickly gobbled it up and were ready for more... that I didn't have!

Try just adding more facets to the story and clue details to found.
"
1950,1950,3109,Does the function which sends a right angled triangle to its area produce infinitely many numbers having hardly any prime factors?,"Let $T$ be the set of pythagorean triples, that is, triples of integers (a,b,c) satisfying a2 + b2 = c2. We think of $T$ as the set of right angles triangles with integer lengths. And let $f : T \rightarrow \mathbb{Z}$ be the function $(a,b,c) \mapsto \frac{ab}{12}$ which computes the area of a triangle (divided by 6, which seems to always be a factor for some reason). 

I was wondering: what are the number theoretic propertires of $f$? It seems to produce numbers with few prime factors. What is the reason for this? For instance, $f(3,4,5) = 1$, $f(36,77,85) = 3 * 11 * 7$, and $f(65,72,97)=39*5*2$. Can we put a bound on the number of prime factors in the numbers that $f$ spits out? Or at least, can we give a 'generic' statement such as 'The output of $f$ almost always spits out numbers with less than 8 factors' or something?
",Bruce Bartlett,https://mathoverflow.net/users/401,"There are many right triangles whose area has as few prime factors as possible:

The Green-Tao paper ""Linear equations in primes"", and the subsequent work on their Mobius Nilsequences conjecture by GT and Gowers Inverse conjecture by GT-Ziegler, implies that $\frac{ab}{12}$ is infintely often a product of four primes, in a quantitative sense.  Indeed, reparametrizing gives $ab=12xy(2x+3y)(2x-3y)$, and now we are asking for points in the lattice $(1,0,2,2)\mathbb{Z}+(0,1,3,-3)\mathbb{Z}$ all of whose coordinates are prime.  This system has finite complexity and thus the main results of ""Linear equations in primes"" applies unconditionally, that is to say the number of pairs $(x,y)$ with $0 &lt; |x| , |y| &lt; T$ and $xy(2x+3y)(2x-3y)$ a product of four primes is asymptotically $cT^2 (\log{T})^{-4}$ for some constant $c$.  

This deduction can be found, for example, in Sarnak's notes ""Equidistribution and primes"".
",David Hansen,https://mathoverflow.net/users/1464,http://mathoverflow.net/questions/31897,SCIENCE,mathoverflow.net,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.8333333333333334,1.0,0.8888888888888888,0.7333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,Does the function that sends a right triangle to its region produce an infinite number with almost no prime factor?,"Let $T$ be the set of pythagorean triples, that is, triples of integers (a,b,c) satisfying a2 + b2 = c2. We think of $T$ as the set of right angles triangles with integer lengths. And let $f : T \rightarrow \mathbb{Z}$ be the function $(a,b,c) \mapsto \frac{ab}{12}$ which computes the area of a triangle (divided by 6, which seems to always be a factor for some reason). 

I was wondering: what are the number theoretic propertires of $f$? It seems to produce numbers with few prime factors. What is the reason for this? For instance, $f(3,4,5) = 1$, $f(36,77,85) = 3 * 11 * 7$, and $f(65,72,97)=39*5*2$. Can we put a bound on the number of prime factors in the numbers that $f$ spits out? Or at least, can we give a 'generic' statement such as 'The output of $f$ almost always spits out numbers with less than 8 factors' or something?
","There are many right triangles whose area has as few prime factors as possible:

The Green-Tao paper ""Linear equations in primes"", and the subsequent work on their Mobius Nilsequences conjecture by GT and Gowers Inverse conjecture by GT-Ziegler, implies that $\frac{ab}{12}$ is infintely often a product of four primes, in a quantitative sense.  Indeed, reparametrizing gives $ab=12xy(2x+3y)(2x-3y)$, and now we are asking for points in the lattice $(1,0,2,2)\mathbb{Z}+(0,1,3,-3)\mathbb{Z}$ all of whose coordinates are prime.  This system has finite complexity and thus the main results of ""Linear equations in primes"" applies unconditionally, that is to say the number of pairs $(x,y)$ with $0 &lt; |x| , |y| &lt; T$ and $xy(2x+3y)(2x-3y)$ a product of four primes is asymptotically $cT^2 (\log{T})^{-4}$ for some constant $c$.  

This deduction can be found, for example, in Sarnak's notes ""Equidistribution and primes"".
"
1348,1348,2123,How do you get your Steam games to run on Ubuntu through Wine or something similar?,"Ok, I was kind of surprised that this hadn't been asked here before, but maybe it's too technical for this site. You guys decide.

I've heard lots of different stories about setting up Wine on Ubuntu, WineTricks, PlayOnLinux etc., but never a 'This is the best way to do it for Steam and Steam games' thread.

So has anyone had any real success getting their Steam games to run on Ubuntu through Wine or something similar? If so, could we get some specific steps?
",LoveMeSomeCode,https://gaming.stackexchange.com/users/7157,"Steam works very well in plain Wine.

I actually paid for Crossover games since they provide commercial support and fix reported bugs in supported games extremely fast. Plus they push fixes back into Wine.
",Let_Me_Be,https://gaming.stackexchange.com/users/2771,http://gaming.stackexchange.com/questions/16751/how-do-you-get-your-steam-games-to-run-on-ubuntu-through-wine-or-something-simil,CULTURE,gaming.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.8,0.6666666666666666,0.0,0.3333333333333333,1.0,How do you make your steam game run on Ubuntu with wine or something like that?,"Ok, I was kind of surprised that this hadn't been asked here before, but maybe it's too technical for this site. You guys decide.

I've heard lots of different stories about setting up Wine on Ubuntu, WineTricks, PlayOnLinux etc., but never a 'This is the best way to do it for Steam and Steam games' thread.

So has anyone had any real success getting their Steam games to run on Ubuntu through Wine or something similar? If so, could we get some specific steps?
","Steam works very well in plain Wine.

I actually paid for Crossover games since they provide commercial support and fix reported bugs in supported games extremely fast. Plus they push fixes back into Wine.
"
250,250,404,What are the pitfalls of buying a used car after an accident?,"I have the option to buy a car that has been in an accident. There are alternatives, but within my budget the alternatives are usually older/have higher mileage. The seller is a local mechanic who did the restoration work and also showed pictures of the car before restoration. The damage was done to one of the front headlights and to the surrounding bits. The mechanic has convinced me that no damage was done to the internal carrying structure. He fixed the lights and did some paintwork restoration.

Problem: I read that people advice not to buy cars after the accident. This is my first car, so my experience is nonexistent.

Question: What are the cons against buying a car after the accident?

About the car: Opel Astra 2007 1.4 Petrol Manual Hatchback priced Â£2200, 1 prev owner, chain, 66K miles, 1 year MOT, 6 month tax
",JimD,https://mechanics.stackexchange.com/users/3196,"For what it's worth, I bought my first car (well, first that was actually mine) shortly after college for $100 with accident damage. Started with no knowledge or experience repairing cars. Took me a few months to get it in working shape, but it served me well for 4 years, and I learned a lot from it. However, it had damage to the frame that kept me from ever getting the alignment perfect, and so it burned through tires. This is something you might want to have checked by a professional on any vehicle that's had accident damage.

Anyway, the main thing I have to add on top of what others have said is that, if you can't afford to spend a lot of money and want to buy a car with potential problems as a way to save money, you might want to go the way I did and take ""accident damage"" over ""engine problems"". Even if you have to do some work on it later yourself, replacing components that might have been damaged in an accident is a lot easier for a beginner than doing a head gasket job or full engine or transmission rebuild (those issues being the other obvious ways you could get a dirt-cheap vehicle).
",R..,https://mechanics.stackexchange.com/users/426,http://mechanics.stackexchange.com/questions/6177/what-are-the-pitfalls-of-buying-a-used-car-after-an-accident,SCIENCE,mechanics.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,0.3333333333333333,1.0,What are the pitfalls of buying a used car after an accident?,"I can choose to buy a car with an accident. There are other options, but within my budget, they are usually older / higher mileage. The seller is a local mechanic who did the repair work and showed pictures of the car before the repair. What was damaged was a headlight and surrounding debris. The mechanic has convinced me that the internal handling structure is not damaged. He fixed the light and did some paint work.","For what it's worth, I bought my first car (well, first that was actually mine) shortly after college for $100 with accident damage. Started with no knowledge or experience repairing cars. Took me a few months to get it in working shape, but it served me well for 4 years, and I learned a lot from it. However, it had damage to the frame that kept me from ever getting the alignment perfect, and so it burned through tires. This is something you might want to have checked by a professional on any vehicle that's had accident damage.

Anyway, the main thing I have to add on top of what others have said is that, if you can't afford to spend a lot of money and want to buy a car with potential problems as a way to save money, you might want to go the way I did and take ""accident damage"" over ""engine problems"". Even if you have to do some work on it later yourself, replacing components that might have been damaged in an accident is a lot easier for a beginner than doing a head gasket job or full engine or transmission rebuild (those issues being the other obvious ways you could get a dirt-cheap vehicle).
"
3618,3618,5776,Proportion of resources devoted to UX Design & Research vs. Software Development on a web app?,"First, some criteria:


The product is an application and is heavy on user interaction.  Think web 2.0 or mobile application, not a marketing or commerce site, or some back-end tool with only command-line access.
I realize that it is not always clear who is a UX person and who is a developer (nor should it be), so I'd like to focus on overall team resource allocation.  For instance, ""My team puts 25% of our resource-time into UX design/research vs. 75% of our resource-time in development.""  
I am not distinguishing between front-end and back-end development as it is too platform-specific and difficult to tease out the dividing like.  It's all software development for this question.
EDIT: Development is occurring in an agile-esque, ongoing manner, rather than a one-time, big-bang delivery.


So:


How does this proportion commonly look in practice?
How should it look?  Or, better yet, what has been the proportion on successful teams?


(I realize this is a classic ""it depends"" question, but I suspect that there is some use in asking when constrained by a few parameters, and allowing that conditions will vary.  I am also open to suggestions to further constrain the question.)
",peteorpeter,https://ux.stackexchange.com/users/3916,"It's hard to draw a line between UX and Dev. There shouldn't be a line (as you state). It's going to depend on the project and the individual skill sets of the team. 

The bigger factor, IMHO, is that the team, as a whole, isn't too large. You want to avoid the 'too many cooks' syndrome which seems all-to-common at the enterprise level where you end up with dev teams pushing over 20 people. That's just a mess. 

You can do a lot with with just a team of 2: a skilled programmer and a skilled UX person who both have some skills that cross the line or, at least appreciate both sides of the equation. 

Maybe a better way to look at it is in reverse...what's a BAD team. I think a sign of a bad team make up is when there is a discernable line between UX and Dev. I'm suffering a bit through that situation right now, where our UX team is entirely independent of the dev team (which I am on)...which is entirely independent from the enterprise architecture team (who's applications services we rely on). Even though we call our selves an agile shop, it ends up being waterfall as there is this assembly line mentality UX -> Dev. Which simply does not make for efficient software development with UX being a priority. 
",DA01,https://ux.stackexchange.com/users/1740,http://ux.stackexchange.com/questions/6844/proportion-of-resources-devoted-to-ux-design-research-vs-software-development,TECHNOLOGY,ux.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,0.3333333333333333,0.5555555555555556,0.3333333333333333,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,1.0,1.0,What is the ratio of resources for user experience design and research to resources for software development for web applications?,"First, some criteria:


The product is an application and is heavy on user interaction.  Think web 2.0 or mobile application, not a marketing or commerce site, or some back-end tool with only command-line access.
I realize that it is not always clear who is a UX person and who is a developer (nor should it be), so I'd like to focus on overall team resource allocation.  For instance, ""My team puts 25% of our resource-time into UX design/research vs. 75% of our resource-time in development.""  
I am not distinguishing between front-end and back-end development as it is too platform-specific and difficult to tease out the dividing like.  It's all software development for this question.
EDIT: Development is occurring in an agile-esque, ongoing manner, rather than a one-time, big-bang delivery.


So:


How does this proportion commonly look in practice?
How should it look?  Or, better yet, what has been the proportion on successful teams?


(I realize this is a classic ""it depends"" question, but I suspect that there is some use in asking when constrained by a few parameters, and allowing that conditions will vary.  I am also open to suggestions to further constrain the question.)
","It's hard to draw a line between UX and Dev. There shouldn't be a line (as you state). It's going to depend on the project and the individual skill sets of the team. 

The bigger factor, IMHO, is that the team, as a whole, isn't too large. You want to avoid the 'too many cooks' syndrome which seems all-to-common at the enterprise level where you end up with dev teams pushing over 20 people. That's just a mess. 

You can do a lot with with just a team of 2: a skilled programmer and a skilled UX person who both have some skills that cross the line or, at least appreciate both sides of the equation. 

Maybe a better way to look at it is in reverse...what's a BAD team. I think a sign of a bad team make up is when there is a discernable line between UX and Dev. I'm suffering a bit through that situation right now, where our UX team is entirely independent of the dev team (which I am on)...which is entirely independent from the enterprise architecture team (who's applications services we rely on). Even though we call our selves an agile shop, it ends up being waterfall as there is this assembly line mentality UX -> Dev. Which simply does not make for efficient software development with UX being a priority. 
"
5550,5550,8817,Android Switch Widget: Setting android:track causes thumb and track to not show up,"I am having trouble customizing the look of an Android Switch widget. I have custom xml drawables that I want to use for the thumb (the little button part that usually says On or Off) and the track (the background that the thumb slides across). When I set just the thumb using android:thumb, it works fine. When I set the track (whether or not the thumb is set), the switch disappears entirely and I'm left with only the text showing.

Here is my code when just the thumb is applied:

&lt;com.blahblahblah.blah.CustomSwitch
    android:id=""@+id/switch_1""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:textOff=""Off""
    android:textOn=""On""
    android:text=""Something Awesome""
    android:textColor=""@android:color/black""
    android:thumb=""@drawable/custom_switch_thumb"" /&gt;


Here is what it looks like in the preview window:



And with the track applied:

&lt;com.blahblahblah.blah.CustomSwitch
    android:id=""@+id/switch_1""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:textOff=""Off""
    android:textOn=""On""
    android:text=""Something Awesome""
    android:textColor=""@android:color/black""
    android:track=""@color/track_color"" /&gt;


Preview window with track applied:



For reference I am using Android Studio 0.2.3 on OSX 10.7.5.
",Phil Ringsmuth,https://stackoverflow.com/users/529554,"I just stumbled upon the same problem and found a fix through on the HoloEverywhere issue tracker. You'll need to set the &lt;size&gt; of the drawable XML shape you are using.

Not working (the widget is there and I can interact with it, but I can't see it, it's hidden):

&lt;shape xmlns:android=""http://schemas.android.com/apk/res/android""
  android:shape=""rectangle""&gt;

  &lt;solid android:color=""@color/black_50"" /&gt;
&lt;/shape&gt;


Working (not the added &lt;size&gt;):

&lt;shape xmlns:android=""http://schemas.android.com/apk/res/android""
  android:shape=""rectangle""&gt;

  &lt;solid android:color=""@color/black_50"" /&gt;
  &lt;size android:width=""56dp"" android:height=""20dp"" /&gt;
&lt;/shape&gt;

",chdorner,https://stackoverflow.com/users/574272,http://stackoverflow.com/questions/18659446/android-switch-widget-setting-androidtrack-causes-thumb-and-track-to-not-show,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Android switch widget: setting Android: track will cause thumb and track not to display,"I am having trouble customizing the look of an Android Switch widget. I have custom xml drawables that I want to use for the thumb (the little button part that usually says On or Off) and the track (the background that the thumb slides across). When I set just the thumb using android:thumb, it works fine. When I set the track (whether or not the thumb is set), the switch disappears entirely and I'm left with only the text showing.

Here is my code when just the thumb is applied:

&lt;com.blahblahblah.blah.CustomSwitch
    android:id=""@+id/switch_1""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:textOff=""Off""
    android:textOn=""On""
    android:text=""Something Awesome""
    android:textColor=""@android:color/black""
    android:thumb=""@drawable/custom_switch_thumb"" /&gt;


Here is what it looks like in the preview window:



And with the track applied:

&lt;com.blahblahblah.blah.CustomSwitch
    android:id=""@+id/switch_1""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:textOff=""Off""
    android:textOn=""On""
    android:text=""Something Awesome""
    android:textColor=""@android:color/black""
    android:track=""@color/track_color"" /&gt;


Preview window with track applied:



For reference I am using Android Studio 0.2.3 on OSX 10.7.5.
","I just stumbled upon the same problem and found a fix through on the HoloEverywhere issue tracker. You'll need to set the &lt;size&gt; of the drawable XML shape you are using.

Not working (the widget is there and I can interact with it, but I can't see it, it's hidden):

&lt;shape xmlns:android=""http://schemas.android.com/apk/res/android""
  android:shape=""rectangle""&gt;

  &lt;solid android:color=""@color/black_50"" /&gt;
&lt;/shape&gt;


Working (not the added &lt;size&gt;):

&lt;shape xmlns:android=""http://schemas.android.com/apk/res/android""
  android:shape=""rectangle""&gt;

  &lt;solid android:color=""@color/black_50"" /&gt;
  &lt;size android:width=""56dp"" android:height=""20dp"" /&gt;
&lt;/shape&gt;

"
4929,4929,7848,How are potions made?,"Where does majority of the energy for the magical effect of a potion comes from? 

Does it all comes from the brewer? Or does most of it comes from the ingredients? 

I know JKR said that you have to use magic at some part of the process of brewing (hence no muggle potion brewers) [what about a squib?]

If brewer provides all of the energy then why aren't NEWT students magically exhausted after every potion class? Hermione successfully brewed batch of Polyjuice Potion (a very potent NEWT level potion) in first semester of her second year, and while brewing it was very time-consuming and required a lot of concentration she never showed any signs of exhaustion as far as I remember.
",Fen1ks,https://scifi.stackexchange.com/users/23010,"
  ""As there is little foolish wand-waving here, many of you will hardly believe this is magic. I don't expect you
  will really understand the beauty of the softly simmering cauldron with
  its shimmering fumes, the delicate power of liquids that creep through
  human veins, bewitching the mind, ensnaring the senses.... I can teach
  you how to bottle fame, brew glory, even stopper death -- if you aren't
  as big a bunch of dunderheads as I usually have to teach."" (Severus Snape to First Years, HP and Philosopher's Stone, CHAPTER EIGHT ""THE POTIONS MASTER"")


In Chemistry (which potion-making is a clear magical equivalent of), there's a concept of catalyst. A catalyst is a chemical which facilitates a given chemical reaction, without actually being consumed as part of it. Usually a fairly small amount of catalyst is enough to affect the reaction.

It seems to me, based on what small info was provided in the books/interviews, that magic in brewing the potions is strongly equivalent to the catalist in a chemical reaction. It aids the potion-making, but isn't there to provide ""energy"" to it. 

This is confirmed by the fact that you tend to boil your cauldrons in Potions using fire - this is what would have provided the energy.


  ""I suppose you added the porcupine quills before taking the cauldron off the fire?"" (same source).


This pretty much answers your main question - the majority of the energy comes from the fire, as is frequently the case with chemical reactions. But some of it can come from the ingredients themselves when reacting.

As such, it seems unlikely that magic involved in making potions is in need of being especially energy-draining, even if it may be somewhat tricky or complicated.
",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,http://scifi.stackexchange.com/questions/32947/how-are-potions-made,LIFE_ARTS,scifi.stackexchange.com,1.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,1.0,How is the liquid medicine made?,"Where does majority of the energy for the magical effect of a potion comes from? 

Does it all comes from the brewer? Or does most of it comes from the ingredients? 

I know JKR said that you have to use magic at some part of the process of brewing (hence no muggle potion brewers) [what about a squib?]

If brewer provides all of the energy then why aren't NEWT students magically exhausted after every potion class? Hermione successfully brewed batch of Polyjuice Potion (a very potent NEWT level potion) in first semester of her second year, and while brewing it was very time-consuming and required a lot of concentration she never showed any signs of exhaustion as far as I remember.
","
  ""As there is little foolish wand-waving here, many of you will hardly believe this is magic. I don't expect you
  will really understand the beauty of the softly simmering cauldron with
  its shimmering fumes, the delicate power of liquids that creep through
  human veins, bewitching the mind, ensnaring the senses.... I can teach
  you how to bottle fame, brew glory, even stopper death -- if you aren't
  as big a bunch of dunderheads as I usually have to teach."" (Severus Snape to First Years, HP and Philosopher's Stone, CHAPTER EIGHT ""THE POTIONS MASTER"")


In Chemistry (which potion-making is a clear magical equivalent of), there's a concept of catalyst. A catalyst is a chemical which facilitates a given chemical reaction, without actually being consumed as part of it. Usually a fairly small amount of catalyst is enough to affect the reaction.

It seems to me, based on what small info was provided in the books/interviews, that magic in brewing the potions is strongly equivalent to the catalist in a chemical reaction. It aids the potion-making, but isn't there to provide ""energy"" to it. 

This is confirmed by the fact that you tend to boil your cauldrons in Potions using fire - this is what would have provided the energy.


  ""I suppose you added the porcupine quills before taking the cauldron off the fire?"" (same source).


This pretty much answers your main question - the majority of the energy comes from the fire, as is frequently the case with chemical reactions. But some of it can come from the ingredients themselves when reacting.

As such, it seems unlikely that magic involved in making potions is in need of being especially energy-draining, even if it may be somewhat tricky or complicated.
"
282,282,454,COP8 MCU information needed,"I have a problem with a sbc that I am repairing, the sbc is controlled by an 8-bit OTP microcontroller which I think is broken.
I only get 200 ohms between pin Vcc and Vss, specifically the chip is COP87L84BC and is out of production. 

What I try is to read the registers of the microcontroller with a cable ISP and any similar software WinPic800 but for this chip.
I never used the COP8 OPT from National Semiconductor so I wanted information about this MCU or web sites where I can find information.
",jotasa,https://electronics.stackexchange.com/users/132,"200 ohms between Vcc and Vss: are you sure the MCU is to blame? You would have to remove it completely from the circuit just in case there is something else connected to the Vcc rail that is actually faulty.

If you apply power, do you see any of the I/O lines changing state?
",Adam Lawrence,https://electronics.stackexchange.com/users/1293,http://electronics.stackexchange.com/questions/684/cop8-mcu-information-needed,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,0.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.3333333333333333,1.0,0.6666666666666666,0.6,0.0,0.0,0.3333333333333333,0.8888888888888888,Need COP8 MCU information,"I have a problem with a sbc that I am repairing, the sbc is controlled by an 8-bit OTP microcontroller which I think is broken.
I only get 200 ohms between pin Vcc and Vss, specifically the chip is COP87L84BC and is out of production. 

What I try is to read the registers of the microcontroller with a cable ISP and any similar software WinPic800 but for this chip.
I never used the COP8 OPT from National Semiconductor so I wanted information about this MCU or web sites where I can find information.
",200 ohm between VCC and VSS: are you sure it is caused by MCU? You have to remove it completely from the circuit to prevent other connections on the VCC rails from failing.
5465,5465,8676,Magento aggregate and between collections?,"1) How to write the below SQL query in Magneto collection :

SELECT * FROM 'table1' WHERE active=0 AND '2014-07-08' between 'not_available_from_date' and 'not_available_to_date'


2) Also how to write this SQL query in Magneto Collection :

Select sum(qty + product_id - any_other_columns) as total from table2  GROUP BY product_id; 


Without using ->columns('  ') function.

Thanks for your help
",VijayS91,https://magento.stackexchange.com/users/2922,"Assuming you have a model mapped to your table1 and one mapped to table2 you can try something like this.

$date = '2014-07-08';
$collection = Mage::getModel('[module]/table1')-&gt;getCollection()
    -&gt;addFieldToFilter('active', 0)
    -&gt;addFieldToFilter('not_available_from_date', array('date' =&gt; true, 'to' =&gt; $date))
    -&gt;addFieldToFilter('not_available_to_date', array('date' =&gt; true, 'from' =&gt; $date));


And for the second one.

$collection = Mage::getModel('[module]/table2')-&gt;getCollection()
    -&gt;addExpressionFieldToSelect('total', 'SUM({{qty}} + {{product_id}} - {{any_other_columns}})', array('{{qty}}'=&gt;'qty', '{{product_id}}'=&gt;'product_id', '{{any_other_columns}}'=&gt;'any_other_columns'));
//since SUM requires a GROUP BY...group by some column
$collection-&gt;getSelect()-&gt;group('product_id');


The examples above are for flat entities. 

If you have an EAV entity similar to products or categories use 

addAttributeToFilter instead of addFieldToFilter 

addExpressionAttributeToSelect instead of addExpressionFieldToSelect

EDIT

After an other investigation I found that for flat entities you can use directly the column names. The attribute placeholders {{...}} are needed only for EAV entities.  

So your second collection should look like this:

$collection = Mage::getModel('[module]/table2')-&gt;getCollection()
    -&gt;addExpressionFieldToSelect('total', 'SUM(qty + product_id - any_other_columns)', array('qty', 'product_id', 'any_other_columns'));
$collection-&gt;getSelect()-&gt;group('product_id');


The third parameter for addExpressionFieldToSelect is required but it can be an empty array. for addExpressionAttributeToSelect that last parameter should contain the mapping between the placeholders and the attribute codes. In this case seams that they are useless. I don't know if this is a bug or a feature.
",Marius,https://magento.stackexchange.com/users/146,http://magento.stackexchange.com/questions/28951/magento-aggregate-and-between-collections,TECHNOLOGY,magento.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Magento between sets?,"1) How to write the below SQL query in Magneto collection :

SELECT * FROM 'table1' WHERE active=0 AND '2014-07-08' between 'not_available_from_date' and 'not_available_to_date'


2) Also how to write this SQL query in Magneto Collection :

Select sum(qty + product_id - any_other_columns) as total from table2  GROUP BY product_id; 


Without using ->columns('  ') function.

Thanks for your help
","Assuming you have a model mapped to your table1 and one mapped to table2 you can try something like this.

$date = '2014-07-08';
$collection = Mage::getModel('[module]/table1')-&gt;getCollection()
    -&gt;addFieldToFilter('active', 0)
    -&gt;addFieldToFilter('not_available_from_date', array('date' =&gt; true, 'to' =&gt; $date))
    -&gt;addFieldToFilter('not_available_to_date', array('date' =&gt; true, 'from' =&gt; $date));


And for the second one.

$collection = Mage::getModel('[module]/table2')-&gt;getCollection()
    -&gt;addExpressionFieldToSelect('total', 'SUM({{qty}} + {{product_id}} - {{any_other_columns}})', array('{{qty}}'=&gt;'qty', '{{product_id}}'=&gt;'product_id', '{{any_other_columns}}'=&gt;'any_other_columns'));
//since SUM requires a GROUP BY...group by some column
$collection-&gt;getSelect()-&gt;group('product_id');


The examples above are for flat entities. 

If you have an EAV entity similar to products or categories use 

addAttributeToFilter instead of addFieldToFilter 

addExpressionAttributeToSelect instead of addExpressionFieldToSelect

EDIT

After an other investigation I found that for flat entities you can use directly the column names. The attribute placeholders {{...}} are needed only for EAV entities.  

So your second collection should look like this:

$collection = Mage::getModel('[module]/table2')-&gt;getCollection()
    -&gt;addExpressionFieldToSelect('total', 'SUM(qty + product_id - any_other_columns)', array('qty', 'product_id', 'any_other_columns'));
$collection-&gt;getSelect()-&gt;group('product_id');


The third parameter for addExpressionFieldToSelect is required but it can be an empty array. for addExpressionAttributeToSelect that last parameter should contain the mapping between the placeholders and the attribute codes. In this case seams that they are useless. I don't know if this is a bug or a feature.
"
1574,1574,2475,Detecting changes to the clipboard on Android,"Is it possible to detect when an Android user uses the copy and/or cut functionality?

I have a client who's idea pretty much depends on being able to call a method inside the app whenever a user copies or cuts out a piece of text or an image, no matter whether the user is actually inside the app or not (though the app would be running in the background).

My initial guess would be no, but you never know. I haven't been able to find any clear information about it, so thought I should ask.
",Tom,https://stackoverflow.com/users/1072272,"
  Is it possible to detect when an Android user uses the copy and/or cut functionality?


Not exactly. You can listen for changes in the clipboard using ClipboardManager. However:


Changes in the clipboard do not always imply ""copy and/or cut"" operations
You can only listen for such changes while your process is running

",CommonsWare,https://stackoverflow.com/users/115145,http://stackoverflow.com/questions/25608887/detecting-changes-to-the-clipboard-on-android,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,Detect clipboard changes on Android,"Is it possible to detect when an Android user uses the copy and/or cut functionality?

I have a client who's idea pretty much depends on being able to call a method inside the app whenever a user copies or cuts out a piece of text or an image, no matter whether the user is actually inside the app or not (though the app would be running in the background).

My initial guess would be no, but you never know. I haven't been able to find any clear information about it, so thought I should ask.
","
  Is it possible to detect when an Android user uses the copy and/or cut functionality?


Not exactly. You can listen for changes in the clipboard using ClipboardManager. However:


Changes in the clipboard do not always imply ""copy and/or cut"" operations
You can only listen for such changes while your process is running

"
802,802,1271,Setfacl configuration issue in Linux,"I am configuring a Linux Server with ACL[Access Control Lists]. It is not allowing me to perform setfacl operation on one of the directoriy /xfiles. I am able to perform the setfacl on other directories as /tmp /op/applocal/.

I am getting the error as :

root@asifdl01devv # setfacl -m   user:eqtrd:rw-,user:feedmgr:r--,user::---,group::r--,mask:rw-,other:--- /xfiles/change1/testfile
setfacl: /xfiles/change1/testfile: Operation not supported


I have defined my /etc/fstab as 

/dev/ROOTVG/rootlv      /                       ext3    defaults        1 1
/dev/ROOTVG/varlv       /var                    ext3    defaults        1 2
/dev/ROOTVG/optlv       /opt                    ext3    defaults        1 2
/dev/ROOTVG/crashlv     /var/crash              ext3    defaults        1 2
/dev/ROOTVG/tmplv       /tmp                    ext3    defaults        1 2
LABEL=/boot             /boot                   ext3    defaults        1 2
tmpfs                   /dev/shm                tmpfs   defaults        0 0
devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
sysfs                   /sys                    sysfs   defaults        0 0
proc                    /proc                   proc    defaults        0 0
/dev/ROOTVG/swaplv      swap                    swap    defaults        0 0
/dev/APPVG/home      /home            ext3    defaults        1 2
/dev/APPVG/archives      /archives            ext3    defaults        1 2
/dev/APPVG/test      /test            ext3    defaults        1 2
/dev/APPVG/oracle      /opt/oracle            ext3    defaults        1 2
/dev/APPVG/ifeeds      /xfiles            ext3    defaults        1 2


I have a solaris server where the vfstab is defined as 

cat vfstab

#device         device          mount           FS      fsck    mount   mount
#to mount       to fsck         point           type    pass    at boot options
#
fd      -       /dev/fd fd      -       no      -
/proc   -       /proc   proc    -       no      -
/dev/vx/dsk/bootdg/swapvol      -       -       swap    -       no      -
swap    -       /tmp    tmpfs   -       yes     size=1024m
/dev/vx/dsk/bootdg/rootvol      /dev/vx/rdsk/bootdg/rootvol     /       ufs     1       no      logging
/dev/vx/dsk/bootdg/var  /dev/vx/rdsk/bootdg/var /var    ufs     1       no      logging
/dev/vx/dsk/bootdg/home /dev/vx/rdsk/bootdg/home        /home   ufs     2       yes     logging
/dev/vx/dsk/APP/test        /dev/vx/rdsk/APP/test       /test     vxfs   3       yes     -
/dev/vx/dsk/APP/archives        /dev/vx/rdsk/APP/archives       /archives     vxfs   3       yes     -
/dev/vx/dsk/APP/oracle        /dev/vx/rdsk/APP/oracle       /opt/oracle     vxfs   3       yes     -
/dev/vx/dsk/APP/xfiles    /dev/vx/rdsk/APP/xfiles   /xfiles vxfs   3       yes     -


I am not able to find out the issue. Any help would be appreciated.
",Balualways,https://serverfault.com/users/110895,"You need to enable acls on the mount point. Either remount with the acl option or reboot with the acl option in the fstab.

You need to first check if your kernel supports the acl option - otherwise, the mount may fail.

To check if acl was compiled into the kernel

cat /boot/config-`uname -r` | grep _ACL


The 'expected' output should be something like this ..

CONFIG_EXT2_FS_POSIX_ACL=y
CONFIG_EXT3_FS_POSIX_ACL=y
CONFIG_EXT4_FS_POSIX_ACL=y
CONFIG_FS_POSIX_ACL=y
CONFIG_XFS_POSIX_ACL=y
CONFIG_NFS_V3_ACL=y
CONFIG_NFSD_V3_ACL=y
CONFIG_NFS_ACL_SUPPORT=m


To remount without reboot

mount -o remount,acl /xfiles


To mount with acl with a reboot/persistent

/dev/APPVG/ifeeds      /xfiles            ext3    defaults,acl        1 2

",Ben Lessani - Sonassi,https://serverfault.com/users/113375,http://serverfault.com/questions/429889,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,The problem of setfacel configuration in Linux,"I am configuring a Linux Server with ACL[Access Control Lists]. It is not allowing me to perform setfacl operation on one of the directoriy /xfiles. I am able to perform the setfacl on other directories as /tmp /op/applocal/.

I am getting the error as :

root@asifdl01devv # setfacl -m   user:eqtrd:rw-,user:feedmgr:r--,user::---,group::r--,mask:rw-,other:--- /xfiles/change1/testfile
setfacl: /xfiles/change1/testfile: Operation not supported


I have defined my /etc/fstab as 

/dev/ROOTVG/rootlv      /                       ext3    defaults        1 1
/dev/ROOTVG/varlv       /var                    ext3    defaults        1 2
/dev/ROOTVG/optlv       /opt                    ext3    defaults        1 2
/dev/ROOTVG/crashlv     /var/crash              ext3    defaults        1 2
/dev/ROOTVG/tmplv       /tmp                    ext3    defaults        1 2
LABEL=/boot             /boot                   ext3    defaults        1 2
tmpfs                   /dev/shm                tmpfs   defaults        0 0
devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
sysfs                   /sys                    sysfs   defaults        0 0
proc                    /proc                   proc    defaults        0 0
/dev/ROOTVG/swaplv      swap                    swap    defaults        0 0
/dev/APPVG/home      /home            ext3    defaults        1 2
/dev/APPVG/archives      /archives            ext3    defaults        1 2
/dev/APPVG/test      /test            ext3    defaults        1 2
/dev/APPVG/oracle      /opt/oracle            ext3    defaults        1 2
/dev/APPVG/ifeeds      /xfiles            ext3    defaults        1 2


I have a solaris server where the vfstab is defined as 

cat vfstab

#device         device          mount           FS      fsck    mount   mount
#to mount       to fsck         point           type    pass    at boot options
#
fd      -       /dev/fd fd      -       no      -
/proc   -       /proc   proc    -       no      -
/dev/vx/dsk/bootdg/swapvol      -       -       swap    -       no      -
swap    -       /tmp    tmpfs   -       yes     size=1024m
/dev/vx/dsk/bootdg/rootvol      /dev/vx/rdsk/bootdg/rootvol     /       ufs     1       no      logging
/dev/vx/dsk/bootdg/var  /dev/vx/rdsk/bootdg/var /var    ufs     1       no      logging
/dev/vx/dsk/bootdg/home /dev/vx/rdsk/bootdg/home        /home   ufs     2       yes     logging
/dev/vx/dsk/APP/test        /dev/vx/rdsk/APP/test       /test     vxfs   3       yes     -
/dev/vx/dsk/APP/archives        /dev/vx/rdsk/APP/archives       /archives     vxfs   3       yes     -
/dev/vx/dsk/APP/oracle        /dev/vx/rdsk/APP/oracle       /opt/oracle     vxfs   3       yes     -
/dev/vx/dsk/APP/xfiles    /dev/vx/rdsk/APP/xfiles   /xfiles vxfs   3       yes     -


I am not able to find out the issue. Any help would be appreciated.
","You need to enable acls on the mount point. Either remount with the acl option or reboot with the acl option in the fstab.

You need to first check if your kernel supports the acl option - otherwise, the mount may fail.

To check if acl was compiled into the kernel

cat /boot/config-`uname -r` | grep _ACL


The 'expected' output should be something like this ..

CONFIG_EXT2_FS_POSIX_ACL=y
CONFIG_EXT3_FS_POSIX_ACL=y
CONFIG_EXT4_FS_POSIX_ACL=y
CONFIG_FS_POSIX_ACL=y
CONFIG_XFS_POSIX_ACL=y
CONFIG_NFS_V3_ACL=y
CONFIG_NFSD_V3_ACL=y
CONFIG_NFS_ACL_SUPPORT=m


To remount without reboot

mount -o remount,acl /xfiles


To mount with acl with a reboot/persistent

/dev/APPVG/ifeeds      /xfiles            ext3    defaults,acl        1 2

"
1294,1294,2039,Failed to allocate memory - What is it trying to say?,"In my early days of programming I often used to get memory related fatal errors in the following format:

Fatal error: Allowed memory size of &lt;some big number&gt; bytes exhausted 
(tried to allocate &lt;some small number&gt; bytes) in /path/to/filename.php 
on line &lt;some line number&gt;


I'm a little embarrassed to state that even though I have figured out how to solve them and take steps to avoid them altogether, I'm still not quite sure what exactly does the message translate to in simple words.

For example, if I get a message such as:

Fatal error: Allowed memory size of 67108864 bytes exhausted (tried to allocate 4000 bytes) 
in ........ on line 34


As things stand at the moment, I assume it to be stating that the script consumes 67108864 bytes of data, but only 4000 bytes are available during runtime.


Am I right in my assumption?
If not, what's the correct interpretation?

",asprin,https://programmers.stackexchange.com/users/136389,"67108864 bytes are also known as 64 MiB (Mebibyte).
Many softwares like PHP still identifies 64 MB as 64 MiB, this is an historically grown issue.

Nowaday we define 64 000 000 bytes as 64 MB (Megabyte, 64 * 1000 ^ 2)
and 67108864 bytes as 64 MiB (Mebibyte, 64 * 1024 ^ 2).
",Just help,https://programmers.stackexchange.com/users/136395,http://programmers.stackexchange.com/questions/244758/failed-to-allocate-memory-what-is-it-trying-to-say,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.0,0.0,0.6666666666666666,0.7777777777777778,Failed to allocate memory - what does it want to say?,"In my early days of programming I often used to get memory related fatal errors in the following format:

Fatal error: Allowed memory size of &lt;some big number&gt; bytes exhausted 
(tried to allocate &lt;some small number&gt; bytes) in /path/to/filename.php 
on line &lt;some line number&gt;


I'm a little embarrassed to state that even though I have figured out how to solve them and take steps to avoid them altogether, I'm still not quite sure what exactly does the message translate to in simple words.

For example, if I get a message such as:

Fatal error: Allowed memory size of 67108864 bytes exhausted (tried to allocate 4000 bytes) 
in ........ on line 34


As things stand at the moment, I assume it to be stating that the script consumes 67108864 bytes of data, but only 4000 bytes are available during runtime.


Am I right in my assumption?
If not, what's the correct interpretation?

","67108864 bytes are also known as 64 MiB (Mebibyte).
Many softwares like PHP still identifies 64 MB as 64 MiB, this is an historically grown issue.

Nowaday we define 64 000 000 bytes as 64 MB (Megabyte, 64 * 1000 ^ 2)
and 67108864 bytes as 64 MiB (Mebibyte, 64 * 1024 ^ 2).
"
350,350,556,Best way to migrate text field to taxonomy reference field,"I want to migrate a text field to taxonomy reference field( the Tags one).

I've 1200 nodes having a field ""Organization name"". Those creating the content are making mistakes like misspelled company names. I'm using the company name in the views to find all related nodes.

This will help those entering can simply choose the company names or if someone has entered IBM for International Business Machines then I can merge those terms when using taxonomy reference field.

Should I go and create a vocabulary, add all existing values as terms in vocabulary then programmatically assign the text field values to the taxonomy reference field? Then delete the text field and change references in the views etc.
",AgA,https://drupal.stackexchange.com/users/2113,"Using the example/suggestion @Molot posted, I created a batch process and packaged it as a module. Thought I would share.

First, create your taxonomy terms and add your entity reference field to your content type, then create and enable your batch module. Be sure to update the **FIELDS** below.

/**
 * Implements hook_menu().
 */

// Lets add a menu link to initiate the batch process
function convert_field_to_taxonomy_menu() {
    $items = array();
    $items['admin/batch'] = array(
        'title' =&gt; 'Convert to Tax Batch',
        'description' =&gt; 'Run batch operations.',
        'page callback' =&gt; 'drupal_get_form',
        'page arguments' =&gt; array('convert_field_to_taxonomy_form'),
        'access arguments' =&gt; array('administer site configuration'),
        'type' =&gt; MENU_NORMAL_ITEM,
    );
    return $items;
}
// And a button to click
function convert_field_to_taxonomy_form() {
    $form = array();
    $form['submit'] = array('#type' =&gt; 'submit', '#value' =&gt; t('Click here to Start'));
    return $form;
}

function convert_field_to_taxonomy_form_submit($form, $form_state) {
    batch_set(convert_field_to_taxonomy_setup_batch());
}

function convert_field_to_taxonomy_setup_batch() {
    drupal_set_message('Updating Nodes');
    // load all the nodes from content type
    $nodes = node_load_multiple(array(), array('type' =&gt; ""**CONTENT_TYPE**""));
    $node_count = count($nodes);

    // build the list of operation functions and function arguments
    foreach($nodes as $nid =&gt; $node) {
        // $operations[] = array(&lt;function name&gt;, &lt;array of arguments to pass to function&gt;);
        $operations[] = array('convert_field_to_taxonomy_method', array($node));
    }

    //put all that information into our batch array
    $batch = array(
        'operations' =&gt; $operations,
        'title' =&gt; t('Convert to Tax Batch'),
        'init_message' =&gt; t('Initializing...'),
        'error_message' =&gt; t('An error occurred'),
        'progress_message' =&gt; t('Operation @current out of @total.'),
        'finished' =&gt; 'convert_field_to_taxonomy_finished_method'
    );
    return $batch;
}

function convert_field_to_taxonomy_method($node, &amp;$context) {
    $context['results'][] = $node-&gt;nid.
    ' : '.check_plain($node-&gt;title);
    // Optional message displayed under the progressbar.
    $context['message'] = t('Processing snapshot ""@title""', array('@title' =&gt; $node-&gt;title));

    $vid = 38; // vocab ID
    $edit = array('vid' =&gt; $vid, 'name' =&gt; $node-&gt;**SOURCE_FIELD**['und'][0]['value']);
    $terms = taxonomy_get_term_by_name($edit['name']);
    if (!empty($terms)) {
        // term already exists
        $first_item = array_shift($terms);
        $tid = $first_item-&gt;tid;
    } else {
        // add term and get the tid
        $status = taxonomy_term_save($edit);
        $tid = $edit['tid'];
    }

    $node-&gt;**TARGET_FIELD**['und'][0]['target_id'] = $tid;
    node_save($node);
    $path = drupal_lookup_path(""alias"", ""node/"".$node-&gt;nid);
    drupal_set_message(""&lt;a href='/$path'&gt;"".$node-&gt;title.
        ""&lt;/a&gt; updated."");
}

function convert_field_to_taxonomy_finished_method($success, $results, $operations) {
    if ($success) {
        // Here we could do something meaningful with the results.
        // We just display the number of data we processed...
        drupal_set_message(t('@count terms processed.', array('@count' =&gt; count($results))));
    } else {
        // An error occurred.
        // $operations contains the operations that remained unprocessed.
        $error_operation = reset($operations);
        drupal_set_message(t('An error occurred while processing @operation with arguments : @args', array('@operation' =&gt; $error_operation[0], '@args' =&gt; print_r($error_operation[0], TRUE))));
    }
}

",knice,https://drupal.stackexchange.com/users/28755,http://drupal.stackexchange.com/questions/76784/best-way-to-migrate-text-field-to-taxonomy-reference-field,TECHNOLOGY,drupal.stackexchange.com,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.5,0.6666666666666666,0.5,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.8333333333333334,1.0,0.6,0.6666666666666666,0.3333333333333333,0.0,1.0,The best way to migrate text fields to classified reference fields,"I want to migrate a text field to taxonomy reference field( the Tags one).

I've 1200 nodes having a field ""Organization name"". Those creating the content are making mistakes like misspelled company names. I'm using the company name in the views to find all related nodes.

This will help those entering can simply choose the company names or if someone has entered IBM for International Business Machines then I can merge those terms when using taxonomy reference field.

Should I go and create a vocabulary, add all existing values as terms in vocabulary then programmatically assign the text field values to the taxonomy reference field? Then delete the text field and change references in the views etc.
","Using the example/suggestion @Molot posted, I created a batch process and packaged it as a module. Thought I would share.

First, create your taxonomy terms and add your entity reference field to your content type, then create and enable your batch module. Be sure to update the **FIELDS** below.

/**
 * Implements hook_menu().
 */

// Lets add a menu link to initiate the batch process
function convert_field_to_taxonomy_menu() {
    $items = array();
    $items['admin/batch'] = array(
        'title' =&gt; 'Convert to Tax Batch',
        'description' =&gt; 'Run batch operations.',
        'page callback' =&gt; 'drupal_get_form',
        'page arguments' =&gt; array('convert_field_to_taxonomy_form'),
        'access arguments' =&gt; array('administer site configuration'),
        'type' =&gt; MENU_NORMAL_ITEM,
    );
    return $items;
}
// And a button to click
function convert_field_to_taxonomy_form() {
    $form = array();
    $form['submit'] = array('#type' =&gt; 'submit', '#value' =&gt; t('Click here to Start'));
    return $form;
}

function convert_field_to_taxonomy_form_submit($form, $form_state) {
    batch_set(convert_field_to_taxonomy_setup_batch());
}

function convert_field_to_taxonomy_setup_batch() {
    drupal_set_message('Updating Nodes');
    // load all the nodes from content type
    $nodes = node_load_multiple(array(), array('type' =&gt; ""**CONTENT_TYPE**""));
    $node_count = count($nodes);

    // build the list of operation functions and function arguments
    foreach($nodes as $nid =&gt; $node) {
        // $operations[] = array(&lt;function name&gt;, &lt;array of arguments to pass to function&gt;);
        $operations[] = array('convert_field_to_taxonomy_method', array($node));
    }

    //put all that information into our batch array
    $batch = array(
        'operations' =&gt; $operations,
        'title' =&gt; t('Convert to Tax Batch'),
        'init_message' =&gt; t('Initializing...'),
        'error_message' =&gt; t('An error occurred'),
        'progress_message' =&gt; t('Operation @current out of @total.'),
        'finished' =&gt; 'convert_field_to_taxonomy_finished_method'
    );
    return $batch;
}

function convert_field_to_taxonomy_method($node, &amp;$context) {
    $context['results'][] = $node-&gt;nid.
    ' : '.check_plain($node-&gt;title);
    // Optional message displayed under the progressbar.
    $context['message'] = t('Processing snapshot ""@title""', array('@title' =&gt; $node-&gt;title));

    $vid = 38; // vocab ID
    $edit = array('vid' =&gt; $vid, 'name' =&gt; $node-&gt;**SOURCE_FIELD**['und'][0]['value']);
    $terms = taxonomy_get_term_by_name($edit['name']);
    if (!empty($terms)) {
        // term already exists
        $first_item = array_shift($terms);
        $tid = $first_item-&gt;tid;
    } else {
        // add term and get the tid
        $status = taxonomy_term_save($edit);
        $tid = $edit['tid'];
    }

    $node-&gt;**TARGET_FIELD**['und'][0]['target_id'] = $tid;
    node_save($node);
    $path = drupal_lookup_path(""alias"", ""node/"".$node-&gt;nid);
    drupal_set_message(""&lt;a href='/$path'&gt;"".$node-&gt;title.
        ""&lt;/a&gt; updated."");
}

function convert_field_to_taxonomy_finished_method($success, $results, $operations) {
    if ($success) {
        // Here we could do something meaningful with the results.
        // We just display the number of data we processed...
        drupal_set_message(t('@count terms processed.', array('@count' =&gt; count($results))));
    } else {
        // An error occurred.
        // $operations contains the operations that remained unprocessed.
        $error_operation = reset($operations);
        drupal_set_message(t('An error occurred while processing @operation with arguments : @args', array('@operation' =&gt; $error_operation[0], '@args' =&gt; print_r($error_operation[0], TRUE))));
    }
}

"
3073,3073,4892,Why does this sequence converges to $\pi$?,"One of my daughters was having a small programming exercise. 

Let's consider following algorithm:


Take a list of length $n$: $\ (1\,\ 2\,\ \ldots\,\ n)$.
Remove every $2$nd number.
From the resulting list, remove every $3$rd number.
From the resulting list, remove every $4$th number.
... Follow on until the list remains unchanged and let $u_n$ be the number of remaining elements.


Example with $n=11$


$(\ 1\,\ 2\,\ 3\,\ 4\,\ 5\,\ 6\,\ 7\,\ 8\,\ 9\,\ 10\,\ 11\ )\quad \Rightarrow\quad (\ 1\ *\ 3\ *\ 5\ *\ 7\ *\ 9 \ *\ 11\ )$
$(\ 1\,\ 3\,\ 5\,\ 7\,\ 9\,\ 11\ )\quad \Rightarrow\quad (\ 1\,\ 3\ *\ 7\,\ 9\ *\ )$
$(\ 1\, 3\,\ 7\,\ 9\ )\quad \Rightarrow\quad (\ 1\,\ 3\,\ 7\ *\ )$
$(\ 1\,\ 3\,\ 7\ )\ $ -- will not be modified anymore, and therefore $u_n=3$.


QUESTION: &nbsp; why do we have $\lim\limits_{n \to +\infty} \frac{n}{u_n^2}=\frac{\pi}{4}$ ?

Thanks!
",mathcounterexamples.net,https://mathoverflow.net/users/41060,"This is an extended comment: Interestingly enough, displaying the differences of consecutive terms of A000960 shows an amazing degree of fluctuation.
",Wolfgang,https://mathoverflow.net/users/29783,http://mathoverflow.net/questions/193933,SCIENCE,mathoverflow.net,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.5333333333333333,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,Why does this sequence converge to $\ PI $?,"One of my daughters was having a small programming exercise. 

Let's consider following algorithm:


Take a list of length $n$: $\ (1\,\ 2\,\ \ldots\,\ n)$.
Remove every $2$nd number.
From the resulting list, remove every $3$rd number.
From the resulting list, remove every $4$th number.
... Follow on until the list remains unchanged and let $u_n$ be the number of remaining elements.


Example with $n=11$


$(\ 1\,\ 2\,\ 3\,\ 4\,\ 5\,\ 6\,\ 7\,\ 8\,\ 9\,\ 10\,\ 11\ )\quad \Rightarrow\quad (\ 1\ *\ 3\ *\ 5\ *\ 7\ *\ 9 \ *\ 11\ )$
$(\ 1\,\ 3\,\ 5\,\ 7\,\ 9\,\ 11\ )\quad \Rightarrow\quad (\ 1\,\ 3\ *\ 7\,\ 9\ *\ )$
$(\ 1\, 3\,\ 7\,\ 9\ )\quad \Rightarrow\quad (\ 1\,\ 3\,\ 7\ *\ )$
$(\ 1\,\ 3\,\ 7\ )\ $ -- will not be modified anymore, and therefore $u_n=3$.


QUESTION: &nbsp; why do we have $\lim\limits_{n \to +\infty} \frac{n}{u_n^2}=\frac{\pi}{4}$ ?

Thanks!
","This is an extended comment: Interestingly enough, displaying the differences of consecutive terms of A000960 shows an amazing degree of fluctuation.
"
3904,3904,6221,Using deep learning for time series prediction,"I'm new in area of deep learning and for me first step was to read interesting articles from deeplearning.net site. In papers about deep learning, Hinton and others mostly talk about applying it to image problems. Can someone try to answer me can it be applied to problem of predicting time series values (financial, internet traffic,...) and what are important things that I should focus if it is possible?
",Vedran,https://stats.stackexchange.com/users/29672,"There has been some work on adapting deep learning methods for sequential data. A lot of this work has focused on developing ""modules"" which can be stacked in a way analogous to stacking restricted boltzmann machines (RBMs) or autoencoders to form a deep neural network. I'll highlight a few below:


Conditional RBMs: Probably one of the most successful applications of deep learning for time series. Taylor develops a RBM like model that adds temporal interactions between visible units and apply it to modeling motion capture data. Essentially you end up with something like a linear dynamical system with some non-linearity added by the hidden units.
Temporal RBMs: In his thesis (section 3) Ilya Sutskever develops several RBM like models with temporal interactions between units. He also presents some interesting results showing training recurrent neural networks with SGD can perform as well or better than more complex methods, like Martens' Hessian-free algorithm, using good initialization and a slightly modified equation for momentum.
Recursive Autoencoders: Lastly I'll mention the work of Richard Socher on using recursive autoencoders for parsing. Although this isn't time series, it is definitely related.

",alto,https://stats.stackexchange.com/users/6248,http://stats.stackexchange.com/questions/68662/using-deep-learning-for-time-series-prediction,SCIENCE,stats.stackexchange.com,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5,0.3333333333333333,1.0,0.6666666666666666,0.5,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,Time series prediction using deep learning,"I am a novice in the field of deep learning. For me, the first step is to read interesting articles from the deep learning.net website. In the paper on deep learning, Hinton and others mainly discuss how to apply it to image problems. Can someone try to answer this question? It can be used to predict time series values (finance, network traffic,...) Is that a problem? If possible, what important things should I focus on?","There has been some work on adapting deep learning methods for sequential data. A lot of this work has focused on developing ""modules"" which can be stacked in a way analogous to stacking restricted boltzmann machines (RBMs) or autoencoders to form a deep neural network. I'll highlight a few below:


Conditional RBMs: Probably one of the most successful applications of deep learning for time series. Taylor develops a RBM like model that adds temporal interactions between visible units and apply it to modeling motion capture data. Essentially you end up with something like a linear dynamical system with some non-linearity added by the hidden units.
Temporal RBMs: In his thesis (section 3) Ilya Sutskever develops several RBM like models with temporal interactions between units. He also presents some interesting results showing training recurrent neural networks with SGD can perform as well or better than more complex methods, like Martens' Hessian-free algorithm, using good initialization and a slightly modified equation for momentum.
Recursive Autoencoders: Lastly I'll mention the work of Richard Socher on using recursive autoencoders for parsing. Although this isn't time series, it is definitely related.

"
4228,4228,6742,Tuples in LaTeX,"I am learning to use TikZ to draw things in LaTeX. One of the things that TikZ seems to use everywhere for specifying coordinates is a tuple.  For example,

\begin{tikzpicture}
  \node[isosceles triangle, isosceles triangle apex angle=70,
     draw=black,fill=white, inner sep=0pt,anchor=lower 
     side,rotate=90,draw=black,
     fill=white, minimum height=2 cm] (a) at (0,0) {};
\end{tikzpicture}


Creates a small isosceles triangle.  Note the use of (0,0).  Let's encapsulate making a triangle as above with the following macro.

\newcommand\Tri[3]{ 
  \node[isosceles triangle, isosceles triangle apex angle=70,
     draw=black,fill=white, inner sep=0pt,anchor=lower 
     side,rotate=90,draw=black,
     fill=white, minimum height={#2} cm] (#1) at #3 {};}


Suppose I wanted to define a function that takes in a size and starting coordinate, and draws a ""triangle"" of triangles such as

\begin{tikzpicture}
  \Tri{a}{1}{(-1,0)}
  \Tri{b}{1}{(1,0)}
  \Tri{c}{1}{(0,1.41)}
\end{tikzpicture}


The simple way to do this is to make a macro \TriTri, such that \TriTri{a}{n}{x}{y} creates a triangle of triangles, with bottom triangle anchored at (x,y).

\newcommand\TriTri[4]{ 
  \Tri{#1}{#2}{(#3,#4)}
  \Tri{#1}{#2}{(#3+2*#2,#4)}
  \Tri{#1}{#2}{(#3+#2,{sqrt(2*#2*#2)})}} %% note #3+#2 = (x1 + x2)/2 
                                         %% the sqrt bit is sqrt(size^2 + size^2)
}


I have gotten this to work! But what I would like to do is instead of having x and y input separately, I would like to have them input as a coordinate pair. I would like to reference the coordinates as \first,\second.  So that \first(x,y) = x. The desired effect is that

$$\first(1,2)$$


would be the same as

$$1$$

",Jonathan Gallagher,https://tex.stackexchange.com/users/16108,"You can use the xparse package:

\documentclass{article}
\usepackage{tikz,xparse}
\usetikzlibrary{shapes.geometric}

\NewDocumentCommand{\Tri}{m m r()}
 {%
  \node[isosceles triangle, isosceles triangle apex angle=70,
     draw=black,fill=white, inner sep=0pt,anchor=lower
     side,rotate=90,draw=black,
     fill=white, minimum height=#2cm] (#1) at (#3) {};
 }

\NewDocumentCommand\TriTri{mmr(,u)}
 {%
  \Tri{#1}{#2}(#3,#4)
  \Tri{#1}{#2}(#3+2*#2,#4)
  \Tri{#1}{#2}(#3+#2,{sqrt(2*#2*#2)}) %% note #3+#2 = (x1 + x2)/2
                                      %% the sqrt bit is sqrt(size^2 + size^2)
 }

\begin{document}

\begin{tikzpicture}
\TriTri{a}{3}(2,2)
\end{tikzpicture}

\end{document}


The \Tri command accepts three arguments; the first and the second ones are enclosed in braces, while the third is between parentheses, so

\Tri{a}{3}(0,0)


In the body of the definition you'll use (#3) instead of #3, because the parentheses are stripped off.

In the case of \TriTri we have to split off the two coordinates, so we define four arguments; the first and the second ones are enclosed in braces; the third is what goes from ( to a comma, the final one is everything up to ).

Thus I have modified accordingly your code for \TriTri based on the requirements for \Tri.
",egreg,https://tex.stackexchange.com/users/4427,http://tex.stackexchange.com/questions/133987/tuples-in-latex,TECHNOLOGY,tex.stackexchange.com,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,Latex tuple,"I am learning to use TikZ to draw things in LaTeX. One of the things that TikZ seems to use everywhere for specifying coordinates is a tuple.  For example,

\begin{tikzpicture}
  \node[isosceles triangle, isosceles triangle apex angle=70,
     draw=black,fill=white, inner sep=0pt,anchor=lower 
     side,rotate=90,draw=black,
     fill=white, minimum height=2 cm] (a) at (0,0) {};
\end{tikzpicture}


Creates a small isosceles triangle.  Note the use of (0,0).  Let's encapsulate making a triangle as above with the following macro.

\newcommand\Tri[3]{ 
  \node[isosceles triangle, isosceles triangle apex angle=70,
     draw=black,fill=white, inner sep=0pt,anchor=lower 
     side,rotate=90,draw=black,
     fill=white, minimum height={#2} cm] (#1) at #3 {};}


Suppose I wanted to define a function that takes in a size and starting coordinate, and draws a ""triangle"" of triangles such as

\begin{tikzpicture}
  \Tri{a}{1}{(-1,0)}
  \Tri{b}{1}{(1,0)}
  \Tri{c}{1}{(0,1.41)}
\end{tikzpicture}


The simple way to do this is to make a macro \TriTri, such that \TriTri{a}{n}{x}{y} creates a triangle of triangles, with bottom triangle anchored at (x,y).

\newcommand\TriTri[4]{ 
  \Tri{#1}{#2}{(#3,#4)}
  \Tri{#1}{#2}{(#3+2*#2,#4)}
  \Tri{#1}{#2}{(#3+#2,{sqrt(2*#2*#2)})}} %% note #3+#2 = (x1 + x2)/2 
                                         %% the sqrt bit is sqrt(size^2 + size^2)
}


I have gotten this to work! But what I would like to do is instead of having x and y input separately, I would like to have them input as a coordinate pair. I would like to reference the coordinates as \first,\second.  So that \first(x,y) = x. The desired effect is that

$$\first(1,2)$$


would be the same as

$$1$$

","You can use the xparse package:

\documentclass{article}
\usepackage{tikz,xparse}
\usetikzlibrary{shapes.geometric}

\NewDocumentCommand{\Tri}{m m r()}
 {%
  \node[isosceles triangle, isosceles triangle apex angle=70,
     draw=black,fill=white, inner sep=0pt,anchor=lower
     side,rotate=90,draw=black,
     fill=white, minimum height=#2cm] (#1) at (#3) {};
 }

\NewDocumentCommand\TriTri{mmr(,u)}
 {%
  \Tri{#1}{#2}(#3,#4)
  \Tri{#1}{#2}(#3+2*#2,#4)
  \Tri{#1}{#2}(#3+#2,{sqrt(2*#2*#2)}) %% note #3+#2 = (x1 + x2)/2
                                      %% the sqrt bit is sqrt(size^2 + size^2)
 }

\begin{document}

\begin{tikzpicture}
\TriTri{a}{3}(2,2)
\end{tikzpicture}

\end{document}


The \Tri command accepts three arguments; the first and the second ones are enclosed in braces, while the third is between parentheses, so

\Tri{a}{3}(0,0)


In the body of the definition you'll use (#3) instead of #3, because the parentheses are stripped off.

In the case of \TriTri we have to split off the two coordinates, so we define four arguments; the first and the second ones are enclosed in braces; the third is what goes from ( to a comma, the final one is everything up to ).

Thus I have modified accordingly your code for \TriTri based on the requirements for \Tri.
"
275,275,441,does re-encrypting the same value with multiple keys reduce security,"I found myself wondering today, how much security is lost if you take a plaintext - assume that its content, including any metadata is unknown to an attacker, for example it may be random data - and encrypt it with multiple keys (not chained) and give all resulting ciphertexts to an attacker, how much higher is the probability of an attacker discovering the plaintext, vs only having a single ciphertext. 

An example:

Take plaintext $P_1$ and encrypt it with $K_1$, and send the resulting ciphertext $C_1$ to attacker $A_1$.

In addition: take the same plaintext $P_1$ and, and encrypt it with $K_1$, giving $C_1$. Then take $P_1$ and encrypt it with $K_2$ giving $C_2$, then $K_n$ giving $C_n$ and send all $n$ ciphertexts to attacker $A_2$.

How much more likely is attacker $A_2$ to discover the value of $P_1$, than $A_1$?
",Zack Newsham,https://crypto.stackexchange.com/users/13023,"The ""security"" of an encryption scheme is commonly defined through a so called indistinguishability games, i.e. the attacker picks two messages of same length. You pick one of those two at random, encrypt it, and give it to the attacker. 
If the scheme is ""secure"", then the attacker's advantage of guessing which messages was encrypted should not be negligibly bigger than pure guessing, i.e. 1/2. This kind of security notion comes in different flavours like CPA, CCA1, and CCA2.

If a private or public key encryption scheme is secure against CPA, CCA1, or CCA2, then it will also be secure against the same games, where instead of giving two messages, the attacker gives you two message vectors and you encrypted one of them. This is proven with a standard technique called hybrid argument, which basically shows that if you can win a game with vectors of messages, then you can also win it where the attacker only outputs two messages.
Very roughly speaking you create a reduction, where your attacker guesses a position in the vector and inputs the challenge from the two message game. The probability of guessing the ""correct"" position in the vector is non-negligible if your vector is of polynomial length. There are plenty of books (e.g. the one by Katz &amp; Lindell) or online resources that explain this in depth, so I won't reiterate it here.

In short: If something is secure w.r.t. to for instance CPA, then it will also be secure if you obtain encrypted message vectors (or as you state where one message is encrypted under multiple different keys). The success-probability might change, but only by a very small (still negligible) amount, so nobody cares, since it's still secure w.r.t to the notion.
",ZeroKnowledge,https://crypto.stackexchange.com/users/12988,http://crypto.stackexchange.com/questions/15590/does-re-encrypting-the-same-value-with-multiple-keys-reduce-security,TECHNOLOGY,crypto.stackexchange.com,0.8333333333333334,1.0,0.0,1.0,0.5,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.0,0.5,1.0,Whether re encrypting the same value with multiple keys will reduce security,"I found myself wondering today, how much security is lost if you take a plaintext - assume that its content, including any metadata is unknown to an attacker, for example it may be random data - and encrypt it with multiple keys (not chained) and give all resulting ciphertexts to an attacker, how much higher is the probability of an attacker discovering the plaintext, vs only having a single ciphertext. 

An example:

Take plaintext $P_1$ and encrypt it with $K_1$, and send the resulting ciphertext $C_1$ to attacker $A_1$.

In addition: take the same plaintext $P_1$ and, and encrypt it with $K_1$, giving $C_1$. Then take $P_1$ and encrypt it with $K_2$ giving $C_2$, then $K_n$ giving $C_n$ and send all $n$ ciphertexts to attacker $A_2$.

How much more likely is attacker $A_2$ to discover the value of $P_1$, than $A_1$?
","The ""security"" of an encryption scheme is commonly defined through a so called indistinguishability games, i.e. the attacker picks two messages of same length. You pick one of those two at random, encrypt it, and give it to the attacker. 
If the scheme is ""secure"", then the attacker's advantage of guessing which messages was encrypted should not be negligibly bigger than pure guessing, i.e. 1/2. This kind of security notion comes in different flavours like CPA, CCA1, and CCA2.

If a private or public key encryption scheme is secure against CPA, CCA1, or CCA2, then it will also be secure against the same games, where instead of giving two messages, the attacker gives you two message vectors and you encrypted one of them. This is proven with a standard technique called hybrid argument, which basically shows that if you can win a game with vectors of messages, then you can also win it where the attacker only outputs two messages.
Very roughly speaking you create a reduction, where your attacker guesses a position in the vector and inputs the challenge from the two message game. The probability of guessing the ""correct"" position in the vector is non-negligible if your vector is of polynomial length. There are plenty of books (e.g. the one by Katz &amp; Lindell) or online resources that explain this in depth, so I won't reiterate it here.

In short: If something is secure w.r.t. to for instance CPA, then it will also be secure if you obtain encrypted message vectors (or as you state where one message is encrypted under multiple different keys). The success-probability might change, but only by a very small (still negligible) amount, so nobody cares, since it's still secure w.r.t to the notion.
"
3513,3513,5603,How do I prevent unwanted routing errors in production,"ActionController::RoutingError (No route matches [GET] ""/google83362a7a0f381ff0.html""):


I see the above logs in production, how should I prevent it.
If user mistypes a URL, how should I re-direct to a common error page

",Rpj,https://stackoverflow.com/users/1900290,"Rails does this automatically when application running in production mode.When uploading application to live server, Rails takes care of handling those exceptions and rendering the correct error pages with the correct header status.You can directly find the files inside public folder.

Whenever you set up your Rails application on a live server, you give the site root as the /public folder in your application. Then, whenever a request is made to that server address, Web server first looks in that public folder and tries to serve a static asset (this is a configurable option in config/environment.rb). If it can't find the requested page, then the request is forwarded through the Ruby stack.

When in production mode, if Rails encounters an error that isn't handled, it throws the error to the stack, which then tells Web server to render an appropriate error.

Here are some common errors that you'll see in development mode and what they render in production mode:

ActiveRecord::RecordNotFound =&gt; 404 (page not found)
nil.method =&gt; 500 (server error) unless you turn off whiny nils
ActionController::RoutingError =&gt; 404 (page not found)

",Amit,https://stackoverflow.com/users/2573155,http://stackoverflow.com/questions/17678087/how-do-i-prevent-unwanted-routing-errors-in-production,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,0.8888888888888888,How to prevent unnecessary routing errors in production,"ActionController::RoutingError (No route matches [GET] ""/google83362a7a0f381ff0.html""):


I see the above logs in production, how should I prevent it.
If user mistypes a URL, how should I re-direct to a common error page

","Rails does this automatically when application running in production mode.When uploading application to live server, Rails takes care of handling those exceptions and rendering the correct error pages with the correct header status.You can directly find the files inside public folder.

Whenever you set up your Rails application on a live server, you give the site root as the /public folder in your application. Then, whenever a request is made to that server address, Web server first looks in that public folder and tries to serve a static asset (this is a configurable option in config/environment.rb). If it can't find the requested page, then the request is forwarded through the Ruby stack.

When in production mode, if Rails encounters an error that isn't handled, it throws the error to the stack, which then tells Web server to render an appropriate error.

Here are some common errors that you'll see in development mode and what they render in production mode:

ActiveRecord::RecordNotFound =&gt; 404 (page not found)
nil.method =&gt; 500 (server error) unless you turn off whiny nils
ActionController::RoutingError =&gt; 404 (page not found)

"
278,278,447,Which of the items below are worth mentioning in my admission documents?,"I really worried about what should I write in my admission documents, such as resume/CV, statement of purpose, informal email communications with professors. From the list below, please tell me what items have enough academic value to be mentioned in such documents?

Note that its a application in PhD program in computer science for US universities 


Stack Overflow (generally Stack Exchange) reputation and badges
Coursera accomplished courses
Small-scaled programming projects (absolutely with no academic value)
Github programming repositories

",Hi I'm Frogatto,https://academia.stackexchange.com/users/31040,"This list does reflect your technical abilities and not your research-based activities.

Therefore, all things listed here should be packaged and be presented under a section
(e.g., such as 'Related Technical Activities'); to represent your technical abilities to program and contribute (e.g., Github).
",Dave Rose,https://academia.stackexchange.com/users/21552,http://academia.stackexchange.com/questions/40928/which-of-the-items-below-are-worth-mentioning-in-my-admission-documents,LIFE_ARTS,academia.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.8,0.0,0.6666666666666666,0.3333333333333333,0.8888888888888888,Which of the following items are worth mentioning in my admission documents?,"I'm really worried about what I should write in the admission documents, such as resume / resume, goal statement, and informal email communication with the professor. From the list below, please tell me which projects have enough academic value to be mentioned in these documents?","This list does reflect your technical abilities and not your research-based activities.

Therefore, all things listed here should be packaged and be presented under a section
(e.g., such as 'Related Technical Activities'); to represent your technical abilities to program and contribute (e.g., Github).
"
4842,4842,7705,how do i get rust stains off driveway,"I used fertilizer with iron and, unfortunately, didn't sweep adequately afterwards. Afterwards I ran my sprinklers and now my driveway and sidewalk are peppered with unsightly rust stains. What are the best ways to get it off? (By ""best"" I mean easiest and most efficient, while still being safe, inexpensive, and not too harmful to the nearby lawn.) Any suggestions?
",kmote,https://diy.stackexchange.com/users/3671,"OK, well, I just figured this out. I did some web research and saw all sorts of suggestions for stuff like TSP, muratic acid, and CLR (thanks, @mikes). But for the most part they're all bad for your lawn, bad for you skin, and bad for your wallet. Let me save you some money...

All you need is a stiff wire brush and a bucket of water (and the water is optional). You can even use one of those BBQ grill scrubbers (although I recommend a 1"" wire brush). Just a little dab of water and a little elbow grease and the rust is gone! You might think of using a hose, but I wouldn't recommend it because, if you just fertilized your lawn, you run the risk of washing more fertilizer right back onto your cement, and you'll have the same problem all over again when it dries. 

Now, I did this about an hour after I first noticed the stains. Perhaps if the stains had ""set"" for a few weeks it might have been harder -- I don't know. I did hear that another ""solvent"" that works well is vinegar (a natural acid), so if anyone doesn't get results from the above method, you might try it. But I didn't try it, so I don't know.
",kmote,https://diy.stackexchange.com/users/3671,http://diy.stackexchange.com/questions/16054/how-do-i-get-rust-stains-off-my-driveway,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.5,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,How can I get rid of the rust on the driveway,"I used iron fertilizer and unfortunately I didn't clean it up enough afterwards. Later I drove the sprinkler, and now my driveway and sidewalk are covered with ugly rust. What's the best way? (by ""best"" I mean the simplest, most effective, safe, cheap, and not too harmful to the nearby lawn) any suggestions?","OK, well, I just figured this out. I did some web research and saw all sorts of suggestions for stuff like TSP, muratic acid, and CLR (thanks, @mikes). But for the most part they're all bad for your lawn, bad for you skin, and bad for your wallet. Let me save you some money...

All you need is a stiff wire brush and a bucket of water (and the water is optional). You can even use one of those BBQ grill scrubbers (although I recommend a 1"" wire brush). Just a little dab of water and a little elbow grease and the rust is gone! You might think of using a hose, but I wouldn't recommend it because, if you just fertilized your lawn, you run the risk of washing more fertilizer right back onto your cement, and you'll have the same problem all over again when it dries. 

Now, I did this about an hour after I first noticed the stains. Perhaps if the stains had ""set"" for a few weeks it might have been harder -- I don't know. I did hear that another ""solvent"" that works well is vinegar (a natural acid), so if anyone doesn't get results from the above method, you might try it. But I didn't try it, so I don't know.
"
4916,4916,7827,TFT display write noise,"I am using a TFT display with ssd1963 controller built-in and stm32f4 discovery board, and everything is working well except when writing to the display.
There is a significant increase in system noise and it is actually
audible on the codec output and also effecting my ADC readings.

All pins are configured correctly and as I mentioned display is working very well. 
I am driving the display controller from the stm32f4 with 150R resistors because I saw this used in a schematic for a dev board with a TFT. I assumed the resistors were used to terminate the tracks to help with track ringing and impedance, but perhaps they are used to limit current.   

Has anyone else seen problems with TFT displays and data pin noise?   

Would putting an array of transistor buffers between the micro and display help as long as the buffers where given it's own regulator to keep noise out of the main power supply?

With these kinds of projects making changes like this are not trivial so looking for possible suggestions before busting out the soldering iron
",Bruce Duncan,https://electronics.stackexchange.com/users/11000,"This is a difficult problem. Normally when you run a wide cable full of single ended signals with 1nS rise time, you can expect high supply/ground currents and high radiated noise. I am not surprised you can hear the video content on your audio.

Every EMC Engineer ought to have a book by Mr Henry Ott in their bookshelf. OK I don't, but I remember what he wrote back in the early 80's and it has served me well.

Let me recall some relevant topics.

Conducted Noise


Isolating Analog and Digital ground currents
Low ESR caps
multi-point grounds


Radiated Noise


Common-mode ferrite filters ( lossy noise absorption )
Shielding, shield termination and shield transfer impedance 
ground planes
optimal driving impedance
controlled impedance cable and terminators
interleaved grounds or twisted pair
standing wave effects


I recall the biggest radiation on ST506 device FCC testing was always the interface 50 wire ribbon cable.

If you were to pick the top 2 of each list and implement an appropriate fix, I would hope these will eliminate your problems.  If you use ribbon cable I would find a flat bar ferrite sleeve to absorb the radiating noise and locate it near the transmitting end or a clamshell sleeve just like on all VGA cables. The ferrite beads help on differential noise but not CM noise radiation. I think this fix is a must have. Laptops will usually have a flat ferrite layer somewhere over the LCD ribbon cable.

I probably missed a few topics but I don't believe buffers will help your issue unless they are ECL differential.
",Tony Stewart. EE since '75,https://electronics.stackexchange.com/users/17574,http://electronics.stackexchange.com/questions/36315/tft-display-write-noise,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.3333333333333333,1.0,0.8888888888888888,TFT display write noise,"I am using a TFT display with ssd1963 controller built-in and stm32f4 discovery board, and everything is working well except when writing to the display.
There is a significant increase in system noise and it is actually
audible on the codec output and also effecting my ADC readings.

All pins are configured correctly and as I mentioned display is working very well. 
I am driving the display controller from the stm32f4 with 150R resistors because I saw this used in a schematic for a dev board with a TFT. I assumed the resistors were used to terminate the tracks to help with track ringing and impedance, but perhaps they are used to limit current.   

Has anyone else seen problems with TFT displays and data pin noise?   

Would putting an array of transistor buffers between the micro and display help as long as the buffers where given it's own regulator to keep noise out of the main power supply?

With these kinds of projects making changes like this are not trivial so looking for possible suggestions before busting out the soldering iron
","This is a difficult problem. Normally when you run a wide cable full of single ended signals with 1nS rise time, you can expect high supply/ground currents and high radiated noise. I am not surprised you can hear the video content on your audio.

Every EMC Engineer ought to have a book by Mr Henry Ott in their bookshelf. OK I don't, but I remember what he wrote back in the early 80's and it has served me well.

Let me recall some relevant topics.

Conducted Noise


Isolating Analog and Digital ground currents
Low ESR caps
multi-point grounds


Radiated Noise


Common-mode ferrite filters ( lossy noise absorption )
Shielding, shield termination and shield transfer impedance 
ground planes
optimal driving impedance
controlled impedance cable and terminators
interleaved grounds or twisted pair
standing wave effects


I recall the biggest radiation on ST506 device FCC testing was always the interface 50 wire ribbon cable.

If you were to pick the top 2 of each list and implement an appropriate fix, I would hope these will eliminate your problems.  If you use ribbon cable I would find a flat bar ferrite sleeve to absorb the radiating noise and locate it near the transmitting end or a clamshell sleeve just like on all VGA cables. The ferrite beads help on differential noise but not CM noise radiation. I think this fix is a must have. Laptops will usually have a flat ferrite layer somewhere over the LCD ribbon cable.

I probably missed a few topics but I don't believe buffers will help your issue unless they are ECL differential.
"
1296,1296,2041,Mercedes SLK (R170) convertible top/trunk release,"I have a 1999 Mercedes SLK 230 (R170), with an interesting combination of problems:

A)  The hydraulics for the convertible top are low (to the point where the top won't even start to open anymore),

B)  The trunk latch is disconnected internally, so the trunk can't be opened.

If the top were still working, it can be opened partway to access the back of the trunk latch, and operate it manually...  or if the trunk would open, I'd have access to the manual release for the top.  But the combination of these two means I have no way to open either now.

So:  Are there any other tricks I can use in this situation?

One possible idea:  If I tear out the headliner (which I'd probably have to cut away, since the screws are only accessible with the top out), and disconnect the lines coming from the hydraulic pump, would this allow the top to move by hand?  This seems plausible, but I don't want to destroy my headliner on a hunch...  But, the only other idea I have at this point is drilling a hole behind the license plate to get to the latch, so I'm hoping to find another solution.
",Jeremy Nikolai,https://mechanics.stackexchange.com/users/3611,"Where is the hydraulic pump? Can you get at that to top up the fluid? 

Another option might be to try and remove the rear trim panel (i.e. the bits behind the seats), and see if there is a way through the rear bulkhead into the trunk. Many cars have a non-solid bulkhead in order to save weight. You ought to be able to remove the trim without damaging anything.
",Nick C,https://mechanics.stackexchange.com/users/373,http://mechanics.stackexchange.com/questions/6956/mercedes-slk-r170-convertible-top-trunk-release,CULTURE,mechanics.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5,0.8888888888888888,1.0,0.7,0.6666666666666666,0.3333333333333333,0.0,1.0,Mercedes SLK (R170) convertible top / trunk release,"I have a 1999 Mercedes SLK 230 (R170), with an interesting combination of problems:

A)  The hydraulics for the convertible top are low (to the point where the top won't even start to open anymore),

B)  The trunk latch is disconnected internally, so the trunk can't be opened.

If the top were still working, it can be opened partway to access the back of the trunk latch, and operate it manually...  or if the trunk would open, I'd have access to the manual release for the top.  But the combination of these two means I have no way to open either now.

So:  Are there any other tricks I can use in this situation?

One possible idea:  If I tear out the headliner (which I'd probably have to cut away, since the screws are only accessible with the top out), and disconnect the lines coming from the hydraulic pump, would this allow the top to move by hand?  This seems plausible, but I don't want to destroy my headliner on a hunch...  But, the only other idea I have at this point is drilling a hole behind the license plate to get to the latch, so I'm hoping to find another solution.
","Where is the hydraulic pump? Can you get at that to top up the fluid? 

Another option might be to try and remove the rear trim panel (i.e. the bits behind the seats), and see if there is a way through the rear bulkhead into the trunk. Many cars have a non-solid bulkhead in order to save weight. You ought to be able to remove the trim without damaging anything.
"
136,136,216,How suddenly does lactose-intolerance onset?,"How quickly can the loss of lactose tolerance onset in an adult?

Such as being able to process lactose normally to having notice symptoms associated with the inability to process lactose.

I am not asking how long it takes to digest food, but rather how long it takes for lactose intolerance to become noticeable (hours, days, weeks, months, years).
",Chase,https://biology.stackexchange.com/users/4022,"Disclaimer: I am not medically qualified, and this answer must not be construed as being medical advice of any kind.

Primary adult hypolactasia is the most common cause of lactose intolerance. The majority of the world's population have this phenotype. 

In these individuals, at weaning, there is a reduction in the level of the enzyme lactase, which is responsible for digesting lactose to galactose and glucose in the small intestine. Undigested lactose can create symptoms via osmotic effects (causing diarrhoea) and because it is metabolised by bacteria in the colon, producing gas and thus abdominal bloating.

About 35% of adults have a genetic variant in an region upstream of the lactase gene which results in the expression of lactase continuing into adult life. These individuals are lactose tolerant. This trait is most common in Northern Europe.

According to references cited in  


  Ingram, CJE et al. (2009) Lactose digestion and the evolutionary genetics of lactase persistence Hum Genet (2009) 124:579â591 


(I have removed citations from the passage for clarity.)


  ""most lactase non-persistent individuals can tolerate small amounts of lactose (as in tea or coffee), and some can consume a lot without ill effects. Variation in the composition of the gut flora between individuals, as well as a psychosomatic component may account for some of the interindividual variation in symptoms.""


The clear implication is that there is a lot of variation in the tolerance of lactose amongst those lacking the lactase persistence trait. Given the contribution of the gut flora to the symptoms these could presumably vary as a result of, for example, antibiotic treatment. Also I imagine that the effects of undigested lactose could be synergistic with some other gut disturbance.

Added in response to comment from the OP:

In someone with the (common) genotype that corresponds to 'no persistence of lactase' the possibility of showing symptoms will be present from a young age. Apparently there is a lot of variation in the severity of symptoms. If an adult suddenly exhibits symptoms then I am suggesting that this could be due to an interaction of non-persistence with some other gut disturbance - I imagine this could happen quite quickly. Alternatively I suppose that a change in diet could trigger symptoms. 
",Alan Boyd,https://biology.stackexchange.com/users/1320,http://biology.stackexchange.com/questions/14535/how-suddenly-does-lactose-intolerance-onset,SCIENCE,biology.stackexchange.com,1.0,1.0,0.0,0.5,1.0,1.0,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.8888888888888888,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,0.8888888888888888,How sudden is the onset of lactose intolerance?,"How quickly can the loss of lactose tolerance onset in an adult?

Such as being able to process lactose normally to having notice symptoms associated with the inability to process lactose.

I am not asking how long it takes to digest food, but rather how long it takes for lactose intolerance to become noticeable (hours, days, weeks, months, years).
","Disclaimer: I am not medically qualified, and this answer must not be construed as being medical advice of any kind.

Primary adult hypolactasia is the most common cause of lactose intolerance. The majority of the world's population have this phenotype. 

In these individuals, at weaning, there is a reduction in the level of the enzyme lactase, which is responsible for digesting lactose to galactose and glucose in the small intestine. Undigested lactose can create symptoms via osmotic effects (causing diarrhoea) and because it is metabolised by bacteria in the colon, producing gas and thus abdominal bloating.

About 35% of adults have a genetic variant in an region upstream of the lactase gene which results in the expression of lactase continuing into adult life. These individuals are lactose tolerant. This trait is most common in Northern Europe.

According to references cited in  


  Ingram, CJE et al. (2009) Lactose digestion and the evolutionary genetics of lactase persistence Hum Genet (2009) 124:579â591 


(I have removed citations from the passage for clarity.)


  ""most lactase non-persistent individuals can tolerate small amounts of lactose (as in tea or coffee), and some can consume a lot without ill effects. Variation in the composition of the gut flora between individuals, as well as a psychosomatic component may account for some of the interindividual variation in symptoms.""


The clear implication is that there is a lot of variation in the tolerance of lactose amongst those lacking the lactase persistence trait. Given the contribution of the gut flora to the symptoms these could presumably vary as a result of, for example, antibiotic treatment. Also I imagine that the effects of undigested lactose could be synergistic with some other gut disturbance.

Added in response to comment from the OP:

In someone with the (common) genotype that corresponds to 'no persistence of lactase' the possibility of showing symptoms will be present from a young age. Apparently there is a lot of variation in the severity of symptoms. If an adult suddenly exhibits symptoms then I am suggesting that this could be due to an interaction of non-persistence with some other gut disturbance - I imagine this could happen quite quickly. Alternatively I suppose that a change in diet could trigger symptoms. 
"
1887,1887,3002,How can I span wallpapers over two monitors in Mac OS X?,"Is there any way to get a single wide desktop wallpaper to span a dual monitor setup in OS X?
",Todd Hunter,https://superuser.com/users/2508,"Their is a program called Multiscape that would automatically do what Chealion explained by getting your screen dimensions and automatically sizing and splitting the wallpaper. Although the google code page is down. If you want to go on a treasure hunt Multiscape is what you're after.
",John T,https://superuser.com/users/1931,http://superuser.com/questions/6581,TECHNOLOGY,superuser.com,1.0,1.0,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,How to span wallpaper on two displays in Mac OS X?,Is there a way to make a single wide desktop wallpaper across a dual monitor set on OS X?,"Their is a program called Multiscape that would automatically do what Chealion explained by getting your screen dimensions and automatically sizing and splitting the wallpaper. Although the google code page is down. If you want to go on a treasure hunt Multiscape is what you're after.
"
4496,4496,7129,WiFi connection history,"I have a hunch someone is logging on my wifi. I already know how to see who is currently using my wifi, but can I find out who was using my wifi in the past?
",johnooo,https://security.stackexchange.com/users/58806,"There are several ways to view who's on your network, some easier/less technical than others:


The logging feature in your router;
Sometimes you can view currently connected devices. For example in a FritzBox you can see all devices that have a dhcp lease (i.e. which got an IP address) on the ""Home Network"" page.
You could scan the network from your laptop using a tool like Zenmap (or Nmap on the command line).
A bit more advanced, but you can also put your WiFi card in monitor mode and look for devices that communicate with your access point. Wireshark and airmon-ng are the tools I would use, but there may be better options.
If you have shell access to your router, you could use netstat or even tcpdump to view connections and traffic.
You could turn off DHCP on your router and enable it on your laptop, so that you can easily see who is trying to get a lease.
Using Wireshark you can see broadcasts on the network. Almost every device broadcasts something from time to time so if your access point works as a switch (i.e. if wireless clients can reach each other on layer 2 (ethernet)) you can pretty easily enumerate all active MAC addresses.

",Luc,https://security.stackexchange.com/users/10863,http://security.stackexchange.com/questions/70878/wifi-connection-history,TECHNOLOGY,security.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,1.0,WiFi connection history,"I have a hunch that someone is logging in to my WiFi. I already know how to see who is using my WiFi, but can I find out who is using my WiFi in the past?","There are several ways to view who's on your network, some easier/less technical than others:


The logging feature in your router;
Sometimes you can view currently connected devices. For example in a FritzBox you can see all devices that have a dhcp lease (i.e. which got an IP address) on the ""Home Network"" page.
You could scan the network from your laptop using a tool like Zenmap (or Nmap on the command line).
A bit more advanced, but you can also put your WiFi card in monitor mode and look for devices that communicate with your access point. Wireshark and airmon-ng are the tools I would use, but there may be better options.
If you have shell access to your router, you could use netstat or even tcpdump to view connections and traffic.
You could turn off DHCP on your router and enable it on your laptop, so that you can easily see who is trying to get a lease.
Using Wireshark you can see broadcasts on the network. Almost every device broadcasts something from time to time so if your access point works as a switch (i.e. if wireless clients can reach each other on layer 2 (ethernet)) you can pretty easily enumerate all active MAC addresses.

"
5303,5303,8422,How can locators be added to the points on a 3D grid?,"Here is a pared down example of some 3D data that I want to make dynamic and add locators to each set of points.  Is that possible?

dimension1 = {{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
              {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3},
              {4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4},
              {5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5},
              {6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6},
              {7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7},
              {8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8},
              {9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9},
              {10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10}};

dimension2 = {{2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2}};

dimension3 = {{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}};

firstDimension = ListPlot3D[dimension1, BoxRatios -&gt; {1, 1, 1}, 
  PlotStyle -&gt; {Cyan, Opacity[0.2]}, Background -&gt; White];

secondDimension = ListPlot3D[dimension2, BoxRatios -&gt; {1, 1, 1}, 
  PlotStyle -&gt; {Magenta, Opacity[0.2]}, Background -&gt; White];

thirdDimension = ListPlot3D[dimension3, BoxRatios -&gt; {1, 1, 1}, 
  PlotStyle -&gt; {Yellow, Opacity[0.2]}, Background -&gt; White];

Show[firstDimension, secondDimension, thirdDimension]




The locators should move the points on the grid, and affect the other surrounding points depending on a variable.
",R Hall,https://mathematica.stackexchange.com/users/686,"Not meant as an answer to the question, but  MousePosition[""Graphics3DBoxIntercepts""] will be the key piece one will need in a full answer. Possibly inside an EventHandler as in @Szabolcs's MathGroup post for moving a point on a 3D surface. 
(Please hold onto your votes till Szabolcs posts his own answer.)

fun[x_, y_] := x^2 + y^2;

DynamicModule[{f, b},
 EventHandler[
  Show[
   Plot3D[fun[x, y], {x, -1, 1}, {y, -1, 1}],
   Graphics3D[
    Dynamic @ Quiet @ 
      Check[
       Sphere[((f - b) t + f) /. 
         FindRoot[fun[#1, #2] == #3 &amp; @@ ((f - b) t + f), {t, 0}], .1],
       {}
      ]
   ],
   BoxRatios -&gt; {1, 1, 1}],
  {""MouseMoved"" :&gt; ({f, b} = MousePosition[""Graphics3DBoxIntercepts""])}
 ]
]


screenshot:


",kglr,https://mathematica.stackexchange.com/users/125,http://mathematica.stackexchange.com/questions/5802/how-can-locators-be-added-to-the-points-on-a-3d-grid,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.3333333333333333,0.0,0.5,1.0,0.5,0.5,0.5,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5,1.0,0.0,0.5,0.8333333333333334,How do I add locators to points on a 3D mesh?,"Here is a pared down example of some 3D data that I want to make dynamic and add locators to each set of points.  Is that possible?

dimension1 = {{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
              {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3},
              {4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4},
              {5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5},
              {6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6},
              {7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7},
              {8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8},
              {9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9},
              {10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10}};

dimension2 = {{2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2},
              {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2}};

dimension3 = {{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
              {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}};

firstDimension = ListPlot3D[dimension1, BoxRatios -&gt; {1, 1, 1}, 
  PlotStyle -&gt; {Cyan, Opacity[0.2]}, Background -&gt; White];

secondDimension = ListPlot3D[dimension2, BoxRatios -&gt; {1, 1, 1}, 
  PlotStyle -&gt; {Magenta, Opacity[0.2]}, Background -&gt; White];

thirdDimension = ListPlot3D[dimension3, BoxRatios -&gt; {1, 1, 1}, 
  PlotStyle -&gt; {Yellow, Opacity[0.2]}, Background -&gt; White];

Show[firstDimension, secondDimension, thirdDimension]




The locators should move the points on the grid, and affect the other surrounding points depending on a variable.
","Not meant as an answer to the question, but  MousePosition[""Graphics3DBoxIntercepts""] will be the key piece one will need in a full answer. Possibly inside an EventHandler as in @Szabolcs's MathGroup post for moving a point on a 3D surface. 
(Please hold onto your votes till Szabolcs posts his own answer.)

fun[x_, y_] := x^2 + y^2;

DynamicModule[{f, b},
 EventHandler[
  Show[
   Plot3D[fun[x, y], {x, -1, 1}, {y, -1, 1}],
   Graphics3D[
    Dynamic @ Quiet @ 
      Check[
       Sphere[((f - b) t + f) /. 
         FindRoot[fun[#1, #2] == #3 &amp; @@ ((f - b) t + f), {t, 0}], .1],
       {}
      ]
   ],
   BoxRatios -&gt; {1, 1, 1}],
  {""MouseMoved"" :&gt; ({f, b} = MousePosition[""Graphics3DBoxIntercepts""])}
 ]
]


screenshot:


"
1240,1240,1946,Proportion of resources devoted to UX Design & Research vs. Software Development on a web app?,"First, some criteria:


The product is an application and is heavy on user interaction.  Think web 2.0 or mobile application, not a marketing or commerce site, or some back-end tool with only command-line access.
I realize that it is not always clear who is a UX person and who is a developer (nor should it be), so I'd like to focus on overall team resource allocation.  For instance, ""My team puts 25% of our resource-time into UX design/research vs. 75% of our resource-time in development.""  
I am not distinguishing between front-end and back-end development as it is too platform-specific and difficult to tease out the dividing like.  It's all software development for this question.
EDIT: Development is occurring in an agile-esque, ongoing manner, rather than a one-time, big-bang delivery.


So:


How does this proportion commonly look in practice?
How should it look?  Or, better yet, what has been the proportion on successful teams?


(I realize this is a classic ""it depends"" question, but I suspect that there is some use in asking when constrained by a few parameters, and allowing that conditions will vary.  I am also open to suggestions to further constrain the question.)
",peteorpeter,https://ux.stackexchange.com/users/3916,"We have been at the same ratio for about 4 years. 8 engineers to 1 UX designer.  Works well for us.
",Glen Lipka,https://ux.stackexchange.com/users/342,http://ux.stackexchange.com/questions/6844/proportion-of-resources-devoted-to-ux-design-research-vs-software-development,TECHNOLOGY,ux.stackexchange.com,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.4,0.0,0.0,1.0,0.6666666666666666,What is the ratio of resources for user experience design and research to resources for software development for web applications?,"First, some criteria:


The product is an application and is heavy on user interaction.  Think web 2.0 or mobile application, not a marketing or commerce site, or some back-end tool with only command-line access.
I realize that it is not always clear who is a UX person and who is a developer (nor should it be), so I'd like to focus on overall team resource allocation.  For instance, ""My team puts 25% of our resource-time into UX design/research vs. 75% of our resource-time in development.""  
I am not distinguishing between front-end and back-end development as it is too platform-specific and difficult to tease out the dividing like.  It's all software development for this question.
EDIT: Development is occurring in an agile-esque, ongoing manner, rather than a one-time, big-bang delivery.


So:


How does this proportion commonly look in practice?
How should it look?  Or, better yet, what has been the proportion on successful teams?


(I realize this is a classic ""it depends"" question, but I suspect that there is some use in asking when constrained by a few parameters, and allowing that conditions will vary.  I am also open to suggestions to further constrain the question.)
","We have been at the same ratio for about 4 years. 8 engineers to 1 UX designer.  Works well for us.
"
1055,1055,1658,Different tyre width (front and back),"Out of necessity, I had to put an 1.26"" (32mm) rear tyre on my bike where the front tyre is only 1.1"" (28mm) wide (and the bike came with 1.1"" tyres when I bought it). Are there any advantages or disadvantages of this, shall I try to get an 1.1"" tyre for the rear wheel ASAP or is it safe this way?
",TamÃ¡s,https://bicycles.stackexchange.com/users/482,"Should be perfectly safe.  I actually did a similar thing on my road bike to allow a little more cushion in the rear, for my rear.  The only hassle I can see is if you have to carry two different tubes.  Can't remember off the top of my head if you can get some that span those two sizes.
",sillyyak,https://bicycles.stackexchange.com/users/1089,http://bicycles.stackexchange.com/questions/3727/different-tyre-width-front-and-back,CULTURE,bicycles.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Different tire width (front and rear),"Because of necessity, I had to install a 1.26-inch (32mm) rear tire on my bike. The front tire was only 1.1-inch (28mm) wide (and when I bought my bike, it came with a 1.1-inch tire). Do you have any advantages or disadvantages? Should I replace the rear wheel with a 1.1-inch tire as soon as possible or is it safe?","Should be perfectly safe.  I actually did a similar thing on my road bike to allow a little more cushion in the rear, for my rear.  The only hassle I can see is if you have to carry two different tubes.  Can't remember off the top of my head if you can get some that span those two sizes.
"
4064,4064,6487,Setting up Exim to forward mail,"I'm trying to setup Exim on a fresh CentOS install so that it will receive mail for a collection of given addresses, and forward the mail respectively to another address. For example, receiving mail from me@example.com would be forwarded to me@gmail.com.

I figure this should be fairly straight forward... I had this working before with Sendmail, using the virtusertable - is there something similar I can do with Exim?

I'd also like to be able to send mail, but only for mail being sent from the local machine (i.e., from applications running on the server) - I don't need/want a publicly available SMTP server.

Are there any other settings I should bear in mind to make sure the mail server is secure? (i.e., prevent relaying) I'm assuming that it will be secure out of the box.

Thanks.
",Joe Freeman,https://serverfault.com/users/3199,"A variation on what Joe Freeman said, without using dsearch (which gave me unknown lookup type ""dsearch"" error):

In the beginning of exim.conf:

#Replace:
domainlist local_domains = lsearch;/etc/virtual/domains
#With:
domainlist local_domains = lsearch;/etc/virtual/domains : lsearch;/etc/virtual/forwarding_domains


In the section ""begin routers"" add:

sender_redirect:
    driver = redirect
    domains = lsearch;/etc/virtual/forwarding_domains
    data = ${lookup{$local_part}lsearch{/etc/virtual/forwarding/$domain}}


In lsearch;/etc/virtual/forwarding_domains add your domains one per line:

example.com


And create /etc/virtual/forwarding/example.com containg: 

me: me@gmail.com

",Marius,https://serverfault.com/users/92207,http://serverfault.com/questions/10279,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.4444444444444444,0.8888888888888888,1.0,0.6666666666666667,0.3333333333333333,0.3333333333333333,0.0,1.0,Set exim to forward mail,"I'm trying to setup Exim on a fresh CentOS install so that it will receive mail for a collection of given addresses, and forward the mail respectively to another address. For example, receiving mail from me@example.com would be forwarded to me@gmail.com.

I figure this should be fairly straight forward... I had this working before with Sendmail, using the virtusertable - is there something similar I can do with Exim?

I'd also like to be able to send mail, but only for mail being sent from the local machine (i.e., from applications running on the server) - I don't need/want a publicly available SMTP server.

Are there any other settings I should bear in mind to make sure the mail server is secure? (i.e., prevent relaying) I'm assuming that it will be secure out of the box.

Thanks.
","A variation on what Joe Freeman said, without using dsearch (which gave me unknown lookup type ""dsearch"" error):

In the beginning of exim.conf:

#Replace:
domainlist local_domains = lsearch;/etc/virtual/domains
#With:
domainlist local_domains = lsearch;/etc/virtual/domains : lsearch;/etc/virtual/forwarding_domains


In the section ""begin routers"" add:

sender_redirect:
    driver = redirect
    domains = lsearch;/etc/virtual/forwarding_domains
    data = ${lookup{$local_part}lsearch{/etc/virtual/forwarding/$domain}}


In lsearch;/etc/virtual/forwarding_domains add your domains one per line:

example.com


And create /etc/virtual/forwarding/example.com containg: 

me: me@gmail.com

"
4445,4445,7056,Multivariate Linear Regression with continuous and discrete explanatory variable,"I have some trouble to apply a multivariate linear regression on my data. I have two features gross_area which is continuous, nb_bathrooms which is discrete (1,2,3) and a dependent variable y which is the price. Firstly I have looked at the feature's distribution which is not normal (Skewed right). I removed some outliers. I standardized my features.I use OLS as cost function and ""batch"" gradient descent in order to find my parameters.
I find my parameter I plot separately the gross_area against the price with parameter gross_area and the y-intercept, and a plot of the nb_bathrooms against the price with parameter nb_bathrooms and the y-intercept also.

This is what I got for the gross_area:

And for the nb_bedrooms:


So my questions are the following,
How can I fit data like nb_bedrooms since I tried polynomial terms but does not seem to fit them better.

Thank you,
",marcL,https://stats.stackexchange.com/users/72800,"Notice that you are predicting negative prices for small gross areas. Does that make sense (Please come and live in this appartment, I will give you money if you do). I would consider using a log link function. 

As for the categorical variable, I would just add indicator variables for the number of bathrooms instead of entering it as a continuous variable. 
",Maarten Buis,https://stats.stackexchange.com/users/23853,http://stats.stackexchange.com/questions/145305/multivariate-linear-regression-with-continuous-and-discrete-explanatory-variable,SCIENCE,stats.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.5,1.0,0.6666666666666666,1.0,0.8333333333333334,0.7,0.0,0.0,1.0,1.0,Multivariate linear regression with continuous and discrete explanatory variables,"I have some trouble to apply a multivariate linear regression on my data. I have two features gross_area which is continuous, nb_bathrooms which is discrete (1,2,3) and a dependent variable y which is the price. Firstly I have looked at the feature's distribution which is not normal (Skewed right). I removed some outliers. I standardized my features.I use OLS as cost function and ""batch"" gradient descent in order to find my parameters.
I find my parameter I plot separately the gross_area against the price with parameter gross_area and the y-intercept, and a plot of the nb_bathrooms against the price with parameter nb_bathrooms and the y-intercept also.

This is what I got for the gross_area:

And for the nb_bedrooms:


So my questions are the following,
How can I fit data like nb_bedrooms since I tried polynomial terms but does not seem to fit them better.

Thank you,
","Please note that you are forecasting a negative price for small area buildings. Does it make sense (please come and live in this apartment, if so, I will give you money). I will consider using the log link function."
1485,1485,2336,Interpretation of riemannian geodesics in probability,"Good morning everybody. My question is, as maybe already hinted in the title, rather philosopic.

We know that geometric properties of a riemannian manifold can be interpreted in terms of certain evolution processes; I'm thinking about all the relations between the expansion of the heat kernel and, for example, the gaussian curvature of the manifold.

Now, since I'm not a probabilist the question is as follows...

are there characterizations, or properties of riemannian geodesics which can be deduced from stochastic operators (like the Brownian motion)? Even more, can we give a characterization of (properties of) riemannian geodesics in these terms?

All references are welcomed.. this is just a soft question for me to know where I have to look at in literature.

Thanks again for the patience.

Guido
",guido giuliani,https://mathoverflow.net/users/57571,"Check out: Franchi and LeJan,

Hyperbolic Dynamics and Brownian Motion: An Introduction
",Igor Rivin,https://mathoverflow.net/users/11142,http://mathoverflow.net/questions/182910,SCIENCE,mathoverflow.net,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6,0.0,0.0,0.0,1.0,Probability interpretation of Riemann geodesics,"Good morning everybody. My question is, as maybe already hinted in the title, rather philosopic.

We know that geometric properties of a riemannian manifold can be interpreted in terms of certain evolution processes; I'm thinking about all the relations between the expansion of the heat kernel and, for example, the gaussian curvature of the manifold.

Now, since I'm not a probabilist the question is as follows...

are there characterizations, or properties of riemannian geodesics which can be deduced from stochastic operators (like the Brownian motion)? Even more, can we give a characterization of (properties of) riemannian geodesics in these terms?

All references are welcomed.. this is just a soft question for me to know where I have to look at in literature.

Thanks again for the patience.

Guido
","Check out: Franchi and LeJan,

Hyperbolic Dynamics and Brownian Motion: An Introduction
"
3542,3542,5652,Is it possible to have a convergent subsequence of a divergent sequence?,"Is it possible to have a convergent subsequence of a divergent sequence? Thanks!
",eChung00,https://math.stackexchange.com/users/92974,"Another example: Let $(x_n)=\sin(\frac{n\pi}{2})$. Obviously $(x_n)$ is a non-convergent sequence, buy if you consider the subsecuence: $(x_n)_{n=2k}$, with $k\in \mathbb{N}$, then $(x_n)_{n=2k}\to 0$.
",Hiperion,https://math.stackexchange.com/users/11648,http://math.stackexchange.com/questions/494623/is-it-possible-to-have-a-convergent-subsequence-of-a-divergent-sequence,SCIENCE,math.stackexchange.com,0.6666666666666666,0.8888888888888888,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.3333333333333333,0.6666666666666666,1.0,Is it possible for convergent subsequences of divergent sequences?,Is it possible for convergent subsequences of divergent sequences? Thank you!,"Another example: Let $(x_n)=\sin(\frac{n\pi}{2})$. Obviously $(x_n)$ is a non-convergent sequence, buy if you consider the subsecuence: $(x_n)_{n=2k}$, with $k\in \mathbb{N}$, then $(x_n)_{n=2k}\to 0$.
"
2341,2341,3731,What to do about students who ask for help too often?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
",Village,https://academia.stackexchange.com/users/600,"Another strategy is to provide more guidance about what sort of help you'll provide and how they should ask for it. Possibilities:


The first time you bring your paper to my office [or during specific dates], we will focus only on whether you have answered the question.
I will be happy to discuss aspects X and Y, but never Z.
Bring the rubric with you. Be prepared to explain which part of the
rubric you most need to address in your draft, and why. We'll focus on that part   of the rubric during our meeting.
Before you bring your paper to me, prepare a list of specific questions you would like me to answer. Bring two copies of the list, one for each of us.
Before you bring your paper to me, show it to someone at the writing center. Bring with you your notes from that visit and the draft you showed to them, along with the draft where you implemented those suggestions.
Always bring two copies of your draft--one for each of us. Be prepared to write  detailed notes on your copy. (Then you can keep your copy and you'll be able to bring it out the next time and say--ok, what did you change? Or you can compare it to the draft they turn in to see if they made significant changes. And if they plagiarised it, you'll have a record.)
Each time you show me your paper, I will expect you to create a checklist of things you will address. The next visit, you need to demonstrate that you have completed those things by bringing a draft with changes marked and annotated.


Another thing you can do is assign ""draft"" deadlines as well as final deadlines for everyone, then give the feedback you think is important on the drafts (maybe using a rubric) and not meet incessantly with a few students.

Another thing you can do--particularly with very structured papers that you have assigned before--is provide to the class a list of the common problems students have. Then when a student shows you a draft, you can initiate a discussion about which common problem the student thinks it illustrates and what can the student do to address it?

Another thing you can do is limit the number of times you will look at a draft, or the period of time during which you will look at a draft. 

I have had a similar problem with students wanting me to grade work before they turn it in for a grade--not just on writing, but with all kinds of assignments. Sometimes they are so lost they are completely stuck. Other times, they seem to be trying to minimize their workload by increasing mine. (""Just tell me in exacting  detail what to do, I'll do that and no more, you'll give me an A."") But what I want is for them to learn how to assess their own writing! 

Whatever strategy you use, when you meet with students, try to elicit their comments. If you give a suggestion, and they nod, then ask them how they expect to apply it. What changes will they make to a particular sentence or paragraph? Are there any other places in the text they should also make that change to--which ones, and why? If they are to provide more evidence, ask them where they intend to search and how. Then you can better assess whether they understand what you've told them and whether they can actually do it.

I often ask students about how they produced the draft. Which parts were the easiest and which parts were the hardest, and why? Which parts do they like best? Which parts do they think need the most revision? Sometimes I ask them to imagine a reader--if they were to show their paper to (mom, roommate, employer, etc.), which part would be the most controversial? What would need the most explanation? If their reader disagrees, what would that person likely argue back? The more they talk about their writing, the more opportunity you have to say, ""Yes! What you just said--write that down. Now do that!"" 

Another benefit of getting students to talk about their draft is that it is tough to talk about something you didn't write. If they let you know they copied passages, you can remind them (or explain how) to cite them properly. If they pretend they wrote every word, you have a different problem to address. 
",iBeth01,https://academia.stackexchange.com/users/19422,http://academia.stackexchange.com/questions/28504/what-to-do-about-students-who-ask-for-help-too-often,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,What to do with students who often ask for help?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
","Another strategy is to provide more guidance about what sort of help you'll provide and how they should ask for it. Possibilities:


The first time you bring your paper to my office [or during specific dates], we will focus only on whether you have answered the question.
I will be happy to discuss aspects X and Y, but never Z.
Bring the rubric with you. Be prepared to explain which part of the
rubric you most need to address in your draft, and why. We'll focus on that part   of the rubric during our meeting.
Before you bring your paper to me, prepare a list of specific questions you would like me to answer. Bring two copies of the list, one for each of us.
Before you bring your paper to me, show it to someone at the writing center. Bring with you your notes from that visit and the draft you showed to them, along with the draft where you implemented those suggestions.
Always bring two copies of your draft--one for each of us. Be prepared to write  detailed notes on your copy. (Then you can keep your copy and you'll be able to bring it out the next time and say--ok, what did you change? Or you can compare it to the draft they turn in to see if they made significant changes. And if they plagiarised it, you'll have a record.)
Each time you show me your paper, I will expect you to create a checklist of things you will address. The next visit, you need to demonstrate that you have completed those things by bringing a draft with changes marked and annotated.


Another thing you can do is assign ""draft"" deadlines as well as final deadlines for everyone, then give the feedback you think is important on the drafts (maybe using a rubric) and not meet incessantly with a few students.

Another thing you can do--particularly with very structured papers that you have assigned before--is provide to the class a list of the common problems students have. Then when a student shows you a draft, you can initiate a discussion about which common problem the student thinks it illustrates and what can the student do to address it?

Another thing you can do is limit the number of times you will look at a draft, or the period of time during which you will look at a draft. 

I have had a similar problem with students wanting me to grade work before they turn it in for a grade--not just on writing, but with all kinds of assignments. Sometimes they are so lost they are completely stuck. Other times, they seem to be trying to minimize their workload by increasing mine. (""Just tell me in exacting  detail what to do, I'll do that and no more, you'll give me an A."") But what I want is for them to learn how to assess their own writing! 

Whatever strategy you use, when you meet with students, try to elicit their comments. If you give a suggestion, and they nod, then ask them how they expect to apply it. What changes will they make to a particular sentence or paragraph? Are there any other places in the text they should also make that change to--which ones, and why? If they are to provide more evidence, ask them where they intend to search and how. Then you can better assess whether they understand what you've told them and whether they can actually do it.

I often ask students about how they produced the draft. Which parts were the easiest and which parts were the hardest, and why? Which parts do they like best? Which parts do they think need the most revision? Sometimes I ask them to imagine a reader--if they were to show their paper to (mom, roommate, employer, etc.), which part would be the most controversial? What would need the most explanation? If their reader disagrees, what would that person likely argue back? The more they talk about their writing, the more opportunity you have to say, ""Yes! What you just said--write that down. Now do that!"" 

Another benefit of getting students to talk about their draft is that it is tough to talk about something you didn't write. If they let you know they copied passages, you can remind them (or explain how) to cite them properly. If they pretend they wrote every word, you have a different problem to address. 
"
4552,4552,7212,"Are DSLRs a dying breed, making now the time to switch to a mirrorless camera system?","I came across this thought provoking article on Stuck in Customs today that makes a strong case to hold off too much investment in DSLR gear, and instead switch to mirror-less cameras like the Sony NEX. The author prefers to call such cameras 3rd generation cameras to prevent any bias.

The crux of the argument lies in the smaller size and faster shooting speeds of the new cameras, while the sensor size is an area where they seem to be lacking (Sony &amp; Samsung cameras are APS-C sized though). Currently the big makers - Nikon &amp; Canon - have practically no presence in this market (Nikon seems to be doing something with the V1). However, they seem to have slowed down the introduction of new entry level DSLR models over the last year as well.

So, as DSLR users looking to build and enhance their kit (there are many like me who've jumped the bandwagon over the last couple of years, and are just starting to build their kit), what are the advantages of sticking with the DSLR system rather than switching to the 3rd gen cameras?

IMO, one point that could cause a massive switch in the DSLR base would be if Nikon &amp; Canon announced mirror-less models compatible with their current lens lineups, but that is a hypothetical scenario.

P.S. There is a similar question on mirror-less cameras, but that seems to be from the perspective of a person starting out rather than a person already invested in the DSLR system.
",ab.aditya,https://photo.stackexchange.com/users/1977,"DSLRs are certainly not going away any time soon, especially at the high end of the market - ruggedness, speed, large sensor size, and the continued availability of excellent glass will keep them around for some time. Large sensor cameras will also continue to appeal to nature photographers, as the 1.0x crop factor on the higher end models will allow them to shoot wider than APS-C, m4/3, or smaller sensored cameras, lens for lens.

That said, I believe that growth of the DSLR market will slow, perhaps even flattening, as I think there are two kinds of DSLR user - pros/enthusiasts who need specific feature sets and are willing to deal with larger size and weight, and people who want better than a point-and-shoot, who would prefer a smaller camera and get some of the benefits of a larger one (APS-C sensors, for example).

It's the latter group who will poach market share from both the DSLR and point-and-shoot market segments. Neither will be destroyed, but I believe both will lose some share.

As for me, I'm a long time SLR user, who's taking the plunge, selling his Nikon bodies and lenses, and going mirrorless (X-Pro1 when it drops). I think it will offer a compromise of features and size that will get me shooting more, because I'm carrying less. And the point is to be out there shooting, after all...
",stevil,https://photo.stackexchange.com/users/8591,http://photo.stackexchange.com/questions/18940/are-dslrs-a-dying-breed-making-now-the-time-to-switch-to-a-mirrorless-camera-sy,LIFE_ARTS,photo.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.0,0.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,SLR is a dying breed that makes the current time switch to a mirror less camera system?,"I came across this thought provoking article on Stuck in Customs today that makes a strong case to hold off too much investment in DSLR gear, and instead switch to mirror-less cameras like the Sony NEX. The author prefers to call such cameras 3rd generation cameras to prevent any bias.

The crux of the argument lies in the smaller size and faster shooting speeds of the new cameras, while the sensor size is an area where they seem to be lacking (Sony &amp; Samsung cameras are APS-C sized though). Currently the big makers - Nikon &amp; Canon - have practically no presence in this market (Nikon seems to be doing something with the V1). However, they seem to have slowed down the introduction of new entry level DSLR models over the last year as well.

So, as DSLR users looking to build and enhance their kit (there are many like me who've jumped the bandwagon over the last couple of years, and are just starting to build their kit), what are the advantages of sticking with the DSLR system rather than switching to the 3rd gen cameras?

IMO, one point that could cause a massive switch in the DSLR base would be if Nikon &amp; Canon announced mirror-less models compatible with their current lens lineups, but that is a hypothetical scenario.

P.S. There is a similar question on mirror-less cameras, but that seems to be from the perspective of a person starting out rather than a person already invested in the DSLR system.
","DSLRs are certainly not going away any time soon, especially at the high end of the market - ruggedness, speed, large sensor size, and the continued availability of excellent glass will keep them around for some time. Large sensor cameras will also continue to appeal to nature photographers, as the 1.0x crop factor on the higher end models will allow them to shoot wider than APS-C, m4/3, or smaller sensored cameras, lens for lens.

That said, I believe that growth of the DSLR market will slow, perhaps even flattening, as I think there are two kinds of DSLR user - pros/enthusiasts who need specific feature sets and are willing to deal with larger size and weight, and people who want better than a point-and-shoot, who would prefer a smaller camera and get some of the benefits of a larger one (APS-C sensors, for example).

It's the latter group who will poach market share from both the DSLR and point-and-shoot market segments. Neither will be destroyed, but I believe both will lose some share.

As for me, I'm a long time SLR user, who's taking the plunge, selling his Nikon bodies and lenses, and going mirrorless (X-Pro1 when it drops). I think it will offer a compromise of features and size that will get me shooting more, because I'm carrying less. And the point is to be out there shooting, after all...
"
5134,5134,8165,Why do people rewrite some libraries to many programming languages?,"There are some libraries, which are available in their versions written in many different programming languages, like for example Lucene, which is written in Java (as they say, 100% pure Java), but has also its versions in C++, C, Perl, Ruby, Lisp and some other languages. And I'm talking about implementations in these languages, not just FFI interfaces.

Why do people do that? I can see one obvious reason: deployment and distribution (and probably development as well) easier when a project has fewer dependencies. But is there anything else? In what situations is it worth it?
",mik01aj,https://programmers.stackexchange.com/users/25529,"Sometimes you're developing for a platform where the tool the software was written in (Java in Lucene's case) isn't an option.  If you want the features without having to reengineer the code from scratch, you port the code.
",Blrfl,https://programmers.stackexchange.com/users/20756,http://programmers.stackexchange.com/questions/79169/why-do-people-rewrite-some-libraries-to-many-programming-languages,TECHNOLOGY,programmers.stackexchange.com,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,1.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,1.0,1.0,1.0,Why do people rewrite some libraries into multiple programming languages?,"There are libraries that can be written in many different programming languages in their versions, such as Lucene, which is written in Java (as they say, 100% pure Java), but it also has versions of C + +, C, Perl, ruby, LISP and other languages. I'm talking about the implementation of these languages, not just the FFI interface.","Sometimes, you are developing a platform on which the tools (Java in Lucene's case) used by the software are not an option. If you need these features without having to redesign the code from scratch, you can migrate the code."
5070,5070,8063,pre hung doors to fit into old frame,"I have purchased some pre hung doors at 30"" by 80""
the jambs are 4 5/8 wide. 
The house is 50 years old and the existing door frame is 5 1/4 wide.
Any solution as to how to fit these doors into the old frame.
",brian smith,https://diy.stackexchange.com/users/20542,"Take off the trim, remove the old frame, install the new frame, re-install trim or install new trim. That, or re-use the existing frame by hanging the new door in it.
",iLikeDirt,https://diy.stackexchange.com/users/15879,http://diy.stackexchange.com/questions/40199,LIFE_ARTS,diy.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,0.7777777777777778,0.5555555555555556,0.7777777777777778,0.8888888888888888,1.0,1.0,0.0,0.0,0.8888888888888888,Pre hung door suitable for the old frame,"I have purchased some pre hung doors at 30"" by 80""
the jambs are 4 5/8 wide. 
The house is 50 years old and the existing door frame is 5 1/4 wide.
Any solution as to how to fit these doors into the old frame.
","Remove trim, remove old frame, install new frame, reinstall trim or install new trim. Alternatively, reuse the existing frame by hanging a new door."
5371,5371,8530,Why do I have house flies in my carport?,"I bought my home in early September 2012. I noticed that flies were flocking around a light in my open air carport whether it was on or off. I tried a few products like fly tape, spray and a fly trap. Still no results. This continued through fall until temps dropped. This Spring I thought I would take preventive measures and cleaned my entire carport with Lysol including my garbage cans which are new. But still flies are flocking around this light. Its strange, they don't land on it that much as if there were some food source. They just fly around it all day until the sun goes down and even then there are a few stragglers. I would say at peak during the day there are about 150 to 200 flies. Why are they attracted to this area and What do I do to get rid of them? 
",Zach G,https://diy.stackexchange.com/users/13243,"You need to do three things.  


Remove all trash/food from the area and clean with bleach - spray down the whole area
fumigate - you need to bomb everything with bug spray.  Maybe a few times.  Lay it on.  Use all precautions and such (wear a mask).  
keep your trash far far away for at least a month.  Flies are attracted to trash and often lay eggs in the trash or close by.  You need to find another area to put your trash for a while.  

",Tom,https://diy.stackexchange.com/users/12577,http://diy.stackexchange.com/questions/28274/why-do-i-have-house-flies-in-my-carport,LIFE_ARTS,diy.stackexchange.com,1.0,0.4444444444444444,0.0,0.5,0.6666666666666666,0.5,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.9,1.0,0.0,0.6666666666666666,0.8888888888888888,Why do I have houseflies in my garage?,"I bought a house in early September 2012. I noticed that flies were flying around a light in my open garage, whether it was on or off. I have tried some products, such as anti fly tape, sprayer and anti fly device. There is still no result. This continued until autumn, when the temperature dropped. This spring, I think I'll take precautions to clean the whole shed with lysine, including my new trash can. But there are still flies flying around in the light. Strangely, they didn't land on it, as if they had a source of food. They fly around it all day until the sun goes down. Even so, there are some scattered people. I think there are about 150 to 200 flies at the peak of the day. Why are they attracted to this area and what can I do to get rid of them?","You need to do three things.  


Remove all trash/food from the area and clean with bleach - spray down the whole area
fumigate - you need to bomb everything with bug spray.  Maybe a few times.  Lay it on.  Use all precautions and such (wear a mask).  
keep your trash far far away for at least a month.  Flies are attracted to trash and often lay eggs in the trash or close by.  You need to find another area to put your trash for a while.  

"
1576,1576,2478,"Solubility, pressure and Henry's law","Im trying to do my chem homework and I'm stumped. 


  Determine the solubility of $\ce{N2}$ in water exposed to air at 25Â°C, if the
  atmospheric pressure is 1.2 atm, assume that the mole fraction of
  nitrogen is 0.78 in air and the Henry's Law constant for nitrogen in
  water at this temperature is $6.1 Ã 10^{-4} M/atm$.



I have the answer, but i want to know how to solve for it. I've been reading through my notes and the book trying to find a reference through which to approach this problem and i have found none. If anyone can guide me in the right direction that would suffice

",Brandon,https://chemistry.stackexchange.com/users/4312,"Henry's law is given by the formula $p$=$K_h$$x$. Here $p$ is partial pressure of the gas $K_h$ is henry's constant for that gas and $x$ is mole fraction.Using this you can find it.
",Devgeet Patel,https://chemistry.stackexchange.com/users/3943,http://chemistry.stackexchange.com/questions/8088/solubility-pressure-and-henrys-law,SCIENCE,chemistry.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,1.0,"Solubility, pressure and Henry's law","Im trying to do my chem homework and I'm stumped. 


  Determine the solubility of $\ce{N2}$ in water exposed to air at 25Â°C, if the
  atmospheric pressure is 1.2 atm, assume that the mole fraction of
  nitrogen is 0.78 in air and the Henry's Law constant for nitrogen in
  water at this temperature is $6.1 Ã 10^{-4} M/atm$.



I have the answer, but i want to know how to solve for it. I've been reading through my notes and the book trying to find a reference through which to approach this problem and i have found none. If anyone can guide me in the right direction that would suffice

","Henry's law is given by the formula $p$=$K_h$$x$. Here $p$ is partial pressure of the gas $K_h$ is henry's constant for that gas and $x$ is mole fraction.Using this you can find it.
"
4063,4063,6485,Exit Google Chrome from terminal,"Is there a way to cause google-chrome to quit, from the terminal, besides using killall google-chrome? 
I would like to be able to close it from a script without killing it.
",slybloty,https://unix.stackexchange.com/users/14775,"Perhaps wmctrl could be of some assistance. You could use the -c option that closes a window gracefully:

wmctrl -c chrome


The string chrome is matched against the window titles. Note that the window might not close if some message pops-up (e.g. when you have multiple tabs open).
",Baldrick,https://unix.stackexchange.com/users/10659,http://unix.stackexchange.com/questions/34101/exit-google-chrome-from-terminal,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8333333333333334,0.6666666666666666,1.0,1.0,0.6,1.0,0.0,0.0,0.7777777777777778,Exit Google browser from the terminal,"Besides using killall Google Chrome, is there any way to get Google Chrome out of the terminal?","Perhaps wmctrl could be of some assistance. You could use the -c option that closes a window gracefully:

wmctrl -c chrome


The string chrome is matched against the window titles. Note that the window might not close if some message pops-up (e.g. when you have multiple tabs open).
"
669,669,1061,Android setOnItemClickListener,"I'm not able to initiate the ""OnItemClickListener"".

You can see my code snippet

 ListAdapter adapter = new SimpleAdapter(this, mylist , R.layout.main, new String[] { ""title""}, new int[] { R.id.item_title});
    setListAdapter(adapter);

    final ListView lv = getListView();
    lv.setTextFilterEnabled(true);

    lv.setOnItemClickListener(new OnItemClickListener() {
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) {              
            @SuppressWarnings(""unchecked"")
            HashMap&lt;String, String&gt; o = (HashMap&lt;String, String&gt;) lv.getItemAtPosition(position);                   
            Toast.makeText(TopNewsActivity.this, ""ID '"" + o.get(""id"") + ""' was clicked."", Toast.LENGTH_LONG).show(); 

        }
    });


after the setListAdapter my debugger goes to ""lv.setOnItemClickListener"" but then does not get into the loop and moves out.

I want to make the links Clickable kindly help.
",ReNa,https://stackoverflow.com/users/694260,"The most probable cause is that your ListView items contain either focusable or clickable Views. If a view contains either focusable or clickable item the OnItemCLickListener won't be called. (Instead the clickable View's own click handlers will be called).

Click here for more information.
See my previous answer here or find more information here.

Try it with a very simple ListItem layout - it should work.
",balazsbalazs,https://stackoverflow.com/users/626628,http://stackoverflow.com/questions/5714522/android-setonitemclicklistener,STACKOVERFLOW,stackoverflow.com,0.5555555555555556,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,0.8888888888888888,Android setonitemclicklistener,"I'm not able to initiate the ""OnItemClickListener"".

You can see my code snippet

 ListAdapter adapter = new SimpleAdapter(this, mylist , R.layout.main, new String[] { ""title""}, new int[] { R.id.item_title});
    setListAdapter(adapter);

    final ListView lv = getListView();
    lv.setTextFilterEnabled(true);

    lv.setOnItemClickListener(new OnItemClickListener() {
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) {              
            @SuppressWarnings(""unchecked"")
            HashMap&lt;String, String&gt; o = (HashMap&lt;String, String&gt;) lv.getItemAtPosition(position);                   
            Toast.makeText(TopNewsActivity.this, ""ID '"" + o.get(""id"") + ""' was clicked."", Toast.LENGTH_LONG).show(); 

        }
    });


after the setListAdapter my debugger goes to ""lv.setOnItemClickListener"" but then does not get into the loop and moves out.

I want to make the links Clickable kindly help.
","The most probable cause is that your ListView items contain either focusable or clickable Views. If a view contains either focusable or clickable item the OnItemCLickListener won't be called. (Instead the clickable View's own click handlers will be called).

Click here for more information.
See my previous answer here or find more information here.

Try it with a very simple ListItem layout - it should work.
"
4671,4671,7400,Traveling into Brazil from Bolivia by land/bus,"I plan on travelling from Bolivia into Western Brazil (Caceres or Cuiaba in Mato Grosso) from Santa Cruz, Bolivia.  I have heard that there are a couple of border cities into which to pass over to Brazil. 

Does anyone know which is the safest/easiest way to go through?

If so, is travelling by bus the only way? I've heard there's also a train that leaves from Santa Cruz to Brazil, via Corumba? Is this currently running? Does anyone have experience travelling to Brazil like this?
",unknownprotocol,https://travel.stackexchange.com/users/9504,"RometoRio shows a route for both bus and train.  Several, in fact.  Each varies by price, and time, for obvious reasons, and it's shown alongside some flight prices as well, if that's a possible consideration.

The bus option looks brutal, however, as they're only finding one that goes via Argentina(!), taking 3 days. The train, on the other hand looks more doable for 43 hours, and looks to be split about 1/3 train 2/3 bus.

There is also a flight option shown.

Bolivian buses, from experience, are a far 'rougher' affair than Argentinian/Chilean/Peruvian buses - I wouldn't worry about several days on those, but in Bolivia, it may be a different thing to consider. Personal preference and all that. 

Good luck, let us know what you find!
",Mark Mayo,https://travel.stackexchange.com/users/101,http://travel.stackexchange.com/questions/22597/traveling-into-brazil-from-bolivia-by-land-bus,CULTURE,travel.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,Land / bus from Bolivia to Brazil,"I plan on travelling from Bolivia into Western Brazil (Caceres or Cuiaba in Mato Grosso) from Santa Cruz, Bolivia.  I have heard that there are a couple of border cities into which to pass over to Brazil. 

Does anyone know which is the safest/easiest way to go through?

If so, is travelling by bus the only way? I've heard there's also a train that leaves from Santa Cruz to Brazil, via Corumba? Is this currently running? Does anyone have experience travelling to Brazil like this?
","RometoRio shows a route for both bus and train.  Several, in fact.  Each varies by price, and time, for obvious reasons, and it's shown alongside some flight prices as well, if that's a possible consideration.

The bus option looks brutal, however, as they're only finding one that goes via Argentina(!), taking 3 days. The train, on the other hand looks more doable for 43 hours, and looks to be split about 1/3 train 2/3 bus.

There is also a flight option shown.

Bolivian buses, from experience, are a far 'rougher' affair than Argentinian/Chilean/Peruvian buses - I wouldn't worry about several days on those, but in Bolivia, it may be a different thing to consider. Personal preference and all that. 

Good luck, let us know what you find!
"
515,515,810,Is the Power-Link designed for routine usage?,"I have a Power-Link which i intended to use in emergencies (when the chain breaks and i'm far from home). Used it once, worked pretty well.

Now i wonder, what if i use it permanently with my chain? My idea is that it might be convenient to quickly remove the chain, stuff it into a bowl of acetone/oil/whatever, and easily install it back onto the bike.

But will the Power-Link wear out quickly (e.g. quicker than the other ""links"" of the chain)? I am not sure whether it was intended to be used all the time or just for emergencies.
",anatolyg,https://bicycles.stackexchange.com/users/4056,"It's intended for permanent use -- it's what SRAM provides for permanently joining their chains.  I've got several thousand miles on them, with no difficulties.
",Daniel R Hicks,https://bicycles.stackexchange.com/users/1584,http://bicycles.stackexchange.com/questions/9402/is-the-power-link-designed-for-routine-usage,CULTURE,bicycles.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Is the power cord designed for everyday use?,"I have a Power-Link which i intended to use in emergencies (when the chain breaks and i'm far from home). Used it once, worked pretty well.

Now i wonder, what if i use it permanently with my chain? My idea is that it might be convenient to quickly remove the chain, stuff it into a bowl of acetone/oil/whatever, and easily install it back onto the bike.

But will the Power-Link wear out quickly (e.g. quicker than the other ""links"" of the chain)? I am not sure whether it was intended to be used all the time or just for emergencies.
","It's intended for permanent use -- it's what SRAM provides for permanently joining their chains.  I've got several thousand miles on them, with no difficulties.
"
2163,2163,3449,How do I deal with a slow and undedicated colleague in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
",HOT,https://programmers.stackexchange.com/users/34092,"Pat's answer was great. I agree 100%. Don't go sneak a meeting with the boss. Either take it with your colleague between 4 eyes or do it with all 3 of you. But Pat's suggestion to focus on the code issues and not on people is the right way to go.

Btw, 40h/week is enough dude. You need to keep your motivation high!
",AndSoYouCode,https://programmers.stackexchange.com/users/34480,http://programmers.stackexchange.com/questions/101528/how-do-i-deal-with-a-slow-and-undedicated-colleague-in-the-team,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,How can I deal with a colleague who is slow-moving and lacks dedication in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
","Pat's answer was great. I agree 100%. Don't go sneak a meeting with the boss. Either take it with your colleague between 4 eyes or do it with all 3 of you. But Pat's suggestion to focus on the code issues and not on people is the right way to go.

Btw, 40h/week is enough dude. You need to keep your motivation high!
"
4728,4728,7502,lion: assign buttons on a Microsoft mouse,"I have an old 5 button Microsoft mouse (Laser Mouse 6000) and forever I've assigned the thumb button to ""back"" in the browser and the middle mouse button to ""next app"" on the desktop. Since I've installed Lion, this doesn't seem to work. The settings in the ""Microsoft Mouse"" panel in System Preferences don't seem have any effect. 

Is there another way to map mouse buttons? I've noticed that Mission Control seems to detect my 5 buttons and let me assign them, but only to Mission Control functions. I don't see anywhere else where I can do this. Do I just need to wait for new MS drivers? Thanks.
",asciitaxi,https://apple.stackexchange.com/users/8223,"It turned out I just needed to install the most recent version of the MS drivers. Everything now works like it did.

The latest MS Drivers can be found at: http://www.microsoft.com/hardware/en-us/downloads (the versions in the MS Downloads Center, and in Google results are older which don't work with Lion)
",asciitaxi,https://apple.stackexchange.com/users/8223,http://apple.stackexchange.com/questions/18361/lion-assign-buttons-on-a-microsoft-mouse,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Lion: specify button on Microsoft Mouse,"I have an old five button Microsoft mouse (Laser Mouse 6000), always I assign a thumb button ""back"" in the browser and middle mouse button ""next app"" on the desktop. Now that I have lion installed, it doesn't seem to work. The settings in the Microsoft mouse panel in system preferences do not appear to have any effect.","It turned out I just needed to install the most recent version of the MS drivers. Everything now works like it did.

The latest MS Drivers can be found at: http://www.microsoft.com/hardware/en-us/downloads (the versions in the MS Downloads Center, and in Google results are older which don't work with Lion)
"
2106,2106,3351,Basic steps to develop python API in Unix environment,"I am developing an API in Unix environment for virtual machines. Most of the modules are developed in python. I have few questions on this.

I have the file extension as abc.py. I would like to make this as a command. For example , virtman dominfo [vmid] should be the command syntax. Now I have to give ./virtman.py dominfo [vmid] to achieve this.  And I have first line as #!/usr/bin/python in the python file. So how can make this as a command?

My echo $PATH looks like '/bin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin0'

I read a lot of articles but I didn't get the clear picture,so any hints/suggestions would be helpful.
",Dany,https://unix.stackexchange.com/users/89936,"You seem to be mistaken in that abc.py would not be a command. If you can execute it, then is, just one with a dot in the name. Execute in the sense that you can do ./abc.py, so the execute bits must be set. If you have to do python abc.py than you it is not a command (yet).

In general, to make a normal  python file abc.py executable you should make sure the first line reads:

#!/usr/bin/env python


(This assumes you have /usr/bin/env as a program, and that will find the python command, which might be in /usr/local/bin. It also assumes that you want to run the default python (which is normally a link to a particular python version like python2.7), you could also use python3 if that is available as a command).

After that do

chmod +x abc.py
mv abc.py abc


And then you can run ./abc. If the current directory is in your path, or if you move abc to a directory in your path, you should be able to execute abc from anywhere.Â¹

There are however disadvantages of renaming and moving the file:


you can no longer to from abc import SomeClass, as the file is renamed
If the file is under revision control it might no longer be


So instead, what I normally do, is make a new file /usr/local/bin/abc that looks like:

#!/usr/bin/env python

from abc import main
main()


and have at the bottom of abc.py:

def main():
    doing the real stuff

if __name__ == '__main__':
    main()


The directory of abc.py needs to be in the PATH python searches for modules, but this way it doesn't have to be changed, and can be used by any program as an import, and started as python abc.py.

Â¹ The mv is necessary to get rid of the dot in the command name, but not really necessary, you can invoke ./abc.py if you don't rename it.   
",Anthon,https://unix.stackexchange.com/users/33055,http://unix.stackexchange.com/questions/165378/basic-steps-to-develop-python-api-in-unix-environment,TECHNOLOGY,unix.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.7777777777777778,The basic steps of developing Python API in UNIX Environment,"I am developing an API in Unix environment for virtual machines. Most of the modules are developed in python. I have few questions on this.

I have the file extension as abc.py. I would like to make this as a command. For example , virtman dominfo [vmid] should be the command syntax. Now I have to give ./virtman.py dominfo [vmid] to achieve this.  And I have first line as #!/usr/bin/python in the python file. So how can make this as a command?

My echo $PATH looks like '/bin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin0'

I read a lot of articles but I didn't get the clear picture,so any hints/suggestions would be helpful.
","You seem to be mistaken in that abc.py would not be a command. If you can execute it, then is, just one with a dot in the name. Execute in the sense that you can do ./abc.py, so the execute bits must be set. If you have to do python abc.py than you it is not a command (yet).

In general, to make a normal  python file abc.py executable you should make sure the first line reads:

#!/usr/bin/env python


(This assumes you have /usr/bin/env as a program, and that will find the python command, which might be in /usr/local/bin. It also assumes that you want to run the default python (which is normally a link to a particular python version like python2.7), you could also use python3 if that is available as a command).

After that do

chmod +x abc.py
mv abc.py abc


And then you can run ./abc. If the current directory is in your path, or if you move abc to a directory in your path, you should be able to execute abc from anywhere.Â¹

There are however disadvantages of renaming and moving the file:


you can no longer to from abc import SomeClass, as the file is renamed
If the file is under revision control it might no longer be


So instead, what I normally do, is make a new file /usr/local/bin/abc that looks like:

#!/usr/bin/env python

from abc import main
main()


and have at the bottom of abc.py:

def main():
    doing the real stuff

if __name__ == '__main__':
    main()


The directory of abc.py needs to be in the PATH python searches for modules, but this way it doesn't have to be changed, and can be used by any program as an import, and started as python abc.py.

Â¹ The mv is necessary to get rid of the dot in the command name, but not really necessary, you can invoke ./abc.py if you don't rename it.   
"
5097,5097,8105,how to resolve LM358's huge error as a current sense differential amplifier,"Ive built a current sense differential amplifier that measures the voltage across a 1 Ohm resistor to give me a reading for the current through it.

Ive connected it as follows, all resistors are matched 10K to give a gain of 1:



I am powering it from a single rail 12 volt source. The problem is even though this is a rail to rail opamp (Output Low swing from 5-20mv) im getting a constant error of 0.62v and it seems the opamp is not able to go below this value. 

I have tired to resolve this by connected Vout to ground using a 10K resistor but that makes no difference what so ever.

I tried it with dual supply configuration (+8v,-8v) and that seems to resolve the issue. But i want to run this off a single supply rail so this is not a viable option.

How can i resolve this? Im trying to measure the voltage drop across a 1ohm resistor to give me a reading for current through the circuit (0-1v represents 0-1 Amp) so i can set up a current limit. A better way (or practice) to doing this is also welcomed.The initial (but not ideal) fix i can think of is to offset the readings by a few volts?

Edit:

Changed R1-R4 from 10K to 100K and im down to about 30-50mv! 
",Adil Malik,https://electronics.stackexchange.com/users/68900,"LM358 is not a rail-to-rail opamp (neither input nor output). 

The input CM range includes the negative rail and the output can swing close to the negative rail under the correct conditions, however this configuration passes current If to the output, and if that current exceeds (typically) about 50uA then the output can no longer swing all that close to the negative rail. This is all in the datasheet.

Your choices are to use a better op-amp (but it still will have to sink current so it can never get all the way to the negative rail) or create a negative supply. Up to you.  
",Spehro Pefhany,https://electronics.stackexchange.com/users/35530,http://electronics.stackexchange.com/questions/164137/how-to-resolve-lm358s-huge-error-as-a-current-sense-differential-amplifier,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,1.0,0.8888888888888888,How to solve the big error of lm358 current differential amplifier,"Ive built a current sense differential amplifier that measures the voltage across a 1 Ohm resistor to give me a reading for the current through it.

Ive connected it as follows, all resistors are matched 10K to give a gain of 1:



I am powering it from a single rail 12 volt source. The problem is even though this is a rail to rail opamp (Output Low swing from 5-20mv) im getting a constant error of 0.62v and it seems the opamp is not able to go below this value. 

I have tired to resolve this by connected Vout to ground using a 10K resistor but that makes no difference what so ever.

I tried it with dual supply configuration (+8v,-8v) and that seems to resolve the issue. But i want to run this off a single supply rail so this is not a viable option.

How can i resolve this? Im trying to measure the voltage drop across a 1ohm resistor to give me a reading for current through the circuit (0-1v represents 0-1 Amp) so i can set up a current limit. A better way (or practice) to doing this is also welcomed.The initial (but not ideal) fix i can think of is to offset the readings by a few volts?

Edit:

Changed R1-R4 from 10K to 100K and im down to about 30-50mv! 
","LM358 is not a rail-to-rail opamp (neither input nor output). 

The input CM range includes the negative rail and the output can swing close to the negative rail under the correct conditions, however this configuration passes current If to the output, and if that current exceeds (typically) about 50uA then the output can no longer swing all that close to the negative rail. This is all in the datasheet.

Your choices are to use a better op-amp (but it still will have to sink current so it can never get all the way to the negative rail) or create a negative supply. Up to you.  
"
2208,2208,3516,Two different analytic curves cannot intersect in infinitely many points,"A curve in Euclidean space $\mathbb{R}^n$, $n \geq 2$ is $analytic$ if the coordinates of its points $x= x_{1},...,x_{n}$ can be expressed as analytic functions of a real parameter $x_{i}=x_{i}(t)$, $i=1,...,n$ and $\alpha \leq t \leq \beta$ and the derivatives $x'(t_{0})$ do not simultaneously vanish for any $t_{0} \in [\alpha, \beta]$.
I search for a proof of the following fact:

If the set of intersection points of two analytic curves is infinite, then these curves coincide.

Can we prove the same as above if we relax the condition that the coordinates are analytic to the condition that the coordinates belong to the class $C^{\infty}$?

Edit: Thanks to below remark by Ramiro, to obtain the above implication, we have to assume that any two curves $K_{1}, K_{2}$ as in the question are such that $K_{1} \cap K_{2}$ is not another analytic curve.

2nd edit: As suggested Peter, we can reformulate our question as follows:
   Consider two immersed curves which are parameterized real analytically on compact intervals. If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
",Grzegorz Tomkowicz,https://mathoverflow.net/users/31376,"What about $t \mapsto (t,t)$ and $t \mapsto (t+1,t+1)$ for $t \in [0,2]$? They have infinite intersection but do not coincide.

On the positive side (following PeterÂ´s answer and NoamÂ´s comment), the set of $t$Â´s for which there is some $u$ such that $f(t)=g(u)$ is a finite union of points and intervals by the o-minimality of the structure involved.
",Ramiro de la Vega,https://mathoverflow.net/users/17836,http://mathoverflow.net/questions/121602,SCIENCE,mathoverflow.net,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.0,0.6666666666666666,1.0,Two different analytic curves cannot intersect at infinity,"A curve in Euclidean space $\mathbb{R}^n$, $n \geq 2$ is $analytic$ if the coordinates of its points $x= x_{1},...,x_{n}$ can be expressed as analytic functions of a real parameter $x_{i}=x_{i}(t)$, $i=1,...,n$ and $\alpha \leq t \leq \beta$ and the derivatives $x'(t_{0})$ do not simultaneously vanish for any $t_{0} \in [\alpha, \beta]$.
I search for a proof of the following fact:

If the set of intersection points of two analytic curves is infinite, then these curves coincide.

Can we prove the same as above if we relax the condition that the coordinates are analytic to the condition that the coordinates belong to the class $C^{\infty}$?

Edit: Thanks to below remark by Ramiro, to obtain the above implication, we have to assume that any two curves $K_{1}, K_{2}$ as in the question are such that $K_{1} \cap K_{2}$ is not another analytic curve.

2nd edit: As suggested Peter, we can reformulate our question as follows:
   Consider two immersed curves which are parameterized real analytically on compact intervals. If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
","What about $t \mapsto (t,t)$ and $t \mapsto (t+1,t+1)$ for $t \in [0,2]$? They have infinite intersection but do not coincide.

On the positive side (following PeterÂ´s answer and NoamÂ´s comment), the set of $t$Â´s for which there is some $u$ such that $f(t)=g(u)$ is a finite union of points and intervals by the o-minimality of the structure involved.
"
5113,5113,8132,How do I deal with a slow and undedicated colleague in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
",HOT,https://programmers.stackexchange.com/users/34092,"First and foremost: 


  Since he is my colleague, I couldn't tell anything to the manager.


You absolutely can and should make sure your manager knows the truth, even if your co-worker is lying to his face. If you don't want to say anything in a meeting with all 3 of you in the room, that's totally understandable. But you should at least pull your manager (the real one, not just the temp) aside and let them know that your work is almost done and is waiting on bug fixes from the other developer's end before the whole application is ready for prime-time. Don't accuse your co-worker of lying, but don't sit there and let your boss operate with incomplete information. 

Report your statuses honestly. If your work is being held up by bugs on another developer's end, document that you've found bugs in the C/C++ and have reported them (please tell me you're using some form of documentation that leaves a paper trail). 

In the meantime, go ahead and wrap up your work, and let your boss know when you're done. If your manager wants to know why the rest of the project isn't up and running yet, you can refer him to the other developer, and maybe mention that it's probably very complicated/large/requires a lot of testing/other developer is very busy/etc. If you know C/C++, you can offer to help on the main application logic to get things moving with that as well. Yes, you'll be doing the other guy's work, but it makes it clear that you're the employee working hard and being productive, and the other guy isn't, not to mention making you even more valuable to your boss. It may even put some pressure on the other developer to step things up and get them done quicker. 
",Eric Hydrick,https://programmers.stackexchange.com/users/28556,http://programmers.stackexchange.com/questions/101528/how-do-i-deal-with-a-slow-and-undedicated-colleague-in-the-team,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,How can I deal with a colleague who is slow-moving and lacks dedication in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
","First and foremost: 


  Since he is my colleague, I couldn't tell anything to the manager.


You absolutely can and should make sure your manager knows the truth, even if your co-worker is lying to his face. If you don't want to say anything in a meeting with all 3 of you in the room, that's totally understandable. But you should at least pull your manager (the real one, not just the temp) aside and let them know that your work is almost done and is waiting on bug fixes from the other developer's end before the whole application is ready for prime-time. Don't accuse your co-worker of lying, but don't sit there and let your boss operate with incomplete information. 

Report your statuses honestly. If your work is being held up by bugs on another developer's end, document that you've found bugs in the C/C++ and have reported them (please tell me you're using some form of documentation that leaves a paper trail). 

In the meantime, go ahead and wrap up your work, and let your boss know when you're done. If your manager wants to know why the rest of the project isn't up and running yet, you can refer him to the other developer, and maybe mention that it's probably very complicated/large/requires a lot of testing/other developer is very busy/etc. If you know C/C++, you can offer to help on the main application logic to get things moving with that as well. Yes, you'll be doing the other guy's work, but it makes it clear that you're the employee working hard and being productive, and the other guy isn't, not to mention making you even more valuable to your boss. It may even put some pressure on the other developer to step things up and get them done quicker. 
"
3121,3121,4974,Would it be possible to show line numbers as part of the pdf document,"Would it be possible to show line numbers as part of the pdf document. What option should I use?
",Joshua,https://superuser.com/users/39083,"I've found the following answer regarding your question. According to the second paragraph, it's almost impossible to do what you want.

Answer by user grantm on perlmonks.org:


  It may be possible - it depends
  on how the PDF was generated. If the
  option was used to convert text to
  curves then you're probably out of
  luck.
  
  Also the PDF file format has no
  concept of 'lines'. Characters in a
  particular font family, weight, size
  (etc) are placed at X/Y coordinates on
  the page. They can be placed in any
  order (ie: not just left-right, top to
  bottom).
  
  So if it were possible, one approach
  would be to find the y coordinate of
  every piece of text on the page;
  reduce that to a unique set; sort them
  and assign line numbers; go down and
  add the line numbers as text elements
  at the same y coordinate on the right
  hand side of the page.
  
  For the first part, you might find
  that the CAM::PDF module has some
  useful tools (eg: it can render just
  the text elements of a PDF page).
  Overlaying new text elements is the
  easy part. I tend to use
  PDF::Reuse but I'm sure that
  PDF::API2 could be used too.

",Mehper C. Palavuzlar,https://superuser.com/users/13567,http://superuser.com/questions/307156,TECHNOLOGY,superuser.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,1.0,Can line numbers be displayed in PDF documents,Whether the line number can be displayed as part of the PDF document. What options should I use?,"I've found the following answer regarding your question. According to the second paragraph, it's almost impossible to do what you want.

Answer by user grantm on perlmonks.org:


  It may be possible - it depends
  on how the PDF was generated. If the
  option was used to convert text to
  curves then you're probably out of
  luck.
  
  Also the PDF file format has no
  concept of 'lines'. Characters in a
  particular font family, weight, size
  (etc) are placed at X/Y coordinates on
  the page. They can be placed in any
  order (ie: not just left-right, top to
  bottom).
  
  So if it were possible, one approach
  would be to find the y coordinate of
  every piece of text on the page;
  reduce that to a unique set; sort them
  and assign line numbers; go down and
  add the line numbers as text elements
  at the same y coordinate on the right
  hand side of the page.
  
  For the first part, you might find
  that the CAM::PDF module has some
  useful tools (eg: it can render just
  the text elements of a PDF page).
  Overlaying new text elements is the
  easy part. I tend to use
  PDF::Reuse but I'm sure that
  PDF::API2 could be used too.

"
594,594,927,Are there any commercially available crystals in the sub 32 kHz range?,"I'm looking for a low power clocking solution and it looks like crystals bottom out at 32 kHz.  Are there any low power (nA) solutions (crystals/ceramic resonators/custom transistor oscillator circuitry) that operate on nanoAmps of power in the single digit kHz range or lower?

EDIT

I wanted to summarize the facts from the answers below as well as my own research:


Crystals do not commercially exist lower than the standard 32 kHz flavor, due to size/resonance constraints of the quartz used internally (thanks to Olin Lathrop)
For a 32 kHz clock solution in the 100s of nA range, this oscillator IC could be used (thanks to stevenvh)
For lower frequencies (but not necessarily nA current consumption) many silicon oscillators, frequency synthesizers, PLLs, or real time clocks include internal clock divider circuitry and can be used to generate clocks as ""slow"" as 1 Hz.


So there is no solution which satisfies both of the constraints of sub-32 kHz &amp; sub-\$\mu\$A operation, but individual solutions that will satisfy one or the other.
",Joel B,https://electronics.stackexchange.com/users/1571,"Some manufacturers refer to 100kHz ~ 1.8432MHz as ""very low frequency"". Below 100kHz you'll find only a few specific values like 77.5kHz for (DCF77 receivers) and of course the 32.768kHz watch crystal. You won't find standard crystals below 10kHz.
Nothing lost, by the way. They won't help you meeting your low power requirements, anyway. A crystal needs a certain power to maintain its oscillation, and if you look at the datasheets you'll often see drive levels in the order of 1mW.  

The lowest power microcontroller application using a crystal I designed was an MSP430 running at 32.768kHz, and that used 3\$\mu\$A, a thousand times your requirements.
This oscillator still uses 300nA, that's 0.3\$\mu\$A.
",stevenvh,https://electronics.stackexchange.com/users/2064,http://electronics.stackexchange.com/questions/16100/are-there-any-commercially-available-crystals-in-the-sub-32-khz-range,SCIENCE,electronics.stackexchange.com,0.3333333333333333,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Are there commercial crystals below 32 kHz?,"I'm looking for a low power clocking solution and it looks like crystals bottom out at 32 kHz.  Are there any low power (nA) solutions (crystals/ceramic resonators/custom transistor oscillator circuitry) that operate on nanoAmps of power in the single digit kHz range or lower?

EDIT

I wanted to summarize the facts from the answers below as well as my own research:


Crystals do not commercially exist lower than the standard 32 kHz flavor, due to size/resonance constraints of the quartz used internally (thanks to Olin Lathrop)
For a 32 kHz clock solution in the 100s of nA range, this oscillator IC could be used (thanks to stevenvh)
For lower frequencies (but not necessarily nA current consumption) many silicon oscillators, frequency synthesizers, PLLs, or real time clocks include internal clock divider circuitry and can be used to generate clocks as ""slow"" as 1 Hz.


So there is no solution which satisfies both of the constraints of sub-32 kHz &amp; sub-\$\mu\$A operation, but individual solutions that will satisfy one or the other.
","Some manufacturers refer to 100kHz ~ 1.8432MHz as ""very low frequency"". Below 100kHz you'll find only a few specific values like 77.5kHz for (DCF77 receivers) and of course the 32.768kHz watch crystal. You won't find standard crystals below 10kHz.
Nothing lost, by the way. They won't help you meeting your low power requirements, anyway. A crystal needs a certain power to maintain its oscillation, and if you look at the datasheets you'll often see drive levels in the order of 1mW.  

The lowest power microcontroller application using a crystal I designed was an MSP430 running at 32.768kHz, and that used 3\$\mu\$A, a thousand times your requirements.
This oscillator still uses 300nA, that's 0.3\$\mu\$A.
"
5435,5435,8627,"Learning the musical concepts in the book ""GÃ¶del, Escher, Bach""","I am reading the book ""GÃ¶del, Escher, Bach"", in which the author tries to present concepts in mathematics, drawings and music as instances of a certain ""pattern"", that he calls ""strange loops"". He makes several comments about Bach's music, in particular, as the title suggests. So, he talks about the fugues, sonatas and partitas, modulation, themes played against themselves, how Bach manages to get two or more musical lines going simultaneously and so on.

But I don't understand a thing about these musical concepts. I have tried to listen on YouTube to some of the compositions he mentions in the book, but my stupid brain only hears a stream of notes flowing. I can't recognize the patterns he talks about, nor can I grasp, for example, the fact the the ""Canon per Tonos"" rises successively until it reaches the key C again. 

So how can I learn more about these musical concepts, so as to better follow the book's main ideas? To make this question narrower, I'm not asking for general references to learn about music, but something very specific to the content of the book, so that I don't miss important information (and fun) from his exposition.
",Otavio Macedo,https://music.stackexchange.com/users/12666,"As someone who has no formal training in music whatsoever but who fell in love with Beethoven and Bach upon hearing them, I discovered that my visual senses are much better at picking out patterns than my auditory senses. Here is a rendition of Bach's great fugue BWV 542 which shows it all to you while sacrificing none of the auditory pleasures derived from hearing this work.

Sometimes just visually looking at what's being played is all you need. The patterns are just so obvious when you hear them AND see them. In this case you'll see what a fugue is and a few of the things Bach is doing with the main melody. You will quite literally see the individual voices. I recommend playing this a few times and focusing on one voice so that you can see and hear what it is doing.

Here is his Fugue BWV 565. In general I recommend any MIDI viewing program and then you can get free MIDIs (for example here), open them up in your favorite MIDI viewer and view the piano roll. There are plenty of paid ones of course but the one I like is called Synthesia which has a pretty good free version and it does everything I need it for. And here is a sample of what Synthesia does. I am still ridiculously slow at sight reading but using MIDI viewers, I can now play my favorite pieces from Bach, Beethoven, Chopin, and Mozart for my own pleasure.
",Fixed Point,https://music.stackexchange.com/users/6200,http://music.stackexchange.com/questions/22216/learning-the-musical-concepts-in-the-book-g%C3%B6del-escher-bach,LIFE_ARTS,music.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,1.0,"Learning the concept of music in Godel, Escher and Bach","I am reading the book ""GÃ¶del, Escher, Bach"", in which the author tries to present concepts in mathematics, drawings and music as instances of a certain ""pattern"", that he calls ""strange loops"". He makes several comments about Bach's music, in particular, as the title suggests. So, he talks about the fugues, sonatas and partitas, modulation, themes played against themselves, how Bach manages to get two or more musical lines going simultaneously and so on.

But I don't understand a thing about these musical concepts. I have tried to listen on YouTube to some of the compositions he mentions in the book, but my stupid brain only hears a stream of notes flowing. I can't recognize the patterns he talks about, nor can I grasp, for example, the fact the the ""Canon per Tonos"" rises successively until it reaches the key C again. 

So how can I learn more about these musical concepts, so as to better follow the book's main ideas? To make this question narrower, I'm not asking for general references to learn about music, but something very specific to the content of the book, so that I don't miss important information (and fun) from his exposition.
","As someone who has no formal training in music whatsoever but who fell in love with Beethoven and Bach upon hearing them, I discovered that my visual senses are much better at picking out patterns than my auditory senses. Here is a rendition of Bach's great fugue BWV 542 which shows it all to you while sacrificing none of the auditory pleasures derived from hearing this work.

Sometimes just visually looking at what's being played is all you need. The patterns are just so obvious when you hear them AND see them. In this case you'll see what a fugue is and a few of the things Bach is doing with the main melody. You will quite literally see the individual voices. I recommend playing this a few times and focusing on one voice so that you can see and hear what it is doing.

Here is his Fugue BWV 565. In general I recommend any MIDI viewing program and then you can get free MIDIs (for example here), open them up in your favorite MIDI viewer and view the piano roll. There are plenty of paid ones of course but the one I like is called Synthesia which has a pretty good free version and it does everything I need it for. And here is a sample of what Synthesia does. I am still ridiculously slow at sight reading but using MIDI viewers, I can now play my favorite pieces from Bach, Beethoven, Chopin, and Mozart for my own pleasure.
"
129,129,204,What is the best way for a user to select an item by unique identifier?,"My team and I are building a mobile app where the user will need to input a human-readable unique identifier (the serial number) of a single unit of inventory. Our system tracks the serial numbers that the user can access. We have considered three possible input modes:

1. We show the user the entire list of serial numbers they can access and allow him to select one from the list (like how a select element would work on an HTML page).

Pros:


The user doesn't have to type anything in.
The user can't enter an invalid serial number.


Cons:


The list is likely to be overwhelmingly large.
The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Data usage for downloading the entire list of serial numbers


2. We allow the user to start entering the serial number in a text input and have an auto-suggest drop-down with a filtered list of serial numbers the user can access.

Pros:


The user doesn't have to type in a complete serial number.
The user is unlikely to enter an invalid serial number.
Smaller list to choose from than Option 1.


Cons:


The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Auto-suggest may have limited value since the unit has a barcode that we could read.
Data usage for downloading a sizable list of serial numbers


3. We require the entire serial number to be entered, and once we recognize the correct number of characters, we validate the serial number against the user's accessible list and show feedback.

Pros:


The unit has a barcode that we could read, so this has the potential to be simpler than an auto-suggest or select-from-list paradigm.
Simpler implementation
Significantly reduced data usage vs. Option 1 and Option 2


Cons:


The unit has multiple barcodes, so it might take a couple of tries for the user to capture the correct one.
Typing manually would be tedious if the camera is unavailable or barcode scanner isn't working for whatever reason (lighting, etc.)


Which of these three is the best approach? Is there a better approach than what we have considered?
",Nick Saunders,https://ux.stackexchange.com/users/50391,"We provide retail and stock control systems so accurate capture of barcodes and serial numbers at high speed is important to us. For what its worth, here's what we do, but our target market might be slightly different to yours.

Use a barcode scanner. There are bluetooth ones that interface easily to most mobile devices. Of course this costs the end user money so might not be an option.

Allow use of camera to capture barcode and/or OCR. Not that hard programming wise but is not actually that fast overall. Good for consumers but not a receiving dock. (Nb quality of cameras varies by device, so this does not work for all devices) Despite some drawbacks for high volume use, cameras do allow us to keep a photo as proof of entry forever, which is useful.

If keyboard entry is required, we present a text box input and display a series of tiles with valid options that can be pressed.  The list of tiles changes dynamically on every keystroke. We find the tiles are better than a classic drop list as (a) bigger and easier to press (b) let us display a bit more info such as description (c) have more options to colour code the background as a signal too.

Personally I would not just display a list of barcodes, try and display something else to help the user. As DaveAlger says in his answer barcodes and serial numbers aren't designed for humans. Display a product description, date it was first seen, anything.

For barcodes, the most useful parts are generally the first and last few characters. We allow users to enter any characters they can see in the barcode, skipping whatever they wish. They just cannot jumble the order.  If you are using sql, and my input is ""9412"" then the query is something like 

 Select ... From barcodes where barcode like '%9%4%1%2%'


Rather than the typically used

 Select ... From barcodes where barcode like '9412%'


Once users learn this, and it isn't obvious I admit, they really appreciate it.  Try reading 94100000000192 and entering it correctly. This technique means I can just enter 941192 and picklist will show it.

(Actually, we use both the above sql queries with the second sql doing the first half the results and the other doing all remaining gaps. This is to ensure the order looks right to users, but the second sql quickly resolves to no records as users enter more characters.)

We put a lot of effort into making the pick list tiles as relevant as possible, eg if you just used supplier #1, then barcodes from supplier number #1 have higher priority. Not sure this will be possible for you, but sometimes it is.  Imagine you are entering serial numbers of watches. After the user has entered ""9412"", you may know that the only brands possible (with 9412) are Seiko and Swatch, so two buttons appear on the pick list to select these as an additional filter if the user wishes. Lots of work to make this seemless, but for us 1/4 second and less friction from user entry is worth the effort.
",rlb,https://ux.stackexchange.com/users/35356,http://ux.stackexchange.com/questions/77187/what-is-the-best-way-for-a-user-to-select-an-item-by-unique-identifier,TECHNOLOGY,ux.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,0.3333333333333333,1.0,0.0,1.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,What is the best way for users to select items by unique identifier?,"My team and I are building a mobile app where the user will need to input a human-readable unique identifier (the serial number) of a single unit of inventory. Our system tracks the serial numbers that the user can access. We have considered three possible input modes:

1. We show the user the entire list of serial numbers they can access and allow him to select one from the list (like how a select element would work on an HTML page).

Pros:


The user doesn't have to type anything in.
The user can't enter an invalid serial number.


Cons:


The list is likely to be overwhelmingly large.
The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Data usage for downloading the entire list of serial numbers


2. We allow the user to start entering the serial number in a text input and have an auto-suggest drop-down with a filtered list of serial numbers the user can access.

Pros:


The user doesn't have to type in a complete serial number.
The user is unlikely to enter an invalid serial number.
Smaller list to choose from than Option 1.


Cons:


The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Auto-suggest may have limited value since the unit has a barcode that we could read.
Data usage for downloading a sizable list of serial numbers


3. We require the entire serial number to be entered, and once we recognize the correct number of characters, we validate the serial number against the user's accessible list and show feedback.

Pros:


The unit has a barcode that we could read, so this has the potential to be simpler than an auto-suggest or select-from-list paradigm.
Simpler implementation
Significantly reduced data usage vs. Option 1 and Option 2


Cons:


The unit has multiple barcodes, so it might take a couple of tries for the user to capture the correct one.
Typing manually would be tedious if the camera is unavailable or barcode scanner isn't working for whatever reason (lighting, etc.)


Which of these three is the best approach? Is there a better approach than what we have considered?
","We provide retail and stock control systems so accurate capture of barcodes and serial numbers at high speed is important to us. For what its worth, here's what we do, but our target market might be slightly different to yours.

Use a barcode scanner. There are bluetooth ones that interface easily to most mobile devices. Of course this costs the end user money so might not be an option.

Allow use of camera to capture barcode and/or OCR. Not that hard programming wise but is not actually that fast overall. Good for consumers but not a receiving dock. (Nb quality of cameras varies by device, so this does not work for all devices) Despite some drawbacks for high volume use, cameras do allow us to keep a photo as proof of entry forever, which is useful.

If keyboard entry is required, we present a text box input and display a series of tiles with valid options that can be pressed.  The list of tiles changes dynamically on every keystroke. We find the tiles are better than a classic drop list as (a) bigger and easier to press (b) let us display a bit more info such as description (c) have more options to colour code the background as a signal too.

Personally I would not just display a list of barcodes, try and display something else to help the user. As DaveAlger says in his answer barcodes and serial numbers aren't designed for humans. Display a product description, date it was first seen, anything.

For barcodes, the most useful parts are generally the first and last few characters. We allow users to enter any characters they can see in the barcode, skipping whatever they wish. They just cannot jumble the order.  If you are using sql, and my input is ""9412"" then the query is something like 

 Select ... From barcodes where barcode like '%9%4%1%2%'


Rather than the typically used

 Select ... From barcodes where barcode like '9412%'


Once users learn this, and it isn't obvious I admit, they really appreciate it.  Try reading 94100000000192 and entering it correctly. This technique means I can just enter 941192 and picklist will show it.

(Actually, we use both the above sql queries with the second sql doing the first half the results and the other doing all remaining gaps. This is to ensure the order looks right to users, but the second sql quickly resolves to no records as users enter more characters.)

We put a lot of effort into making the pick list tiles as relevant as possible, eg if you just used supplier #1, then barcodes from supplier number #1 have higher priority. Not sure this will be possible for you, but sometimes it is.  Imagine you are entering serial numbers of watches. After the user has entered ""9412"", you may know that the only brands possible (with 9412) are Seiko and Swatch, so two buttons appear on the pick list to select these as an additional filter if the user wishes. Lots of work to make this seemless, but for us 1/4 second and less friction from user entry is worth the effort.
"
3270,3270,5210,How does postgrey handle changing FQDNs?,"Let's say I receive emails from the following clients:

mail2.dx300.mail.net
mail4.dx121.mail.net
mail5.dx121.mail.net

Even though these are all from the same service (e.g. LinkedIn or MailChimp), postgrey sees them as entirely different clients. How can I configure postgrey to just look at the domain (mail.net), not the FQDN?
",CaptSaltyJack,https://serverfault.com/users/148247,"The reason Postgrey sees them as different clients is simply because they are. Each is a Different server with a unique ip-address and hostname. 

Unless you add them to a whitelist first  they each have to prove they behave like a proper smtp daemon. 

But if they all are trusted clients you do not have to individually add them to the whitelist, you have the following options:

# Whitelist the whole domain
example.com
mail.net

# Use Regular Expressions 
/^mail[0-9].dx[0-9]{3}.mail.net$/

# Use CIDR IP Addresses:
10.9.8.0/24

",HBruijn,https://serverfault.com/users/37681,http://serverfault.com/questions/613743,TECHNOLOGY,serverfault.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.7777777777777778,How does postgrey handle changing fqdns?,"Let's say I receive emails from the following clients:

mail2.dx300.mail.net
mail4.dx121.mail.net
mail5.dx121.mail.net

Even though these are all from the same service (e.g. LinkedIn or MailChimp), postgrey sees them as entirely different clients. How can I configure postgrey to just look at the domain (mail.net), not the FQDN?
","The reason Postgrey sees them as different clients is simply because they are. Each is a Different server with a unique ip-address and hostname. 

Unless you add them to a whitelist first  they each have to prove they behave like a proper smtp daemon. 

But if they all are trusted clients you do not have to individually add them to the whitelist, you have the following options:

# Whitelist the whole domain
example.com
mail.net

# Use Regular Expressions 
/^mail[0-9].dx[0-9]{3}.mail.net$/

# Use CIDR IP Addresses:
10.9.8.0/24

"
1246,1246,1958,Preventing player passivity in GUMSHOE?,"I really like the game worlds of the various GUMSHOE games I have (Fear Itself, Esoterrorists, Mutant City Blues) but haven't run it yet.  My big concern is that I've seen the ""ablative skill system"" kind of mechanic work very poorly in other games - players hoard their ""uses,"" or use them all and then sit on their hands during the latter part of the game session because they know they're not going to be able to succeed at anything and trying will just get them killed.  

In GUMSHOE, your skills are a ""pool"" of points that you spend either for benefits or for adds to the dice when testing.  You basically roll d6 + spend vs a difficulty, typically 4 for general stuff but often going higher.  Fighting works the same way, so if you have a Scuffling pool of 8, once you've used them all, you know you won't live through any meaningful combat.  

For those that have run GUMSHOE or similar ablative systems, do you find that happening, and what are ways to avoid it?  I mean, I don't mind trying to capture the ""downward spiral"" but it risks characters just checking out if they don't think whatever plot is at hand is really worth all their lives.  ""Let's try to save her next session..."" 
",mxyzplk,https://rpg.stackexchange.com/users/140,"Tell them to spend Investigative at every opportunity. It's like Monopoly in that respect - if you land, you buy. Being allowed a spend is a reward.

The resource that you are managing is really spotlight time. General skills? That's different. If they are avoiding combat to save points for later, that's all good.
",Simon Rogers,https://rpg.stackexchange.com/users/826,http://rpg.stackexchange.com/questions/2311/preventing-player-passivity-in-gumshoe,CULTURE,rpg.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,0.8,1.0,0.0,0.0,1.0,Prevent players from being passive in rubber shoes?,"I really like the game worlds of the various GUMSHOE games I have (Fear Itself, Esoterrorists, Mutant City Blues) but haven't run it yet.  My big concern is that I've seen the ""ablative skill system"" kind of mechanic work very poorly in other games - players hoard their ""uses,"" or use them all and then sit on their hands during the latter part of the game session because they know they're not going to be able to succeed at anything and trying will just get them killed.  

In GUMSHOE, your skills are a ""pool"" of points that you spend either for benefits or for adds to the dice when testing.  You basically roll d6 + spend vs a difficulty, typically 4 for general stuff but often going higher.  Fighting works the same way, so if you have a Scuffling pool of 8, once you've used them all, you know you won't live through any meaningful combat.  

For those that have run GUMSHOE or similar ablative systems, do you find that happening, and what are ways to avoid it?  I mean, I don't mind trying to capture the ""downward spiral"" but it risks characters just checking out if they don't think whatever plot is at hand is really worth all their lives.  ""Let's try to save her next session..."" 
","Tell them to spend Investigative at every opportunity. It's like Monopoly in that respect - if you land, you buy. Being allowed a spend is a reward.

The resource that you are managing is really spotlight time. General skills? That's different. If they are avoiding combat to save points for later, that's all good.
"
5302,5302,8420,How long should the hot water last during a shower?,"Given a 40 gallon natural gas water heater, and a shower head with a flow rate of 2.5 gallons per minute. How long should the shower be able to maintain 105Â°F water temperature?

Assume the average cold water supply temperature is 58.7Â°F. The tank will be set at 140Â°F, to avoid Legionella. The tank recovery is typical of a natural gas heater, so it can recover its volume in an hour (40 gph in this case).
",Tester101,https://diy.stackexchange.com/users/33,"Model the water heater as a continuously stirred tank reactor (CSTR), so it is always at a uniform temperature. Assume the recovery time is not dependent on temperature and completely accounts for insulation losses and the like. Neglect losses in pipes and assume the operator controls the shower temperature to 105Â°F perfectly. Taking the stopping criterion from the question, the shower is over when the water in the tank becomes 105Â°F.

The recovery rate raises 140 gallons of water by 81.3Â°F in one hour. We'll say this is a constant heat input of 9118 W.

The key is that a constant-temperature shower removes a constant rate of heat from the tank, that which is associated with raising 2.5Â gpm of water from 58.7Â°F to 105Â°F. This is 16986.5Â W.

The difference is 7868.5Â W. With constant heat, you don't need any complicated integrals.



The time for the tank to drop from 140Â°F to 105Â°F is 1568Â s or 26 minutes.

The (maybe counterintuitive) fact that the variable flow rate from the water heater does not influence the rate of heat removal from the water heater comes from the fact that the incoming cold water is the same temperature at the shower and at the water heater.



Note that, because  does not appear in the expression for ,  is now a constant.
",ArgentoSapiens,https://diy.stackexchange.com/users/5804,http://diy.stackexchange.com/questions/52567/how-long-should-the-hot-water-last-during-a-shower,LIFE_ARTS,diy.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,How long should hot water be used in the shower?,"Given a 40 gallon natural gas water heater, and a shower head with a flow rate of 2.5 gallons per minute. How long should the shower be able to maintain 105Â°F water temperature?

Assume the average cold water supply temperature is 58.7Â°F. The tank will be set at 140Â°F, to avoid Legionella. The tank recovery is typical of a natural gas heater, so it can recover its volume in an hour (40 gph in this case).
","Model the water heater as a continuously stirred tank reactor (CSTR), so it is always at a uniform temperature. Assume the recovery time is not dependent on temperature and completely accounts for insulation losses and the like. Neglect losses in pipes and assume the operator controls the shower temperature to 105Â°F perfectly. Taking the stopping criterion from the question, the shower is over when the water in the tank becomes 105Â°F.

The recovery rate raises 140 gallons of water by 81.3Â°F in one hour. We'll say this is a constant heat input of 9118 W.

The key is that a constant-temperature shower removes a constant rate of heat from the tank, that which is associated with raising 2.5Â gpm of water from 58.7Â°F to 105Â°F. This is 16986.5Â W.

The difference is 7868.5Â W. With constant heat, you don't need any complicated integrals.



The time for the tank to drop from 140Â°F to 105Â°F is 1568Â s or 26 minutes.

The (maybe counterintuitive) fact that the variable flow rate from the water heater does not influence the rate of heat removal from the water heater comes from the fact that the incoming cold water is the same temperature at the shower and at the water heater.



Note that, because  does not appear in the expression for ,  is now a constant.
"
3637,3637,5805,Get an item in a list of taxonomy,"Hello Drupal Community,

I am creating a menu which has a link to an ""editorial"". I created a taxonomy named ""edito"" and created articles (content type) that are tagged with this taxonomy. 

I need to recover the last article tagged with this taxonomy in the menu as a link (see image attached). Does anyone have an idea of how to achieve this ?

Thanks,
",Ismail H,https://drupal.stackexchange.com/users/46285,"You should not try to hard-code the URL to the item in the menu item edit screen.

You should add a View to your Menu.

Views allows you create a view including a filter to show only recent content.



You can then add a filter for a specific Content Type, User or whatever. And you can limit the View to show only N items.

You can insert the View of new items into your menu with the help of 3rd party modules, an example is Menu Attach Block, see the project page for a list of similar helper modules.
",tenken,https://drupal.stackexchange.com/users/3279,http://drupal.stackexchange.com/questions/165774/get-an-item-in-a-list-of-taxonomy,TECHNOLOGY,drupal.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,Get items in the category list,"Hello Drupal Community,

I am creating a menu which has a link to an ""editorial"". I created a taxonomy named ""edito"" and created articles (content type) that are tagged with this taxonomy. 

I need to recover the last article tagged with this taxonomy in the menu as a link (see image attached). Does anyone have an idea of how to achieve this ?

Thanks,
","You should not try to hard-code the URL to the item in the menu item edit screen.

You should add a View to your Menu.

Views allows you create a view including a filter to show only recent content.



You can then add a filter for a specific Content Type, User or whatever. And you can limit the View to show only N items.

You can insert the View of new items into your menu with the help of 3rd party modules, an example is Menu Attach Block, see the project page for a list of similar helper modules.
"
4190,4190,6682,Why do I have house flies in my carport?,"I bought my home in early September 2012. I noticed that flies were flocking around a light in my open air carport whether it was on or off. I tried a few products like fly tape, spray and a fly trap. Still no results. This continued through fall until temps dropped. This Spring I thought I would take preventive measures and cleaned my entire carport with Lysol including my garbage cans which are new. But still flies are flocking around this light. Its strange, they don't land on it that much as if there were some food source. They just fly around it all day until the sun goes down and even then there are a few stragglers. I would say at peak during the day there are about 150 to 200 flies. Why are they attracted to this area and What do I do to get rid of them? 
",Zach G,https://diy.stackexchange.com/users/13243,"Is it possible that these are not your regular house flies but instead something called a cluster fly?



I've seen these flies make a nuisance of themselves in the ceiling of one house of a friend.  He had to get it fumigated.  After that, no problems.  

Is your carport right next to your house?  is the light attached to the carport or to the house?  Could there be a little nest in there somewhere?
",Matt,https://diy.stackexchange.com/users/13136,http://diy.stackexchange.com/questions/28274/why-do-i-have-house-flies-in-my-carport,LIFE_ARTS,diy.stackexchange.com,1.0,0.5555555555555556,0.0,0.5,0.6666666666666666,0.5,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,1.0,0.7777777777777778,0.4444444444444444,1.0,1.0,0.6666666666666667,0.0,0.0,1.0,0.8888888888888888,Why do I have houseflies in my garage?,"I bought a house in early September 2012. I noticed that flies were flying around a light in my open garage, whether it was on or off. I have tried some products, such as anti fly tape, sprayer and anti fly device. There is still no result. This continued until autumn, when the temperature dropped. This spring, I think I'll take precautions to clean the whole shed with lysine, including my new trash can. But there are still flies flying around in the light. Strangely, they didn't land on it, as if they had a source of food. They fly around it all day until the sun goes down. Even so, there are some scattered people. I think there are about 150 to 200 flies at the peak of the day. Why are they attracted to this area and what can I do to get rid of them?","Is it possible that these are not your regular house flies but instead something called a cluster fly?



I've seen these flies make a nuisance of themselves in the ceiling of one house of a friend.  He had to get it fumigated.  After that, no problems.  

Is your carport right next to your house?  is the light attached to the carport or to the house?  Could there be a little nest in there somewhere?
"
5562,5562,8835,Drupal 7 - Node Clone Alternatives,"just want to ask if there are any other suggested alternatives for cloning a node for drupal 7. Now I know most of you will answer ""Node Clone Module"", but is there any other module out there that can do the same thing? Thanks.
",Marky,https://drupal.stackexchange.com/users/17882,"""Drupal way"" is to collaborate, not compete. It means that anyone wanting to write his own cloning solution will be asked to cooperate with author of existing one to provide what he finds lacking. Only if that's not possible, and some basic differences in approach or expected results are found, community will welcome new module. Otherwise it'll just die silently, unloved.

That said, you can use node exporting and importing tools to export nodes, edit them or not and import again, possibly under new nid. Node export is example of modules that can do that. Probably there are other ways to get content duplicated, and if you can think of basically different scenario, there is a big chance someone got that implemented.
",MoÅot,https://drupal.stackexchange.com/users/16495,http://drupal.stackexchange.com/questions/74529/drupal-7-node-clone-alternatives,TECHNOLOGY,drupal.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,1.0,Drupal 7-node clone alternative,"I just want to ask if there are other suggested ways to clone nodes of Drupal 7. Now I know that most of you will answer ""node cloning module"", but is there any other module that can do the same thing? Thank you.","The Drupal approach is collaboration, not competition. This means that anyone who wants to write their own cloning solution will be asked to work with existing authors to provide what they lack. The community will welcome new modules only if this is not possible and some basic differences are found in methods or expected results. Otherwise it will die quietly and not be loved."
1309,1309,2063,Resume and Pause Mechanism,"I am working on this application for Android it is called Button Chaser. I have to crate a pause and resume mechanism . I created the pause mechanism and it works just fine, but I am having trouble creating the Resume one. how can I make the resume mechanism? This is my code:     

package com.example.buttonchaser;

import java.util.Random;
import java.util.Timer;

import android.support.v7.app.ActionBarActivity;
import android.os.Bundle;
import android.view.*;
import android.widget.*;
import android.graphics.Point;
import android.view.View.OnClickListener;


public class ButtonChaserActivity extends ActionBarActivity implements OnClickListener{
private Button btn;

private TextView lblScore;
private Timer timer;
private int x, y, w, h, score;
ButtonChaserTimerTask task;

@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_button_chaser);
    //Inflate UI
    btn = (Button)findViewById(R.id.btn);
    lblScore = (TextView)findViewById(R.id.lblScore);

    btn.setOnClickListener(this);
    Display display = getWindowManager().getDefaultDisplay();
    Point size = new Point();
    display.getSize(size);
    w = size.x - btn.getWidth() - 48;
    h = size.y - btn.getHeight() - 48;
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 1500);

}



@Override
public boolean onCreateOptionsMenu(Menu menu) {
    // Inflate the menu; this adds items to the action bar if it is present.
    getMenuInflater().inflate(R.menu.button_chaser, menu);
    return true;
}

@Override
public boolean onOptionsItemSelected(MenuItem item) {
    // Handle action bar item clicks here. The action bar will
    // automatically handle clicks on the Home/Up button, so long
    // as you specify a parent activity in AndroidManifest.xml.
    switch(item.getItemId()){
        case R.id.mnuEasy:
            newGame();
            return true;
        case R.id.mnuMed:
            medGame();
            return true;
        case R.id.mnuHard:
            hardGame();
            return true;
        case R.id.mnuNew:
        newGame();
        return true;
    case R.id.mnuQuit:
        quit();
        return true;

    default:
        return super.onOptionsItemSelected(item);
    }
}

public void newGame(){
    score = 0;
    lblScore.setText(""Score: "" + score);
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 1500);
}
public void medGame(){
    score = 0;
    lblScore.setText(""Score: "" + score);
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 500);
}
public void hardGame(){
    score = 0;
    lblScore.setText(""Score: "" + score);
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 250);
}

public void quit(){
    timer.cancel();
    finish();
}

public void moveButton(){
    Random generator = new Random();
    generator.setSeed(System.currentTimeMillis());
    float f = generator.nextFloat();
    x = (int)(f*w)%w;
    f = generator.nextFloat();
    y = (int)(f*h)%h;
    btn.setX(x);
    btn.setY(y);
}

public void pauseOnClick(View view) {
    Button pause = (Button) view;
    ((Button)view).setText(""Resume"");
        timer.cancel();}

        //((Button)view).setText(""Pause"");
        //moveButton();





@Override
public void onClick(View v) {
    score +=1;
    lblScore.setText(""Score: "" + score);

}
}

",GT123,https://stackoverflow.com/users/4233888,"You can add onPause and onResume methods:

@Override
public void onPause() {

}


and

@Override
public void onResume() {

}


Then put your pausing code and your resuming code in the proper section.
",26hmkk,https://stackoverflow.com/users/2165980,http://stackoverflow.com/questions/27586041/resume-and-pause-mechanism,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Recovery and suspension mechanism,"I am working on this application for Android it is called Button Chaser. I have to crate a pause and resume mechanism . I created the pause mechanism and it works just fine, but I am having trouble creating the Resume one. how can I make the resume mechanism? This is my code:     

package com.example.buttonchaser;

import java.util.Random;
import java.util.Timer;

import android.support.v7.app.ActionBarActivity;
import android.os.Bundle;
import android.view.*;
import android.widget.*;
import android.graphics.Point;
import android.view.View.OnClickListener;


public class ButtonChaserActivity extends ActionBarActivity implements OnClickListener{
private Button btn;

private TextView lblScore;
private Timer timer;
private int x, y, w, h, score;
ButtonChaserTimerTask task;

@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_button_chaser);
    //Inflate UI
    btn = (Button)findViewById(R.id.btn);
    lblScore = (TextView)findViewById(R.id.lblScore);

    btn.setOnClickListener(this);
    Display display = getWindowManager().getDefaultDisplay();
    Point size = new Point();
    display.getSize(size);
    w = size.x - btn.getWidth() - 48;
    h = size.y - btn.getHeight() - 48;
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 1500);

}



@Override
public boolean onCreateOptionsMenu(Menu menu) {
    // Inflate the menu; this adds items to the action bar if it is present.
    getMenuInflater().inflate(R.menu.button_chaser, menu);
    return true;
}

@Override
public boolean onOptionsItemSelected(MenuItem item) {
    // Handle action bar item clicks here. The action bar will
    // automatically handle clicks on the Home/Up button, so long
    // as you specify a parent activity in AndroidManifest.xml.
    switch(item.getItemId()){
        case R.id.mnuEasy:
            newGame();
            return true;
        case R.id.mnuMed:
            medGame();
            return true;
        case R.id.mnuHard:
            hardGame();
            return true;
        case R.id.mnuNew:
        newGame();
        return true;
    case R.id.mnuQuit:
        quit();
        return true;

    default:
        return super.onOptionsItemSelected(item);
    }
}

public void newGame(){
    score = 0;
    lblScore.setText(""Score: "" + score);
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 1500);
}
public void medGame(){
    score = 0;
    lblScore.setText(""Score: "" + score);
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 500);
}
public void hardGame(){
    score = 0;
    lblScore.setText(""Score: "" + score);
    timer = new Timer();
    task = new ButtonChaserTimerTask(this);
    timer.schedule(task, 0, 250);
}

public void quit(){
    timer.cancel();
    finish();
}

public void moveButton(){
    Random generator = new Random();
    generator.setSeed(System.currentTimeMillis());
    float f = generator.nextFloat();
    x = (int)(f*w)%w;
    f = generator.nextFloat();
    y = (int)(f*h)%h;
    btn.setX(x);
    btn.setY(y);
}

public void pauseOnClick(View view) {
    Button pause = (Button) view;
    ((Button)view).setText(""Resume"");
        timer.cancel();}

        //((Button)view).setText(""Pause"");
        //moveButton();





@Override
public void onClick(View v) {
    score +=1;
    lblScore.setText(""Score: "" + score);

}
}

","You can add onPause and onResume methods:

@Override
public void onPause() {

}


and

@Override
public void onResume() {

}


Then put your pausing code and your resuming code in the proper section.
"
2952,2952,4696,Etiquette for posting civil and informative comments,"Sometimes I leave a comment like ""Stack Overflow is not your personal research assistant,"" but am accused of being rude.  How can I craft a comment that is seen as civil to the community and instructive to the OP?


What tone should I strike in comments?
What are some examples of bad comments and their better replacements?

",Robert Harvey,https://meta.stackexchange.com/users/102937,"Assume that the person you are replying to is not intentionally clueless/lazy.

Answer them the way you'd want someone to answer you if you accidentally posted something that sounded clueless/lazy (even though you know you're not like that IRL).

Assume the best of them, not the worst.

Civillity = respect + benefit of doubt

So you don't have to get florid, just refrain from answering as though the OP is annoying you on purpose.
",spongefile,https://meta.stackexchange.com/users/169889,http://meta.stackexchange.com/questions/138173/etiquette-for-posting-civil-and-informative-comments,TECHNOLOGY,meta.stackexchange.com,1.0,0.5,0.0,0.0,0.5,0.0,0.8333333333333334,0.8333333333333334,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.5,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.5,0.5,1.0,Etiquette for making civilized and informative comments,"Sometimes I leave a comment like, ""stack overflow is not your personal research assistant,"" but it will be accused of being rude. How can I write a comment that is considered polite to the community and instructive to the op?","Assume that the person you are replying to is not intentionally clueless/lazy.

Answer them the way you'd want someone to answer you if you accidentally posted something that sounded clueless/lazy (even though you know you're not like that IRL).

Assume the best of them, not the worst.

Civillity = respect + benefit of doubt

So you don't have to get florid, just refrain from answering as though the OP is annoying you on purpose.
"
5625,5625,8920,how to install .net framework? if not already installed using autorun.inf,"I need the file autorun.inf with this content:

[autorun]
open=file.bat
icon=icon.ico


and file.bat with this content for detect setup.exe and framework4 (if the last don't exist):

REG HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full /v Version :rechek 
IF %errorlevel%==0 GOTO INSTALL start setup.exe exit GOTO eof :INSTALL dotNetFx40_Full_x86_x64.exe GOTO rechek


What is the error in the file .bat file?
",malrios,https://stackoverflow.com/users/4403196,"Here is a not tested batch code which makes more sense then your batch code:

@echo off
setlocal
set ""RetryCount=0""
:ReCheckFramework
%SystemRoot%\System32\reg.exe query ""HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full"" /v Version&gt;nul 2&gt;nul 
if not errorlevel 1 goto EndFrameworkInstall
start ""Install FrameWork"" /wait dotNetFx40_Full_x86_x64.exe
set /A RetryCount+=1
if %RetryCount% LSS 3 goto ReCheckFramework
:EndFrameworkInstall
endlocal


Testing a batch file should be always done by opening a command prompt window and running the batch file from within this console window. Then syntax errors and errors on parameter list of commands and applications can be easily seen.

reg.exe requires as first parameter the action to do, here query. And you forget the double quotes around registry key as it contains spaces.

Also writing nearly all commands in one line is also wrong.

Well, best would be to really check version of installed .NET Framework 4 in case of a newer version is already installed then what is put on CD/DVD.
",Mofi,https://stackoverflow.com/users/3074564,http://stackoverflow.com/questions/30463625/how-to-install-net-framework-if-not-already-installed-using-autorun-inf,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,1.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.4444444444444444,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,1.0,How do I install the. Net framework? If you have not already installed with autorun.inf,"I need the file autorun.inf with this content:

[autorun]
open=file.bat
icon=icon.ico


and file.bat with this content for detect setup.exe and framework4 (if the last don't exist):

REG HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full /v Version :rechek 
IF %errorlevel%==0 GOTO INSTALL start setup.exe exit GOTO eof :INSTALL dotNetFx40_Full_x86_x64.exe GOTO rechek


What is the error in the file .bat file?
","Here is a not tested batch code which makes more sense then your batch code:

@echo off
setlocal
set ""RetryCount=0""
:ReCheckFramework
%SystemRoot%\System32\reg.exe query ""HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full"" /v Version&gt;nul 2&gt;nul 
if not errorlevel 1 goto EndFrameworkInstall
start ""Install FrameWork"" /wait dotNetFx40_Full_x86_x64.exe
set /A RetryCount+=1
if %RetryCount% LSS 3 goto ReCheckFramework
:EndFrameworkInstall
endlocal


Testing a batch file should be always done by opening a command prompt window and running the batch file from within this console window. Then syntax errors and errors on parameter list of commands and applications can be easily seen.

reg.exe requires as first parameter the action to do, here query. And you forget the double quotes around registry key as it contains spaces.

Also writing nearly all commands in one line is also wrong.

Well, best would be to really check version of installed .NET Framework 4 in case of a newer version is already installed then what is put on CD/DVD.
"
2811,2811,4476,Does the function which sends a right angled triangle to its area produce infinitely many numbers having hardly any prime factors?,"Let $T$ be the set of pythagorean triples, that is, triples of integers (a,b,c) satisfying a2 + b2 = c2. We think of $T$ as the set of right angles triangles with integer lengths. And let $f : T \rightarrow \mathbb{Z}$ be the function $(a,b,c) \mapsto \frac{ab}{12}$ which computes the area of a triangle (divided by 6, which seems to always be a factor for some reason). 

I was wondering: what are the number theoretic propertires of $f$? It seems to produce numbers with few prime factors. What is the reason for this? For instance, $f(3,4,5) = 1$, $f(36,77,85) = 3 * 11 * 7$, and $f(65,72,97)=39*5*2$. Can we put a bound on the number of prime factors in the numbers that $f$ spits out? Or at least, can we give a 'generic' statement such as 'The output of $f$ almost always spits out numbers with less than 8 factors' or something?
",Bruce Bartlett,https://mathoverflow.net/users/401,"Presumably, there are infinitely many primes $p$, $q$, such that $p+q$ is 6 times a prime and $p-q$ is 4 times a prime (e.g., $73+5=6\times13$, $73-5=4\times17$). This ought to follow from the prime $k$-tuples conjecture. Proving it is another matter. 

Slightly simpler (but still out of reach), there should be infinitely many primes $p$, $q$, such that $2p+q$ is prime and $2p-q$ is 3 times a prime (e.g., $p=13$, $q=5$). Then the integer right-triangle with sides $4pq$ and $4p^2-q^2$ has area 6 times a product of 4 primes.

EDIT: Maybe not prime $k$-tuples but Schinzel's Hypothesis H is what's needed.  
",Gerry Myerson,https://mathoverflow.net/users/3684,http://mathoverflow.net/questions/31897,SCIENCE,mathoverflow.net,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.5,0.0,0.5,0.8888888888888888,Does the function that sends a right triangle to its region produce an infinite number with almost no prime factor?,"Let $T$ be the set of pythagorean triples, that is, triples of integers (a,b,c) satisfying a2 + b2 = c2. We think of $T$ as the set of right angles triangles with integer lengths. And let $f : T \rightarrow \mathbb{Z}$ be the function $(a,b,c) \mapsto \frac{ab}{12}$ which computes the area of a triangle (divided by 6, which seems to always be a factor for some reason). 

I was wondering: what are the number theoretic propertires of $f$? It seems to produce numbers with few prime factors. What is the reason for this? For instance, $f(3,4,5) = 1$, $f(36,77,85) = 3 * 11 * 7$, and $f(65,72,97)=39*5*2$. Can we put a bound on the number of prime factors in the numbers that $f$ spits out? Or at least, can we give a 'generic' statement such as 'The output of $f$ almost always spits out numbers with less than 8 factors' or something?
","Presumably, there are infinitely many primes $p$, $q$, such that $p+q$ is 6 times a prime and $p-q$ is 4 times a prime (e.g., $73+5=6\times13$, $73-5=4\times17$). This ought to follow from the prime $k$-tuples conjecture. Proving it is another matter. 

Slightly simpler (but still out of reach), there should be infinitely many primes $p$, $q$, such that $2p+q$ is prime and $2p-q$ is 3 times a prime (e.g., $p=13$, $q=5$). Then the integer right-triangle with sides $4pq$ and $4p^2-q^2$ has area 6 times a product of 4 primes.

EDIT: Maybe not prime $k$-tuples but Schinzel's Hypothesis H is what's needed.  
"
1263,1263,1991,"How can I learn how to lay out an ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
",xenoterracide,https://rpg.stackexchange.com/users/1015,"With questions like these, I always point to Alexandrian's Three Clue Rule essay.

http://thealexandrian.net/wordpress/1118/roleplaying-games/three-clue-rule

As Alexandrian says, have at least three clues per thing that you want the players to figure out. And as Bankuei says, make at least some of them obvious. Generally I use two tiers when making a mystery. There are three first tier clues that point to the person/location/thing that the players need to run into. But when the players enter the mystery, what they find first are second tier clues to the first tier clues or places they can find other second tier clues.

So lets say we have a murder mystery. We come up with three first tier clues: the guy who acted as lookout while the murder was committed, the murder weapon, and the fact that the two victims knew the murderer.

We decide that we have three second tier sources of clues: The two crime scenes, and the CCTV network that one player has access to.

At the first crime scene are stab wounds that will match the murder weapon, a witness who saw the lookout and can describe him, and the matchbooks that the lookout dropped at his lookout point, which points to his favorite bar.

At the second crime scene are stab wounds that will match the murder weapon, a witness who saw where the murderer disposed of the murder weapon, and a series of emails between the murdered and murderer which shows they had business ties.

The CCTV network will show the outlook at the second crime scene, and the fact that the murderer frequently visited both victims. He looked very angry when he visited the second victim before the day before the murder.

To shore up the outlook clues, we'll also decide that the outlook is a petty crook, so his name and address can be found by finding him in the criminal database (if they know what he looks like).

Finally our first tier clues: The murder weapon has the murderer's finger prints and his initials on the grip.

The outlook can be made to spill the beans. He knows exactly who the murderer is.

And digging into the emails and other records will reveal that the three were engaged in shady business deals, where the murderer was getting the short end of the stick.
",Rubberduck,https://rpg.stackexchange.com/users/3544,http://rpg.stackexchange.com/questions/50671/how-can-i-learn-how-to-lay-out-an-evidence-scene,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,0.8888888888888888,"How can I learn to set up ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
","With questions like these, I always point to Alexandrian's Three Clue Rule essay.

http://thealexandrian.net/wordpress/1118/roleplaying-games/three-clue-rule

As Alexandrian says, have at least three clues per thing that you want the players to figure out. And as Bankuei says, make at least some of them obvious. Generally I use two tiers when making a mystery. There are three first tier clues that point to the person/location/thing that the players need to run into. But when the players enter the mystery, what they find first are second tier clues to the first tier clues or places they can find other second tier clues.

So lets say we have a murder mystery. We come up with three first tier clues: the guy who acted as lookout while the murder was committed, the murder weapon, and the fact that the two victims knew the murderer.

We decide that we have three second tier sources of clues: The two crime scenes, and the CCTV network that one player has access to.

At the first crime scene are stab wounds that will match the murder weapon, a witness who saw the lookout and can describe him, and the matchbooks that the lookout dropped at his lookout point, which points to his favorite bar.

At the second crime scene are stab wounds that will match the murder weapon, a witness who saw where the murderer disposed of the murder weapon, and a series of emails between the murdered and murderer which shows they had business ties.

The CCTV network will show the outlook at the second crime scene, and the fact that the murderer frequently visited both victims. He looked very angry when he visited the second victim before the day before the murder.

To shore up the outlook clues, we'll also decide that the outlook is a petty crook, so his name and address can be found by finding him in the criminal database (if they know what he looks like).

Finally our first tier clues: The murder weapon has the murderer's finger prints and his initials on the grip.

The outlook can be made to spill the beans. He knows exactly who the murderer is.

And digging into the emails and other records will reveal that the three were engaged in shady business deals, where the murderer was getting the short end of the stick.
"
5611,5611,8903,Getting the value of a select option,"I would like to validate the company name chosen in a form in a ""select"" form field.

When I try $form_values['submitted_tree']['company_1']; it shows me the key instead of the string value.

I tried the following code, but it still prints '1' (the key) instead of the value associated with the key.

    $_page_num = $form_state['values']['details']['page_num'];
    $key1 = $form_state['values']['submitted_tree']['company_1'];
    $value1 = $form['submitted_tree']['company_1']['#options'][$key1];
    $key2 = $form_state['values']['submitted_tree']['company_2'];
    $value2 = $form['submitted_tree']['company_2']['#options'][$key2];

    if (($_page_num == 2) &amp;&amp; ($value1 == $value2)) {
      drupal_set_message(print_r($form['submitted_tree']['company_2']['#options'][$key2]));
    }


Could anyone help me to retrieve the actual text value displayed in select option chosen? I have tried $form_state as well, but it returns the same result.
",iRiddler,https://drupal.stackexchange.com/users/4729,"You can use the key to get the value by referencing the options array in the original form element:

$key = $form_state['values']['submitted_tree']['company_1'];
$value = $form['submitted_tree']['company_1']['#options'][$key];

",Clive,https://drupal.stackexchange.com/users/2800,http://drupal.stackexchange.com/questions/21355/getting-the-value-of-a-select-option,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Get the value of the select option,"I would like to validate the company name chosen in a form in a ""select"" form field.

When I try $form_values['submitted_tree']['company_1']; it shows me the key instead of the string value.

I tried the following code, but it still prints '1' (the key) instead of the value associated with the key.

    $_page_num = $form_state['values']['details']['page_num'];
    $key1 = $form_state['values']['submitted_tree']['company_1'];
    $value1 = $form['submitted_tree']['company_1']['#options'][$key1];
    $key2 = $form_state['values']['submitted_tree']['company_2'];
    $value2 = $form['submitted_tree']['company_2']['#options'][$key2];

    if (($_page_num == 2) &amp;&amp; ($value1 == $value2)) {
      drupal_set_message(print_r($form['submitted_tree']['company_2']['#options'][$key2]));
    }


Could anyone help me to retrieve the actual text value displayed in select option chosen? I have tried $form_state as well, but it returns the same result.
","You can use the key to get the value by referencing the options array in the original form element:

$key = $form_state['values']['submitted_tree']['company_1'];
$value = $form['submitted_tree']['company_1']['#options'][$key];

"
212,212,339,"How can I learn how to lay out an ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
",xenoterracide,https://rpg.stackexchange.com/users/1015,"I watched a whole lot of Law &amp; Order with an eye toward trying to understand how they structure their mysteries. I noticed a few things that I think ought to help run a mystery game. (Life has gotten in the way of testing my theories in the game I was to run, so do report back if any of this helps!)

First, a mystery is not a confusing story--it's a simple story about a perpetrator, a victim, and a crime scene, that the characters learn out of sequence. Supposing we're talking about a murder, there is a victim, and there is physical evidence. The detectives will have physical evidence to check out, and they'll want to learn about the social network that the victim was a part of. The clues and interviewees lead to more places to look for more evidence. 

Bringing me to the second point: the detectives spend as much time or more ruling possibilities out than learning about them. The common problem GMs face is not wanting to give out too much information; I suspect that the thing to do is give out a good amount of information that looks suspicious, so that the characters turn up new evidence while ruling out suspects. 

The elements of a mystery game, then:


nameless NPCs who are forthcoming with information, though they don't have any idea how it fits into an investigation; 
named NPCs who act suspiciously and lie to the PCs, but because they are concealing a secret that doesn't directly relate to the crime;
a perpetrator who seems like they can be ruled out, but whose guilt will be revealed when facts that come up while the PCs are ruling things out show the motive, means, and opportunity of this perpetrator. Justice is served, etc. etc.


Like I said, these are theories that haven't been borne out by play. But I stand by this idea that a crime is a simple linear incident, and an investigation is a nonlinear process of alternately expanding the network of physical and social links, and ruling things out, until only the perpetrator remains. 
",user17909,https://rpg.stackexchange.com/users/17909,http://rpg.stackexchange.com/questions/50671/how-can-i-learn-how-to-lay-out-an-evidence-scene,CULTURE,rpg.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,"How can I learn to set up ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
","I watched a whole lot of Law &amp; Order with an eye toward trying to understand how they structure their mysteries. I noticed a few things that I think ought to help run a mystery game. (Life has gotten in the way of testing my theories in the game I was to run, so do report back if any of this helps!)

First, a mystery is not a confusing story--it's a simple story about a perpetrator, a victim, and a crime scene, that the characters learn out of sequence. Supposing we're talking about a murder, there is a victim, and there is physical evidence. The detectives will have physical evidence to check out, and they'll want to learn about the social network that the victim was a part of. The clues and interviewees lead to more places to look for more evidence. 

Bringing me to the second point: the detectives spend as much time or more ruling possibilities out than learning about them. The common problem GMs face is not wanting to give out too much information; I suspect that the thing to do is give out a good amount of information that looks suspicious, so that the characters turn up new evidence while ruling out suspects. 

The elements of a mystery game, then:


nameless NPCs who are forthcoming with information, though they don't have any idea how it fits into an investigation; 
named NPCs who act suspiciously and lie to the PCs, but because they are concealing a secret that doesn't directly relate to the crime;
a perpetrator who seems like they can be ruled out, but whose guilt will be revealed when facts that come up while the PCs are ruling things out show the motive, means, and opportunity of this perpetrator. Justice is served, etc. etc.


Like I said, these are theories that haven't been borne out by play. But I stand by this idea that a crime is a simple linear incident, and an investigation is a nonlinear process of alternately expanding the network of physical and social links, and ruling things out, until only the perpetrator remains. 
"
3242,3242,5169,pre hung doors to fit into old frame,"I have purchased some pre hung doors at 30"" by 80""
the jambs are 4 5/8 wide. 
The house is 50 years old and the existing door frame is 5 1/4 wide.
Any solution as to how to fit these doors into the old frame.
",brian smith,https://diy.stackexchange.com/users/20542,"All you need to do is install the door with what is called a ""jamb extension"". Just get some strips of 5/8""x3/4"" inch molding, then glue them to the non-hinge side of the new door jamb.  On a painted jamb these will for all intents and purposes disappear with sanding and some wood putty.  On a stained jamb you'll be able to see the extension, but you can minimize how much it stands out by picking wood with a similar grain pattern. 
",Comintern,https://diy.stackexchange.com/users/20454,http://diy.stackexchange.com/questions/40199,LIFE_ARTS,diy.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Pre hung door suitable for the old frame,"I have purchased some pre hung doors at 30"" by 80""
the jambs are 4 5/8 wide. 
The house is 50 years old and the existing door frame is 5 1/4 wide.
Any solution as to how to fit these doors into the old frame.
","All you need to do is install the door with what is called a ""jamb extension"". Just get some strips of 5/8""x3/4"" inch molding, then glue them to the non-hinge side of the new door jamb.  On a painted jamb these will for all intents and purposes disappear with sanding and some wood putty.  On a stained jamb you'll be able to see the extension, but you can minimize how much it stands out by picking wood with a similar grain pattern. 
"
2632,2632,4185,KL divergence between two univariate Gaussians,"I need to determine the KL-divergence between two Gaussians. I am comparing my results to these, but I can't reproduce their result. My result is obviously wrong, because the KL is not 0 for KL(p, p).

I wonder where I am doing a mistake and ask if anyone can spot it.

Let $p(x) = N(\mu_1, \sigma_1)$ and $q(x) = N(\mu_2, \sigma_2)$. From Bishop's
PRML I know that

$$KL(p, q) = - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx$$

where integration is done over all real line, and that

$$\int p(x) \log p(x) dx = \frac{1}{2} (1 + \log 2 \pi \sigma_1^2),$$

so I restrict myself to $\int p(x) \log q(x) dx$, which I can write out as

$$-\int p(x) \log \frac{1}{(2 \pi \sigma_2^2)^{(1/2)}} e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx,$$

which I can separate into

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) \log e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx.$$

Taking the log I get

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) -\frac{(x-\mu_2)^2}{2 \sigma_2^2} dx,$$

where I separate the sums and get $\sigma_2^2$ out of the integral.

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\int p(x) x^2 dx - \int p(x) 2x\mu dx + \int p(x) \mu^2 dx}{2 \sigma_2^2}$$

Letting $\langle \rangle$ denote the expectation operator under $p$, I can rewrite this as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\langle x^2 \rangle - 2 \langle x \rangle \mu_2 + \mu_2^2}{2 \sigma_2^2}.$$

We know that $var(x) = \langle x^2 \rangle - \langle x \rangle ^2$. Thus 

$$\langle x^2 \rangle = \sigma_1^2 + \mu_1^2$$

and therefore

$$\frac{1}{2} \log (2 \pi \sigma^2) + \frac{\sigma_1^2 + \mu_1^2 - 2 \mu_1 \mu_2 + \mu_2^2}{2 \sigma_2^2},$$

which I can put as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.$$

Putting everything together, I get to 

\begin{align*}
KL(p, q) &amp;= - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx\\
&amp;= \frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2} (1 + \log 2 \pi \sigma_1^2)\\
&amp;= \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.
\end{align*}
Which is wrong since it equals $1$ for two identical Gaussians.

Can anyone spot my error?

Update

Thanks to mpiktas for clearing things up. The correct answer is:

$KL(p, q) = \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2}$
",bayerj,https://stats.stackexchange.com/users/2860,"I did not have a look at your calculation but here is mine with a lot of details. 
Suppose $p$ is the density of a normal random variable with mean $\mu_1$ and variance $\sigma^2_1$, and that $q$ is the density of a normal random variable with mean $\mu_2$ and variance $\sigma^2_2$. 
The Kullback-Leibler distance from $q$ to $p$ is:

$\int \left[\log( p(x)) - log( q(x)) \right] p(x) dx$

$=\int \left[ -\frac{1}{2} \log(2\pi) - \log(\sigma_1) - \frac{1}{2} \left(\frac{x-\mu_1}{\sigma_1}\right)^2 + \frac{1}{2}\log(2\pi) + \log(\sigma_2) + \frac{1}{2} \left(\frac{x-\mu_2}{\sigma_2}\right)^2  \right]$
$\times \frac{1}{\sqrt{2\pi}\sigma_1} \exp\left[-\frac{1}{2}\left(\frac{x-\mu_1}{\sigma_1}\right)^2\right] dx$

$=\int \left\{\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2} \left[ \left(\frac{x-\mu_2}{\sigma_2}\right)^2 - \left(\frac{x-\mu_1}{\sigma_1}\right)^2 \right] \right\}$
$\times \frac{1}{\sqrt{2\pi}\sigma_1} \exp\left[-\frac{1}{2}\left(\frac{x-\mu_1}{\sigma_1}\right)^2\right] dx$

$=E_{1} \left\{\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2} \left[ \left(\frac{x-\mu_2}{\sigma_2}\right)^2 - \left(\frac{x-\mu_1}{\sigma_1}\right)^2 \right]\right\}$

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2\sigma_2^2} E_1 \left\{(X-\mu_2)^2\right\} - \frac{1}{2\sigma_1^2} E_1 \left\{(X-\mu_1)^2\right\}$ 

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2\sigma_2^2} E_1 \left\{(X-\mu_2)^2\right\} - \frac{1}{2}$

(Now note that $(X - \mu_2)^2 = (X-\mu_1+\mu_1-\mu_2)^2 = (X-\mu_1)^2 + 2(X-\mu_1)(\mu_1-\mu_2) + (\mu_1-\mu_2)^2$)

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2\sigma_2^2}
\left[E_1\left\{(X-\mu_1)^2\right\} + 2(\mu_1-\mu_2)E_1\left\{X-\mu_1\right\} + (\mu_1-\mu_2)^2\right] - \frac{1}{2}$

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{\sigma_1^2 + (\mu_1-\mu_2)^2}{2\sigma_2^2} - \frac{1}{2}$
",ocram,https://stats.stackexchange.com/users/3019,http://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians,SCIENCE,stats.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,1.0,0.0,0.7777777777777778,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.9,0.6666666666666666,0.6666666666666666,0.3333333333333333,1.0,KL divergence of two univariate Gauss,"I need to determine the KL-divergence between two Gaussians. I am comparing my results to these, but I can't reproduce their result. My result is obviously wrong, because the KL is not 0 for KL(p, p).

I wonder where I am doing a mistake and ask if anyone can spot it.

Let $p(x) = N(\mu_1, \sigma_1)$ and $q(x) = N(\mu_2, \sigma_2)$. From Bishop's
PRML I know that

$$KL(p, q) = - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx$$

where integration is done over all real line, and that

$$\int p(x) \log p(x) dx = \frac{1}{2} (1 + \log 2 \pi \sigma_1^2),$$

so I restrict myself to $\int p(x) \log q(x) dx$, which I can write out as

$$-\int p(x) \log \frac{1}{(2 \pi \sigma_2^2)^{(1/2)}} e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx,$$

which I can separate into

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) \log e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx.$$

Taking the log I get

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) -\frac{(x-\mu_2)^2}{2 \sigma_2^2} dx,$$

where I separate the sums and get $\sigma_2^2$ out of the integral.

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\int p(x) x^2 dx - \int p(x) 2x\mu dx + \int p(x) \mu^2 dx}{2 \sigma_2^2}$$

Letting $\langle \rangle$ denote the expectation operator under $p$, I can rewrite this as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\langle x^2 \rangle - 2 \langle x \rangle \mu_2 + \mu_2^2}{2 \sigma_2^2}.$$

We know that $var(x) = \langle x^2 \rangle - \langle x \rangle ^2$. Thus 

$$\langle x^2 \rangle = \sigma_1^2 + \mu_1^2$$

and therefore

$$\frac{1}{2} \log (2 \pi \sigma^2) + \frac{\sigma_1^2 + \mu_1^2 - 2 \mu_1 \mu_2 + \mu_2^2}{2 \sigma_2^2},$$

which I can put as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.$$

Putting everything together, I get to 

\begin{align*}
KL(p, q) &amp;= - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx\\
&amp;= \frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2} (1 + \log 2 \pi \sigma_1^2)\\
&amp;= \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.
\end{align*}
Which is wrong since it equals $1$ for two identical Gaussians.

Can anyone spot my error?

Update

Thanks to mpiktas for clearing things up. The correct answer is:

$KL(p, q) = \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2}$
","I did not have a look at your calculation but here is mine with a lot of details. 
Suppose $p$ is the density of a normal random variable with mean $\mu_1$ and variance $\sigma^2_1$, and that $q$ is the density of a normal random variable with mean $\mu_2$ and variance $\sigma^2_2$. 
The Kullback-Leibler distance from $q$ to $p$ is:

$\int \left[\log( p(x)) - log( q(x)) \right] p(x) dx$

$=\int \left[ -\frac{1}{2} \log(2\pi) - \log(\sigma_1) - \frac{1}{2} \left(\frac{x-\mu_1}{\sigma_1}\right)^2 + \frac{1}{2}\log(2\pi) + \log(\sigma_2) + \frac{1}{2} \left(\frac{x-\mu_2}{\sigma_2}\right)^2  \right]$
$\times \frac{1}{\sqrt{2\pi}\sigma_1} \exp\left[-\frac{1}{2}\left(\frac{x-\mu_1}{\sigma_1}\right)^2\right] dx$

$=\int \left\{\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2} \left[ \left(\frac{x-\mu_2}{\sigma_2}\right)^2 - \left(\frac{x-\mu_1}{\sigma_1}\right)^2 \right] \right\}$
$\times \frac{1}{\sqrt{2\pi}\sigma_1} \exp\left[-\frac{1}{2}\left(\frac{x-\mu_1}{\sigma_1}\right)^2\right] dx$

$=E_{1} \left\{\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2} \left[ \left(\frac{x-\mu_2}{\sigma_2}\right)^2 - \left(\frac{x-\mu_1}{\sigma_1}\right)^2 \right]\right\}$

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2\sigma_2^2} E_1 \left\{(X-\mu_2)^2\right\} - \frac{1}{2\sigma_1^2} E_1 \left\{(X-\mu_1)^2\right\}$ 

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2\sigma_2^2} E_1 \left\{(X-\mu_2)^2\right\} - \frac{1}{2}$

(Now note that $(X - \mu_2)^2 = (X-\mu_1+\mu_1-\mu_2)^2 = (X-\mu_1)^2 + 2(X-\mu_1)(\mu_1-\mu_2) + (\mu_1-\mu_2)^2$)

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{1}{2\sigma_2^2}
\left[E_1\left\{(X-\mu_1)^2\right\} + 2(\mu_1-\mu_2)E_1\left\{X-\mu_1\right\} + (\mu_1-\mu_2)^2\right] - \frac{1}{2}$

$=\log\left(\frac{\sigma_2}{\sigma_1}\right) + \frac{\sigma_1^2 + (\mu_1-\mu_2)^2}{2\sigma_2^2} - \frac{1}{2}$
"
1040,1040,1636,How much of the English language comes from each of its influences?,"I was watching a video linked in this answer and it made the following claim:


  [...] like most words in English is derived from German.


That got me thinking. While I know that Germanic languages have greatly influenced English, so have the Latin and Celtic ones (and various others to a greater or lesser degree). Is it true that more than 50% of the English vocabulary is derived from Germanic roots?

More generally, can someone point me to data on this? I imagine attempts have been made to quantify the contribution of different languages to English; what were the results? What percentage of the language comes from each source?

Ideally I would like to see this expressed in terms of % of words but I am aware that, at least to some linguists, attempting to quantify vocabulary is anathema (to give a simple reason, all languages that allow number construction have an infinite  vocabulary by definition), so alternative approaches to quantifying this are also welcome.
",terdon,https://english.stackexchange.com/users/25030,"Wikipedia has the following pie chart showing the word origins:



It shows the breakdown as


Latin (including words used only in scientific / medical / legal contexts) â 29%
French â 29%
Germanic â 26%
Greek â 6%
Others â 10%


It cites some references which back up these numbers but I don't have access to those.

To answer your question, it does not appear to be true that 50% of words are Germanic. However, that probably depends on what your context is. If you exclude scientific, medical, and legal, you will probably find a much lower incidence of Latin words. Given that English is itself a Germanic language, it's more surprising that Germanic doesn't account for MORE of the vocabulary.
",Mr. Shiny and New å®å®,https://english.stackexchange.com/users/380,http://english.stackexchange.com/questions/155705/how-much-of-the-english-language-comes-from-each-of-its-influences,CULTURE,english.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.0,1.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,How much of the English language comes from each of its influences?,"I was watching a video linked in this answer and it made the following claim:


  [...] like most words in English is derived from German.


That got me thinking. While I know that Germanic languages have greatly influenced English, so have the Latin and Celtic ones (and various others to a greater or lesser degree). Is it true that more than 50% of the English vocabulary is derived from Germanic roots?

More generally, can someone point me to data on this? I imagine attempts have been made to quantify the contribution of different languages to English; what were the results? What percentage of the language comes from each source?

Ideally I would like to see this expressed in terms of % of words but I am aware that, at least to some linguists, attempting to quantify vocabulary is anathema (to give a simple reason, all languages that allow number construction have an infinite  vocabulary by definition), so alternative approaches to quantifying this are also welcome.
","Wikipedia has the following pie chart showing the word origins:



It shows the breakdown as


Latin (including words used only in scientific / medical / legal contexts) â 29%
French â 29%
Germanic â 26%
Greek â 6%
Others â 10%


It cites some references which back up these numbers but I don't have access to those.

To answer your question, it does not appear to be true that 50% of words are Germanic. However, that probably depends on what your context is. If you exclude scientific, medical, and legal, you will probably find a much lower incidence of Latin words. Given that English is itself a Germanic language, it's more surprising that Germanic doesn't account for MORE of the vocabulary.
"
5216,5216,8288,Timing inside a shift register,"How I imagine synchronous digital networks work: data lines are sampled at rising clock edge, a set of transients occur, system settles, and data lines are sampled again on next rising edge. I would place transients at falling clock edges, that way both Tsu and Th time for sampling are clear. (Somewhat similar to SPI bus behavior.)

What see in a datasheet of a real world device (74595): D flipflops connected in series having a common clock. At the output of the first flipflop, transient on the data line follows rising clock edge with Tpd. The next flipflop needs Th time stable data line after rising edge to operate correctly. Of course it works because Tpd>Th, but it's only a matter of nanoseconds.

My problem with all this is that it's not robust (maybe not the best word). Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge. Random errors caused by Th>Tpd are not really visible and go undetected. If I connect another shift register in series from a different technology, which requires longer hold times, the circuit won't work, no matter how slow clock I chose.

Is this the way most commonly synchronous digital circuits are constructed? Only the propagation delay of components make it work? Am I being to idealistic? :)
",Gyorgy Szekely,https://electronics.stackexchange.com/users/23677,"You are correct in your gut feeling that there is a potential problem. Within a chip, the chip designer chaps have taken care of it. When you connect a chain of let's say 74x595's you can indeed run into trouble, especially with a long chain, a weak driver, and clock wiring that starts at the 'first' chip (the one that receives the data). A 'standard' solution is to feed the clock starting at the last chip.

A better solution is to use a chip like the CD4094 that has a delayed output. It has an extra flipflop, that is clocked on the opposite edge. Using this output to feed the nect SR eliminates all setup/hold problems (but it does reduce the maximum clock frequency).

I think you can achieve the same effect (sort of poor man's implementation of the delayed output) by clocking the even 595's with the plain clock, and the odd 595's with the inverted clock. But I never really worked this out.
",Wouter van Ooijen,https://electronics.stackexchange.com/users/4831,http://electronics.stackexchange.com/questions/23771/timing-inside-a-shift-register,TECHNOLOGY,electronics.stackexchange.com,0.5,0.3333333333333333,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.5,1.0,1.0,Timing in shift register,"How I imagine synchronous digital networks work: data lines are sampled at rising clock edge, a set of transients occur, system settles, and data lines are sampled again on next rising edge. I would place transients at falling clock edges, that way both Tsu and Th time for sampling are clear. (Somewhat similar to SPI bus behavior.)

What see in a datasheet of a real world device (74595): D flipflops connected in series having a common clock. At the output of the first flipflop, transient on the data line follows rising clock edge with Tpd. The next flipflop needs Th time stable data line after rising edge to operate correctly. Of course it works because Tpd>Th, but it's only a matter of nanoseconds.

My problem with all this is that it's not robust (maybe not the best word). Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge. Random errors caused by Th>Tpd are not really visible and go undetected. If I connect another shift register in series from a different technology, which requires longer hold times, the circuit won't work, no matter how slow clock I chose.

Is this the way most commonly synchronous digital circuits are constructed? Only the propagation delay of components make it work? Am I being to idealistic? :)
","You are correct in your gut feeling that there is a potential problem. Within a chip, the chip designer chaps have taken care of it. When you connect a chain of let's say 74x595's you can indeed run into trouble, especially with a long chain, a weak driver, and clock wiring that starts at the 'first' chip (the one that receives the data). A 'standard' solution is to feed the clock starting at the last chip.

A better solution is to use a chip like the CD4094 that has a delayed output. It has an extra flipflop, that is clocked on the opposite edge. Using this output to feed the nect SR eliminates all setup/hold problems (but it does reduce the maximum clock frequency).

I think you can achieve the same effect (sort of poor man's implementation of the delayed output) by clocking the even 595's with the plain clock, and the odd 595's with the inverted clock. But I never really worked this out.
"
1958,1958,3119,Who counters Jayce top lane besides Yorick?,"I'm aware that Yorick and Cho'Gath are both good counters for Jayce (in Top Lane) but who else might be a good matchup and why?
",Eddie,https://gaming.stackexchange.com/users/29370,"Jayce is very squishy early - pick Jax or even Lee Sin and punch him in the face as many times as possible. It is more individual play style that counters Jayce rather than the champion you're playing - one of Jayce's biggest strengths is when he gets ganks from his jungler, so ward as many times as possible. 

Remember, Jayce has no sustain so if you can get a fast two Doran's or a Vamp Scepter you can punch him in the face and heal back up fast. Never let him free farm on you - keep up the pressure.  
",johnbarry,https://gaming.stackexchange.com/users/29374,http://gaming.stackexchange.com/questions/77029/who-counters-jayce-top-lane-besides-yorick,CULTURE,gaming.stackexchange.com,1.0,0.5,1.0,0.0,0.0,0.0,0.6666666666666666,0.5,1.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"Who's dealing with Jess in the top floor lane, except York?","I know that both joric and jogat are good rivals for Joyce, but who else are good rivals and why?","Jayce is very squishy early - pick Jax or even Lee Sin and punch him in the face as many times as possible. It is more individual play style that counters Jayce rather than the champion you're playing - one of Jayce's biggest strengths is when he gets ganks from his jungler, so ward as many times as possible. 

Remember, Jayce has no sustain so if you can get a fast two Doran's or a Vamp Scepter you can punch him in the face and heal back up fast. Never let him free farm on you - keep up the pressure.  
"
4571,4571,7242,"What is the Goal of ""Hot Network Questions""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
",jmac,https://meta.stackexchange.com/users/209637,"Well, I can tell you what I hoped for when I was a regular user on a tiny site: network-wide exposure. When Biblical Hermeneutics showed up in the hot question list, I vividly recall day-dreaming that everyone who had an interest in the Bible on the network would see our little site and have a burning desire to ask and answer hermeneutics questions.  It was a good feeling to know that Jack's question and the answers it had already accumulated would get some exposure. It felt like our little community had earned a collective gold star.

Now I'll admit it was a bigger deal in my mind than it was in reality.  As of this writing, the question has fewer than 600 views. It's not anywhere to be found on the first page of BH's Greatest Hits. Likely we didn't get even one new user out of the deal. And we certainly didn't have any crowd control problems. But you know what? I'm still proud of our little community and that question. There aren't a lot of achievements a site can earn from the time pro tem moderators are appointed until graduation, but having a ""hot question"" is one of them.

Back then, it wasn't as easy to find network-wide hot questions. Now that they are listed in the sidebar, it's not uncommon for me to wander over to a site I'd forgotten even existed.  (Hello, Code Golf!) Ideally, I will find a question that isn't just entertaining to read, but also sparks my interest in writing something. There are some brilliant, eloquent, and thoughtful people on our sites, so I think some cross-pollination can strengthen the whole network.

The other day, I was looking into the RPG site and trying to figure out how it got a healthy bump in visitors since the beginning of the year. As I dug, it became clear that one factor has been direct traffic from other sites on the network. Digging a bit more, I turned up a series of ""hot questions"" such as Is 3d6 the same as 1d18? Since you don't have to be an expert in a particular RPG system to read, appreciate, or even answer this question, it attracted considerable attention (11,377 views so far). Site traffic also spiked noticeably the week the question was asked.

It was not without pain: two answers were deleted and the voting seems disproportionate. Arguably the question is not even on topic, yet it's tied for 26th on the all-time best questions list. While the answers tend to be good, none of them demonstrate any particular RPG expertise. But the question also got two solid first answers (one from Eric Lippert and the other from someone who has provided an equally upvoted answer). All-in-all, the HQ list looks like a net positive on that site. 

Speaking of rolling the dice, hot questions are a sort of gamble. They take advantage of the blockbuster business model. Every day there are dozens of new hot questions. Some of them blow up and others fizzle. Most sites consider it a great success to convert just one reader in a hundred (or even a thousand) into an occasional contributor. The hot question formula improves the odds by taking into account indicators of interest and quality signalled by regular users of the site. In other words, if lots of people on a site read, answer, and vote on posts, we can feel pretty confident that showing the question around will attract similar people.
",Jon Ericson,https://meta.stackexchange.com/users/1438,http://meta.stackexchange.com/questions/219922/what-is-the-goal-of-hot-network-questions,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.5555555555555556,1.0,0.0,0.0,0.0,0.5555555555555556,0.5555555555555556,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,"What is the goal of ""network hot issues""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
","Well, I can tell you what I hoped for when I was a regular user on a tiny site: network-wide exposure. When Biblical Hermeneutics showed up in the hot question list, I vividly recall day-dreaming that everyone who had an interest in the Bible on the network would see our little site and have a burning desire to ask and answer hermeneutics questions.  It was a good feeling to know that Jack's question and the answers it had already accumulated would get some exposure. It felt like our little community had earned a collective gold star.

Now I'll admit it was a bigger deal in my mind than it was in reality.  As of this writing, the question has fewer than 600 views. It's not anywhere to be found on the first page of BH's Greatest Hits. Likely we didn't get even one new user out of the deal. And we certainly didn't have any crowd control problems. But you know what? I'm still proud of our little community and that question. There aren't a lot of achievements a site can earn from the time pro tem moderators are appointed until graduation, but having a ""hot question"" is one of them.

Back then, it wasn't as easy to find network-wide hot questions. Now that they are listed in the sidebar, it's not uncommon for me to wander over to a site I'd forgotten even existed.  (Hello, Code Golf!) Ideally, I will find a question that isn't just entertaining to read, but also sparks my interest in writing something. There are some brilliant, eloquent, and thoughtful people on our sites, so I think some cross-pollination can strengthen the whole network.

The other day, I was looking into the RPG site and trying to figure out how it got a healthy bump in visitors since the beginning of the year. As I dug, it became clear that one factor has been direct traffic from other sites on the network. Digging a bit more, I turned up a series of ""hot questions"" such as Is 3d6 the same as 1d18? Since you don't have to be an expert in a particular RPG system to read, appreciate, or even answer this question, it attracted considerable attention (11,377 views so far). Site traffic also spiked noticeably the week the question was asked.

It was not without pain: two answers were deleted and the voting seems disproportionate. Arguably the question is not even on topic, yet it's tied for 26th on the all-time best questions list. While the answers tend to be good, none of them demonstrate any particular RPG expertise. But the question also got two solid first answers (one from Eric Lippert and the other from someone who has provided an equally upvoted answer). All-in-all, the HQ list looks like a net positive on that site. 

Speaking of rolling the dice, hot questions are a sort of gamble. They take advantage of the blockbuster business model. Every day there are dozens of new hot questions. Some of them blow up and others fizzle. Most sites consider it a great success to convert just one reader in a hundred (or even a thousand) into an occasional contributor. The hot question formula improves the odds by taking into account indicators of interest and quality signalled by regular users of the site. In other words, if lots of people on a site read, answer, and vote on posts, we can feel pretty confident that showing the question around will attract similar people.
"
1481,1481,2329,How to use multiple VLOOKUP with duplicate data?,"I have huge excel file. Column A has invoices(duplicate rows since each item in the invoice is a row), column B has SKU value of item bought(like 200ml, 300ml etc), column C has the brand bought(like Coca-Cola,Sprite etc) and column D has the no of items bought(like 10,15 etc).



The first table has is the dump file for all invoices and the intems bought

Now i want to find the No. of items bought given the condition that the brand is Coca-Cola, the SKU is 200ml and the invoice no. is XAX1X2X3 and display it in another cell.



Now in the second table, i want to match the invoice with the pack size and brand from first table and put the quantity in the empty cell

So the row that is highlighted in table 2 will show the value 3 cause invoice T1411031400114, pack size 200, brand coca-cola has Qty as 3.

I was thinking of using nested VLOOKUP but cant get the correct formula for it.

Any help will be appreciated.

Regards

Anand
",anand,https://stackoverflow.com/users/124075,"=OFFSET($C$9, SMALL(IF(D10=($B$10:$B$38),
                    ROW($B$10:$B$38)-9),COUNTIF($B$10:$B10,D10)),0)


Use this formula. Take care with cell referencing though.
",user4691608,https://stackoverflow.com/users/4691608,http://stackoverflow.com/questions/25008387/how-to-use-multiple-vlookup-with-duplicate-data,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,How to use multiple vlookups with duplicate data?,"I have huge excel file. Column A has invoices(duplicate rows since each item in the invoice is a row), column B has SKU value of item bought(like 200ml, 300ml etc), column C has the brand bought(like Coca-Cola,Sprite etc) and column D has the no of items bought(like 10,15 etc).



The first table has is the dump file for all invoices and the intems bought

Now i want to find the No. of items bought given the condition that the brand is Coca-Cola, the SKU is 200ml and the invoice no. is XAX1X2X3 and display it in another cell.



Now in the second table, i want to match the invoice with the pack size and brand from first table and put the quantity in the empty cell

So the row that is highlighted in table 2 will show the value 3 cause invoice T1411031400114, pack size 200, brand coca-cola has Qty as 3.

I was thinking of using nested VLOOKUP but cant get the correct formula for it.

Any help will be appreciated.

Regards

Anand
","=OFFSET($C$9, SMALL(IF(D10=($B$10:$B$38),
                    ROW($B$10:$B$38)-9),COUNTIF($B$10:$B10,D10)),0)


Use this formula. Take care with cell referencing though.
"
3610,3610,5763,The Rademacher functions for counting binary digits,"In the probability space $((0,1),{\cal B}(0,1), \lambda)$, we define the Rademacher functions as:
$R_n(\omega)=\displaystyle\sum_{k=0}^{2^n-1}(-1)^{k+1}I_{\Delta_{k,n}}(\omega)$, where  

$(0,1)=\displaystyle\bigcup_{k=0}^{2^n-1}\Delta_{k,n}$  

$\Delta_{k,n}=\left(\dfrac{k}{2^n},\dfrac{k+1}{2^n}\right]$, for $k=0,1,\dots2^n-2$
and
$\Delta_{2^n-1,n}=\left(1-\dfrac{1}{2^n},1\right)$  

I know that if $\omega\in(0,1)$ and $\omega=\displaystyle\sum_{n=1}^{\infty}\dfrac{x_n}{2^n}$ is the binary representation of $\omega$, then: $R_n(\omega)=-1\ \Longleftrightarrow\ $the $n^{th}$ binary digit of $\omega$ is 0 (i.e. $x_n=0$)   $(I)$
and
$R_n(\omega)=1\ \Longleftrightarrow\ $the $n^{th}$ binary digit of $\omega$ is 1 (i.e. $x_n=1$)   $(II)$.  

Some prefer this as the definition of the Rademacher functions.
I would like to know why these two definitions are equivalent, that is why the equivalences $(I)$ and $(II)$ hold. Intuitively I understand it, but I can't seem to write it down as a rigorous mathematical proof.  

Thanks in advance!  

EDIT:
I corrected the $\Delta_{k,n}$ sets. As it was, it wasn't a proper partition of $(0,1)$ (some elements were not included - the right endpoints of the $\Delta_{k,n}$'s).
",Nick Papadopoulos,https://math.stackexchange.com/users/50118,"The fact that $R_n(\omega)=1$ means that $\omega$ belongs to $\Delta_{k,n}$ for some odd integer $k$. That is, $k\leqslant2^n\omega\lt k+1$ and $k=2\ell+\color{red}{1}$ for some integer $\ell$. Hence $2^n\omega=2\ell+\color{red}{1}+s$ with $0\leqslant s\lt 1$. Since $0\leqslant k\lt2^n$, $0\leqslant\ell\lt2^{n-1}$ and $\ell$ is a binary integer $\ell=\sum\limits_{i=0}^{n-2}\ell_i2^i$ with $\ell_i=0$ or $\ell_i=1$. Thus,
$$
\omega=\frac2{2^n}\sum\limits_{i=0}^{n-2}\ell_i2^i+\frac{\color{red}{1}}{2^n}+\frac{s}{2^n}=\sum\limits_{i=1}^{n-1}\frac{\ell_{n-i-1}}{2^i}+\frac{\color{red}{1}}{2^n}+\frac{s}{2^n}.
$$
This is the binary expansion of $\omega$, up to and including its $n$th bit, and this $n$th bit is $\color{red}{1}$.

To solve the case $R_n(\omega)=-1$, rewrite the whole paragraph replacing each $\color{red}{1}$ by $\color{blue}{0}$.
",Did,https://math.stackexchange.com/users/6179,http://math.stackexchange.com/questions/269378/the-rademacher-functions-for-counting-binary-digits,SCIENCE,math.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,1.0,The Rademacher function calculates binary numbers,"In the probability space $((0,1),{\cal B}(0,1), \lambda)$, we define the Rademacher functions as:
$R_n(\omega)=\displaystyle\sum_{k=0}^{2^n-1}(-1)^{k+1}I_{\Delta_{k,n}}(\omega)$, where  

$(0,1)=\displaystyle\bigcup_{k=0}^{2^n-1}\Delta_{k,n}$  

$\Delta_{k,n}=\left(\dfrac{k}{2^n},\dfrac{k+1}{2^n}\right]$, for $k=0,1,\dots2^n-2$
and
$\Delta_{2^n-1,n}=\left(1-\dfrac{1}{2^n},1\right)$  

I know that if $\omega\in(0,1)$ and $\omega=\displaystyle\sum_{n=1}^{\infty}\dfrac{x_n}{2^n}$ is the binary representation of $\omega$, then: $R_n(\omega)=-1\ \Longleftrightarrow\ $the $n^{th}$ binary digit of $\omega$ is 0 (i.e. $x_n=0$)   $(I)$
and
$R_n(\omega)=1\ \Longleftrightarrow\ $the $n^{th}$ binary digit of $\omega$ is 1 (i.e. $x_n=1$)   $(II)$.  

Some prefer this as the definition of the Rademacher functions.
I would like to know why these two definitions are equivalent, that is why the equivalences $(I)$ and $(II)$ hold. Intuitively I understand it, but I can't seem to write it down as a rigorous mathematical proof.  

Thanks in advance!  

EDIT:
I corrected the $\Delta_{k,n}$ sets. As it was, it wasn't a proper partition of $(0,1)$ (some elements were not included - the right endpoints of the $\Delta_{k,n}$'s).
","The fact that $R_n(\omega)=1$ means that $\omega$ belongs to $\Delta_{k,n}$ for some odd integer $k$. That is, $k\leqslant2^n\omega\lt k+1$ and $k=2\ell+\color{red}{1}$ for some integer $\ell$. Hence $2^n\omega=2\ell+\color{red}{1}+s$ with $0\leqslant s\lt 1$. Since $0\leqslant k\lt2^n$, $0\leqslant\ell\lt2^{n-1}$ and $\ell$ is a binary integer $\ell=\sum\limits_{i=0}^{n-2}\ell_i2^i$ with $\ell_i=0$ or $\ell_i=1$. Thus,
$$
\omega=\frac2{2^n}\sum\limits_{i=0}^{n-2}\ell_i2^i+\frac{\color{red}{1}}{2^n}+\frac{s}{2^n}=\sum\limits_{i=1}^{n-1}\frac{\ell_{n-i-1}}{2^i}+\frac{\color{red}{1}}{2^n}+\frac{s}{2^n}.
$$
This is the binary expansion of $\omega$, up to and including its $n$th bit, and this $n$th bit is $\color{red}{1}$.

To solve the case $R_n(\omega)=-1$, rewrite the whole paragraph replacing each $\color{red}{1}$ by $\color{blue}{0}$.
"
1285,1285,2028,Reliable way of detecting whether an Android app is running in 'BlueStacks',"I would like to ascertain at run-time inside an Android app whether it is running within the BlueStacks Android emulator. This is so I can modify the way the app runs when running inside BlueStacks.

BlueStacks does not support multi-touch so I want to implement an alternative to the standard pinch-to-zoom functionality my current app has.

E.g.

If (appIsRunningInBlueStacks){
    mySurfaceView.enableMultiTouchAlternatives();
} else{
    mySurfaceView.enableMultiTouchFeatures();
}


What is a reliable way of ascertaining the value of appIsRunningInBlueStacks?

EDIT Summary of answers to comments on question:

Ben, Taras, thanks for the suggestions. The Build.MODEL etc. values for BlueStacks are:


Model: ""GT-I9100""
Manufacturer: ""samsung""
Device: ""GT-I9100""
Product: ""GT-I9100""


This is the same model number as the Samsung Galaxy SII so it would not be ideal to use this for fear of treating all users with SIIs the same as those on BlueStacks.

CommonsWare, the app continues to run in BlueStacks even with the &lt; uses-feature> for multitouch in the manifest. In fact (also answering iagreen's question)...

packageManager.hasSystemFeature(PackageManager.FEATURE_TOUCHSCREEN_MULTITOUCH_DISTINCT);


... returns true! This is to be expected I suppose as the emulator is convinced it is a Samsung Galaxy SII!

Therefore we are still without a way of reliably detecting whether an app is running on BlueStacks without also throwing all Samsung Galaxy SII users in the same bucket. Any other ideas?
",Twice Circled,https://stackoverflow.com/users/1804325,"I was also looking for a solution to this, I found this code snippet on some chinese blog when searching, I cant make out what its doing but maybe someone else can?

  public boolean isEmulator() {
        String android_id = Settings.Secure.getString(getContentResolver(), Settings.Secure.ANDROID_ID);
        Log.d(""ares"",""ANDROID_ID: ""+android_id);
        Log.d(""ares"",""Build.PRODUCT: ""+Build.PRODUCT); 
        boolean emulator = TextUtils.isEmpty(android_id) || ""google_sdk"".equals( Build.PRODUCT ) || ""sdk"".equals(Build.PRODUCT);            
        return emulator;
    }


Please ignore if its totally no help...
",law,https://stackoverflow.com/users/2696080,http://stackoverflow.com/questions/14143896/reliable-way-of-detecting-whether-an-android-app-is-running-in-bluestacks,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.5,0.0,0.5,1.0,0.5,0.6666666666666666,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,1.0,0.5,0.0,0.8333333333333334,0.6666666666666666,0.3333333333333333,0.8333333333333334,0.8333333333333334,0.4,0.5,0.5,0.5,0.8333333333333334,"A reliable way to detect whether Android applications are running in ""bluestack""","I would like to ascertain at run-time inside an Android app whether it is running within the BlueStacks Android emulator. This is so I can modify the way the app runs when running inside BlueStacks.

BlueStacks does not support multi-touch so I want to implement an alternative to the standard pinch-to-zoom functionality my current app has.

E.g.

If (appIsRunningInBlueStacks){
    mySurfaceView.enableMultiTouchAlternatives();
} else{
    mySurfaceView.enableMultiTouchFeatures();
}


What is a reliable way of ascertaining the value of appIsRunningInBlueStacks?

EDIT Summary of answers to comments on question:

Ben, Taras, thanks for the suggestions. The Build.MODEL etc. values for BlueStacks are:


Model: ""GT-I9100""
Manufacturer: ""samsung""
Device: ""GT-I9100""
Product: ""GT-I9100""


This is the same model number as the Samsung Galaxy SII so it would not be ideal to use this for fear of treating all users with SIIs the same as those on BlueStacks.

CommonsWare, the app continues to run in BlueStacks even with the &lt; uses-feature> for multitouch in the manifest. In fact (also answering iagreen's question)...

packageManager.hasSystemFeature(PackageManager.FEATURE_TOUCHSCREEN_MULTITOUCH_DISTINCT);


... returns true! This is to be expected I suppose as the emulator is convinced it is a Samsung Galaxy SII!

Therefore we are still without a way of reliably detecting whether an app is running on BlueStacks without also throwing all Samsung Galaxy SII users in the same bucket. Any other ideas?
","I was also looking for a solution to this, I found this code snippet on some chinese blog when searching, I cant make out what its doing but maybe someone else can?

  public boolean isEmulator() {
        String android_id = Settings.Secure.getString(getContentResolver(), Settings.Secure.ANDROID_ID);
        Log.d(""ares"",""ANDROID_ID: ""+android_id);
        Log.d(""ares"",""Build.PRODUCT: ""+Build.PRODUCT); 
        boolean emulator = TextUtils.isEmpty(android_id) || ""google_sdk"".equals( Build.PRODUCT ) || ""sdk"".equals(Build.PRODUCT);            
        return emulator;
    }


Please ignore if its totally no help...
"
2370,2370,3779,"What does ""pie"" mean in the following sentence?","I once saw a sentence: 


  I will go to a restaurant for pie.


Native speakers didn't correct this sentence. I don't know why. I would say ""I will go to a restaurant to eat a pie"". But maybe that sentence was right. Could you please explain to me what that (first) sentence means?
",user5369,https://ell.stackexchange.com/users/5369,"
  I will go to a resturant for pie.


There is nothing wrong with this sentence. I imagine the speaker will soon be seated in a restaurant, ordering a slice of pie. 

However:


  I will go to a resturant to eat a pie.


This is the version that would make me look surprised. When you ""eat a pie"", that typically means you eat the whole pie. 

The same could be said for cake: ""eat cake"" means ""eat some cake"", but ""eat a cake"" means ""eat the entire cake."" 



We don't usually use the word ""a"" unless a person eats the whole thing as a single unit (in this context, ""a"" means ""one""):


  I went to the restaurant and ate a sandwich.
  I went to the restaurant and ate a gyro.
  I went to the restaurant and ate a salad. 


or unless we specify the unit somehow:


  I went to the restaurant and ate a bowl of soup.
  I went to the restaurant and ate a piece of pie.
  I went to the restaurant and ate a rack of ribs.
  I went to the restaurant and drank a glass of wine. 


But no article is used when there is an unspecified amount of food (the lack of the word ""a"" means ""some""):


  When I get to the restaurant, I'll order scrambled eggs.
  When I get to the restaurant, I'll order spaghetti.
  When I get to the restaurant, I'll order shrimp.
  When I get to the restaurant, I'll order pie for dessert.
  When I get to the restaurant, I'll get coffee.  




Here's something a bit more advanced: The word ""the"" can be used when referring to a particular restaurant's version of a dish. 


  What would you like today, sir?
  I'll have the veal saltimbocca. 

",J.R.,https://ell.stackexchange.com/users/113,http://ell.stackexchange.com/questions/20276/what-does-pie-mean-in-the-following-sentence,CULTURE,ell.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,"What does ""Pai"" mean in the following sentence?","I once saw a sentence: 


  I will go to a restaurant for pie.


Native speakers didn't correct this sentence. I don't know why. I would say ""I will go to a restaurant to eat a pie"". But maybe that sentence was right. Could you please explain to me what that (first) sentence means?
","
  I will go to a resturant for pie.


There is nothing wrong with this sentence. I imagine the speaker will soon be seated in a restaurant, ordering a slice of pie. 

However:


  I will go to a resturant to eat a pie.


This is the version that would make me look surprised. When you ""eat a pie"", that typically means you eat the whole pie. 

The same could be said for cake: ""eat cake"" means ""eat some cake"", but ""eat a cake"" means ""eat the entire cake."" 



We don't usually use the word ""a"" unless a person eats the whole thing as a single unit (in this context, ""a"" means ""one""):


  I went to the restaurant and ate a sandwich.
  I went to the restaurant and ate a gyro.
  I went to the restaurant and ate a salad. 


or unless we specify the unit somehow:


  I went to the restaurant and ate a bowl of soup.
  I went to the restaurant and ate a piece of pie.
  I went to the restaurant and ate a rack of ribs.
  I went to the restaurant and drank a glass of wine. 


But no article is used when there is an unspecified amount of food (the lack of the word ""a"" means ""some""):


  When I get to the restaurant, I'll order scrambled eggs.
  When I get to the restaurant, I'll order spaghetti.
  When I get to the restaurant, I'll order shrimp.
  When I get to the restaurant, I'll order pie for dessert.
  When I get to the restaurant, I'll get coffee.  




Here's something a bit more advanced: The word ""the"" can be used when referring to a particular restaurant's version of a dish. 


  What would you like today, sir?
  I'll have the veal saltimbocca. 

"
3237,3237,5160,Android setOnItemClickListener,"I'm not able to initiate the ""OnItemClickListener"".

You can see my code snippet

 ListAdapter adapter = new SimpleAdapter(this, mylist , R.layout.main, new String[] { ""title""}, new int[] { R.id.item_title});
    setListAdapter(adapter);

    final ListView lv = getListView();
    lv.setTextFilterEnabled(true);

    lv.setOnItemClickListener(new OnItemClickListener() {
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) {              
            @SuppressWarnings(""unchecked"")
            HashMap&lt;String, String&gt; o = (HashMap&lt;String, String&gt;) lv.getItemAtPosition(position);                   
            Toast.makeText(TopNewsActivity.this, ""ID '"" + o.get(""id"") + ""' was clicked."", Toast.LENGTH_LONG).show(); 

        }
    });


after the setListAdapter my debugger goes to ""lv.setOnItemClickListener"" but then does not get into the loop and moves out.

I want to make the links Clickable kindly help.
",ReNa,https://stackoverflow.com/users/694260,"bbalazs is right. I would like to put it more precisely: If you have a view A as a child of a view B and A is by default clickable(button f.e.), than setOnItemClickListener won't work on B.
It is pure magic, but it works so.
",Gangnus,https://stackoverflow.com/users/715269,http://stackoverflow.com/questions/5714522/android-setonitemclicklistener,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,Android setonitemclicklistener,"I'm not able to initiate the ""OnItemClickListener"".

You can see my code snippet

 ListAdapter adapter = new SimpleAdapter(this, mylist , R.layout.main, new String[] { ""title""}, new int[] { R.id.item_title});
    setListAdapter(adapter);

    final ListView lv = getListView();
    lv.setTextFilterEnabled(true);

    lv.setOnItemClickListener(new OnItemClickListener() {
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) {              
            @SuppressWarnings(""unchecked"")
            HashMap&lt;String, String&gt; o = (HashMap&lt;String, String&gt;) lv.getItemAtPosition(position);                   
            Toast.makeText(TopNewsActivity.this, ""ID '"" + o.get(""id"") + ""' was clicked."", Toast.LENGTH_LONG).show(); 

        }
    });


after the setListAdapter my debugger goes to ""lv.setOnItemClickListener"" but then does not get into the loop and moves out.

I want to make the links Clickable kindly help.
","bbalazs is right. I would like to put it more precisely: If you have a view A as a child of a view B and A is by default clickable(button f.e.), than setOnItemClickListener won't work on B.
It is pure magic, but it works so.
"
649,649,1030,Regular Expression to Match String Exactly?,"I'll preface this question by mentioning that while I'm far from a regular expressions guru, they are not completely foreign to me. Building a regular expression to search for a pattern inside a particular string generally isn't a problem for me, but I have a (maybe?) unique situation.

I have a set of values, say:


  028938
  DEF567987
  390987.456
  GHI345928.039  


I want to match a certain set of strings, such as:


Strings composed of exactly 6 digits
Strings composed of exactly 6 digits, a decimal, followed by exactly 3 more digits


In the above examples, the first and third values should be matched.

I'm using the regular expressions:

[0-9]{6}
[0-9]{6}.[0-9]{3}


Unfortunately, since all the above examples contain the specified pattern, all values are matched. This is not my intention.

So my question, in a nutshell, is how to write a regular expression that matches a string exactly and completely, with no additional characters to the right or left of the matched pattern? Is there a term for this type of matching? (Google was no help.) TIA
",Craig Otis,https://stackoverflow.com/users/88111,"use ^ and $ to match the start and end of your string

^[0-9]{6}$
^[0-9]{6}\.[0-9]{3}$


Reference: http://www.regular-expressions.info/anchors.html

Also, as noted by Mikael Svenson, you can use the word boundary \b if you are searching for this pattern in a larger chunk of text.

Reference: http://www.regular-expressions.info/wordboundaries.html

You could also write both those regexes in one shot

^\d{6}(\.\d{3})?$

",CaffGeek,https://stackoverflow.com/users/54746,http://stackoverflow.com/questions/3479324/regular-expression-to-match-string-exactly,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,A regular expression that exactly matches a string?,"I'll preface this question by mentioning that while I'm far from a regular expressions guru, they are not completely foreign to me. Building a regular expression to search for a pattern inside a particular string generally isn't a problem for me, but I have a (maybe?) unique situation.

I have a set of values, say:


  028938
  DEF567987
  390987.456
  GHI345928.039  


I want to match a certain set of strings, such as:


Strings composed of exactly 6 digits
Strings composed of exactly 6 digits, a decimal, followed by exactly 3 more digits


In the above examples, the first and third values should be matched.

I'm using the regular expressions:

[0-9]{6}
[0-9]{6}.[0-9]{3}


Unfortunately, since all the above examples contain the specified pattern, all values are matched. This is not my intention.

So my question, in a nutshell, is how to write a regular expression that matches a string exactly and completely, with no additional characters to the right or left of the matched pattern? Is there a term for this type of matching? (Google was no help.) TIA
","use ^ and $ to match the start and end of your string

^[0-9]{6}$
^[0-9]{6}\.[0-9]{3}$


Reference: http://www.regular-expressions.info/anchors.html

Also, as noted by Mikael Svenson, you can use the word boundary \b if you are searching for this pattern in a larger chunk of text.

Reference: http://www.regular-expressions.info/wordboundaries.html

You could also write both those regexes in one shot

^\d{6}(\.\d{3})?$

"
1433,1433,2254,Layman's guide to getting started with Forex (foreign exchange trading)?,"How should I get started with Forex (foreign exchange trading)? How should I prepare myself for it? Please give your answer thinking of me as a layman.
",harvardfail,https://money.stackexchange.com/users/4311,"I definitely can recommend you a site called babypips. Their beginner course section is great to get a good overview what you ""could"" do in FOREX trading. For starting out I definitely recommend a dummy account! (NEVER use real money in the beginning!)
",Kare,https://money.stackexchange.com/users/10583,http://money.stackexchange.com/questions/12446/laymans-guide-to-getting-started-with-forex-foreign-exchange-trading,LIFE_ARTS,money.stackexchange.com,1.0,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.5555555555555556,0.8888888888888888,1.0,0.6,0.6666666666666666,0.3333333333333333,0.0,1.0,A guide to foreign exchange trading?,How should I start foreign exchange trading? How can I prepare? Please answer me as a layman.,"I definitely can recommend you a site called babypips. Their beginner course section is great to get a good overview what you ""could"" do in FOREX trading. For starting out I definitely recommend a dummy account! (NEVER use real money in the beginning!)
"
1935,1935,3086,Timing inside a shift register,"How I imagine synchronous digital networks work: data lines are sampled at rising clock edge, a set of transients occur, system settles, and data lines are sampled again on next rising edge. I would place transients at falling clock edges, that way both Tsu and Th time for sampling are clear. (Somewhat similar to SPI bus behavior.)

What see in a datasheet of a real world device (74595): D flipflops connected in series having a common clock. At the output of the first flipflop, transient on the data line follows rising clock edge with Tpd. The next flipflop needs Th time stable data line after rising edge to operate correctly. Of course it works because Tpd>Th, but it's only a matter of nanoseconds.

My problem with all this is that it's not robust (maybe not the best word). Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge. Random errors caused by Th>Tpd are not really visible and go undetected. If I connect another shift register in series from a different technology, which requires longer hold times, the circuit won't work, no matter how slow clock I chose.

Is this the way most commonly synchronous digital circuits are constructed? Only the propagation delay of components make it work? Am I being to idealistic? :)
",Gyorgy Szekely,https://electronics.stackexchange.com/users/23677,"
  My problem with all this is that it's not robust (maybe not the best word). Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge. Random errors caused by Th>Tpd are not really visible and go undetected. If I connect another shift register in series from a different technology, which requires longer hold times, the circuit won't work, no matter how slow clock I chose.


You bring up two issues. Let's call the two synchronous circuits A and B, where A feeds into B, and both share the same clock


Circuit won't work if total Tpd(A) &lt; Th(B) where Tpd is the combinational delay of the clock. Is this true? Absolutely! You're the circuit designer and it's your final responsibility to make sure the circuit works. In reality, it's not usually a source of worry; even if you feed one register output right into another's input, the design margin of the chip's specs is high. For a NXP 74HC595, for example, typical propagation delay at 4.5V supply is 19ns, required hold time is 3nsec, and typical hold time is -2nsec -- no problem there. For a TI SN74LV595A at 5V, typical propagation delay is 4.5nsec, minimum propagation delay is 1nsec, required hold time is 2nsec. Could this be a problem if the propagation delay and hold times are at their worst case? Absolutely. Could it be a problem if you cascade a SN74LV595A into an NXP74HC595? Absolutely. In those cases you may need to add combinational elements (buffers) with enough delay to make sure the hold time is met.
""Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge."" True. Take a tip from SPI buses, and set the logic analyzer so that it samples the data on the clock falling edge. SPI's rules are simple: you update outputs on one edge, and you sample inputs on the other.

",Jason S,https://electronics.stackexchange.com/users/330,http://electronics.stackexchange.com/questions/23771/timing-inside-a-shift-register,TECHNOLOGY,electronics.stackexchange.com,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.3333333333333333,0.3333333333333333,1.0,1.0,Timing in shift register,"How I imagine synchronous digital networks work: data lines are sampled at rising clock edge, a set of transients occur, system settles, and data lines are sampled again on next rising edge. I would place transients at falling clock edges, that way both Tsu and Th time for sampling are clear. (Somewhat similar to SPI bus behavior.)

What see in a datasheet of a real world device (74595): D flipflops connected in series having a common clock. At the output of the first flipflop, transient on the data line follows rising clock edge with Tpd. The next flipflop needs Th time stable data line after rising edge to operate correctly. Of course it works because Tpd>Th, but it's only a matter of nanoseconds.

My problem with all this is that it's not robust (maybe not the best word). Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge. Random errors caused by Th>Tpd are not really visible and go undetected. If I connect another shift register in series from a different technology, which requires longer hold times, the circuit won't work, no matter how slow clock I chose.

Is this the way most commonly synchronous digital circuits are constructed? Only the propagation delay of components make it work? Am I being to idealistic? :)
","
  My problem with all this is that it's not robust (maybe not the best word). Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge. Random errors caused by Th>Tpd are not really visible and go undetected. If I connect another shift register in series from a different technology, which requires longer hold times, the circuit won't work, no matter how slow clock I chose.


You bring up two issues. Let's call the two synchronous circuits A and B, where A feeds into B, and both share the same clock


Circuit won't work if total Tpd(A) &lt; Th(B) where Tpd is the combinational delay of the clock. Is this true? Absolutely! You're the circuit designer and it's your final responsibility to make sure the circuit works. In reality, it's not usually a source of worry; even if you feed one register output right into another's input, the design margin of the chip's specs is high. For a NXP 74HC595, for example, typical propagation delay at 4.5V supply is 19ns, required hold time is 3nsec, and typical hold time is -2nsec -- no problem there. For a TI SN74LV595A at 5V, typical propagation delay is 4.5nsec, minimum propagation delay is 1nsec, required hold time is 2nsec. Could this be a problem if the propagation delay and hold times are at their worst case? Absolutely. Could it be a problem if you cascade a SN74LV595A into an NXP74HC595? Absolutely. In those cases you may need to add combinational elements (buffers) with enough delay to make sure the hold time is met.
""Visualizing stuff on a logic analyzer will be less useful because data lines practically change in sync with clock rising edge."" True. Take a tip from SPI buses, and set the logic analyzer so that it samples the data on the clock falling edge. SPI's rules are simple: you update outputs on one edge, and you sample inputs on the other.

"
4292,4292,6841,"What is the Goal of ""Hot Network Questions""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
",jmac,https://meta.stackexchange.com/users/209637,"I agree that increasing viewership to good questions and driving users to sites they may wish to join but might not naturally visit are both good goals. I would like to mention a third goal:

In the....other corner, random intermittent positive reinforcement

Studies have shown that random intermittent positive reinforcement can be more effective that purely positive reinforcement. This means that a reward that is given for good behaviour, but only sometime and to varying degrees, is more effective than a proportional reward. This is perhaps because people are always chasing the next ""big score"".

So what has this got to do with hot questions?

Hot questions are (one can only hope) good questions with a good answer since the upvotes are a major part of what drives them - So the positive part is taken care of. 

However, it is rare to get one of your questions/answers on the ""Hot questions"" list, and I haven't been able to detect much of a pattern (except that the questions seem to be more easily understandable to a general audience and are high quality) - So the intermittent random portion is taken care of.

And I think we can all agree you are heavily rewarded for having a good answer/question in the hot questions list.

My experience

When I got my first answer on the hot questions list it was the most exciting Stack Exchange had been since the initial honeymoon period was over. These rare periodic large rewards are key to keeping long term expert users loving the site.

Conclusion

I'm not saying that random intermittent positive reinforcement should be the main goal of the hot questions list. But it is an additional positive effect to take into consideration.
",Richard Tingle,https://meta.stackexchange.com/users/220332,http://meta.stackexchange.com/questions/219922/what-is-the-goal-of-hot-network-questions,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,"What is the goal of ""network hot issues""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
","I agree that increasing viewership to good questions and driving users to sites they may wish to join but might not naturally visit are both good goals. I would like to mention a third goal:

In the....other corner, random intermittent positive reinforcement

Studies have shown that random intermittent positive reinforcement can be more effective that purely positive reinforcement. This means that a reward that is given for good behaviour, but only sometime and to varying degrees, is more effective than a proportional reward. This is perhaps because people are always chasing the next ""big score"".

So what has this got to do with hot questions?

Hot questions are (one can only hope) good questions with a good answer since the upvotes are a major part of what drives them - So the positive part is taken care of. 

However, it is rare to get one of your questions/answers on the ""Hot questions"" list, and I haven't been able to detect much of a pattern (except that the questions seem to be more easily understandable to a general audience and are high quality) - So the intermittent random portion is taken care of.

And I think we can all agree you are heavily rewarded for having a good answer/question in the hot questions list.

My experience

When I got my first answer on the hot questions list it was the most exciting Stack Exchange had been since the initial honeymoon period was over. These rare periodic large rewards are key to keeping long term expert users loving the site.

Conclusion

I'm not saying that random intermittent positive reinforcement should be the main goal of the hot questions list. But it is an additional positive effect to take into consideration.
"
1763,1763,2798,Hide microphone button Android virtual keyboard,"I wanted to know if is it possible to hide the microphone button (speech-to-text) in Android Virtual Keyboard programatically.

I know I can disable this option through device settings, but I don't want the user to use this feature in my application independently of his/her settings. 
I mean i want to force this behaviour inside my app.

Thanks in advance,
Demian
",Demian,https://stackoverflow.com/users/943009,"You can't force the user input through anything other than pre-defined keyboards that already exist in the user's device.

The only way you could get around this is by programming your own custom, on-the-fly keyboard, and that is a very bad idea.

Just disable voice input programmatically by using XML declarations in the EditText you're looking at.  You can do this with the attribute:

android:privateImeOptions=""nm""

",Codeman,https://stackoverflow.com/users/598637,http://stackoverflow.com/questions/7405500/hide-microphone-button-android-virtual-keyboard,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.7777777777777778,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,1.0,Hide microphone button Android virtual keyboard,"I wanted to know if is it possible to hide the microphone button (speech-to-text) in Android Virtual Keyboard programatically.

I know I can disable this option through device settings, but I don't want the user to use this feature in my application independently of his/her settings. 
I mean i want to force this behaviour inside my app.

Thanks in advance,
Demian
","You can't force the user input through anything other than pre-defined keyboards that already exist in the user's device.

The only way you could get around this is by programming your own custom, on-the-fly keyboard, and that is a very bad idea.

Just disable voice input programmatically by using XML declarations in the EditText you're looking at.  You can do this with the attribute:

android:privateImeOptions=""nm""

"
1460,1460,2297,How do I deal with a slow and undedicated colleague in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
",HOT,https://programmers.stackexchange.com/users/34092,"There are a number of issues at work. Be aware that:


You are making assumptions about the motivations of other people
You are coloring facts with opinions.
Outsiders (anyone else) are not aware of the history and are not aware of your frustrations with your colleague. 
You may look childish if it appears that you are playing a ""gotcha"" game. Your colleague can probably play it better - after all he still has a job doesn't he? 


Therefore, when presenting the status of your project:


Do not mention the other person.
When reporting errors or issues with the code - not the developer. Say ""The call to method FooBar() is returning 1 when it should be returning a 2"". Then any issue is not a personal attack, you are just talking about code - not people.
stick to the facts that you have proof for.
If your colleague gets defensive or hostile, ask questions. ""I don't understand why you think that I should do _ ""
Be oblivious to social slights or innuendoes. Pretend you don't get the personal attack.
Get lots of sleep the night before any status meeting, so you are mentally nimble.
Document, document, document.
Don't be shy about asking this guy to help you with some interesting problem, he might take to you if he feels that you respect him. This is about building rapport. (note this is not sucking up - this is something else ) 
Be prepared to leave if you have to, so that way you are not needy or emotionally trapped. This will help with keeping your head in meetings.

",Pat,https://programmers.stackexchange.com/users/31992,http://programmers.stackexchange.com/questions/101528/how-do-i-deal-with-a-slow-and-undedicated-colleague-in-the-team,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,How can I deal with a colleague who is slow-moving and lacks dedication in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
","There are a number of issues at work. Be aware that:


You are making assumptions about the motivations of other people
You are coloring facts with opinions.
Outsiders (anyone else) are not aware of the history and are not aware of your frustrations with your colleague. 
You may look childish if it appears that you are playing a ""gotcha"" game. Your colleague can probably play it better - after all he still has a job doesn't he? 


Therefore, when presenting the status of your project:


Do not mention the other person.
When reporting errors or issues with the code - not the developer. Say ""The call to method FooBar() is returning 1 when it should be returning a 2"". Then any issue is not a personal attack, you are just talking about code - not people.
stick to the facts that you have proof for.
If your colleague gets defensive or hostile, ask questions. ""I don't understand why you think that I should do _ ""
Be oblivious to social slights or innuendoes. Pretend you don't get the personal attack.
Get lots of sleep the night before any status meeting, so you are mentally nimble.
Document, document, document.
Don't be shy about asking this guy to help you with some interesting problem, he might take to you if he feels that you respect him. This is about building rapport. (note this is not sucking up - this is something else ) 
Be prepared to leave if you have to, so that way you are not needy or emotionally trapped. This will help with keeping your head in meetings.

"
3950,3950,6303,"Huffy Cranbrook 26"" Ladies' Cruiser crank / pedal / chain ""pop"" sound...?","Before you say it's a cheap bike, what more do you want... I get that! :D
But it's brand new, and as you pedal it... no matter the speed, you get a pop sound at a specific point on each rotation...

What could / should I do to help silence this sound and make the ride more enjoyable.

Please advise if you can!

VIDEO UPDATE:
I uploaded this video of the happenings ;)


                
            
",Joshua F. Rountree,https://bicycles.stackexchange.com/users/4032,"I have the exact same bike with the exact same problem. After a while of riding the chain broke and fell off on the road leaving me without brakes headed into traffic. I suggest buying a new chain for these bikes. So far I've had to replace quit a few of the parts on this bike, including the plastic pedals, the handle bar grippers, the chain, and both inner tubes( which suddenly popped with no sign of a puncture). It's a good looking bike but just about everything on it is trash.
",Daniel,https://bicycles.stackexchange.com/users/9009,http://bicycles.stackexchange.com/questions/9307/huffy-cranbrook-26-ladies-cruiser-crank-pedal-chain-pop-sound,CULTURE,bicycles.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,"Hafi Cranbrook 26 ""women's cruiser crank / pedal / chain"" Bang...?","Before you say it's a cheap bike, what more do you want... I get that! :D
But it's brand new, and as you pedal it... no matter the speed, you get a pop sound at a specific point on each rotation...

What could / should I do to help silence this sound and make the ride more enjoyable.

Please advise if you can!

VIDEO UPDATE:
I uploaded this video of the happenings ;)


                
            
","I have the exact same bike with the exact same problem. After a while of riding the chain broke and fell off on the road leaving me without brakes headed into traffic. I suggest buying a new chain for these bikes. So far I've had to replace quit a few of the parts on this bike, including the plastic pedals, the handle bar grippers, the chain, and both inner tubes( which suddenly popped with no sign of a puncture). It's a good looking bike but just about everything on it is trash.
"
4524,4524,7169,Would magic 'weapons' make the monk more balanced?,"The monk in D&amp;D 3.5 (and, to a lesser extent, in Pathfinder) is generally considered underpowered. 

Would adding magic 'weapons' that could add enhancement bonuses and magic weapon effects to a monk's unarmed strikes be sufficient to re-balance them? Would they then be over-balanced?

To be specific I'm thinking of something like hand wraps that are a zero-cost weapon having no mundane effect on combat (the wielder counts as unarmed) but  that can be enchanted in the same way and at the same cost as a normal magic weapon.

Update: 

Thanks to @mxyzplk, I see that Gauntlets would effectively fulfill this effect. Odd that I haven't seen this in any of the discussions on monk optimisation!

Regarding assessing balance, I'll judge this based on how well it addresses the issues in @KRyan's answer in the above-linked question. Obviously if anyone doesn't agree with his analysis then this question is moot, although I would like to see those competing opinions.
",Paul Hutton,https://rpg.stackexchange.com/users/2689,"Sure they help.

First of all, the monk isn't designed to be better at a single thing than other classes, so expecting its DPR to match a fighter's is a false expectation and in my opinion the monk being ""underpowered"" is a problem that exists only in highly optimized games, which is not the sum total of all the game types out there.  The linked question is about optimizing and making the monk ""brokenly good,"" which I can't speak to. However, in the various campaigns I've played in since 2000 with various groups in various cities under 3e, 3.5, and Pathfinder, monks have been popular classes at the table and have been considered a fun option not terribly overshadowed by others. 

However, it's certainly not the strongest class, and so Paizo's put out some gear and changes to help the monk get better! The amulet of mighty fists is the usual core item to magically buff the monk.  They just revised it and lowered its price, as well as gave the monk's ki strike some DR-overcoming power - see ""Monkeying Around"" on the Paizo blog.

The new body wrap of mighty strikes also directly augments unarmed strikes.  

There's been back and forth debate and conflicting rulings (to the point of conflicting verbiage in successive printings of the same weapon in different books) on whether weapons like cesti, gauntlets, rope gauntlets, emei piercers, and/or brass knuckles use a monk's unarmed damage or not. Many are monk weapons and thus by definition may be flurried, ki striked, etc. with, but the damage has been debated. I just say ""yes, use your unarmed damage"" to all of them.  In my pirate campaign the captain is a monk; he has magical gauntlets and also some cold iron brass knuckles he bought that have the knuckles inscribed with ""ELFPU"" and ""NCHER"".  By letting these weapons leverage unarmed damage, the monk avoids some of his traditional problems with DR and cheaper enhancement means less ""flurry of misses.""
",mxyzplk,https://rpg.stackexchange.com/users/140,http://rpg.stackexchange.com/questions/22452/would-magic-weapons-make-the-monk-more-balanced,CULTURE,rpg.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,Will magic weapons make monks more balanced?,"The monk in D&amp;D 3.5 (and, to a lesser extent, in Pathfinder) is generally considered underpowered. 

Would adding magic 'weapons' that could add enhancement bonuses and magic weapon effects to a monk's unarmed strikes be sufficient to re-balance them? Would they then be over-balanced?

To be specific I'm thinking of something like hand wraps that are a zero-cost weapon having no mundane effect on combat (the wielder counts as unarmed) but  that can be enchanted in the same way and at the same cost as a normal magic weapon.

Update: 

Thanks to @mxyzplk, I see that Gauntlets would effectively fulfill this effect. Odd that I haven't seen this in any of the discussions on monk optimisation!

Regarding assessing balance, I'll judge this based on how well it addresses the issues in @KRyan's answer in the above-linked question. Obviously if anyone doesn't agree with his analysis then this question is moot, although I would like to see those competing opinions.
","Sure they help.

First of all, the monk isn't designed to be better at a single thing than other classes, so expecting its DPR to match a fighter's is a false expectation and in my opinion the monk being ""underpowered"" is a problem that exists only in highly optimized games, which is not the sum total of all the game types out there.  The linked question is about optimizing and making the monk ""brokenly good,"" which I can't speak to. However, in the various campaigns I've played in since 2000 with various groups in various cities under 3e, 3.5, and Pathfinder, monks have been popular classes at the table and have been considered a fun option not terribly overshadowed by others. 

However, it's certainly not the strongest class, and so Paizo's put out some gear and changes to help the monk get better! The amulet of mighty fists is the usual core item to magically buff the monk.  They just revised it and lowered its price, as well as gave the monk's ki strike some DR-overcoming power - see ""Monkeying Around"" on the Paizo blog.

The new body wrap of mighty strikes also directly augments unarmed strikes.  

There's been back and forth debate and conflicting rulings (to the point of conflicting verbiage in successive printings of the same weapon in different books) on whether weapons like cesti, gauntlets, rope gauntlets, emei piercers, and/or brass knuckles use a monk's unarmed damage or not. Many are monk weapons and thus by definition may be flurried, ki striked, etc. with, but the damage has been debated. I just say ""yes, use your unarmed damage"" to all of them.  In my pirate campaign the captain is a monk; he has magical gauntlets and also some cold iron brass knuckles he bought that have the knuckles inscribed with ""ELFPU"" and ""NCHER"".  By letting these weapons leverage unarmed damage, the monk avoids some of his traditional problems with DR and cheaper enhancement means less ""flurry of misses.""
"
4350,4350,6925,Do the four brothers in TMNT train in other weapons?,"So I've been watching a lot of the 2003 TMNT cartoon, and I've noticed that whilst they claim to be ninjas they only seem to use their own iconic weapons.

Is there any evidence that they train with other weapons? I'm not asking about just use, I mean proper training, involving kata or some such?

Because I like to pretend all the reboots and remakes share a sort of pseudo-canon I'm happy for answers from the comics or other cartoons.
",AncientSwordRage,https://scifi.stackexchange.com/users/3804,"All of the turtles were trained by Master Splinter who learned his martial arts from his owner before he was mutated. He taught the Turtles all the martial arts they knew and each Turtle is quite capable no matter what weapons they used. They are all capable open-hand fighters and able to use any weapon they have at hand when necessary. 

When the original comics were written, each had chosen a signature weapon that suited their mental preferences and combat styles. Eastman and Laird showed many examples during their appearances in the comic series. The cartoons were far less likely to show such training since the cartoons were often a marketing tool for associated toys.



The Turtles trained from 7:00 AM until noon. Master Splinter extols that diligence is the only path to mastery. Tales of the TMNT (Vol. 2) #55



Bo Staff (Donatello) vs Tonfa (Raphael) from Teenage Mutant Ninja Turtles vol.1 #9



Leonardo vs Raphael in sword training from Teenage Mutant Ninja Turtles vol.1 #9



Leonardo effectively throws shuriken from Teenage Mutant Ninja Turtles vol.1 #9


Leonardo (Dual Katanas): The Sword is the weapon of leadership and command. The de facto leader of the Turtles, Leonardo is courageous, decisive, and a disciplined student of martial arts. As a strict adherent to Bushido, he has a very strong sense of honor and justice.
Raphael (Dual Sais): The sai is used both offensively and defensively, can be used to pierce or club an opponent and is able to disarm an opponent. Sais can also be thrown. The team's ""Hot-Head"", Raphael has an aggressive nature and seldom hesitates to throw the first punch. He is also an intense fighter. His personality can be alternately fierce, sarcastic, and full of angst, and oftentimes delivers deadpan humor. Still, he is good-hearted, willing to protect others and is intensely loyal.
Michelangelo (Dual Nunchakus): Nunchaku are fast and deadly, requiring extreme skill and reflexes. Michelangelo is easily the most agile and quick of all the Turtles. The easy-going and free-spirited Michelangelo provides much of the comic relief. While he loves to read comics and eat pizza, this Turtle also has an adventurous side. 
Donatello (Bo Staff): Used to keep an opponent at range, but capable of dealing devastating damage in the hands of a master. The inventor, and technology geek, Donatello has a reputation as something of a smart aleck. He is perhaps the least violent Turtle, preferring to use his intellect to solve conflicts. 
Splinter - The Turtles' sensei and adoptive father, Splinter is a mutant rat who learned the ways of ninjutsu from his own master, Hamato Yoshi. Splinter is able to use any and all martial arts weapons. In the 1987 TV series and Archie Comics series, Splinter was Hamato Yoshi mutated into a rat instead of being just Yoshi's pet. Splinter's name is a parody of Stick, the man who mentored Daredevil.

",Thaddeus Howze,https://scifi.stackexchange.com/users/2765,http://scifi.stackexchange.com/questions/27219/do-the-four-brothers-in-tmnt-train-in-other-weapons,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.8333333333333334,0.8333333333333334,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,0.8,0.0,0.0,0.0,1.0,Did TMNT's four brothers train with other weapons?,"So I've been watching a lot of the 2003 TMNT cartoon, and I've noticed that whilst they claim to be ninjas they only seem to use their own iconic weapons.

Is there any evidence that they train with other weapons? I'm not asking about just use, I mean proper training, involving kata or some such?

Because I like to pretend all the reboots and remakes share a sort of pseudo-canon I'm happy for answers from the comics or other cartoons.
","All of the turtles were trained by Master Splinter who learned his martial arts from his owner before he was mutated. He taught the Turtles all the martial arts they knew and each Turtle is quite capable no matter what weapons they used. They are all capable open-hand fighters and able to use any weapon they have at hand when necessary. 

When the original comics were written, each had chosen a signature weapon that suited their mental preferences and combat styles. Eastman and Laird showed many examples during their appearances in the comic series. The cartoons were far less likely to show such training since the cartoons were often a marketing tool for associated toys.



The Turtles trained from 7:00 AM until noon. Master Splinter extols that diligence is the only path to mastery. Tales of the TMNT (Vol. 2) #55



Bo Staff (Donatello) vs Tonfa (Raphael) from Teenage Mutant Ninja Turtles vol.1 #9



Leonardo vs Raphael in sword training from Teenage Mutant Ninja Turtles vol.1 #9



Leonardo effectively throws shuriken from Teenage Mutant Ninja Turtles vol.1 #9


Leonardo (Dual Katanas): The Sword is the weapon of leadership and command. The de facto leader of the Turtles, Leonardo is courageous, decisive, and a disciplined student of martial arts. As a strict adherent to Bushido, he has a very strong sense of honor and justice.
Raphael (Dual Sais): The sai is used both offensively and defensively, can be used to pierce or club an opponent and is able to disarm an opponent. Sais can also be thrown. The team's ""Hot-Head"", Raphael has an aggressive nature and seldom hesitates to throw the first punch. He is also an intense fighter. His personality can be alternately fierce, sarcastic, and full of angst, and oftentimes delivers deadpan humor. Still, he is good-hearted, willing to protect others and is intensely loyal.
Michelangelo (Dual Nunchakus): Nunchaku are fast and deadly, requiring extreme skill and reflexes. Michelangelo is easily the most agile and quick of all the Turtles. The easy-going and free-spirited Michelangelo provides much of the comic relief. While he loves to read comics and eat pizza, this Turtle also has an adventurous side. 
Donatello (Bo Staff): Used to keep an opponent at range, but capable of dealing devastating damage in the hands of a master. The inventor, and technology geek, Donatello has a reputation as something of a smart aleck. He is perhaps the least violent Turtle, preferring to use his intellect to solve conflicts. 
Splinter - The Turtles' sensei and adoptive father, Splinter is a mutant rat who learned the ways of ninjutsu from his own master, Hamato Yoshi. Splinter is able to use any and all martial arts weapons. In the 1987 TV series and Archie Comics series, Splinter was Hamato Yoshi mutated into a rat instead of being just Yoshi's pet. Splinter's name is a parody of Stick, the man who mentored Daredevil.

"
4502,4502,7137,What is the torque and sequence for a '99 Jetta Oil Pan?,"I have a '99 Jetta TDI (diesel) with a cracked oil pan.  I'm looking for the sequence of tightening the bolts and the torque needed for each bolt.  I've been doing to google-fu but can't seem to find it. Does anyone specifically know these details, or where I can maybe find this?

Note: Can someone with priv please put 'oil-pan' and 'bolt-sequence' as tags :)
",KronoS,https://mechanics.stackexchange.com/users/578,"Oil pans don't have a specific bolt sequence like a cylinder head or crankshaft bolts. 

This link should be helpful: TDIClub Forums - View Single Post -  frequently asked torque specs:


  Use Silicone sealant D 176 404 A2
  
  Removing
  Remove center, left and right sound insulation trays:
  
  Drain engine oil. 
  
  Remove securing bolts for oil pan. 
  
  Loosen oil pan with light blows of a rubber-headed hammer, if necessary. 
  
  Remove oil pan. 
  
  Remove sealant residue on cylinder block with a flat scraper. 
  
  Remove sealant residue on oil pan with a rotating brush, e.g. a drill motor with a plastic brush (wear eye protection). 
  
  Clean sealing surfaces. Surfaces must be free of oil and grease. 
  
  Installing
  Note: Observe the use-by date of the sealing compound. 
  
  The oil pan must be installed within 5 minutes of applying the silicone sealing compound. 
  
  Cut off tube nozzle at forward marking (approx. nozzle diameter: 3 mm). 
  
  Apply silicone sealing compound, as shown, to clean oil pan sealing surface. Sealant bead must be 2 to 3 mm thick 
  
  Run along inner side of bolt holes 
  
  The sealing compound bead must not be thicker, otherwise excess sealing compound will enter the oil pan and may block the oil suction pipe strainer. 
  
  Apply silicone sealant bead carefully as shown to areas marked by arrows. (Illustration shows position of sealant bead on cylinder block). 
  
  Install oil pan immediately and tighten all oil pan bolts lightly. 
  
  The oil pan must be flush with the cylinder block. 
  
  Tighten oil pan bolts to 15 Nm. 
  
  Tighten oil pan/transmission bolts to 45 Nm. 
  
  Let the sealing compound dry for approx. 30 minutes after installing the oil pan. Only then fill the engine with oil. 
  
  Further assembly is basically the reverse of the disassembly procedure. 

",Dude318is,https://mechanics.stackexchange.com/users/194,http://mechanics.stackexchange.com/questions/1013/what-is-the-torque-and-sequence-for-a-99-jetta-oil-pan,CULTURE,mechanics.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,99 what is the torque and sequence for the Jetta sump?,"I have a 99 year old Jetta TDI with a cracked oil pan. I am looking for the sequence of tightening bolts and the torque required for each bolt. I've been looking up Fu on Google, but I can't seem to find it. Is anyone particularly aware of these details, or where can I find them?","Oil pans don't have a specific bolt sequence like a cylinder head or crankshaft bolts. 

This link should be helpful: TDIClub Forums - View Single Post -  frequently asked torque specs:


  Use Silicone sealant D 176 404 A2
  
  Removing
  Remove center, left and right sound insulation trays:
  
  Drain engine oil. 
  
  Remove securing bolts for oil pan. 
  
  Loosen oil pan with light blows of a rubber-headed hammer, if necessary. 
  
  Remove oil pan. 
  
  Remove sealant residue on cylinder block with a flat scraper. 
  
  Remove sealant residue on oil pan with a rotating brush, e.g. a drill motor with a plastic brush (wear eye protection). 
  
  Clean sealing surfaces. Surfaces must be free of oil and grease. 
  
  Installing
  Note: Observe the use-by date of the sealing compound. 
  
  The oil pan must be installed within 5 minutes of applying the silicone sealing compound. 
  
  Cut off tube nozzle at forward marking (approx. nozzle diameter: 3 mm). 
  
  Apply silicone sealing compound, as shown, to clean oil pan sealing surface. Sealant bead must be 2 to 3 mm thick 
  
  Run along inner side of bolt holes 
  
  The sealing compound bead must not be thicker, otherwise excess sealing compound will enter the oil pan and may block the oil suction pipe strainer. 
  
  Apply silicone sealant bead carefully as shown to areas marked by arrows. (Illustration shows position of sealant bead on cylinder block). 
  
  Install oil pan immediately and tighten all oil pan bolts lightly. 
  
  The oil pan must be flush with the cylinder block. 
  
  Tighten oil pan bolts to 15 Nm. 
  
  Tighten oil pan/transmission bolts to 45 Nm. 
  
  Let the sealing compound dry for approx. 30 minutes after installing the oil pan. Only then fill the engine with oil. 
  
  Further assembly is basically the reverse of the disassembly procedure. 

"
913,913,1448,Is my interval training routine effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
",DigiKev,https://bicycles.stackexchange.com/users/3323,"At the end of this workout are you 'smoked'? If so, then these are 'anaerobic endurance' intervals. Some training plans suggest just starting these 6-8 weeks before your first ""A race""

Some plans suggest you work on ""muscular endurance"" first with long fairly hard efforts = 10m plus - then 6-8 weeks prior add anaerobic endurance intervals. The two biggest abilities for MTB are said to be muscular and anaerobic endurance.

http://www.joefrielsblog.com/2011/01/build-period-overview.html
",user6124,https://bicycles.stackexchange.com/users/6124,http://bicycles.stackexchange.com/questions/7801/is-my-interval-training-routine-effective-for-mountain-bike-training,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Is my interval training effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
","At the end of this workout are you 'smoked'? If so, then these are 'anaerobic endurance' intervals. Some training plans suggest just starting these 6-8 weeks before your first ""A race""

Some plans suggest you work on ""muscular endurance"" first with long fairly hard efforts = 10m plus - then 6-8 weeks prior add anaerobic endurance intervals. The two biggest abilities for MTB are said to be muscular and anaerobic endurance.

http://www.joefrielsblog.com/2011/01/build-period-overview.html
"
5738,5738,9087,In-game rewards for game-related work?,"The other GM in my group and I are both big fans of giving XP rewards for things done out of the game. Ex: We have an artist who will draw and design all sorts of stuff to ""fluff out"" our campaign. 

We noticed participation spiked when we offered rewards like this. Eventually, we even offered XP to our ""scribe"" for recording everything that happened each session. At the most, though, this gives bonus XP for up to two of our players. We do not plan to remove these bonuses, but want to be fair to all our players.

What are some fun things your players can do out of game that you can reward as GM? The goal is to have them be engaged in our game even when we aren't playing.
",pblock,https://rpg.stackexchange.com/users/8116,"For our group, we usually went for non-xp or level related rewards. Usually, we tried to keep them related to the real-life activity.

We were playing in a magic rich campaign, so if these rewards seem high, remember these items were relatively common (though expensive) in our world:


The player giving rides to everyone would find himself with a fairly regular supply of short-lived (they'd expire after limited in-game time) Haste potions, to do with as he pleased. 
The cartographer would get a choice of one of several items per session, such as find-item scrolls, detect magic wands. Since he put in a lot of work and proved useful to the party, the rewards both scaled up, and were often augmented by in-game tips from other players (the highest reward were single use teleportation items)
Snack providers would get bonus healing potions


etc... As a DM, I particularly liked that the rewards:


didn't mess up my planned levelling-up curve
fit in with the game-play
it was fairly easy to account for the rewards
usually it was items the players would try and stock up on anyways
since they were all consumable, usually with an expiration date, the players were encouraged to deplete their own supplies regularly.

",blueberryfields,https://rpg.stackexchange.com/users/1056,http://rpg.stackexchange.com/questions/25167/in-game-rewards-for-game-related-work,CULTURE,rpg.stackexchange.com,1.0,0.4444444444444444,1.0,0.6666666666666666,0.0,0.0,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.0,1.0,Game rewards for game related work?,"The other GM in my group and I are both big fans of giving XP rewards for things done out of the game. Ex: We have an artist who will draw and design all sorts of stuff to ""fluff out"" our campaign. 

We noticed participation spiked when we offered rewards like this. Eventually, we even offered XP to our ""scribe"" for recording everything that happened each session. At the most, though, this gives bonus XP for up to two of our players. We do not plan to remove these bonuses, but want to be fair to all our players.

What are some fun things your players can do out of game that you can reward as GM? The goal is to have them be engaged in our game even when we aren't playing.
","For our group, we usually went for non-xp or level related rewards. Usually, we tried to keep them related to the real-life activity.

We were playing in a magic rich campaign, so if these rewards seem high, remember these items were relatively common (though expensive) in our world:


The player giving rides to everyone would find himself with a fairly regular supply of short-lived (they'd expire after limited in-game time) Haste potions, to do with as he pleased. 
The cartographer would get a choice of one of several items per session, such as find-item scrolls, detect magic wands. Since he put in a lot of work and proved useful to the party, the rewards both scaled up, and were often augmented by in-game tips from other players (the highest reward were single use teleportation items)
Snack providers would get bonus healing potions


etc... As a DM, I particularly liked that the rewards:


didn't mess up my planned levelling-up curve
fit in with the game-play
it was fairly easy to account for the rewards
usually it was items the players would try and stock up on anyways
since they were all consumable, usually with an expiration date, the players were encouraged to deplete their own supplies regularly.

"
5880,5880,9316,"Can I delete my fork of a BitBucket repository, after the owner has accepted and merged my pull request?","I created a fork of a public repository on BitBucket, with the sole purpose of committing a pull request that fixed some bug. The pull request was accepted and merged. Now, I want to delete the repository, that has outlived its purpose. If I do that, will the changes be lost?

There is already a question about this same issue, but for GitHub. Apparently, on GitHub you can delete the repository before the request has been even merged, as it gets automatically saved in the target repository. I guess that on BitBucket, things will be similar, but I wanted to be sure.
",user8792354,https://stackoverflow.com/users/3497081,"I would say if things work as expected on GitHub, then they would work on BitBucket.  If the pull request was ""accepted and merged"", then nothing you do to your personal repository will modify the repository that has merged in your changes.
",Uxonith,https://stackoverflow.com/users/1217236,http://stackoverflow.com/questions/22857212/can-i-delete-my-fork-of-a-bitbucket-repository-after-the-owner-has-accepted-and,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Can I delete the fork of my bitbucket repository after the owner accepts and merges my pull request?,"I created a fork of a public repository on BitBucket, with the sole purpose of committing a pull request that fixed some bug. The pull request was accepted and merged. Now, I want to delete the repository, that has outlived its purpose. If I do that, will the changes be lost?

There is already a question about this same issue, but for GitHub. Apparently, on GitHub you can delete the repository before the request has been even merged, as it gets automatically saved in the target repository. I guess that on BitBucket, things will be similar, but I wanted to be sure.
","I want to say that if the work on GitHub is normal, then they can work on bitbucket. If the pull request is accepted and merged, nothing done to the personal repository will modify the repository that has been merged into the change."
826,826,1311,I want to run 20A constant current and 4.2V on a load using a variable DC power supply rated same,"I want to run 20A constant current and 4.2V on a load using a variable DC power supply rated as 20A, 30V. But because my power supply is a switching CC, Cv type, and it kept switching to CV at only 1.2A. I really want to run it at 20A and 4.2V (CC, CV) on the same load despite the change of resistance of the load.

I will really appreciate step by step instruction on how to achieve that, if using resistors etc. In more details, the load is a 3.75V, 1000mAh battery and this battery is designed to take this much load for only 3 minutes to recharge. Currently the battery is on the nominal voltage checked using a multimeter.
",greman73,https://electronics.stackexchange.com/users/57116,"I'd be charging that battery in a purpose built charging bag, and wearing Nomex overalls (you, not the battery) while doing so would probably do no harm. 

You also want to be sure that the supply will genuinely deliver 20A at 4.2V. 

Assuming that   


the battery CAN tolerate the rate you say, 
The supply is capable of safely delivering 4.2V at 20A for 3+ minutes.
The supply current limit can not be set when not loaded.


Disconnect any load.
Set supply to say 4.25V.
Set CC control to minimum.
Short supply output terminals
Adjust CC control until I = 20A
Unshort terminals.  

The supply is now ready. When loaded below 4.2V it will deliver 20A.
When Vload rises to 4.2V it will deliver 20A or less. 

Connect supply to fully discharged battery with correct polarity.
After 3 minutes the battery WILL NOT be fully charged.
This is because when Vbattery rises to 4.2V the supply will go into CV mode ND current will be set by the battery. It will start to taper down.
CV to CC change over will probably happen in the 2 m to 2m 30s range.
This is a natural consequence of LiIon / LiPo chemistry.

IF you are sure that the batter will tolerate (for some values of tolerate) a constant 20A input then the charger should be set to 20A CC as above AND the supply voltage set ""higher.
MAYBE 4.5V. Maybe 4.7 Maybe - flaming ruin .... .
This is not how the books ever say you can do it.
this violates the most fundamental principles of LiIon charging.
This sounds like fun :-)

If it works, more power to you, but battery life will be shortened so it will be less energy to you overall long term.
",Russell McMahon,https://electronics.stackexchange.com/users/3288,http://electronics.stackexchange.com/questions/136296/i-want-to-run-20a-constant-current-and-4-2v-on-a-load-using-a-variable-dc-power,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,I want to use the same rated variable DC power supply to run 20A constant current and 4.2V on the load,"I want to run 20A constant current and 4.2V on a load using a variable DC power supply rated as 20A, 30V. But because my power supply is a switching CC, Cv type, and it kept switching to CV at only 1.2A. I really want to run it at 20A and 4.2V (CC, CV) on the same load despite the change of resistance of the load.

I will really appreciate step by step instruction on how to achieve that, if using resistors etc. In more details, the load is a 3.75V, 1000mAh battery and this battery is designed to take this much load for only 3 minutes to recharge. Currently the battery is on the nominal voltage checked using a multimeter.
","I'd be charging that battery in a purpose built charging bag, and wearing Nomex overalls (you, not the battery) while doing so would probably do no harm. 

You also want to be sure that the supply will genuinely deliver 20A at 4.2V. 

Assuming that   


the battery CAN tolerate the rate you say, 
The supply is capable of safely delivering 4.2V at 20A for 3+ minutes.
The supply current limit can not be set when not loaded.


Disconnect any load.
Set supply to say 4.25V.
Set CC control to minimum.
Short supply output terminals
Adjust CC control until I = 20A
Unshort terminals.  

The supply is now ready. When loaded below 4.2V it will deliver 20A.
When Vload rises to 4.2V it will deliver 20A or less. 

Connect supply to fully discharged battery with correct polarity.
After 3 minutes the battery WILL NOT be fully charged.
This is because when Vbattery rises to 4.2V the supply will go into CV mode ND current will be set by the battery. It will start to taper down.
CV to CC change over will probably happen in the 2 m to 2m 30s range.
This is a natural consequence of LiIon / LiPo chemistry.

IF you are sure that the batter will tolerate (for some values of tolerate) a constant 20A input then the charger should be set to 20A CC as above AND the supply voltage set ""higher.
MAYBE 4.5V. Maybe 4.7 Maybe - flaming ruin .... .
This is not how the books ever say you can do it.
this violates the most fundamental principles of LiIon charging.
This sounds like fun :-)

If it works, more power to you, but battery life will be shortened so it will be less energy to you overall long term.
"
2949,2949,4692,ASA5520 stops sending to splunk syslog,"I have an ASA5520 that is set up to send logs to a splunk syslog server.  the setup works for a while, usually around 24 hours or so, but then stops until either the logging is reconfigured (twiddling the ports) or the ASA is restarted.

what should i be looking at to resolve this issue?  im not sure if its the splunk syslog daemon ignoring connections or the ASA that gets messed up and stops sending.

id like to enable the 'dont pass traffic without logging working' option, but without a stable connection to syslog, thats a non starter.

tried so far:
TCP and UDP, different ports, changing the logging level
",Devnull,https://serverfault.com/users/11087,"Put a packet sniffer on the Splunk host, set up a capture filter to capture only packets that originate from the ASA, start a capture, when splunk stops ""seeing"" data from the ASA look at the capture and see if traffic is still coming in from the ASA, if it is then the problem is with Splunk, if it's not then the problem is with the ASA or the network between the two.
",joeqwerty,https://serverfault.com/users/19152,http://serverfault.com/questions/209960,TECHNOLOGY,serverfault.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.5,1.0,Asa5520 stop sending to Splunk syslog,"I have an ASA5520 that is set up to send logs to a splunk syslog server.  the setup works for a while, usually around 24 hours or so, but then stops until either the logging is reconfigured (twiddling the ports) or the ASA is restarted.

what should i be looking at to resolve this issue?  im not sure if its the splunk syslog daemon ignoring connections or the ASA that gets messed up and stops sending.

id like to enable the 'dont pass traffic without logging working' option, but without a stable connection to syslog, thats a non starter.

tried so far:
TCP and UDP, different ports, changing the logging level
","Put a packet sniffer on the Splunk host, set up a capture filter to capture only packets that originate from the ASA, start a capture, when splunk stops ""seeing"" data from the ASA look at the capture and see if traffic is still coming in from the ASA, if it is then the problem is with Splunk, if it's not then the problem is with the ASA or the network between the two.
"
319,319,512,Automatic internationalization in Java,"I have an issue with automatic internationalization in java, using netbeans. In actionListener I am chaging locale with this:

String s = (String)langBox.getSelectedItem();
switch(s){
    case ""ÄeÅ¡tina"":
        BP_evolution.language = ""cs"";
        BP_evolution.currentLocale = new Locale(BP_evolution.language);
        break;
    case ""English"":
        BP_evolution.language = ""en"";
        BP_evolution.currentLocale = new Locale(BP_evolution.language);
        break;
}


Actually, the issue is, that I don't know what function should I call for switching language in my application. I am using Java SE and Swing. Like I already said, ResourceBundle has been created automatically.
",Martin PlÃ¡vek,https://stackoverflow.com/users/4153493,"My issue with this has been resolved by SwingWorkers. When I put the function of switching languages, it started to work.

You can read about it here -> java doc

Problem was probably that main thread stucked with running GUI itself and it was not able to do anything else. 
",Martin PlÃ¡vek,https://stackoverflow.com/users/4153493,http://stackoverflow.com/questions/26573709/automatic-internationalization-in-java,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Automatic internationalization in Java,"I have an issue with automatic internationalization in java, using netbeans. In actionListener I am chaging locale with this:

String s = (String)langBox.getSelectedItem();
switch(s){
    case ""ÄeÅ¡tina"":
        BP_evolution.language = ""cs"";
        BP_evolution.currentLocale = new Locale(BP_evolution.language);
        break;
    case ""English"":
        BP_evolution.language = ""en"";
        BP_evolution.currentLocale = new Locale(BP_evolution.language);
        break;
}


Actually, the issue is, that I don't know what function should I call for switching language in my application. I am using Java SE and Swing. Like I already said, ResourceBundle has been created automatically.
","My issue with this has been resolved by SwingWorkers. When I put the function of switching languages, it started to work.

You can read about it here -> java doc

Problem was probably that main thread stucked with running GUI itself and it was not able to do anything else. 
"
3661,3661,5841,Best way to move live site local,"I'm trying to move a big site that's currently live onto my local machine so I can edit locally. I'm using Wamp Server. I've tried using the Duplicator plugin but I'm getting several warnings and errors when I try to unpackage it locally. Is there a more foolproof way to do this?

Otherwise, would it be easier to move the live site onto a sub-domain on my personal site? Something like 'site.com/clients/test-site'? I just need an environment where I can make changes without affecting the live site.
",vytfla,https://wordpress.stackexchange.com/users/36530,"Why didn't you try to copy your live website manually. It's not as easy as using a plugin but much more error proof. You will need to follow these steps.


Make a dump of MYSQL database on server.

mysqldump -u username -p -h localhost dbname &gt; domain.sql

Create a archive of your WordPress website on server.

tar -czf domain.tar.gz domain.com

Download both on local machine. And extract the archive.

tar -xzf domain.tar.gz

Import database at local machine.

mysql -u username -p -h localhost dbname &lt; domain.sql

Now change wp-config.php values for local server.
Change domain name in MySQL. You can run these mysql queries to replace it with local domain setup.

UPDATE wp_options SET option_value = replace(option_value, 'http://www.oldurl.com', 'http://www.newurl.com') WHERE option_name = 'home' OR option_name = 'siteurl';
UPDATE wp_posts SET guid = replace(guid, 'http://www.oldurl.com','http://www.newurl.com');
UPDATE wp_posts SET post_content = replace(post_content, 'http://www.oldurl.com', 'http://www.newurl.com');
UPDATE wp_postmeta SET meta_value = replace(meta_value,'http://www.oldurl.com','http://www.newurl.com');



Or simply define these in wp-config.php, these will overwrite domain URLs in database. I think this will be better for local development.

define( 'WP_HOME', 'http://example.com/blog' );
define( 'WP_SITEURL', 'http://example.com/blog' );



Done.


I develop and move nearly 7-10 WordPress websites each month and this is what I do. I can't say it's better than using a plugin or any other migration tool but it's more controlled. And once you get familiar with the process, there are very less chances of error.
",Robert hue,https://wordpress.stackexchange.com/users/22461,http://wordpress.stackexchange.com/questions/166905/best-way-to-move-live-site-local,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.0,0.7777777777777778,Best way to move the site locally,"I'm trying to move a big site that's currently live onto my local machine so I can edit locally. I'm using Wamp Server. I've tried using the Duplicator plugin but I'm getting several warnings and errors when I try to unpackage it locally. Is there a more foolproof way to do this?

Otherwise, would it be easier to move the live site onto a sub-domain on my personal site? Something like 'site.com/clients/test-site'? I just need an environment where I can make changes without affecting the live site.
","Why didn't you try to copy your live website manually. It's not as easy as using a plugin but much more error proof. You will need to follow these steps.


Make a dump of MYSQL database on server.

mysqldump -u username -p -h localhost dbname &gt; domain.sql

Create a archive of your WordPress website on server.

tar -czf domain.tar.gz domain.com

Download both on local machine. And extract the archive.

tar -xzf domain.tar.gz

Import database at local machine.

mysql -u username -p -h localhost dbname &lt; domain.sql

Now change wp-config.php values for local server.
Change domain name in MySQL. You can run these mysql queries to replace it with local domain setup.

UPDATE wp_options SET option_value = replace(option_value, 'http://www.oldurl.com', 'http://www.newurl.com') WHERE option_name = 'home' OR option_name = 'siteurl';
UPDATE wp_posts SET guid = replace(guid, 'http://www.oldurl.com','http://www.newurl.com');
UPDATE wp_posts SET post_content = replace(post_content, 'http://www.oldurl.com', 'http://www.newurl.com');
UPDATE wp_postmeta SET meta_value = replace(meta_value,'http://www.oldurl.com','http://www.newurl.com');



Or simply define these in wp-config.php, these will overwrite domain URLs in database. I think this will be better for local development.

define( 'WP_HOME', 'http://example.com/blog' );
define( 'WP_SITEURL', 'http://example.com/blog' );



Done.


I develop and move nearly 7-10 WordPress websites each month and this is what I do. I can't say it's better than using a plugin or any other migration tool but it's more controlled. And once you get familiar with the process, there are very less chances of error.
"
3503,3503,5587,Using logical operators on loops results in contradiction,"I'm dealing with a really, really weird issue in JavaScript. I'm working on a validator script that loops through a list of fields with jQuery. Each validation is tied to a regular expression on an object that goes like this:


var formats = {

      email: /[a-z0-9!#$%&'*+\/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+\/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?/g,

      phone: /(?!:\A|\s)(?!(\d{1,6}\s+\D)|((\d{1,2}\s+){2,2}))(((\+\d{1,3})|(\(\+\d{1,3}\)))\s*)?((\d{1,6})|(\(\d{1,6}\)))\/?(([ -.]?)\d{1,5}){1,5}((\s*(#|x|(ext))\.?\s*)\d{1,5})?(?!:(\Z|\w|\b\s))/gm,

      numeric: /(\d+)(((.|,)\d+)+)?/g,

      url: /^((http\:\/\/|https\:\/\/|ftp\:\/\/)|(www.))+(([a-zA-Z0-9\.-]+\.[a-zA-Z]{2,4})|([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}))(\/[a-zA-Z0-9%:\/-_\\?\.'~]*)?$/gi

    };


Then I've created a function that given two parameters, the format and the test subject, returns true or false (merely a wrapper of the test method for the RegExp object):


validy.is = function(what, str) {
    return formats[what].test(str);
};


On a jQuery collection, I have INPUT elements with classes named accordingly to each format:


&lt;input type=""text"" class=""field email"" id=""field-1-1"" />
&lt;input type=""text"" class=""field phone"" id=""field-1-2"" />
...


Then, my validation function goes like this:


    formBuilder.validate = function() {
      console.info(""=== STARTING VALIDATE ==="");

      var isValid = true;
      var allFields = $("".field"", formBuilder.form).toArray();
      var validable = [""email"",""phone"",""numeric"",""url""];

      var errors = {
        ""email"": ""DebÃ©s ingresar una direcciÃ³n de e-mail vÃ¡lida (por ejemplo: juanperez@gmail.com)."",
        ""phone"": ""DebÃ©s ingresar un nÃºmero de telÃ©fono vÃ¡lido."",
        ""numeric"": ""DebÃ©s ingresar un nÃºmero."",
        ""url"": ""DebÃ©s ingresar una direcciÃ³n Web vÃ¡lida (por ejemplo: www.misitio.com.ar).""
      };

      for (var f = 0; f &lt; allFields.length; f++) {

        var $field = $(allFields[f]);

        console.info($field);
        console.info(""--> Field has classes: "" + $field.attr(""class""));

        for (var v = 0; v &lt; validable.length; v++) {

          var validableClass = validable[v];

          if ($field.hasClass(validableClass)) {

            console.info(""--> Validating against "" + validableClass + "" with value &lt;&lt;"" + $field.val() + "">>"");
            console.info(""--> Test result: validy.is(validableClass, $field.val()) = "" + vw.validy.is(validableClass, $field.val()));
            console.info(""--> Last value of isValid = "" + isValid);

            isValid = isValid && (validy.is(validableClass, $field.val()) ? true : false);

            console.info(""--> Value of isValid is now = "" + isValid);
            break;

          };

        }

        console.info(""** Status of isValid: "" + isValid + "" **"");

        if (!isValid) {

          console.info(""--> Invalid field detected"");
          //vw.popoverError($field, ""Error"", errors[validableClass]);
          break;

        };

      };

      return isValid;

    };


The problem with it is that even when the field value is valid and isValid == true, when it does the isValid == isValid &amp;&amp; ... operation, isValid ends up being false.

How can it be possible for a true &amp;&amp; true expression to throw false.

I know there must be some stupidity I can't see, but I can't seem to find it. Can anyone lend a hand on this one?

Thanks!

Update 1

Originally, the line:

isValid = isValid &amp;&amp; (validy.is(validableClass, $field.val()) ? true : false);

was

isValid &amp;= validy.is(validableClass, $field.val();

Update 2

At some point, apparently the test method is returning 1 or 0 instead of true or false. But I can't pinpoint the exact moment when it happens.

Update 3

So it turns out that I was misusing the &amp;= operator as mentioned in the comments. But...

isValid = isValid &amp;&amp; validy.is(validableClass, $field.val());

...returns false when isValid == true and validy.is returns true independently.

Update 4

Changed the validy.is definition according to answer by CaffGeek:


    validy.is = function(what, str) {

      return !!formats[what].test(str);

    };


It had no effect, unfortunately.
",Joel A. Villarreal Bertoldi,https://stackoverflow.com/users/250301,"Try changing

validy.is = function(what, str) {
    return formats[what].test(str);
};


to this to ensure it's a boolean result.

validy.is = function(what, str) {
    return !!formats[what].test(str);
};


I haven't tested this, but you don't need all the loops with jQuery.  It's set based.  You can simplify your code along this manner.

formBuilder.validate = function() {
    console.info(""=== STARTING VALIDATE ==="");

    var isValid = true;
    var allFields = $("".field"", formBuilder.form).toArray();
    var validable = [""email"", ""phone"", ""numeric"", ""url""];

    var errors = {
        ""email"": ""DebÃ©s ingresar una direcciÃ³n de e-mail vÃ¡lida (por ejemplo: juanperez@gmail.com)."",
        ""phone"": ""DebÃ©s ingresar un nÃºmero de telÃ©fono vÃ¡lido."",
        ""numeric"": ""DebÃ©s ingresar un nÃºmero."",
        ""url"": ""DebÃ©s ingresar una direcciÃ³n Web vÃ¡lida (por ejemplo: www.misitio.com.ar).""
    };

    var failedFields = $('EMPTYJQUERYSET');

    $.each(validable, function(index, className) {
        failedFields.add(
            allFields.filter('.' + className).filter(function(index) {
                return ! validy.is(validableClass, $(this).val());
            });
        );
    });

    isValid = !!(failedFields.length == 0);

    console.info(""** Status of isValid: "" + isValid + "" **"");

    if (!isValid) {
        console.info(""--&gt; Invalid field detected"");
        //vw.popoverError($field, ""Error"", errors[validableClass]);
        break;
    };

    return isValid;
};

",CaffGeek,https://stackoverflow.com/users/54746,http://stackoverflow.com/questions/13422292/using-logical-operators-on-loops-results-in-contradiction,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Using logical operators on loops can lead to conflicts,"I'm dealing with a really, really weird issue in JavaScript. I'm working on a validator script that loops through a list of fields with jQuery. Each validation is tied to a regular expression on an object that goes like this:


var formats = {

      email: /[a-z0-9!#$%&'*+\/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+\/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?/g,

      phone: /(?!:\A|\s)(?!(\d{1,6}\s+\D)|((\d{1,2}\s+){2,2}))(((\+\d{1,3})|(\(\+\d{1,3}\)))\s*)?((\d{1,6})|(\(\d{1,6}\)))\/?(([ -.]?)\d{1,5}){1,5}((\s*(#|x|(ext))\.?\s*)\d{1,5})?(?!:(\Z|\w|\b\s))/gm,

      numeric: /(\d+)(((.|,)\d+)+)?/g,

      url: /^((http\:\/\/|https\:\/\/|ftp\:\/\/)|(www.))+(([a-zA-Z0-9\.-]+\.[a-zA-Z]{2,4})|([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}))(\/[a-zA-Z0-9%:\/-_\\?\.'~]*)?$/gi

    };


Then I've created a function that given two parameters, the format and the test subject, returns true or false (merely a wrapper of the test method for the RegExp object):


validy.is = function(what, str) {
    return formats[what].test(str);
};


On a jQuery collection, I have INPUT elements with classes named accordingly to each format:


&lt;input type=""text"" class=""field email"" id=""field-1-1"" />
&lt;input type=""text"" class=""field phone"" id=""field-1-2"" />
...


Then, my validation function goes like this:


    formBuilder.validate = function() {
      console.info(""=== STARTING VALIDATE ==="");

      var isValid = true;
      var allFields = $("".field"", formBuilder.form).toArray();
      var validable = [""email"",""phone"",""numeric"",""url""];

      var errors = {
        ""email"": ""DebÃ©s ingresar una direcciÃ³n de e-mail vÃ¡lida (por ejemplo: juanperez@gmail.com)."",
        ""phone"": ""DebÃ©s ingresar un nÃºmero de telÃ©fono vÃ¡lido."",
        ""numeric"": ""DebÃ©s ingresar un nÃºmero."",
        ""url"": ""DebÃ©s ingresar una direcciÃ³n Web vÃ¡lida (por ejemplo: www.misitio.com.ar).""
      };

      for (var f = 0; f &lt; allFields.length; f++) {

        var $field = $(allFields[f]);

        console.info($field);
        console.info(""--> Field has classes: "" + $field.attr(""class""));

        for (var v = 0; v &lt; validable.length; v++) {

          var validableClass = validable[v];

          if ($field.hasClass(validableClass)) {

            console.info(""--> Validating against "" + validableClass + "" with value &lt;&lt;"" + $field.val() + "">>"");
            console.info(""--> Test result: validy.is(validableClass, $field.val()) = "" + vw.validy.is(validableClass, $field.val()));
            console.info(""--> Last value of isValid = "" + isValid);

            isValid = isValid && (validy.is(validableClass, $field.val()) ? true : false);

            console.info(""--> Value of isValid is now = "" + isValid);
            break;

          };

        }

        console.info(""** Status of isValid: "" + isValid + "" **"");

        if (!isValid) {

          console.info(""--> Invalid field detected"");
          //vw.popoverError($field, ""Error"", errors[validableClass]);
          break;

        };

      };

      return isValid;

    };


The problem with it is that even when the field value is valid and isValid == true, when it does the isValid == isValid &amp;&amp; ... operation, isValid ends up being false.

How can it be possible for a true &amp;&amp; true expression to throw false.

I know there must be some stupidity I can't see, but I can't seem to find it. Can anyone lend a hand on this one?

Thanks!

Update 1

Originally, the line:

isValid = isValid &amp;&amp; (validy.is(validableClass, $field.val()) ? true : false);

was

isValid &amp;= validy.is(validableClass, $field.val();

Update 2

At some point, apparently the test method is returning 1 or 0 instead of true or false. But I can't pinpoint the exact moment when it happens.

Update 3

So it turns out that I was misusing the &amp;= operator as mentioned in the comments. But...

isValid = isValid &amp;&amp; validy.is(validableClass, $field.val());

...returns false when isValid == true and validy.is returns true independently.

Update 4

Changed the validy.is definition according to answer by CaffGeek:


    validy.is = function(what, str) {

      return !!formats[what].test(str);

    };


It had no effect, unfortunately.
","Try changing

validy.is = function(what, str) {
    return formats[what].test(str);
};


to this to ensure it's a boolean result.

validy.is = function(what, str) {
    return !!formats[what].test(str);
};


I haven't tested this, but you don't need all the loops with jQuery.  It's set based.  You can simplify your code along this manner.

formBuilder.validate = function() {
    console.info(""=== STARTING VALIDATE ==="");

    var isValid = true;
    var allFields = $("".field"", formBuilder.form).toArray();
    var validable = [""email"", ""phone"", ""numeric"", ""url""];

    var errors = {
        ""email"": ""DebÃ©s ingresar una direcciÃ³n de e-mail vÃ¡lida (por ejemplo: juanperez@gmail.com)."",
        ""phone"": ""DebÃ©s ingresar un nÃºmero de telÃ©fono vÃ¡lido."",
        ""numeric"": ""DebÃ©s ingresar un nÃºmero."",
        ""url"": ""DebÃ©s ingresar una direcciÃ³n Web vÃ¡lida (por ejemplo: www.misitio.com.ar).""
    };

    var failedFields = $('EMPTYJQUERYSET');

    $.each(validable, function(index, className) {
        failedFields.add(
            allFields.filter('.' + className).filter(function(index) {
                return ! validy.is(validableClass, $(this).val());
            });
        );
    });

    isValid = !!(failedFields.length == 0);

    console.info(""** Status of isValid: "" + isValid + "" **"");

    if (!isValid) {
        console.info(""--&gt; Invalid field detected"");
        //vw.popoverError($field, ""Error"", errors[validableClass]);
        break;
    };

    return isValid;
};

"
5051,5051,8036,Shalom alecha rebbi (u'mori),"What is the significance of the time it takes to say Shalom Alecha Rebbi (U'mori)?
",shlomo,https://judaism.stackexchange.com/users/107,"Tosafos (Bava Basra 129b, s.v. vehilchesa) offers the following reason:

Suppose that a person is just completing a business deal, and as he's transferring the goods he realizes that he's making a mistake and wants to cancel the transaction. Now also suppose that, at the same moment, his teacher (or another prominent Torah scholar to whom he is obligated to show respect) passes by. He'll be caught in a dilemma: if he takes the time to greet them respectfully, as he should, then the deal will be final and he'll be unable to retract; on the other hand, it's disrespectful to finish his business and only then to acknowledge them. The solution? Allow him the time it takes to greet them with ""shalom alecha rabi (umori),"" and to still be able to cancel the deal immediately thereafter.

Once, then, this timeframe is established as the standard for the amount of time in which a person can retract a business deal, it is used in other halachic contexts too.

Ran cites the Raavad, who gives another rationale:

When reciting Shema, one may pause (even in the middle of a passage) in order to reply to someone out of yir'ah (Berachos 13a). Rashi there explains ""yir'ah"" to mean ""fear of being killed,"" such as by a ruler who would take offense at not being greeted respectfully; but Raavad takes it to mean ""awe,"" as in what one should feel towards his Torah teacher. Since, then, according to this understanding, greeting him (with this three- or four-word phrase) is not considered a real interruption of the Shema, then this establishes the precedent that the time it takes to say this phrase is not considered an interruption for other purposes either.
",Alex,https://judaism.stackexchange.com/users/37,http://judaism.stackexchange.com/questions/955/shalom-alecha-rebbi-umori,CULTURE,judaism.stackexchange.com,0.5555555555555556,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Shalom alecha rebbi,What's the point of saying the time of Shalom alecha rebbi (u'mori)?,"Tosafos (Bava Basra 129b, s.v. vehilchesa) offers the following reason:

Suppose that a person is just completing a business deal, and as he's transferring the goods he realizes that he's making a mistake and wants to cancel the transaction. Now also suppose that, at the same moment, his teacher (or another prominent Torah scholar to whom he is obligated to show respect) passes by. He'll be caught in a dilemma: if he takes the time to greet them respectfully, as he should, then the deal will be final and he'll be unable to retract; on the other hand, it's disrespectful to finish his business and only then to acknowledge them. The solution? Allow him the time it takes to greet them with ""shalom alecha rabi (umori),"" and to still be able to cancel the deal immediately thereafter.

Once, then, this timeframe is established as the standard for the amount of time in which a person can retract a business deal, it is used in other halachic contexts too.

Ran cites the Raavad, who gives another rationale:

When reciting Shema, one may pause (even in the middle of a passage) in order to reply to someone out of yir'ah (Berachos 13a). Rashi there explains ""yir'ah"" to mean ""fear of being killed,"" such as by a ruler who would take offense at not being greeted respectfully; but Raavad takes it to mean ""awe,"" as in what one should feel towards his Torah teacher. Since, then, according to this understanding, greeting him (with this three- or four-word phrase) is not considered a real interruption of the Shema, then this establishes the precedent that the time it takes to say this phrase is not considered an interruption for other purposes either.
"
1229,1229,1925,check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
",Oneb,https://stackoverflow.com/users/1012518,"Consider this 

String s = ""aba"";
for (int i = 0; i &lt; s.length() - 1; i++) {
    if (!(Character.isLetter(c1) &amp;&amp; Character.isLetter(c2))) {
            //reject
    } 
    if ((int)s.charAt(i) &gt; (int)s.charAt(i + 1))) {
        //reject
    }


}

for s the if statement would be true so you could reject it. If s was abc then the if statement would never be true.

The code above using the &gt; checks for ascending order. Use &lt; for descending order
",RNJ,https://stackoverflow.com/users/846476,http://stackoverflow.com/questions/12493931/check-if-a-string-has-four-consecutive-letters-in-ascending-or-descending-order,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
","Consider this 

String s = ""aba"";
for (int i = 0; i &lt; s.length() - 1; i++) {
    if (!(Character.isLetter(c1) &amp;&amp; Character.isLetter(c2))) {
            //reject
    } 
    if ((int)s.charAt(i) &gt; (int)s.charAt(i + 1))) {
        //reject
    }


}

for s the if statement would be true so you could reject it. If s was abc then the if statement would never be true.

The code above using the &gt; checks for ascending order. Use &lt; for descending order
"
5234,5234,8321,"Disk became full, had to force shutdown, now it doesn't boot","Don't know why I didn't get a warning about disk being almost full... It came down to zero free space and I couldn't do anything except force-shutdown it. I booted into Windows, deleted some files from OSX drive, but now on boot there is a progress bar every time and when it reaches the end (in 15 min), the computer shuts down.

I went into the recovery mode and tried to repair the disk, but it says ""The Disk Utility cannot repair the drive... backup files and reinstall the OS"" -- something like that.

I have a time machine backup but I'm currently not at home - going home in 3 weeks.

Is it ""normal"" that system gets borked like this because of full disk + force shutdown? Seems too fragile to me. I have Mavericks 10.9.4 on this system.

Is there anything I can do?
",davidhq,https://apple.stackexchange.com/users/51636,"I used Disk Warrior and it fixed the problem.
",davidhq,https://apple.stackexchange.com/users/51636,http://apple.stackexchange.com/questions/138635/disk-became-full-had-to-force-shutdown-now-it-doesnt-boot,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.5,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,The disk is full and must be forced to shut down. It cannot be started at this time,"Don't know why I didn't get a warning about disk being almost full... It came down to zero free space and I couldn't do anything except force-shutdown it. I booted into Windows, deleted some files from OSX drive, but now on boot there is a progress bar every time and when it reaches the end (in 15 min), the computer shuts down.

I went into the recovery mode and tried to repair the disk, but it says ""The Disk Utility cannot repair the drive... backup files and reinstall the OS"" -- something like that.

I have a time machine backup but I'm currently not at home - going home in 3 weeks.

Is it ""normal"" that system gets borked like this because of full disk + force shutdown? Seems too fragile to me. I have Mavericks 10.9.4 on this system.

Is there anything I can do?
",I used the disk warrior to solve this problem.
399,399,623,"add_action(), add_filter() before or after function","When looking through WordPress snippets/tutorials/plugins I often see add_action() and add_filter() being placed before the function is declared:

add_action( 'publish_post', 'email_friends' );

function email_friends( $post_ID ) {
   $friends = 'bob@example.org, susie@example.org';
   mail( $friends, ""sally's blog updated"" , 'I just put something on my blog: http://blog.example.com' );
   return $post_ID;
}


From a logic standpoint this just doesn't make sense to me.  Why would you place the function after it is called in your code?  This is usually how I would handle the same situation:

function email_friends( $post_ID )  {
   $friends = 'bob@example.org, susie@example.org';
   mail( $friends, ""sally's blog updated"" , 'I just put something on my blog: http://blog.example.com' );
   return $post_ID;
}

add_action( 'publish_post', 'email_friends' );


I know both scenarios work, but is there a specific advantage to one or the other?  About 90% of the time I see the first scenario being used, so that leads me to believe there is a benefit to this in some way.
",voodooGQ,https://wordpress.stackexchange.com/users/19379,"It is easier to read: When is what called? If you are debugging a hook you can immediately see if you have to read the function or not: If it is not your hook, you can skip the code.

In my themes and plugins I combine all registrations for actions, filters and shortcodes at the top and I add the hook to the PHPDoc block:

add_action( 'wp_head',  'foo' );
add_action( 'shutdown', 'bar' );

/**
 * Foo you!
 *
 * @wp-hook wp_head
 * @return  void
 */
function foo()
{
    print '&lt;!-- foo --&gt;';
}

",fuxia,https://wordpress.stackexchange.com/users/73,http://wordpress.stackexchange.com/questions/66366/add-action-add-filter-before-or-after-function,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8333333333333334,0.5,0.8333333333333334,0.8888888888888888,0.7,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,"Add? Action(), add? Filter(), before or after the function","When looking through WordPress snippets/tutorials/plugins I often see add_action() and add_filter() being placed before the function is declared:

add_action( 'publish_post', 'email_friends' );

function email_friends( $post_ID ) {
   $friends = 'bob@example.org, susie@example.org';
   mail( $friends, ""sally's blog updated"" , 'I just put something on my blog: http://blog.example.com' );
   return $post_ID;
}


From a logic standpoint this just doesn't make sense to me.  Why would you place the function after it is called in your code?  This is usually how I would handle the same situation:

function email_friends( $post_ID )  {
   $friends = 'bob@example.org, susie@example.org';
   mail( $friends, ""sally's blog updated"" , 'I just put something on my blog: http://blog.example.com' );
   return $post_ID;
}

add_action( 'publish_post', 'email_friends' );


I know both scenarios work, but is there a specific advantage to one or the other?  About 90% of the time I see the first scenario being used, so that leads me to believe there is a benefit to this in some way.
","It is easier to read: When is what called? If you are debugging a hook you can immediately see if you have to read the function or not: If it is not your hook, you can skip the code.

In my themes and plugins I combine all registrations for actions, filters and shortcodes at the top and I add the hook to the PHPDoc block:

add_action( 'wp_head',  'foo' );
add_action( 'shutdown', 'bar' );

/**
 * Foo you!
 *
 * @wp-hook wp_head
 * @return  void
 */
function foo()
{
    print '&lt;!-- foo --&gt;';
}

"
3648,3648,5822,Add authors as footnote in lncs,"please, I was asked to modify the .tex file of a manuscript. The problem is that I want to add ""supervised by ..."" as a footnote and when use \footnote{supervised by ...} in \author{} it does not work. I use a Latex lncs format. Thank you!
",Sofiane,https://tex.stackexchange.com/users/46464,"The correct way is using \thanks, not \footnote:

\documentclass[runningheads]{llncs}
\usepackage{kantlipsum}


\begin{document}

\title{LaTeX Template for Your LNCS Paper}

\author{Author 1\thanks{Supervised by Author 9}, Author 2}

\institute{Lab, University, Address}
\maketitle

\begin{abstract}
Abstract is here.
\end{abstract}

\section{Introduction}\label{sec:Introduction}

The rest goes here.

\kant

\end{document}


I added also the runningheads option just to show that the headline containing the authors' names is not influenced by the presence of \thanks.

First page



Second page


",egreg,https://tex.stackexchange.com/users/4427,http://tex.stackexchange.com/questions/161232/add-authors-as-footnote-in-lncs,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Add author as footnote in LNCS,"Please, I was asked to revise a manuscript's. Tex file. The problem is, I want to add ""supervisor..."" As a footnote, when using \ footnote {supervised by }It doesn't work. I use the latex LNCS format. Thank you very much!","The correct way is using \thanks, not \footnote:

\documentclass[runningheads]{llncs}
\usepackage{kantlipsum}


\begin{document}

\title{LaTeX Template for Your LNCS Paper}

\author{Author 1\thanks{Supervised by Author 9}, Author 2}

\institute{Lab, University, Address}
\maketitle

\begin{abstract}
Abstract is here.
\end{abstract}

\section{Introduction}\label{sec:Introduction}

The rest goes here.

\kant

\end{document}


I added also the runningheads option just to show that the headline containing the authors' names is not influenced by the presence of \thanks.

First page



Second page


"
701,701,1107,Why are the two buttons on the apple TV remote shaped differently (Menu & Play/Pause),"On the apple TV remote, I have realized that the two buttons have a different physical design. The menu button goes invward (convex) and the play/pause one is flatter/goes more outward.

I tried to figure out why with my common sense, but failed. Does someone know?

",nichochar,https://ux.stackexchange.com/users/41518,"So in the dark, you'll know which is which without looking at it.
",Chairman Meow,https://ux.stackexchange.com/users/42354,http://ux.stackexchange.com/questions/54999/why-are-the-two-buttons-on-the-apple-tv-remote-shaped-differently-menu-play-p,TECHNOLOGY,ux.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why are the two buttons on the Apple TV remote different shapes (menu and play / pause),"On the Apple TV remote control, I realized that the physical design of the two buttons was different. The menu button is facing forward (convex), and the play / pause button is flatter / outward.","So in the dark, you'll know which is which without looking at it.
"
1797,1797,2854,What happens when we call pg_dump while users are still using the system?,"We have a web application with PostgreSQL as our database and use celery background tasks for somewhat complex task. At the very beginning of this complex task we take a backup of the database using pg_dump.

I was wondering about the state of this sql dump if the users are still using the system. Could it cause any inconsistencies ?

Also, I would like to know if pg_dump is the best choice for taking backups in this case. Of course as the database grows the backup takes a lot of time which slows the overall process.

Thanks.
",thelinuxer,https://dba.stackexchange.com/users/35016,"
  I was wondering about the state of this sql dump if the users are still using the system


pg_dump relies on PostgreSQL's MVCC support to ask PostgreSQL to take a snapshot of the database state at a given point in time.

Changes made by concurrent transactions after the point where pg_dump gets its snapshot do not affect pg_dump, whether they're committed or not.

There are a few things that aren't necessarily consistent, like sequences, which continue to increase while pg_dump is running. But applications have to be prepared for gaps in sequences anyway, so this isn't considered to be a problem.


  Also, I would like to know if pg_dump is the best choice for taking backups in this case


No, you're way better off using WAL archiving and PITR for your purpose. Look into PgBarman and read the docs on continuous archiving.

You should still take logical dumps for disaster recovery, but it need not be an all-the-time thing.
",Craig Ringer,https://dba.stackexchange.com/users/7788,http://dba.stackexchange.com/questions/63642/what-happens-when-we-call-pg-dump-while-users-are-still-using-the-system,TECHNOLOGY,dba.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.5,0.0,0.0,0.8333333333333334,What happens when we call PG dump while the user is still using the system?,"We have a web application with PostgreSQL as our database and use celery background tasks for somewhat complex task. At the very beginning of this complex task we take a backup of the database using pg_dump.

I was wondering about the state of this sql dump if the users are still using the system. Could it cause any inconsistencies ?

Also, I would like to know if pg_dump is the best choice for taking backups in this case. Of course as the database grows the backup takes a lot of time which slows the overall process.

Thanks.
","
  I was wondering about the state of this sql dump if the users are still using the system


pg_dump relies on PostgreSQL's MVCC support to ask PostgreSQL to take a snapshot of the database state at a given point in time.

Changes made by concurrent transactions after the point where pg_dump gets its snapshot do not affect pg_dump, whether they're committed or not.

There are a few things that aren't necessarily consistent, like sequences, which continue to increase while pg_dump is running. But applications have to be prepared for gaps in sequences anyway, so this isn't considered to be a problem.


  Also, I would like to know if pg_dump is the best choice for taking backups in this case


No, you're way better off using WAL archiving and PITR for your purpose. Look into PgBarman and read the docs on continuous archiving.

You should still take logical dumps for disaster recovery, but it need not be an all-the-time thing.
"
5415,5415,8600,Weil's Riemann Hypothesis for dummies?,"Weil's Riemann Hypothesis is a deep result that I don't fully understand, but it has understandable corollaries which interest me. For example:

(a) For any projective curve $X$ satisfying certain conditions, the number $N$ of points in $X$ with coordinates in $\mathrm{GF}(q)$ satisfies $|N-(q+1)|\leq\mathrm{const}\cdot\sqrt{q}$. (The deviation is $0$ when $X$ is a projective line.)

(b) For any nontrivial multiplicative character $\chi$ on $\mathrm{GF}(q)$ and any polynomial $f$ of degree $n$ satisfying certain conditions, we have 

$$\bigg|\sum_{x\in\mathrm{GF}(q)}\chi(f(x))\bigg|\leq(n-1)\sqrt{q}.$$

Questions:


Is there a reference (legible to an English-speaking non-expert in the field) which gives the rigorous statements of these corollaries? In particular, I would like conditions which one can verify without a background in algebraic geometry.
Are there other corollaries of Weil's Riemann Hypothesis which are also widely understandable? EDIT: I'm mostly interested in the Riemann Hypothesis, but I'm also happy to learn understandable consequences of the other Weil conjectures and related results.

",Dustin G. Mixon,https://mathoverflow.net/users/29873,"Here are the statements from Schmidt's book (as pointed to in my comment). 

(a) Suppose $f(x,y)$ is a polynomial of total degree $d$, with coefficients in the field of $q$ elements and with $N$ zeros with coordinates in that field. Suppose $f(x,y)$ is absolutely irreducible, that is, irreducible not only over the field of $q$ elements, but also over every algebraic extension thereof. Then $$|N-q|\le2g\sqrt q+c_1(d)$$ where $g$ is the genus of the curve $f(x,y)=0$. 

I am not up to explaining ""genus"" without algebraic geometry, but it is known that $g\le(d-1)(d-2)/2$, so if you are willing to settle for $$|N-q|\le(d-1)(d-2)\sqrt q+c_1(d)$$ then I think you have what you are after. 

(b) Let $\chi$ be a multiplicative character of order $d&gt;1$. Suppose that $f(x)$, a polynomial in one variable over the field of $q$ elements, has $m$ distinct zeros, and is not a $d$th power. Then $$\Bigl|\sum_{x\in{\bf F}_q}\chi(f(x))\Bigr|\le(m-1)\sqrt q$$
",Gerry Myerson,https://mathoverflow.net/users/3684,http://mathoverflow.net/questions/176649,SCIENCE,mathoverflow.net,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6,0.0,0.0,1.0,1.0,Will's Riemann hypothesis on Dummies?,"Weil's Riemann Hypothesis is a deep result that I don't fully understand, but it has understandable corollaries which interest me. For example:

(a) For any projective curve $X$ satisfying certain conditions, the number $N$ of points in $X$ with coordinates in $\mathrm{GF}(q)$ satisfies $|N-(q+1)|\leq\mathrm{const}\cdot\sqrt{q}$. (The deviation is $0$ when $X$ is a projective line.)

(b) For any nontrivial multiplicative character $\chi$ on $\mathrm{GF}(q)$ and any polynomial $f$ of degree $n$ satisfying certain conditions, we have 

$$\bigg|\sum_{x\in\mathrm{GF}(q)}\chi(f(x))\bigg|\leq(n-1)\sqrt{q}.$$

Questions:


Is there a reference (legible to an English-speaking non-expert in the field) which gives the rigorous statements of these corollaries? In particular, I would like conditions which one can verify without a background in algebraic geometry.
Are there other corollaries of Weil's Riemann Hypothesis which are also widely understandable? EDIT: I'm mostly interested in the Riemann Hypothesis, but I'm also happy to learn understandable consequences of the other Weil conjectures and related results.

","Here are the statements from Schmidt's book (as pointed to in my comment). 

(a) Suppose $f(x,y)$ is a polynomial of total degree $d$, with coefficients in the field of $q$ elements and with $N$ zeros with coordinates in that field. Suppose $f(x,y)$ is absolutely irreducible, that is, irreducible not only over the field of $q$ elements, but also over every algebraic extension thereof. Then $$|N-q|\le2g\sqrt q+c_1(d)$$ where $g$ is the genus of the curve $f(x,y)=0$. 

I am not up to explaining ""genus"" without algebraic geometry, but it is known that $g\le(d-1)(d-2)/2$, so if you are willing to settle for $$|N-q|\le(d-1)(d-2)\sqrt q+c_1(d)$$ then I think you have what you are after. 

(b) Let $\chi$ be a multiplicative character of order $d&gt;1$. Suppose that $f(x)$, a polynomial in one variable over the field of $q$ elements, has $m$ distinct zeros, and is not a $d$th power. Then $$\Bigl|\sum_{x\in{\bf F}_q}\chi(f(x))\Bigr|\le(m-1)\sqrt q$$
"
5516,5516,8750,Password hashes should run md5 thousands of time: really?,"I skimmed through How Companies Can Beef Up Password Security and I thought that several assertions were completely wrong, in particular:


Cryptographic hash (like md5) with salt are bad.
It isn't uncommon to break/crack unix shadow files.
To make a password hash I should run it over md5 or whatever hundreds or thousands of times.


The article suggests that salted hashes are too easy to break and you'd want to select a password hash because its computationally longer to check passwords so you can not do as many per second.

I think doing 3 is bad for security and 1 is in reality the best option. What do you guys think?
",acidzombie24,https://security.stackexchange.com/users/5575,"
  Cryptographic hash (like md5) with salt are bad.


I didn't read the article, but this could be read in one of two ways:


MD5, even when salted is bad.
Salted hashes are bad.


In response to the first one, yes, this is true. MD5 has been proven insecure, and is too fast to be a secure hashing function anyways. Don't use MD5.

As for the second, it's completely wrong. Always salt your hash's. This helps prevent against rainbow table attacks.


  It isn't uncommon to break/crack unix shadow files.


This is true, most people choose insecure passwords that are quite easy to break. End of story. The classic security tool for doing this is John the Ripper. Even shadow files that use modern hashes often use algorithms that are too fast to really provide much protection (see below).


  To make a password hash I should run it over md5 or whatever hundreds or thousands of times.


This used to be true. The reason for doing this is to make it much slower per password attempt (since you have to run the hashing algorithm a lot). Even with a modern hash like SHA2, it's still often so fast that brute forcing a poorly chosen password can take a matter of days, or even hours.

Modern digest algorithms take this into account, and are designed to be computationally, or memory intensive. Common examples include bcrypt which includes a salt and is designed to be computationally expensive. A newer algorithm, scrypt, has been getting a bit of attention recently for also being memory intensive (making GPU cracking that much more difficult).
",Sam Whited,https://security.stackexchange.com/users/6906,http://security.stackexchange.com/questions/16121/password-hashes-should-run-md5-thousands-of-time-really,TECHNOLOGY,security.stackexchange.com,1.0,1.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Password hash should run md5000 times: really?,"I skimmed through How Companies Can Beef Up Password Security and I thought that several assertions were completely wrong, in particular:


Cryptographic hash (like md5) with salt are bad.
It isn't uncommon to break/crack unix shadow files.
To make a password hash I should run it over md5 or whatever hundreds or thousands of times.


The article suggests that salted hashes are too easy to break and you'd want to select a password hash because its computationally longer to check passwords so you can not do as many per second.

I think doing 3 is bad for security and 1 is in reality the best option. What do you guys think?
","
  Cryptographic hash (like md5) with salt are bad.


I didn't read the article, but this could be read in one of two ways:


MD5, even when salted is bad.
Salted hashes are bad.


In response to the first one, yes, this is true. MD5 has been proven insecure, and is too fast to be a secure hashing function anyways. Don't use MD5.

As for the second, it's completely wrong. Always salt your hash's. This helps prevent against rainbow table attacks.


  It isn't uncommon to break/crack unix shadow files.


This is true, most people choose insecure passwords that are quite easy to break. End of story. The classic security tool for doing this is John the Ripper. Even shadow files that use modern hashes often use algorithms that are too fast to really provide much protection (see below).


  To make a password hash I should run it over md5 or whatever hundreds or thousands of times.


This used to be true. The reason for doing this is to make it much slower per password attempt (since you have to run the hashing algorithm a lot). Even with a modern hash like SHA2, it's still often so fast that brute forcing a poorly chosen password can take a matter of days, or even hours.

Modern digest algorithms take this into account, and are designed to be computationally, or memory intensive. Common examples include bcrypt which includes a salt and is designed to be computationally expensive. A newer algorithm, scrypt, has been getting a bit of attention recently for also being memory intensive (making GPU cracking that much more difficult).
"
3309,3309,5279,What is the point of the super secret settings option in the video settings in minecraft 1.7?,"I was messing around with my settings in single creative mode, and I came across these really weird video settings, and I immediately thought what the heck!  They made the game hard, and it was almost impossible to tell between certain blocks.  It made no sense.
",bob at bob dot bob,https://gaming.stackexchange.com/users/69154,"The super secret settings are a list of sounds and effects that may come out in future updates. You must turn all of the volume slides up inorder to hear them.


                
            
",Peter V.,https://gaming.stackexchange.com/users/67603,http://gaming.stackexchange.com/questions/157597/what-is-the-point-of-the-super-secret-settings-option-in-the-video-settings-in-m,CULTURE,gaming.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.8888888888888888,0.6666666666666667,0.0,0.0,1.0,1.0,What is the meaning of the super secret setting option in the video settings of minecraft 1.7?,"I messed up my settings in a creative mode. I met these very strange video settings, and I immediately thought of what the hell! They make the game so difficult that it's almost impossible to distinguish certain blocks. It makes no sense.","The super secret settings are a list of sounds and effects that may come out in future updates. You must turn all of the volume slides up inorder to hear them.


                
            
"
3829,3829,6093,XNA 2D camera just part of screen,"Is it possible to use the 2D camera, but just for a part of the screen? Perhaps I want some info on the screen about score and other things, but I want that at a fixed place, just like when not using a 2D camera?
",3D-kreativ,https://gamedev.stackexchange.com/users/17921,"Sure! Since there's no concept of 2D camera built into XNA, I am guessing that you are using some class to generate a ViewMatrix and passing that matrix as a parameter to SpriteBatch.Begin().

If that's the case, the solution is simple... All you have to do is draw your score and anything that you don't want to be affected by the camera in a separate SpriteBatch.Begin() / SpriteBatch.End() block, but without passing it the ViewMatrix. Example:

spriteBatch.Begin(SpriteSortMode.Deferred, null, null, null, null, null, camera.ViewMatrix);
// Draw game world
spriteBatch.End();

spriteBatch.Begin();
// Draw score and other information
spriteBatch.End();

",David Gouveia,https://gamedev.stackexchange.com/users/11686,http://gamedev.stackexchange.com/questions/33633/xna-2d-camera-just-part-of-screen,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,0.0,0.8888888888888888,XNA 2D camera is just a part of the screen,"Is it possible to use a 2D camera, but only part of the screen? Maybe I want to see some information about scores and other things on the screen, but I want to see it in a fixed place, like not using a 2D camera?","Sure! Since there's no concept of 2D camera built into XNA, I am guessing that you are using some class to generate a ViewMatrix and passing that matrix as a parameter to SpriteBatch.Begin().

If that's the case, the solution is simple... All you have to do is draw your score and anything that you don't want to be affected by the camera in a separate SpriteBatch.Begin() / SpriteBatch.End() block, but without passing it the ViewMatrix. Example:

spriteBatch.Begin(SpriteSortMode.Deferred, null, null, null, null, null, camera.ViewMatrix);
// Draw game world
spriteBatch.End();

spriteBatch.Begin();
// Draw score and other information
spriteBatch.End();

"
4780,4780,7592,Call external javascript in the default administration page in Django,"How can I call external javascript in my default admin html page in Django. 

I know that using MEDIA class I can do this in admin.py file.

Here is the my try:

  class PlayerAdmin(admin.ModelAdmin):
      class Media:
        js = ('/static_files/js/adminsettings.js')


But I am not getting data written in the JavaScript file.
",Prashant Gaur,https://stackoverflow.com/users/1850358,"You need to use a path relative to STATIC_URL (or MEDIA_URL), in your example this may work:

  class PlayerAdmin(admin.ModelAdmin):
      class Media:
        js = ('js/adminsettings.js',)


Also, not that the js attribute is a tuple in my example (it can be any iterable, a list, set, etc.)

An alternative is overriding admin templates, which can give you more flexibility, and allow you to apply the same javascript to many models easily.
",Gonzalo Delgado,https://stackoverflow.com/users/1465181,http://stackoverflow.com/questions/13931001/call-external-javascript-in-the-default-administration-page-in-django,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Invoke external JavaScript in the default management page of Django,"How can I call external javascript in my default admin html page in Django. 

I know that using MEDIA class I can do this in admin.py file.

Here is the my try:

  class PlayerAdmin(admin.ModelAdmin):
      class Media:
        js = ('/static_files/js/adminsettings.js')


But I am not getting data written in the JavaScript file.
","You need to use a path relative to STATIC_URL (or MEDIA_URL), in your example this may work:

  class PlayerAdmin(admin.ModelAdmin):
      class Media:
        js = ('js/adminsettings.js',)


Also, not that the js attribute is a tuple in my example (it can be any iterable, a list, set, etc.)

An alternative is overriding admin templates, which can give you more flexibility, and allow you to apply the same javascript to many models easily.
"
2844,2844,4527,can we override start field with custom fields in event object,"can we put custom date field &amp; custom picklist field with no's in it. IN start(SartDateTime) field in event object with trigger code. plz can any one provide me with a sample code please

when event is created for opportunity, date field and picklist field should override the star feild and populate the custom fields values.
",rakesh,https://salesforce.stackexchange.com/users/892,"Step 1: Create a VF page like : New_event_Override:

&lt;apex:page standardController=""event"" action=""{!urlredirect}"" extensions=""event_override""&gt;
&lt;/apex:page&gt;


controller: 

public with sharing class event_override {
public date custom_date;
public string custom_picklistval;
    public event_override(ApexPages.StandardController controller) {
    custom_date = date.newInstance(2012, 11, 30);
    custom_picklistval = '07:00 AM';
    }
    public pagereference urlredirect(){
    Pagereference page = new pagereference('/00U/e');
    page.getparameters().put('StartDateTime',string.valueof(custom_date.format()));
    page.getparameters().put('StartDateTime_time',custom_picklistval);
    page.setredirect(true);
    return page;
    }
}


NOTE : The way I get the 'StartDateTime' and 'StartDateTime_time' is by going to the input field next to the start right clicking on the field and inspecting element in chrome ( this gives the Id of the field , which we can override) 
",Rao,https://salesforce.stackexchange.com/users/582,http://salesforce.stackexchange.com/questions/5622/can-we-override-start-field-with-custom-fields-in-event-object,TECHNOLOGY,salesforce.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Can we overwrite the start field with the custom field in the event object,Whether we can set the custom date field and custom pick list field to none. Use trigger code in the start (sartdatetime) field of the event object. Anyone please give me a sample code,"Step 1: Create a VF page like : New_event_Override:

&lt;apex:page standardController=""event"" action=""{!urlredirect}"" extensions=""event_override""&gt;
&lt;/apex:page&gt;


controller: 

public with sharing class event_override {
public date custom_date;
public string custom_picklistval;
    public event_override(ApexPages.StandardController controller) {
    custom_date = date.newInstance(2012, 11, 30);
    custom_picklistval = '07:00 AM';
    }
    public pagereference urlredirect(){
    Pagereference page = new pagereference('/00U/e');
    page.getparameters().put('StartDateTime',string.valueof(custom_date.format()));
    page.getparameters().put('StartDateTime_time',custom_picklistval);
    page.setredirect(true);
    return page;
    }
}


NOTE : The way I get the 'StartDateTime' and 'StartDateTime_time' is by going to the input field next to the start right clicking on the field and inspecting element in chrome ( this gives the Id of the field , which we can override) 
"
1367,1367,2151,Does the question mark mean this is a question?,"Imagine the following written conversation, as recently occurred via SMS between me and a friend (edited for brevity):


  A: What are you going to do today?
  
  B:  I don't know.  Go shopping?


What is the meaning of the question mark in the reply?  Is person B asking a question of person A?  If so, why would person B expect person A to know the answer in this case? If not, why use the question mark?
",Flimzy,https://ell.stackexchange.com/users/69,"It looks as if Person B is saying that he might go shopping, but that he is not certain. It is common in very informal communication to append a question mark to indicate uncertainty. In speech, this would usually be inflected as a question.
",ctype.h,https://ell.stackexchange.com/users/94,http://ell.stackexchange.com/questions/1042/does-the-question-mark-mean-this-is-a-question,CULTURE,ell.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Does the question mark mean it's a problem?,"Imagine the following written conversation, as recently occurred via SMS between me and a friend (edited for brevity):


  A: What are you going to do today?
  
  B:  I don't know.  Go shopping?


What is the meaning of the question mark in the reply?  Is person B asking a question of person A?  If so, why would person B expect person A to know the answer in this case? If not, why use the question mark?
","It looks as if Person B is saying that he might go shopping, but that he is not certain. It is common in very informal communication to append a question mark to indicate uncertainty. In speech, this would usually be inflected as a question.
"
4411,4411,7006,What is a word for somebody who lies to themselves,"I feel like the fact that people lie to themselves about things can tell you a lot about that person but I just can't put my finger on a single word that I'd use to describe them. In fact, not just describe them, but truly convey that they lie to themselves.


  Example of a person who lies to themself: ""I will do all my work
  tomorrow, I swear.""

",Petar,https://english.stackexchange.com/users/64497,"Another way to say it is that person is in denial.
",oconnor0,https://english.stackexchange.com/users/69685,http://english.stackexchange.com/questions/158869/what-is-a-word-for-somebody-who-lies-to-themselves,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.3333333333333333,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,0.3333333333333333,1.0,What does it mean to a self Deceiver,"I think the fact that people lie to themselves can tell you a lot about that person, but I can't use one word to describe them. In fact, it's not just about describing them, it's about telling them that they lie to themselves.",Another way is that the person is denying it.
985,985,1560,Is the Power-Link designed for routine usage?,"I have a Power-Link which i intended to use in emergencies (when the chain breaks and i'm far from home). Used it once, worked pretty well.

Now i wonder, what if i use it permanently with my chain? My idea is that it might be convenient to quickly remove the chain, stuff it into a bowl of acetone/oil/whatever, and easily install it back onto the bike.

But will the Power-Link wear out quickly (e.g. quicker than the other ""links"" of the chain)? I am not sure whether it was intended to be used all the time or just for emergencies.
",anatolyg,https://bicycles.stackexchange.com/users/4056,"There are several versions of SRAMs power links. The original versions were intended for reuse, and you would have no problem using them in that manner. If you have an 8 or 9 speed bike, you've got one of the original designs. 

If you have a ten speed SRAM drivetrain, then you need to look at the link and the model of the chain. SRAMs newest power links for 10 speed are not designed to be used more than once. They are sold in a 4 pack so that you have replacements to use. 

The gold power link you've pictured is either 9 speed, or one of the first 10 speed links, which is reusable. If yours is black, you have one of the newer, non reusable variety. 

If the chain is a PC-1071, PC-1091 or 1091r, this is the links it comes with, and while you can remove them, they need to be replaced with a fresh link each time you do. 

I hope that helps. 
",zenbike,https://bicycles.stackexchange.com/users/1259,http://bicycles.stackexchange.com/questions/9402/is-the-power-link-designed-for-routine-usage,CULTURE,bicycles.stackexchange.com,0.8888888888888888,0.8888888888888888,0.3333333333333333,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,Is the power cord designed for everyday use?,"I have a Power-Link which i intended to use in emergencies (when the chain breaks and i'm far from home). Used it once, worked pretty well.

Now i wonder, what if i use it permanently with my chain? My idea is that it might be convenient to quickly remove the chain, stuff it into a bowl of acetone/oil/whatever, and easily install it back onto the bike.

But will the Power-Link wear out quickly (e.g. quicker than the other ""links"" of the chain)? I am not sure whether it was intended to be used all the time or just for emergencies.
","There are several versions of SRAMs power links. The original versions were intended for reuse, and you would have no problem using them in that manner. If you have an 8 or 9 speed bike, you've got one of the original designs. 

If you have a ten speed SRAM drivetrain, then you need to look at the link and the model of the chain. SRAMs newest power links for 10 speed are not designed to be used more than once. They are sold in a 4 pack so that you have replacements to use. 

The gold power link you've pictured is either 9 speed, or one of the first 10 speed links, which is reusable. If yours is black, you have one of the newer, non reusable variety. 

If the chain is a PC-1071, PC-1091 or 1091r, this is the links it comes with, and while you can remove them, they need to be replaced with a fresh link each time you do. 

I hope that helps. 
"
5558,5558,8827,High-Tech Dungeon Crawling in Hard Sci-Fi,"I've started playing Eclipse Phase with a group of friends. Most of them have a Dungeons and Dragon history, and love getting magic items and such. I've already made up my mind to take the party on more dungeon raids, but what specifically can I do in the way of loot? It is a hard science fiction setting; no magic. It's noted in the core book that some brand-name weapons and items will have special features, and there is something called Psi that is basically watered-down psychic abilities. What are some recommendations you would make for drops and treasure caches?
",Tasuret,https://rpg.stackexchange.com/users/1598,"Goto RPGNow and look at the first three Traveller Adventures, 

Adventure 1 The Kinunir
Adventure 2 Research Station Gamma
Adventure 3 Twilight Peaks 

If you get one Twilight Peaks is the one to get. They are pretty stat light and while the Imperium is not a Eclipse Phase style background they do overlap in addressing various science fiction issues. For example the Kinunir has an ship A.I as part of the central plot. Reasearch Station Gamma and Twilight Peak could be plotted to involve genetic engineering.
",RS Conley,https://rpg.stackexchange.com/users/93,http://rpg.stackexchange.com/questions/6974/high-tech-dungeon-crawling-in-hard-sci-fi,CULTURE,rpg.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.9,1.0,0.0,0.0,0.7777777777777778,High tech dungeons crawling in hard science fiction,"I've started the eclipse phase with a group of friends. Most of them have a history of dungeons and dragons, like to get magic items and so on. I have made up my mind to let the party make more raids in the dungeons, but what can I do to rob? It's a hard science fiction scene; there's no magic. As mentioned in the core book, some famous brand weapons and articles will have special functions. There is also something called psi, which basically weakens the psychological ability. What advice would you give to drips and treasures?","Goto RPGNow and look at the first three Traveller Adventures, 

Adventure 1 The Kinunir
Adventure 2 Research Station Gamma
Adventure 3 Twilight Peaks 

If you get one Twilight Peaks is the one to get. They are pretty stat light and while the Imperium is not a Eclipse Phase style background they do overlap in addressing various science fiction issues. For example the Kinunir has an ship A.I as part of the central plot. Reasearch Station Gamma and Twilight Peak could be plotted to involve genetic engineering.
"
554,554,873,Possible to remove p tags from a table cell in Wygwam,"I have a problem that occasionally a &lt;p&gt; tag is being added to a table cell, usually when someone pastes something into it. 

Is there a way to remove that &lt;p&gt; and just have the cell be an empty &lt;td&gt; or &lt;th&gt;, ideally without editing the source? 

Is there an option that could be added through the advanced settings?
",since1976,https://expressionengine.stackexchange.com/users/53,"I doubt you can do it easily. A custom extension to parse the text on submission might do it, but the issue is CKEditor forces &lt;p&gt; tags around pretty much every inline element. You're better off just leaving it and changing the styles like GDMac suggested.
",Brian Litzinger,https://expressionengine.stackexchange.com/users/82,http://expressionengine.stackexchange.com/questions/4852/possible-to-remove-p-tags-from-a-table-cell-in-wygwam,TECHNOLOGY,expressionengine.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.3333333333333333,1.0,1.0,0.6,1.0,0.0,0.0,1.0,You can remove the P tag from a table cell in wygwam,"I have a problem that occasionally a &lt;p&gt; tag is being added to a table cell, usually when someone pastes something into it. 

Is there a way to remove that &lt;p&gt; and just have the cell be an empty &lt;td&gt; or &lt;th&gt;, ideally without editing the source? 

Is there an option that could be added through the advanced settings?
","I doubt you can do it easily. A custom extension to parse the text on submission might do it, but the issue is CKEditor forces &lt;p&gt; tags around pretty much every inline element. You're better off just leaving it and changing the styles like GDMac suggested.
"
7,7,9,How do you get your Steam games to run on Ubuntu through Wine or something similar?,"Ok, I was kind of surprised that this hadn't been asked here before, but maybe it's too technical for this site. You guys decide.

I've heard lots of different stories about setting up Wine on Ubuntu, WineTricks, PlayOnLinux etc., but never a 'This is the best way to do it for Steam and Steam games' thread.

So has anyone had any real success getting their Steam games to run on Ubuntu through Wine or something similar? If so, could we get some specific steps?
",LoveMeSomeCode,https://gaming.stackexchange.com/users/7157,"You could try http://transgaming.com/ (Cedega).  I did this in the past and it worked fine, but you have to pay for it - :\
",VoltaicShock,https://gaming.stackexchange.com/users/8419,http://gaming.stackexchange.com/questions/16751/how-do-you-get-your-steam-games-to-run-on-ubuntu-through-wine-or-something-simil,CULTURE,gaming.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.8888888888888888,0.7777777777777778,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,How do you make your steam game run on Ubuntu with wine or something like that?,"Ok, I was kind of surprised that this hadn't been asked here before, but maybe it's too technical for this site. You guys decide.

I've heard lots of different stories about setting up Wine on Ubuntu, WineTricks, PlayOnLinux etc., but never a 'This is the best way to do it for Steam and Steam games' thread.

So has anyone had any real success getting their Steam games to run on Ubuntu through Wine or something similar? If so, could we get some specific steps?
","You can try http://transgaming.com/ (cedega). I've done it before and it works well, but you have to pay for it -:\"
5881,5881,9317,"If you attempt to predict a Roulette wheel $n$ times, what's the probability you'll get $5$ in a row at some point?","I'm talking about a Roulette wheel with $38$ equally probable outcomes. Someone mentioned that he guessed the correct number five times in a row, and said that this was surprising because the probability of this happening was $$\left(\frac{1}{38}\right)^5$$

This is true if you only play the game $5$ times. However, if you play it more than $5$ times there's a higher (should be much higher?) probability that you'll get $5$ in a row at some point. 

I was thinking about how surprised this person should be at their streak of $m$ correct guesses given that they play $n$ games, each with probability $p$ of success. It makes intuitive sense that their surprise should be proportional to $1/q$ (or maybe $\log(1/q)$ since $1$ in a billion doesn't surprise you $10$ times more than $1$ in $100$ million), where $q$ is the probability that they get at least one streak of $m$ correct guesses at some point in their $n$ games. 

So, with the Roulette example I was thinking about, $p=1/38$ and $m=5$. 

I tried to find an explicit formula for $q$ in terms of $n$, and encountered some difficulty, because of the non-independence of ""getting a streak in the first five tries"" and ""getting a streak in tries $2$ through $6$"" (if the first is a failure, it's much more  likely that the second will be too). 



In summary, two questions:


How do I find the probability that you get $5$ correct guesses in a row at some point if you play $n$ games of Roulette?
More generally, what is the probability that you get $m$ successes at some point in a series of $n$ events, each with probability $p$ of success? 


The variables satisfy $\,\,\,m,n \in \mathbb{N}$, $\,\,\,m\leq n$, $\,\,\,p \in \mathbb{R}$, $\,\,\,0 \leq p \leq 1$.



If we write the answer to the second question as a function $q(m,n,p)$, then we can say that $q$ should be increasing with $n$, decreasing with $m$, and increasing with $p$. It should equal $p^n$ when $m=n$ and should equal $1$ when $p=1$ and $0$ when $p=0$. 

I feel as though this should be a basic probability problem, but I'm having trouble solving it. Maybe some kind of recursive approach would work? Given $q(n,m,p)$, I think I could write $q(n+1,m,p)$ using the probability that the last $m-1$ results are all successes ...
",Zubin Mukerjee,https://math.stackexchange.com/users/111946,"To answer your general question, if the events are independent then the probability of getting only $m$ successes at a row once is $$(n-m+1)p^m(1-p)^{n-m}$$ This is because one can have success $m$ times at a row out of $n$ plays in $n-m+1$ ways and in each of these events have a probability $p^m$ of happening and the failures then happen in the rest of the $n-m$ cases with probability $(1-p)^{n-m}$. 

EDIT: As I understand now my previous answer does not correctly address the question. Now, let $P(m,n)$ denote the required probability which is of getting $m$ or more consecutive successes in a series of $n$ independent events. Then, basically we want the event that the first time $m&gt;1$ consecutive successes occur. Now, let $R_k(m,n)$ denotes the probability that $m$ consecutive successes happen for the first time at $n\ge k&gt; m$ th trail. Then we have $$R_k(m,n)=qR_{k-1}(m,n-1)+pqR_{k-2}(m,n-2)+p^2qR_{k-3}(m,n-3)+\cdots+p^{m-1}qR_{k-m}(m,n-m)$$ with $R_1(m,n)=\cdots=R_{m-1}(m,n)=0,R_{m}(m,n)=p^m$ where $q=1-p$. Now, the probability $R_{k}(m,n)$ should not depend upon the second argument as long as $k\le n$. Then calling only $R_{k}$, and defining $r=[R_1\cdots R_n]^T$, we have the equation $$R_k=qR_{k-1}+pqR_{k-2}+\cdots+qp^{m-1}R_{k-m}$$ which can be solved by solving the equation $$x^m-qx^{m-1}-\cdots-qp^{m-2}x-qp^{m-1}=0$$ to get $R_k=\sum_{i=1}^m a_i \lambda_i^k$ where $\lambda_i$ are the roots of the last equation and the coefficients $a_i$ can be obtained from the initial conditions. Then, we have $$P(n,m)=\sum_{k=n-m}^n R_k=\sum_{i=0}^m a_i \frac{\lambda_i^{n-m}(1-\lambda_i^{m+1})}{1-\lambda_i}$$
",Samrat Mukhopadhyay,https://math.stackexchange.com/users/83973,http://math.stackexchange.com/questions/1081447/if-you-attempt-to-predict-a-roulette-wheel-n-times-whats-the-probability-you,SCIENCE,math.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,"If you try to predict that the number of times a roulette is n dollars, what is the probability that you will get 5 dollars in a row at a certain time?","I'm talking about a Roulette wheel with $38$ equally probable outcomes. Someone mentioned that he guessed the correct number five times in a row, and said that this was surprising because the probability of this happening was $$\left(\frac{1}{38}\right)^5$$

This is true if you only play the game $5$ times. However, if you play it more than $5$ times there's a higher (should be much higher?) probability that you'll get $5$ in a row at some point. 

I was thinking about how surprised this person should be at their streak of $m$ correct guesses given that they play $n$ games, each with probability $p$ of success. It makes intuitive sense that their surprise should be proportional to $1/q$ (or maybe $\log(1/q)$ since $1$ in a billion doesn't surprise you $10$ times more than $1$ in $100$ million), where $q$ is the probability that they get at least one streak of $m$ correct guesses at some point in their $n$ games. 

So, with the Roulette example I was thinking about, $p=1/38$ and $m=5$. 

I tried to find an explicit formula for $q$ in terms of $n$, and encountered some difficulty, because of the non-independence of ""getting a streak in the first five tries"" and ""getting a streak in tries $2$ through $6$"" (if the first is a failure, it's much more  likely that the second will be too). 



In summary, two questions:


How do I find the probability that you get $5$ correct guesses in a row at some point if you play $n$ games of Roulette?
More generally, what is the probability that you get $m$ successes at some point in a series of $n$ events, each with probability $p$ of success? 


The variables satisfy $\,\,\,m,n \in \mathbb{N}$, $\,\,\,m\leq n$, $\,\,\,p \in \mathbb{R}$, $\,\,\,0 \leq p \leq 1$.



If we write the answer to the second question as a function $q(m,n,p)$, then we can say that $q$ should be increasing with $n$, decreasing with $m$, and increasing with $p$. It should equal $p^n$ when $m=n$ and should equal $1$ when $p=1$ and $0$ when $p=0$. 

I feel as though this should be a basic probability problem, but I'm having trouble solving it. Maybe some kind of recursive approach would work? Given $q(n,m,p)$, I think I could write $q(n+1,m,p)$ using the probability that the last $m-1$ results are all successes ...
","To answer your general question, if the events are independent then the probability of getting only $m$ successes at a row once is $$(n-m+1)p^m(1-p)^{n-m}$$ This is because one can have success $m$ times at a row out of $n$ plays in $n-m+1$ ways and in each of these events have a probability $p^m$ of happening and the failures then happen in the rest of the $n-m$ cases with probability $(1-p)^{n-m}$. 

EDIT: As I understand now my previous answer does not correctly address the question. Now, let $P(m,n)$ denote the required probability which is of getting $m$ or more consecutive successes in a series of $n$ independent events. Then, basically we want the event that the first time $m&gt;1$ consecutive successes occur. Now, let $R_k(m,n)$ denotes the probability that $m$ consecutive successes happen for the first time at $n\ge k&gt; m$ th trail. Then we have $$R_k(m,n)=qR_{k-1}(m,n-1)+pqR_{k-2}(m,n-2)+p^2qR_{k-3}(m,n-3)+\cdots+p^{m-1}qR_{k-m}(m,n-m)$$ with $R_1(m,n)=\cdots=R_{m-1}(m,n)=0,R_{m}(m,n)=p^m$ where $q=1-p$. Now, the probability $R_{k}(m,n)$ should not depend upon the second argument as long as $k\le n$. Then calling only $R_{k}$, and defining $r=[R_1\cdots R_n]^T$, we have the equation $$R_k=qR_{k-1}+pqR_{k-2}+\cdots+qp^{m-1}R_{k-m}$$ which can be solved by solving the equation $$x^m-qx^{m-1}-\cdots-qp^{m-2}x-qp^{m-1}=0$$ to get $R_k=\sum_{i=1}^m a_i \lambda_i^k$ where $\lambda_i$ are the roots of the last equation and the coefficients $a_i$ can be obtained from the initial conditions. Then, we have $$P(n,m)=\sum_{k=n-m}^n R_k=\sum_{i=0}^m a_i \frac{\lambda_i^{n-m}(1-\lambda_i^{m+1})}{1-\lambda_i}$$
"
4084,4084,6519,I with my friends vs my friends and I,"I'm pretty sure it's not correct to say I with my friends go to the cinema every weekend. However I sometimes hear it from other Russians. 

I have to use ""and"" instead of ""with"" and put this like this My friends and I go to the cinema every weekend. I'm still wondering what if...

Am I right or wrong?
",Dunno,https://english.stackexchange.com/users/48978,"The first form is correct, but only if the ""with my friends"" is in parenthesis:


  I (with my friends) go to the cinema every weekend. 


However, this would only be used to stress the fact that you go to the cinema with your friends (for example if this had previously been put into doubt) and I really can only think of a couple of very specific contexts where it would be preferable to use this construction over an alternative. 

To more generally state that you and your friends go to the cinema (particularly if your going to the cinema is more important than who you go with, or if your going to the cinema and your going there with friends are equally important) then the second form you proposed would be the correct one to use.

Please note I speak British English, and while I am fairly confident that what I've said also applies to other dialects, I am not certain of it. 
",568ml,https://english.stackexchange.com/users/69536,http://english.stackexchange.com/questions/161959/i-with-my-friends-vs-my-friends-and-i,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,1.0,1.0,0.7777777777777778,1.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,I with my friends vs my friends and I,"I'm pretty sure it's not correct to say I with my friends go to the cinema every weekend. However I sometimes hear it from other Russians. 

I have to use ""and"" instead of ""with"" and put this like this My friends and I go to the cinema every weekend. I'm still wondering what if...

Am I right or wrong?
","The first form is correct, but only if the ""with my friends"" is in parenthesis:


  I (with my friends) go to the cinema every weekend. 


However, this would only be used to stress the fact that you go to the cinema with your friends (for example if this had previously been put into doubt) and I really can only think of a couple of very specific contexts where it would be preferable to use this construction over an alternative. 

To more generally state that you and your friends go to the cinema (particularly if your going to the cinema is more important than who you go with, or if your going to the cinema and your going there with friends are equally important) then the second form you proposed would be the correct one to use.

Please note I speak British English, and while I am fairly confident that what I've said also applies to other dialects, I am not certain of it. 
"
1160,1160,1820,"What's the name of the characteristic of being ""open hearted""?","I can not think of any another good phrase to describe the sense, ""Open Hearted"". This characteristic is like one who does not posses the nature of being stubborn, who has the ability to listen and in certain cases accept others' theories though they can be in opposite of his own theory. A good example would be if a person is capable of admitting if there is some bad customs in his own religion and he does not fall back to admit it in front of others and change the custom in his regular life. What is the name of this characteristic?
",Mistu4u,https://ell.stackexchange.com/users/91,"Other ways to say this would be ""easy going"" or ""flexible"".


  Joe is such an easy going guy.  He never argues with Bob, even when everyone knows that Joe is correct.
  
  Jane is pretty flexible â she never gets hung up on the sticky parts; instead, she focuses on the big picture and getting things done.


NOAD defines easy-going as:


  relaxed and tolerant in approach or manner 


and lists tolerant and broad-minded as synonyms. This may not be completely synonymous with open minded, but there is some overlap. Similarly, NOAD defines flexible as:


  (of a person) ready and able to change so as to adapt to different circumstances


Here, ""different circumstances"" can be applied much more broadly than matters of beliefs and opinions (such as coping with an unexpected job change). Still, the word might be used when talking about the situation you described.
",Eric S,https://ell.stackexchange.com/users/865,http://ell.stackexchange.com/questions/3516/whats-the-name-of-the-characteristic-of-being-open-hearted,CULTURE,ell.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.7777777777777778,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,"What is the name of ""open mind""?","I can't think of another good word to describe the feeling, ""open mind."". It's like a person who doesn't have a stubborn nature. He has the ability to listen and in some cases accept other people's theories, even though they may be contrary to his own. A good example is if a person can admit that there are some bad customs in his own religion, and he will not shrink from admitting in front of others, and change the customs in his normal life. What's the name of this feature?","Other ways to say this would be ""easy going"" or ""flexible"".


  Joe is such an easy going guy.  He never argues with Bob, even when everyone knows that Joe is correct.
  
  Jane is pretty flexible â she never gets hung up on the sticky parts; instead, she focuses on the big picture and getting things done.


NOAD defines easy-going as:


  relaxed and tolerant in approach or manner 


and lists tolerant and broad-minded as synonyms. This may not be completely synonymous with open minded, but there is some overlap. Similarly, NOAD defines flexible as:


  (of a person) ready and able to change so as to adapt to different circumstances


Here, ""different circumstances"" can be applied much more broadly than matters of beliefs and opinions (such as coping with an unexpected job change). Still, the word might be used when talking about the situation you described.
"
5917,5917,9373,Why is PWM used to control LEDs even when they're only used On or Off?,"I've noticed on cars with LED tail lights that they have a flicker to them - I presume because they're PWM controlled.
But I've seen it on vehicles where brake lights and tail lights are separate luminaires, therefore are just on or off and do not have varying brightness. I understand that LEDs need to have current through them limited, but I don't see how PWM would achieve this?

Edit: bad phrasing - sorry. Better phrasing: why would the LEDs be flickering even though there is no apparent feature to allow changing of the brightness? Perhaps the brightness is factory set, or maybe there is a feedback circuit to keep brightness constant. But could there be any other reason?

Thoughts: because a vehicle's battery has a significantly different voltage across it when the engine is off or on, (12v vs 14.5v) perhaps there is a controlling PWM circuit that keeps brightness constant over a range of voltages. Saying that, I'm convinced that smart phone screen back-lights have some flicker to them even on full brightness, yet their Li-ion batteries' voltages are near constant.
",Jodes,https://electronics.stackexchange.com/users/4436,"Contrary to initial intuition, it's actually to increase the brightness.

LEDs can be driven at a constant current, or they can be driven with a pulsed current.

With constant current you have to limit the current to a relatively low value - for instance many common small LEDs are limited to a constant current of say 20mA.  That gives good brightness for indication purposes, but it's not that great.

LEDs, when driven with pulsed current, can be driven with a considerably higher current - maybe 5 to 10 times as much, or even more.  That could be say 100mA for what would normally be a 20mA LED.  However, there are restrictions on what the pulses can be - typically with limits on the frequency and duty cycle - maybe as little as 1% duty.

The end result is that the higher current increases the perceived brightness of the LEDs, since more photons are being emitted when they are on, but at the cost of some flicker, which is only really noticed when the LEDs are in motion.

So you get more perceived brightness from smaller and cheaper LEDs without using more current (often less current) on average than if they were on constant.
",Majenko,https://electronics.stackexchange.com/users/4245,http://electronics.stackexchange.com/questions/164078/why-is-pwm-used-to-control-leds-even-when-theyre-only-used-on-or-off,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,1.0,"Why use PWM to control LEDs, even if they are only on or off?","I've noticed on cars with LED tail lights that they have a flicker to them - I presume because they're PWM controlled.
But I've seen it on vehicles where brake lights and tail lights are separate luminaires, therefore are just on or off and do not have varying brightness. I understand that LEDs need to have current through them limited, but I don't see how PWM would achieve this?

Edit: bad phrasing - sorry. Better phrasing: why would the LEDs be flickering even though there is no apparent feature to allow changing of the brightness? Perhaps the brightness is factory set, or maybe there is a feedback circuit to keep brightness constant. But could there be any other reason?

Thoughts: because a vehicle's battery has a significantly different voltage across it when the engine is off or on, (12v vs 14.5v) perhaps there is a controlling PWM circuit that keeps brightness constant over a range of voltages. Saying that, I'm convinced that smart phone screen back-lights have some flicker to them even on full brightness, yet their Li-ion batteries' voltages are near constant.
","Contrary to initial intuition, it's actually to increase the brightness.

LEDs can be driven at a constant current, or they can be driven with a pulsed current.

With constant current you have to limit the current to a relatively low value - for instance many common small LEDs are limited to a constant current of say 20mA.  That gives good brightness for indication purposes, but it's not that great.

LEDs, when driven with pulsed current, can be driven with a considerably higher current - maybe 5 to 10 times as much, or even more.  That could be say 100mA for what would normally be a 20mA LED.  However, there are restrictions on what the pulses can be - typically with limits on the frequency and duty cycle - maybe as little as 1% duty.

The end result is that the higher current increases the perceived brightness of the LEDs, since more photons are being emitted when they are on, but at the cost of some flicker, which is only really noticed when the LEDs are in motion.

So you get more perceived brightness from smaller and cheaper LEDs without using more current (often less current) on average than if they were on constant.
"
3979,3979,6352,Grouping by day + events spanning several days,"This is a question that has already been asked on Drupal.org. It's exactly what I need on my view, but it hasn't been answered yet.

Posted by Amanda-333 on April 12, 2011 at 5:58am
I wanted to ask how I can group events by day in a view.

It works fine if I only have events that have their start- and endtime on the same day.
2011-04-12
2011-04-12 10:00 â 2011-04-12 18:00 Event 1
2011-04-12 12:00 â 2011-04-12 14:00 Event 2

2011-04-13
2011-04-13 10:00 â 2011-04-13 18:00 Event 5
2011-04-13 12:00 â 2011-04-13 14:00 Event 8

The problem: I have some events that take several days or weeks.
Example: I create one event with the start date of 2011-04-12 10:00 and the end date of 2011-04-15 19:00 for example.

This event now shows up in the grouped view as
2011-04-12 - 2011-04-18
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

I would like to have that event sorted into the regular day groups (split that event into day parts):
2011-04-12
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

2011-04-13
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

2011-04-14
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

2011-04-15
2011-04-12 10:00 - 2011-04-15 19:05 Event 11

Similar to how it is done in the calendar â day view. But with a simple text list format.
I can not find a way to do this? Perhaps someone can give me a little help?


https://www.drupal.org/node/1124616
",Johnny Martin,https://drupal.stackexchange.com/users/32218,"Make 2 or 3 computed view fields (which will require some php):


1field for day of event
1 or 2 fields for start time and end time dates.


You can group the View output by the first field. Then create the event time range by inlining the 2 other fields.

With these 3 pieces of info the calendar should be able to see the start and end datetimes and make a line representing the event duration.
",tenken,https://drupal.stackexchange.com/users/3279,http://drupal.stackexchange.com/questions/120378/grouping-by-day-events-spanning-several-days,TECHNOLOGY,drupal.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.4444444444444444,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Group by day + events across days,"This is a question that has already been asked on Drupal.org. It's exactly what I need on my view, but it hasn't been answered yet.

Posted by Amanda-333 on April 12, 2011 at 5:58am
I wanted to ask how I can group events by day in a view.

It works fine if I only have events that have their start- and endtime on the same day.
2011-04-12
2011-04-12 10:00 â 2011-04-12 18:00 Event 1
2011-04-12 12:00 â 2011-04-12 14:00 Event 2

2011-04-13
2011-04-13 10:00 â 2011-04-13 18:00 Event 5
2011-04-13 12:00 â 2011-04-13 14:00 Event 8

The problem: I have some events that take several days or weeks.
Example: I create one event with the start date of 2011-04-12 10:00 and the end date of 2011-04-15 19:00 for example.

This event now shows up in the grouped view as
2011-04-12 - 2011-04-18
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

I would like to have that event sorted into the regular day groups (split that event into day parts):
2011-04-12
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

2011-04-13
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

2011-04-14
2011-04-12 10:00 - 2011-04-15 19:00 Event 11

2011-04-15
2011-04-12 10:00 - 2011-04-15 19:05 Event 11

Similar to how it is done in the calendar â day view. But with a simple text list format.
I can not find a way to do this? Perhaps someone can give me a little help?


https://www.drupal.org/node/1124616
","Make 2 or 3 computed view fields (which will require some php):


1field for day of event
1 or 2 fields for start time and end time dates.


You can group the View output by the first field. Then create the event time range by inlining the 2 other fields.

With these 3 pieces of info the calendar should be able to see the start and end datetimes and make a line representing the event duration.
"
2995,2995,4775,Layman's guide to getting started with Forex (foreign exchange trading)?,"How should I get started with Forex (foreign exchange trading)? How should I prepare myself for it? Please give your answer thinking of me as a layman.
",harvardfail,https://money.stackexchange.com/users/4311,"There are various indexes on the stock market that track the currencies.  Though it is different than Forex (probably less leverage), you may be able to get the effects you're looking for.  I don't have a lot of knowledge in this area, but looked some into FXE, to trade the Euro debt crisis.  Here's an article on Forex, putting FXE down (obviously a biased view, but perhaps will give you a starting point for comparison, should you want to trade something specific, like the current euro/dollar situation).
",Ray K,https://money.stackexchange.com/users/4722,http://money.stackexchange.com/questions/12446/laymans-guide-to-getting-started-with-forex-foreign-exchange-trading,LIFE_ARTS,money.stackexchange.com,1.0,1.0,0.0,1.0,0.6666666666666666,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.6,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,A guide to foreign exchange trading?,How should I start foreign exchange trading? How can I prepare? Please answer me as a layman.,"There are various indexes on the stock market that track the currencies.  Though it is different than Forex (probably less leverage), you may be able to get the effects you're looking for.  I don't have a lot of knowledge in this area, but looked some into FXE, to trade the Euro debt crisis.  Here's an article on Forex, putting FXE down (obviously a biased view, but perhaps will give you a starting point for comparison, should you want to trade something specific, like the current euro/dollar situation).
"
5073,5073,8068,Looking up for an item in a list and different table styles in iOS,"I have a settings view with a grouped table. One of the cells of such table is intended to show a very long list of items from where I want the user to select one. Due to the length of the list, I need to provide a way to make easier to find a certain item.

One of the options I think there are, is to show letters of alphabet as indexes at the right side of a plain table. Since my first table is a grouped one, my navigation hierarchy would be then like this:

  

Would it be inconsistent to navigate from a grouped table to a plain table? If so, could somebody give an existing example? I didn't find anything related to this in iOS Human Interface Guidelines, maybe it is described somewhere else and this navigation pattern breaks the guidelines.

Another option could be having a search bar. Can a search bar be used in both a plain table and a grouped table? The existing example of such bar I found is in Contacts app and it is a plain table. In a plain table, could both an alphabet index and a search bar be shown?
",AppsDev,https://ux.stackexchange.com/users/30975,"You already named the best solution: Search. Just look at the Contacts app. There is a global search for all contact groups and a search for just a group at a time. 

Don't think about about the implementation while finding the best UI/problem solution. Ignore the code. UI design first. Otherwise you limit yourself finding the best solution for the user.
",Martin Labuschin,https://ux.stackexchange.com/users/2824,http://ux.stackexchange.com/questions/42839/looking-up-for-an-item-in-a-list-and-different-table-styles-in-ios,TECHNOLOGY,ux.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Find items in the list and different table styles in IOS,"I have a settings view with a grouped table. One of the cells of such table is intended to show a very long list of items from where I want the user to select one. Due to the length of the list, I need to provide a way to make easier to find a certain item.

One of the options I think there are, is to show letters of alphabet as indexes at the right side of a plain table. Since my first table is a grouped one, my navigation hierarchy would be then like this:

  

Would it be inconsistent to navigate from a grouped table to a plain table? If so, could somebody give an existing example? I didn't find anything related to this in iOS Human Interface Guidelines, maybe it is described somewhere else and this navigation pattern breaks the guidelines.

Another option could be having a search bar. Can a search bar be used in both a plain table and a grouped table? The existing example of such bar I found is in Contacts app and it is a plain table. In a plain table, could both an alphabet index and a search bar be shown?
","You already named the best solution: Search. Just look at the Contacts app. There is a global search for all contact groups and a search for just a group at a time. 

Don't think about about the implementation while finding the best UI/problem solution. Ignore the code. UI design first. Otherwise you limit yourself finding the best solution for the user.
"
4883,4883,7772,Where is the Atiyah-Singer index theorem used in physics?,"I'm trying to get motivated in learning the Atiyah-Singer index theorem.  In most places I read about it, e.g. wikipedia, it is mentioned that the theorem is important in theoretical physics.  So my question is, what are some examples of these applications?
",Eric,https://physics.stackexchange.com/users/37,"The equations of motion, or the equations of instantons, or solitons, or Einstein's equations, or just about any equations in physics, are differential equations.  In many cases, we are interested in the space of solutions of a differential equation.  If we write the total (possibly nonlinear) differential equation of interest as $L(u) = 0,$ we can linearize near a solution $u_0,$ i.e. write $u = u_0 + v$ and expand $L(u_0 + v) = 0 + L&#39;|_{u_0}(v) + ... =: D(v)$ to construct a linear equation $D(v)=0$ in the displacement $v.$

A linear differential equation is like a matrix equation.  Recall that an $n\times m$ matrix $M$ is a map from $R^n$ to $R^m$, and $dim(ker(M)) - dim(ker(M^*)) = n-m,$ independent of the particular matrix (or linear transformation, more generally).  This number is called the ""index.""  In infinite dimensions, these numbers are not generally finite, but often (especially for elliptic differential equations) they are, and depend only on certain ""global"" information about the spaces on which they act.

The index theorem tells you what the index of a linear differential operator ($D,$ above) is.  You can use it to calculate the dimension of the space of solutions to the equation $L(u)=0.$  (When the solution space is a manifold [another story], the dimension is the dimension of the tangent space, which the equation $D(v)=0$ describes.)  It does not tell you what the actual space of solutions is.  That's a hard, nonlinear question.
",Eric Zaslow,https://physics.stackexchange.com/users/20,http://physics.stackexchange.com/questions/1858/where-is-the-atiyah-singer-index-theorem-used-in-physics,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.6666666666666666,0.0,1.0,Where is the Attica singer index theorem used in physics?,"I'm trying to learn the Atiyah singer index theorem. In most places I read, such as Wikipedia, theorems are important in theoretical physics. So my question is, what are some examples of these applications?","The equations of motion, or the equations of instantons, or solitons, or Einstein's equations, or just about any equations in physics, are differential equations.  In many cases, we are interested in the space of solutions of a differential equation.  If we write the total (possibly nonlinear) differential equation of interest as $L(u) = 0,$ we can linearize near a solution $u_0,$ i.e. write $u = u_0 + v$ and expand $L(u_0 + v) = 0 + L&#39;|_{u_0}(v) + ... =: D(v)$ to construct a linear equation $D(v)=0$ in the displacement $v.$

A linear differential equation is like a matrix equation.  Recall that an $n\times m$ matrix $M$ is a map from $R^n$ to $R^m$, and $dim(ker(M)) - dim(ker(M^*)) = n-m,$ independent of the particular matrix (or linear transformation, more generally).  This number is called the ""index.""  In infinite dimensions, these numbers are not generally finite, but often (especially for elliptic differential equations) they are, and depend only on certain ""global"" information about the spaces on which they act.

The index theorem tells you what the index of a linear differential operator ($D,$ above) is.  You can use it to calculate the dimension of the space of solutions to the equation $L(u)=0.$  (When the solution space is a manifold [another story], the dimension is the dimension of the tangent space, which the equation $D(v)=0$ describes.)  It does not tell you what the actual space of solutions is.  That's a hard, nonlinear question.
"
2284,2284,3640,How to restore a site from a backup done with Backup and Migrate module using Drush,"Just that. I've a backup using the backup and migrate module. I've done some changes and now the site is down. I can't restore the site using the admin interface (because it's broken). 

Can I use Drush to restore it? 
",chefnelone,https://drupal.stackexchange.com/users/1352,"Yes, you can restore your backup with Drush.

Here are Backup and Migrate commands for Drush explained: http://www.only10types.com/2011/03/drush-backup-and-migrate-command.html

I think drush bam-restore command is what you are looking for.


  bam-restore Restore the site's database with Backup and Migrate.
  
  Examples: drush bam-restore db manual
  ""LCC-31.03.2011-14.01.59.mysql.gz"" - restore the default database
  using the given dump file, which can be found in the destination
  called ""manual""
  
  Arguments: source - Required. The id of the source (usually a
  database) to restore the backup to. Use 'drush bam-sources' to get a
  list of sources. Defaults to 'db' destination - Required. The id of
  destination to send the backup file to. Use 'drush bam-destinations'
  to get a list of destinations. Defaults to 'manual' backup id -
  Required. The id of a backup file restore. Use 'drush bam-backups' to
  get a list of available backup files.

",BÃ¡lint DeÃ¡ki,https://drupal.stackexchange.com/users/9297,http://drupal.stackexchange.com/questions/40490/how-to-restore-a-site-from-a-backup-done-with-backup-and-migrate-module-using-dr,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How to use drush to recover a site from a backup completed by the backup and migration module,That's it. I have a backup using the backup and migration module. I've made some changes and now the site is closed. I can't restore the site using the administration interface (because it's corrupted).,"Yes, you can restore your backup with Drush.

Here are Backup and Migrate commands for Drush explained: http://www.only10types.com/2011/03/drush-backup-and-migrate-command.html

I think drush bam-restore command is what you are looking for.


  bam-restore Restore the site's database with Backup and Migrate.
  
  Examples: drush bam-restore db manual
  ""LCC-31.03.2011-14.01.59.mysql.gz"" - restore the default database
  using the given dump file, which can be found in the destination
  called ""manual""
  
  Arguments: source - Required. The id of the source (usually a
  database) to restore the backup to. Use 'drush bam-sources' to get a
  list of sources. Defaults to 'db' destination - Required. The id of
  destination to send the backup file to. Use 'drush bam-destinations'
  to get a list of destinations. Defaults to 'manual' backup id -
  Required. The id of a backup file restore. Use 'drush bam-backups' to
  get a list of available backup files.

"
4451,4451,7063,Is pretending to want to trade before playing a monopoly card objectionable?,"In Settlers of Catan, I sometimes try to ask people if they want to trade a certain resource, tricking them into revealing the approximate amount of that resource in everyone's hand. After this I play the monopoly card. This has on some occasions not been received very well.

Is this fair play?
",Matthijs Wessels,https://boardgames.stackexchange.com/users/117,"I've seen people get upset over less underhanded Monopoly grabs, but I wouldn't expect the bad feeling to linger excessively.

As an example, I made a legitimate trade request for a resource I knew an opponent had (it had been recently rolled), but was rejected.  I responded with the Monopoly card, even though it netted only one of the resource, because I really needed it that turn.  The other players were much more wary of my trade requests for the rest of the game; one even asked what would happen if they refused.
",eswald,https://boardgames.stackexchange.com/users/145,http://boardgames.stackexchange.com/questions/577/is-pretending-to-want-to-trade-before-playing-a-monopoly-card-objectionable,CULTURE,boardgames.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,0.6666666666666666,0.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Is it offensive to pretend to trade before playing Monopoly?,"Among the settlers in katan, I sometimes try to ask people if they want to exchange certain resources and cheat them to reveal the approximate amount of resources in each person's hands. After that, I played Monopoly. This is not well accepted in some cases.","I've seen people get upset over less underhanded Monopoly grabs, but I wouldn't expect the bad feeling to linger excessively.

As an example, I made a legitimate trade request for a resource I knew an opponent had (it had been recently rolled), but was rejected.  I responded with the Monopoly card, even though it netted only one of the resource, because I really needed it that turn.  The other players were much more wary of my trade requests for the rest of the game; one even asked what would happen if they refused.
"
5181,5181,8231,Are there any disadvantages to encrypting the password hash?,"Is encrypting the password hash in database more secure than storing only the hash?

Suppose we store encrypted SHA-256 result with AES instead of hash directly. Is this a good protection from a situation in the future when someone will break one of the algorithms?
",Piotr MÃ¼ller,https://security.stackexchange.com/users/61366,"Provided that you mean Hash first (BCrypt) and then encrypt the hash, security should not be weakened, yet you are not improving security either.
Encryption is, by definition, a reversible scheme. Since there really is no use-case for which you would require the decryption in this case, encryption is the wrong tool for the job.

If you are looking use a 'secret key' in combination with password hashing, your should make use of an HMAC instead (commonly refered to as 'using salt &amp; pepper'). For more information on HMAC and Hash see: Password Hashing add salt + pepper or is salt enough?. For a discussion on how to implement this, see: How to apply a pepper correctly to bcrypt?.
",Monika,https://security.stackexchange.com/users/53887,http://security.stackexchange.com/questions/73586/are-there-any-disadvantages-to-encrypting-the-password-hash,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,What are the disadvantages of encrypted password hash?,"Is encrypting the password hash in database more secure than storing only the hash?

Suppose we store encrypted SHA-256 result with AES instead of hash directly. Is this a good protection from a situation in the future when someone will break one of the algorithms?
","Provided that you mean Hash first (BCrypt) and then encrypt the hash, security should not be weakened, yet you are not improving security either.
Encryption is, by definition, a reversible scheme. Since there really is no use-case for which you would require the decryption in this case, encryption is the wrong tool for the job.

If you are looking use a 'secret key' in combination with password hashing, your should make use of an HMAC instead (commonly refered to as 'using salt &amp; pepper'). For more information on HMAC and Hash see: Password Hashing add salt + pepper or is salt enough?. For a discussion on how to implement this, see: How to apply a pepper correctly to bcrypt?.
"
5257,5257,8358,Hydrophobia Outside of Rabies?,"
  RELATED: 
  
  Why does rabies cause hydrophobia? 
  
  Agony, Hydrophobia and viruses in the light of evolutionary principles


Has hydrophobia been found outside of rabies?

I have only seen it being mentioned as a symptom of rabies.
",user3306356,https://biology.stackexchange.com/users/6818,"You are correct that hydrophobia is often considered pathognomonic of rabies. However, I offer for your consideration: 

Hydrophobia as a rare presentation of Cotard's syndrome: a case report.1

Cotard's syndrome itself is a bizarre psychiatric condition that the authors of the above paper define well:


  Cotardâs syndrome is a rare condition where the central symptom is a nihilistic delusion, which, in its complete form, leads the patient to deny his own existence and that of the external world.


The patient described in this case report harbored delusions that his internal organs were shrinking. He asserted that his abdomen would rupture if he internalized anything. The hydrophobia was secondary to this concern. When given a glass of water he showed a panic reaction and attempted to keep away. Orientation and memory remained intact. 

The authors go to length to point out that this was not, in fact, a case of rabies (as thought that were in question at this point!). Also, the patient himself was not aware of symptoms of rabies, ruling out ""rabies hysteria"" (a hypochondriacal delusion that one has rabies).

Hydrophobia, then, is a rare manifestation of a rare psychiatric disease in addition to the more frequent and well-known association with rabies.


1. Nejad AG. Acta Psychiatr Scand. 2002 Aug;106(2):156-8; discussion 158.

",Susan,https://biology.stackexchange.com/users/9268,http://biology.stackexchange.com/questions/24718/hydrophobia-outside-of-rabies,SCIENCE,biology.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,0.3333333333333333,1.0,Other than rabies?,"
  RELATED: 
  
  Why does rabies cause hydrophobia? 
  
  Agony, Hydrophobia and viruses in the light of evolutionary principles


Has hydrophobia been found outside of rabies?

I have only seen it being mentioned as a symptom of rabies.
","You are correct that hydrophobia is often considered pathognomonic of rabies. However, I offer for your consideration: 

Hydrophobia as a rare presentation of Cotard's syndrome: a case report.1

Cotard's syndrome itself is a bizarre psychiatric condition that the authors of the above paper define well:


  Cotardâs syndrome is a rare condition where the central symptom is a nihilistic delusion, which, in its complete form, leads the patient to deny his own existence and that of the external world.


The patient described in this case report harbored delusions that his internal organs were shrinking. He asserted that his abdomen would rupture if he internalized anything. The hydrophobia was secondary to this concern. When given a glass of water he showed a panic reaction and attempted to keep away. Orientation and memory remained intact. 

The authors go to length to point out that this was not, in fact, a case of rabies (as thought that were in question at this point!). Also, the patient himself was not aware of symptoms of rabies, ruling out ""rabies hysteria"" (a hypochondriacal delusion that one has rabies).

Hydrophobia, then, is a rare manifestation of a rare psychiatric disease in addition to the more frequent and well-known association with rabies.


1. Nejad AG. Acta Psychiatr Scand. 2002 Aug;106(2):156-8; discussion 158.

"
3891,3891,6197,Should users be forced to go through a walkthrough?,"We've found that our users have almost universally benefited from actually going through our walkthrough. Obviously, we have some more ux work to do on our service. But, based on this information, we decided to force users through the short walkthrough in the interim. Somewhat unsurprisingly, people have protested a bit :) So, what do you think, is it ok to force users through a brief walkthrough when you know it will benefit them in the end?

Edit
We are going to add some mixpanel hooks to find out if users are leaving when presented with a walkthrough they can't exit out of.
",jscheel,https://ux.stackexchange.com/users/22949,"Force users to start an optional walkthrough.

To me, it seems most important to give users the option to opt out of the walkthrough. Some little no thanks button to exit the walkthrough should suffice. 

The users that are annoyed by the walkthrough are most often those, that know the service and feel like they will not profit from it - so the percentage of ""helpless"" users actually going through the walkthrough and profiting from it will remain high, while the negative feedback from ""versed"" users already somewhat familiar with your product will go down as they can opt out.

Additionally, I think @MJJ has a point in his answer saying that eventually it also comes down to decreasing the need for a walkthrough that your users will profit from the most. Furthermore, @yisela's answer also gives an example of how a less intrusive walkthrough with just little tooltips can also improve the tutorial acceptance.
",kontur,https://ux.stackexchange.com/users/21973,http://ux.stackexchange.com/questions/33126/should-users-be-forced-to-go-through-a-walkthrough,TECHNOLOGY,ux.stackexchange.com,1.0,1.0,1.0,0.5,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8333333333333334,Should users be forced to drill?,"We found that almost all of our users benefited from our walkthroughs. Obviously, we have more user experience work to do. However, based on this information, we decided to force the user to complete a short walkthrough during the transition. It's not surprising that people are protesting:) so, do you think it's OK to force users to have a short drill when you know that it will ultimately benefit them?","Force users to start an optional walkthrough.

To me, it seems most important to give users the option to opt out of the walkthrough. Some little no thanks button to exit the walkthrough should suffice. 

The users that are annoyed by the walkthrough are most often those, that know the service and feel like they will not profit from it - so the percentage of ""helpless"" users actually going through the walkthrough and profiting from it will remain high, while the negative feedback from ""versed"" users already somewhat familiar with your product will go down as they can opt out.

Additionally, I think @MJJ has a point in his answer saying that eventually it also comes down to decreasing the need for a walkthrough that your users will profit from the most. Furthermore, @yisela's answer also gives an example of how a less intrusive walkthrough with just little tooltips can also improve the tutorial acceptance.
"
3794,3794,6031,Basic steps to develop python API in Unix environment,"I am developing an API in Unix environment for virtual machines. Most of the modules are developed in python. I have few questions on this.

I have the file extension as abc.py. I would like to make this as a command. For example , virtman dominfo [vmid] should be the command syntax. Now I have to give ./virtman.py dominfo [vmid] to achieve this.  And I have first line as #!/usr/bin/python in the python file. So how can make this as a command?

My echo $PATH looks like '/bin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin0'

I read a lot of articles but I didn't get the clear picture,so any hints/suggestions would be helpful.
",Dany,https://unix.stackexchange.com/users/89936,"Anthon's answer is correct, however for non-trivial Python projects you should have a look at the distutils module in the standard library. It's designed to deploy python modules and executables on a system the ""right way"", and :


Python devs are familiar with this module (or should be) because it's in the standard library and most well-known Python packages (Django, NumPy, Celery to name a few) are using it. Newcomers will know instantly how to deploy your project.
Once you've defined which files and packages you have in your project, just run  python setup.py install to deploy and update your package on the system.

No more manually updating the PATH variable copying files to /usr/local/bin or setting them to be executable, it's all handled for you!
You can use pip install -e to install your package in development mode.
It's portable (sort of) in Windows or OSX environments as well.


Also, I can't recomment the use of an argument parser such as argparse enough if you're designing command-line tools.
",F.X.,https://unix.stackexchange.com/users/28174,http://unix.stackexchange.com/questions/165378/basic-steps-to-develop-python-api-in-unix-environment,TECHNOLOGY,unix.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,1.0,0.0,1.0,1.0,The basic steps of developing Python API in UNIX Environment,"I am developing an API in Unix environment for virtual machines. Most of the modules are developed in python. I have few questions on this.

I have the file extension as abc.py. I would like to make this as a command. For example , virtman dominfo [vmid] should be the command syntax. Now I have to give ./virtman.py dominfo [vmid] to achieve this.  And I have first line as #!/usr/bin/python in the python file. So how can make this as a command?

My echo $PATH looks like '/bin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin0'

I read a lot of articles but I didn't get the clear picture,so any hints/suggestions would be helpful.
","Anthon's answer is correct, however for non-trivial Python projects you should have a look at the distutils module in the standard library. It's designed to deploy python modules and executables on a system the ""right way"", and :


Python devs are familiar with this module (or should be) because it's in the standard library and most well-known Python packages (Django, NumPy, Celery to name a few) are using it. Newcomers will know instantly how to deploy your project.
Once you've defined which files and packages you have in your project, just run  python setup.py install to deploy and update your package on the system.

No more manually updating the PATH variable copying files to /usr/local/bin or setting them to be executable, it's all handled for you!
You can use pip install -e to install your package in development mode.
It's portable (sort of) in Windows or OSX environments as well.


Also, I can't recomment the use of an argument parser such as argparse enough if you're designing command-line tools.
"
5050,5050,8035,How many wounds does a Rogue Trader character start with?,"I do not seem to be able to see where in the RT core rulebook you can work out how many wounds a character starts with. During character creation there are modifiers to it, mostly through career path, but what exactly should the base figure be?

Based on the NPCs provided in the introductory campaign I would assume this figure would be around 20 to 25.

I would appreciate knowing what page actually states this.
",thecoshman,https://rpg.stackexchange.com/users/8235,"Starting wounds depend on your homeworld, and can be found in the section starting on page 17 of the core rulebook. 

For example, Deathworld characters start with (2 x Toughness) + (1d5 + 2)
",Wibbs,https://rpg.stackexchange.com/users/2253,http://rpg.stackexchange.com/questions/25464/how-many-wounds-does-a-rogue-trader-character-start-with,CULTURE,rpg.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,How many wounds does the role of a rogue trader begin with?,"I can't seem to see in the RT Core Rulebook how many wounds you can find in the beginning of a character. There are many modifiers in the process of characterization, mainly through career path, but what should the basic characters be?",The initial wound depends on your home world and can be found at the beginning of page 17 of the Core Rulebook.
512,512,805,can i make an outlined path thicker in illustrator?,"i have downloaded some svg icons form the web which are all outlined paths. In illustrator i would like to make those paths thicker. Is there a way to do this? I know when a line is still in stroke-mode you can just adjust the size of the stroke, but once this has been converted to outlines i don't know if this is still possible?

thx
",Justin Othername,https://graphicdesign.stackexchange.com/users/34188,"Yes, you can make the outlined path thicker. Simplest way is to just apply a stroke on the outlines. This will then be added to your stroke (so remember it needs to be 1/2 the additional weight you need). Closed outlines may need this done to both sides.

A bit more cleaner way would be to offset the outline. I suggest using Effect &rarr; Path &rarr; Offset Path... as its nondestructive so you can change your mind later (as opposed to Object &rarr; Path &rarr; Offset Path...). You can then later expand this if you need to bake the effect in.



Image 1: Offset the path to create thicker (for thinner use negative values) outlines.

It is also possible to reduce the outlined stroke back to a stroke. To do this measure the distance between the outlines and then delete the other side and offset by half the distance. This is slightly less work for closed paths as you dont need to clean up after yourself.



Image 2: Reversing the expanded path back to a stroke.
",joojaa,https://graphicdesign.stackexchange.com/users/18306,http://graphicdesign.stackexchange.com/questions/42839/can-i-make-an-outlined-path-thicker-in-illustrator,LIFE_ARTS,graphicdesign.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,Can I make a rougher path in illustrator?,"I've downloaded some SVG icons from the Internet, which are the paths of the overview. In illustrator, I want to make these paths thicker. Is there a way? I know that when a line is still in stroke mode, you can resize the stroke, but once it's converted to a contour, I don't know if it's still possible?","Yes, you can make the outlined path thicker. Simplest way is to just apply a stroke on the outlines. This will then be added to your stroke (so remember it needs to be 1/2 the additional weight you need). Closed outlines may need this done to both sides.

A bit more cleaner way would be to offset the outline. I suggest using Effect &rarr; Path &rarr; Offset Path... as its nondestructive so you can change your mind later (as opposed to Object &rarr; Path &rarr; Offset Path...). You can then later expand this if you need to bake the effect in.



Image 1: Offset the path to create thicker (for thinner use negative values) outlines.

It is also possible to reduce the outlined stroke back to a stroke. To do this measure the distance between the outlines and then delete the other side and offset by half the distance. This is slightly less work for closed paths as you dont need to clean up after yourself.



Image 2: Reversing the expanded path back to a stroke.
"
5130,5130,8161,magical record complex predicate,"I am using MagicalRecord with core data.  

The objects I am dealing with are:

salesPerson 

salesTool - this has a one to many relationship to salesPerson, but also has a season property.  Each season(spring, summer etc) has a value of either 0 or 1.

I am filling a tableView with my view.  The view has a salesPerson property(self.company).  I would like to call the appropriate seasonal salesTools for the salesPerson.  The Predicate I have tried is--

NSPredicate *salesToolFilter = [NSPredicate predicateWithFormat:@""((salesPerson == %@) AND (spring == '0')), self.salesPerson];
NSArray *salesTools = [salesTool MR_findAllWithPredicate:salesToolFilter];
[_dataArray addObjectsFromArray:salesTools];


Unfortunately, this predicate throws an error. 'Unable to parse the format string'  I'm sure this is a simple thing I am doing wrong, but I have yet to figure it out after a couple days and much searching.

Thanks for any help
",Mountainbrussell,https://stackoverflow.com/users/3661330,"You don't need the outer paraens, and you're missing a trailing "". Prett sure the compiler will catch that for you.  When you get an error like that, look at everything between the quotes, and make sure your expression names


exist
are following the proper key paths 
are capitolized correctly
use the proper format placeholders, like %K, etc


You can also reference the predicate (once it parses) and print it out in the debug console to see how it evaluated (interpreted) by the parser.  However, it seems you aren't that far yet.
",casademora,https://stackoverflow.com/users/5619,http://stackoverflow.com/questions/25791717/magical-record-complex-predicate,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,1.0,0.0,0.0,0.8888888888888888,Magic record compound predicate,"I am using MagicalRecord with core data.  

The objects I am dealing with are:

salesPerson 

salesTool - this has a one to many relationship to salesPerson, but also has a season property.  Each season(spring, summer etc) has a value of either 0 or 1.

I am filling a tableView with my view.  The view has a salesPerson property(self.company).  I would like to call the appropriate seasonal salesTools for the salesPerson.  The Predicate I have tried is--

NSPredicate *salesToolFilter = [NSPredicate predicateWithFormat:@""((salesPerson == %@) AND (spring == '0')), self.salesPerson];
NSArray *salesTools = [salesTool MR_findAllWithPredicate:salesToolFilter];
[_dataArray addObjectsFromArray:salesTools];


Unfortunately, this predicate throws an error. 'Unable to parse the format string'  I'm sure this is a simple thing I am doing wrong, but I have yet to figure it out after a couple days and much searching.

Thanks for any help
","You don't need the outer paraens, and you're missing a trailing "". Prett sure the compiler will catch that for you.  When you get an error like that, look at everything between the quotes, and make sure your expression names


exist
are following the proper key paths 
are capitolized correctly
use the proper format placeholders, like %K, etc


You can also reference the predicate (once it parses) and print it out in the debug console to see how it evaluated (interpreted) by the parser.  However, it seems you aren't that far yet.
"
15,15,19,What filter should I use to avoid overly-whitened daylight  images?,"What filter should I use to avoid whitened images (blown highlights) caused by intense daylight? At the moment I am only using an UV Filter, but it doesn't solve the whole problem.

I am a newbie in photography, and I've recently bought a Nikon DSLR.
",Daniel,https://photo.stackexchange.com/users/6471,"If you are indeed referring to your images having too much contrast to allow for both a properly exposed subject and sky, then there are a few options.


As Zak stated, you could use exposure compensation to darken the entire image (this might make the non-sky portion of the image too dark though)
Use a graduated neutral density filter. This will selectively darken one part of an image while leaving the other part alone. This is the old-school method. While it typically limits the transition between the filtered and unfiltered parts to a straight line, it does allow you to fix things at the time of the shot without having to spend time tweaking it on the computer afterwards. 
HDR (High Dynamic Range) photography. This is the hi-tech way to do things. This requires that you take multiple shots of the same scene at different exposures and use software to combine them into one image where both the highlights and shadows are well-exposed. 

",AndrewStevens,https://photo.stackexchange.com/users/6186,http://photo.stackexchange.com/questions/15334/what-filter-should-i-use-to-avoid-overly-whitened-daylight-images,LIFE_ARTS,photo.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.0,1.0,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,0.0,1.0,What filter should I use to avoid over whitening the sun image?,"What kind of filter should I use to avoid the white image caused by strong sunlight? At present, I only use ultraviolet filter, but it can't solve the whole problem.","If you are indeed referring to your images having too much contrast to allow for both a properly exposed subject and sky, then there are a few options.


As Zak stated, you could use exposure compensation to darken the entire image (this might make the non-sky portion of the image too dark though)
Use a graduated neutral density filter. This will selectively darken one part of an image while leaving the other part alone. This is the old-school method. While it typically limits the transition between the filtered and unfiltered parts to a straight line, it does allow you to fix things at the time of the shot without having to spend time tweaking it on the computer afterwards. 
HDR (High Dynamic Range) photography. This is the hi-tech way to do things. This requires that you take multiple shots of the same scene at different exposures and use software to combine them into one image where both the highlights and shadows are well-exposed. 

"
2687,2687,4287,What is the best way to paste code into a Trello card?,"When I try to paste code in Trello, I get very weird formatting after saving, but it seems like it does format for code, I just can't get it to work right. What is the best way to paste code into Trello?

Currently I'm just putting links to Gist, but I would prefer to just paste it straight in there.
",GiH,https://webapps.stackexchange.com/users/4534,"Finally found the answer here:

http://daringfireball.net/projects/markdown/syntax#code

using markdown is outdated, its not as easy as just using Gist haha, think I'll keep that route... they should really work on their tools.
",GiH,https://webapps.stackexchange.com/users/4534,http://webapps.stackexchange.com/questions/26799/what-is-the-best-way-to-paste-code-into-a-trello-card,TECHNOLOGY,webapps.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,What is the best way to paste code into a trello card?,"When I try to paste the code in trello, I will get a very strange format after saving, but it seems that it does format the code, I just can't let it work properly. What is the best way to paste code into trello?","Finally found the answer here:

http://daringfireball.net/projects/markdown/syntax#code

using markdown is outdated, its not as easy as just using Gist haha, think I'll keep that route... they should really work on their tools.
"
3042,3042,4850,Can't see all the font styles installed in Windows 7,"I've installed a font that has different styles (bold, italics, thin, medium, ultra and so on...), but I can't use them all because I can't see them in Photoshop. The fonts are installed, but seem in some way ""overlapped"" by windows.

If I open the Windows fonts dir I can see only one style. If I delete it, then a different style appear and so on.

Anyone has a solution for this problem?

Thanks.
",Alex,https://graphicdesign.stackexchange.com/users/2030,"The source of this problem is malformed font files. The internal names of the fonts are in conflict and the flags that indicate connections between the different font files in a typeface family (Regular, Bold, Italic, Bold Italic, etc.) are missing. 

The terminology is awkward. Technically and historically ""Foo"" is a typeface and ""18 pt Foo Bold Condensed"" is a font, but in the era of personal computers the definitions have blurred: a typeface is now often referred to as a ""font"" (even though you'll buy a particular style of that typeface as a ""font"" in any online store), particularly among non-typographers. The variations tend to be called ""styles."" People coming newly (last 25 years or so) into design are so used to scaling a font in software that they forget every size of every style of a typeface was once drawn and made individually.

For a regular application (non-professional) to give you the usual ""Regular, Bold, Italic, Bold Italic"" choices, the font files themselves must be individually named internally and the fact that they are associated is a specific internal flag. It's these internal flags that allow you to create bold or italic text with a keyboard shortcut or style dropdown -- the Foo Bold font file tells the OS ""I am the Bold version of Foo,"" and so on.

You have a situation where all the individual font files have the same internal name, so Windows can't differentiate them. You see exactly one font (style) in a family; delete it, and you see another one, and so on. In Word, Open Office, etc., that's probably all you'll see. (Arial Narrow famously suffered from this problem because of an error in creating the files -- it just wouldn't show up at all, or would never show up as an available style for Arial.) 

Most non-graphics applications natively understand only the usual four fonts in a family. Additional members (narrow, thin, black, extended, etc.) show up as separate typefaces.

More sophisticated applications such as Photoshop or InDesign know how to read the association flags in a set of font files and can display all the variations in a single dropdown. Garamond Premier Pro, as an example, has 39 font files in four optical sizes -- caption, regular, subhead and display -- that all show up in a single dropdown if and only if the files themselves contain the correct internal information. The ones you are having trouble with do not.

The most common source of the problem you are seeing is conversion utilities that don't do a proper job of taking older or other-platform files and turning them into well-formed OpenType or TrueType files. This often affects (illegal, it must be said) Mac --> Windows conversions, because on Mac OS the font information is split between a visible file and a hidden one. If the conversion utility doesn't correctly parse the hidden file, you get a malformed OpenType or TrueType font file that won't work properly on either platform.

Very old and ""freebie"" font files that are incorrectly set up internally can cause the same issue.
",Alan Gilbertson,https://graphicdesign.stackexchange.com/users/1286,http://graphicdesign.stackexchange.com/questions/3067/cant-see-all-the-font-styles-installed-in-windows-7,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.5,0.0,1.0,1.0,0.5,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,0.6666666666666666,0.8333333333333334,1.0,1.0,0.8333333333333334,0.8,0.5,0.0,1.0,1.0,Unable to see all font styles installed in Windows 7,"I've installed a font with different styles (bold, italics, thin, medium, super, etc.), but I can't use them all because I can't see them in Photoshop. Fonts are installed, but appear to ""overlap"" with windows to some extent.","The source of this problem is malformed font files. The internal names of the fonts are in conflict and the flags that indicate connections between the different font files in a typeface family (Regular, Bold, Italic, Bold Italic, etc.) are missing. 

The terminology is awkward. Technically and historically ""Foo"" is a typeface and ""18 pt Foo Bold Condensed"" is a font, but in the era of personal computers the definitions have blurred: a typeface is now often referred to as a ""font"" (even though you'll buy a particular style of that typeface as a ""font"" in any online store), particularly among non-typographers. The variations tend to be called ""styles."" People coming newly (last 25 years or so) into design are so used to scaling a font in software that they forget every size of every style of a typeface was once drawn and made individually.

For a regular application (non-professional) to give you the usual ""Regular, Bold, Italic, Bold Italic"" choices, the font files themselves must be individually named internally and the fact that they are associated is a specific internal flag. It's these internal flags that allow you to create bold or italic text with a keyboard shortcut or style dropdown -- the Foo Bold font file tells the OS ""I am the Bold version of Foo,"" and so on.

You have a situation where all the individual font files have the same internal name, so Windows can't differentiate them. You see exactly one font (style) in a family; delete it, and you see another one, and so on. In Word, Open Office, etc., that's probably all you'll see. (Arial Narrow famously suffered from this problem because of an error in creating the files -- it just wouldn't show up at all, or would never show up as an available style for Arial.) 

Most non-graphics applications natively understand only the usual four fonts in a family. Additional members (narrow, thin, black, extended, etc.) show up as separate typefaces.

More sophisticated applications such as Photoshop or InDesign know how to read the association flags in a set of font files and can display all the variations in a single dropdown. Garamond Premier Pro, as an example, has 39 font files in four optical sizes -- caption, regular, subhead and display -- that all show up in a single dropdown if and only if the files themselves contain the correct internal information. The ones you are having trouble with do not.

The most common source of the problem you are seeing is conversion utilities that don't do a proper job of taking older or other-platform files and turning them into well-formed OpenType or TrueType files. This often affects (illegal, it must be said) Mac --> Windows conversions, because on Mac OS the font information is split between a visible file and a hidden one. If the conversion utility doesn't correctly parse the hidden file, you get a malformed OpenType or TrueType font file that won't work properly on either platform.

Very old and ""freebie"" font files that are incorrectly set up internally can cause the same issue.
"
1677,1677,2651,Is there anyway to stack or merge .hdf files in R Studio?,"I would like to be able to merge, mosaic, or stack several .hdf files. Does anyone know the package or library i should be looking for the tool to do this?
",MrKirkwood,https://gis.stackexchange.com/users/16473,"First, you are using R. R Studio is just an IDE for R so in the future please make this an R question. I will warn you that working with HDF files in R is a pain. In theory GDAL supports HDF5 so one could use readGDAL in the rgdal package. Depending on the source of the data readGDAL has a high fail rate making it less than reliable.  

Historically, there is a ""hdf5"" package available but it has some odd dependencies, is a bit clunky and not available for the current version of R. You would have to back version R and then download a supported version of the package.   

I would recommend using ""rhdf5"" which is available on Bioconductor. There is some slight overhead in installing it but is quite easy with a few lines of code. The bioLite script allows for access to Bioconductor and management of packages.  

If in windows, run R as administrator. This installs bioLite and rhdf5

source(""http://bioconductor.org/biocLite.R"")
biocLite(""rhdf5"")    


Once you have the data read into R you can coerce into your preferred spatial class and perform whatever operation you wish. I do have to say that R does not seem like the ideal software for this task. For a mosaic operation on a number of HDF files I would use a utility to convert the data into a different image format and the use a GIS software (e.g., GRASS, QGIS...) to mosaic the images. GRASS does support HDF and seems like a sensible alternative. You may be able to do this in QGIS using the GRASS utilities.       

Here is an example of working with HDF files in R.
http://www.r-bloggers.com/working-with-hdf-files-in-r-example-pathfinder-sst-data/
",Jeffrey Evans,https://gis.stackexchange.com/users/8520,http://gis.stackexchange.com/questions/84534/is-there-anyway-to-stack-or-merge-hdf-files-in-r-studio,TECHNOLOGY,gis.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.3333333333333333,0.8888888888888888,Is there still a way to stack or merge. HDF files in R studio?,"I want to be able to merge, mosaic, or stack several. HDF files. Does anyone know the toolkit or library I should be looking for?","First, you are using R. R Studio is just an IDE for R so in the future please make this an R question. I will warn you that working with HDF files in R is a pain. In theory GDAL supports HDF5 so one could use readGDAL in the rgdal package. Depending on the source of the data readGDAL has a high fail rate making it less than reliable.  

Historically, there is a ""hdf5"" package available but it has some odd dependencies, is a bit clunky and not available for the current version of R. You would have to back version R and then download a supported version of the package.   

I would recommend using ""rhdf5"" which is available on Bioconductor. There is some slight overhead in installing it but is quite easy with a few lines of code. The bioLite script allows for access to Bioconductor and management of packages.  

If in windows, run R as administrator. This installs bioLite and rhdf5

source(""http://bioconductor.org/biocLite.R"")
biocLite(""rhdf5"")    


Once you have the data read into R you can coerce into your preferred spatial class and perform whatever operation you wish. I do have to say that R does not seem like the ideal software for this task. For a mosaic operation on a number of HDF files I would use a utility to convert the data into a different image format and the use a GIS software (e.g., GRASS, QGIS...) to mosaic the images. GRASS does support HDF and seems like a sensible alternative. You may be able to do this in QGIS using the GRASS utilities.       

Here is an example of working with HDF files in R.
http://www.r-bloggers.com/working-with-hdf-files-in-r-example-pathfinder-sst-data/
"
990,990,1565,Do I need Android SDK to connect my phone in USB debug mode?,"I'm following the steps provided here to root my Samsung Captivate (Galaxy-S).  I install the USB drivers in the link provided.  Whenever I connect my phone, I get the error There was a problem installing this hardware... SAMSUNG Android Composite ADB Interface.  I do have USB Debug mode checked on my phone.

The googling I have done on this issue mention downloading the Android SDK, but I have heard no mention of needing this on the XDA developers forum or in any other conversation about rooting.  So, I wanted to ensure that downloading the Android SDK was necessary, or would even fix my problem before I bother installing it and its dependencies (Java JDK).  I'm running Windows XP.  

Note:  Although I'm running a 64-bit machine, I Installed the x86 Samsung Drivers since Windows XP is a 32-bit OS.  I hope that's right.

  
",Chance,https://android.stackexchange.com/users/3415,"Usually, all that's needed are the bits to make ADB (Android Debug Bridge) operate, which on Windows are the two libraries (AdbWinApi.dll and AdbWinUsbApi.dll).  But, that really shouldn't be necessary for a commercial product.
",Eric Cloninger,https://android.stackexchange.com/users/4551,http://android.stackexchange.com/questions/8913/do-i-need-android-sdk-to-connect-my-phone-in-usb-debug-mode,TECHNOLOGY,android.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.6666666666666667,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Do I need the Android SDK to connect to my phone in USB debugging mode?,"I'm following the steps provided here to root my Samsung Captivate (Galaxy-S).  I install the USB drivers in the link provided.  Whenever I connect my phone, I get the error There was a problem installing this hardware... SAMSUNG Android Composite ADB Interface.  I do have USB Debug mode checked on my phone.

The googling I have done on this issue mention downloading the Android SDK, but I have heard no mention of needing this on the XDA developers forum or in any other conversation about rooting.  So, I wanted to ensure that downloading the Android SDK was necessary, or would even fix my problem before I bother installing it and its dependencies (Java JDK).  I'm running Windows XP.  

Note:  Although I'm running a 64-bit machine, I Installed the x86 Samsung Drivers since Windows XP is a 32-bit OS.  I hope that's right.

  
","Usually, all that's needed are the bits to make ADB (Android Debug Bridge) operate, which on Windows are the two libraries (AdbWinApi.dll and AdbWinUsbApi.dll).  But, that really shouldn't be necessary for a commercial product.
"
1747,1747,2764,How to calculate mean and standard deviation in R given confidence interval and a normal or gamma distribution?,"Suppose you are given a $95 \%$ CI $(1,6)$ based on the normal distribution. Is there any easy way to find $\mu$ and $\sigma$? What if it came from a gamma distribution? Can we do this in R?
",toby j,https://stats.stackexchange.com/users/11963,"If you mean the true parameters of course the answer is no.  But if you mean that you want to recover the sample estimates from the confidence interval the answer is yes for the normal distribution if the sample size $n$ is also given.

If the confidence interval was $(1,6)$, then $1= \overline{X}-1.96 \cdot S/\sqrt{n}$ and $6=\overline{X}+1.96 \cdot S/\sqrt{n}$.  So $\overline{X}= (6+1)/2=3.5$
and then $6=3.5 +1.96 \cdot S/\sqrt{n}$ or $S=\sqrt{n} 2.5/(1.96)$.

For the gamma distribution this paper shows various ways to get the approximate and exact confidence intervals for rates.  Getting the parameter estimates from these confidence intervals may be complicated.
",Michael Chernick,https://stats.stackexchange.com/users/11032,http://stats.stackexchange.com/questions/30402/how-to-calculate-mean-and-standard-deviation-in-r-given-confidence-interval-and,SCIENCE,stats.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,How to calculate the mean and standard deviation of R under given signal interval and normal distribution or gamma distribution?,"Suppose you are given a $95 \% $CI $(1,6) $, based on a normal distribution. Is there any easy way to find $\ Mu $and $\ sigma $? What if it comes from the gamma distribution? Can we do it in R?","If you mean the true parameters of course the answer is no.  But if you mean that you want to recover the sample estimates from the confidence interval the answer is yes for the normal distribution if the sample size $n$ is also given.

If the confidence interval was $(1,6)$, then $1= \overline{X}-1.96 \cdot S/\sqrt{n}$ and $6=\overline{X}+1.96 \cdot S/\sqrt{n}$.  So $\overline{X}= (6+1)/2=3.5$
and then $6=3.5 +1.96 \cdot S/\sqrt{n}$ or $S=\sqrt{n} 2.5/(1.96)$.

For the gamma distribution this paper shows various ways to get the approximate and exact confidence intervals for rates.  Getting the parameter estimates from these confidence intervals may be complicated.
"
3474,3474,5539,KL divergence between two univariate Gaussians,"I need to determine the KL-divergence between two Gaussians. I am comparing my results to these, but I can't reproduce their result. My result is obviously wrong, because the KL is not 0 for KL(p, p).

I wonder where I am doing a mistake and ask if anyone can spot it.

Let $p(x) = N(\mu_1, \sigma_1)$ and $q(x) = N(\mu_2, \sigma_2)$. From Bishop's
PRML I know that

$$KL(p, q) = - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx$$

where integration is done over all real line, and that

$$\int p(x) \log p(x) dx = \frac{1}{2} (1 + \log 2 \pi \sigma_1^2),$$

so I restrict myself to $\int p(x) \log q(x) dx$, which I can write out as

$$-\int p(x) \log \frac{1}{(2 \pi \sigma_2^2)^{(1/2)}} e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx,$$

which I can separate into

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) \log e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx.$$

Taking the log I get

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) -\frac{(x-\mu_2)^2}{2 \sigma_2^2} dx,$$

where I separate the sums and get $\sigma_2^2$ out of the integral.

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\int p(x) x^2 dx - \int p(x) 2x\mu dx + \int p(x) \mu^2 dx}{2 \sigma_2^2}$$

Letting $\langle \rangle$ denote the expectation operator under $p$, I can rewrite this as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\langle x^2 \rangle - 2 \langle x \rangle \mu_2 + \mu_2^2}{2 \sigma_2^2}.$$

We know that $var(x) = \langle x^2 \rangle - \langle x \rangle ^2$. Thus 

$$\langle x^2 \rangle = \sigma_1^2 + \mu_1^2$$

and therefore

$$\frac{1}{2} \log (2 \pi \sigma^2) + \frac{\sigma_1^2 + \mu_1^2 - 2 \mu_1 \mu_2 + \mu_2^2}{2 \sigma_2^2},$$

which I can put as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.$$

Putting everything together, I get to 

\begin{align*}
KL(p, q) &amp;= - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx\\
&amp;= \frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2} (1 + \log 2 \pi \sigma_1^2)\\
&amp;= \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.
\end{align*}
Which is wrong since it equals $1$ for two identical Gaussians.

Can anyone spot my error?

Update

Thanks to mpiktas for clearing things up. The correct answer is:

$KL(p, q) = \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2}$
",bayerj,https://stats.stackexchange.com/users/2860,"OK, my bad. The error is in the last equation:

\begin{align}
KL(p, q) &amp;= - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx\\
&amp;=\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2} (1 + \log 2 \pi \sigma_1^2)\\
&amp;= \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}
\end{align}

$-\frac{1}{2}$ is missing in the last line. With it the last line becomes zero when $\mu_1=\mu_2$ and $\sigma_1=\sigma_2$.
",mpiktas,https://stats.stackexchange.com/users/2116,http://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians,SCIENCE,stats.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,KL divergence of two univariate Gauss,"I need to determine the KL-divergence between two Gaussians. I am comparing my results to these, but I can't reproduce their result. My result is obviously wrong, because the KL is not 0 for KL(p, p).

I wonder where I am doing a mistake and ask if anyone can spot it.

Let $p(x) = N(\mu_1, \sigma_1)$ and $q(x) = N(\mu_2, \sigma_2)$. From Bishop's
PRML I know that

$$KL(p, q) = - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx$$

where integration is done over all real line, and that

$$\int p(x) \log p(x) dx = \frac{1}{2} (1 + \log 2 \pi \sigma_1^2),$$

so I restrict myself to $\int p(x) \log q(x) dx$, which I can write out as

$$-\int p(x) \log \frac{1}{(2 \pi \sigma_2^2)^{(1/2)}} e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx,$$

which I can separate into

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) \log e^{-\frac{(x-\mu_2)^2}{2 \sigma_2^2}} dx.$$

Taking the log I get

$$\frac{1}{2} \log (2 \pi \sigma_2^2) - \int p(x) -\frac{(x-\mu_2)^2}{2 \sigma_2^2} dx,$$

where I separate the sums and get $\sigma_2^2$ out of the integral.

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\int p(x) x^2 dx - \int p(x) 2x\mu dx + \int p(x) \mu^2 dx}{2 \sigma_2^2}$$

Letting $\langle \rangle$ denote the expectation operator under $p$, I can rewrite this as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\langle x^2 \rangle - 2 \langle x \rangle \mu_2 + \mu_2^2}{2 \sigma_2^2}.$$

We know that $var(x) = \langle x^2 \rangle - \langle x \rangle ^2$. Thus 

$$\langle x^2 \rangle = \sigma_1^2 + \mu_1^2$$

and therefore

$$\frac{1}{2} \log (2 \pi \sigma^2) + \frac{\sigma_1^2 + \mu_1^2 - 2 \mu_1 \mu_2 + \mu_2^2}{2 \sigma_2^2},$$

which I can put as

$$\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.$$

Putting everything together, I get to 

\begin{align*}
KL(p, q) &amp;= - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx\\
&amp;= \frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2} (1 + \log 2 \pi \sigma_1^2)\\
&amp;= \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}.
\end{align*}
Which is wrong since it equals $1$ for two identical Gaussians.

Can anyone spot my error?

Update

Thanks to mpiktas for clearing things up. The correct answer is:

$KL(p, q) = \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2}$
","OK, my bad. The error is in the last equation:

\begin{align}
KL(p, q) &amp;= - \int p(x) \log q(x) dx + \int p(x) \log p(x) dx\\
&amp;=\frac{1}{2} \log (2 \pi \sigma_2^2) + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2} - \frac{1}{2} (1 + \log 2 \pi \sigma_1^2)\\
&amp;= \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2 \sigma_2^2}
\end{align}

$-\frac{1}{2}$ is missing in the last line. With it the last line becomes zero when $\mu_1=\mu_2$ and $\sigma_1=\sigma_2$.
"
781,781,1242,Layman's guide to getting started with Forex (foreign exchange trading)?,"How should I get started with Forex (foreign exchange trading)? How should I prepare myself for it? Please give your answer thinking of me as a layman.
",harvardfail,https://money.stackexchange.com/users/4311,"Currency Trading For Dummies, no offense. The ""For Dummies"" series is well known for its expertise in every field one can imagine.

That said, what prompts you to want to get into this? The average person is very likely to lose money as the long time experts walk away winners. Do you have an urge to trade commodity futures? I sure don't. 

While I offer the book as a guide, the real answer is ""you shouldn't."" 
",JoeTaxpayer,https://money.stackexchange.com/users/187,http://money.stackexchange.com/questions/12446/laymans-guide-to-getting-started-with-forex-foreign-exchange-trading,LIFE_ARTS,money.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,0.0,0.4444444444444444,0.4444444444444444,1.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6,0.6666666666666666,0.0,0.0,0.6666666666666666,A guide to foreign exchange trading?,How should I start foreign exchange trading? How can I prepare? Please answer me as a layman.,"Currency Trading For Dummies, no offense. The ""For Dummies"" series is well known for its expertise in every field one can imagine.

That said, what prompts you to want to get into this? The average person is very likely to lose money as the long time experts walk away winners. Do you have an urge to trade commodity futures? I sure don't. 

While I offer the book as a guide, the real answer is ""you shouldn't."" 
"
4642,4642,7362,jQuery plugin naming convention (for the function),"Which casing looks better to you for a jQuery plugin:

$(""#foo"").runMyPlugin();


or

$(""#foo"").runmyplugin();


Is there a naming convention for jQuery that prefers on over the other?

Thanks in advance!
",Marc Stober,https://stackoverflow.com/users/119901,"I would recommend you the first one, that convention is widely used in JavaScript, even in the core language by itself, the ECMA Specification uses it, e.g. 

Array.prototype.toLocaleString
Object.prototype.hasOwnProperty
Object.prototype.propertyIsEnumerable
// etc...


All identifiers are named with camelCase, and only constructor functions are named with the first letter as capital (PascalCase).
",CMS,https://stackoverflow.com/users/5445,http://stackoverflow.com/questions/2185425/jquery-plugin-naming-convention-for-the-function,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.7777777777777778,JQuery plug-in naming convention (for functions),"Which casing looks better to you for a jQuery plugin:

$(""#foo"").runMyPlugin();


or

$(""#foo"").runmyplugin();


Is there a naming convention for jQuery that prefers on over the other?

Thanks in advance!
","I would recommend you the first one, that convention is widely used in JavaScript, even in the core language by itself, the ECMA Specification uses it, e.g. 

Array.prototype.toLocaleString
Object.prototype.hasOwnProperty
Object.prototype.propertyIsEnumerable
// etc...


All identifiers are named with camelCase, and only constructor functions are named with the first letter as capital (PascalCase).
"
501,501,781,Is pretending to want to trade before playing a monopoly card objectionable?,"In Settlers of Catan, I sometimes try to ask people if they want to trade a certain resource, tricking them into revealing the approximate amount of that resource in everyone's hand. After this I play the monopoly card. This has on some occasions not been received very well.

Is this fair play?
",Matthijs Wessels,https://boardgames.stackexchange.com/users/117,"To counter the move, I make it clear at the begining of the game that if you ask if I have any brick, I may not tell you the truth. If you ask if I want to trade, that's a different question, and I can say no without implying I don't have any. I may also say, 'maybe,' when I don't have the requested resource, then turn down the ensuing trade offer. Doesn't work if you're playing with people with good memories, but how many of us pay scrupulous attention to every resource people pick up?
",shawnschirmer,https://boardgames.stackexchange.com/users/967,http://boardgames.stackexchange.com/questions/577/is-pretending-to-want-to-trade-before-playing-a-monopoly-card-objectionable,CULTURE,boardgames.stackexchange.com,1.0,0.4444444444444444,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8,0.0,0.0,0.0,1.0,Is it offensive to pretend to trade before playing Monopoly?,"Among the settlers in katan, I sometimes try to ask people if they want to exchange certain resources and cheat them to reveal the approximate amount of resources in each person's hands. After that, I played Monopoly. This is not well accepted in some cases.","To counter the move, I make it clear at the begining of the game that if you ask if I have any brick, I may not tell you the truth. If you ask if I want to trade, that's a different question, and I can say no without implying I don't have any. I may also say, 'maybe,' when I don't have the requested resource, then turn down the ensuing trade offer. Doesn't work if you're playing with people with good memories, but how many of us pay scrupulous attention to every resource people pick up?
"
606,606,948,Would it be a problem if all Amazon links were converted to affiliate links?,"I'm thinking that one way Jeff and the Stack Overflow team could squeeze some extra money out of this site would be to automatically convert all Amazon links posted here into affiliate links, e.g. Stick ""tag=codinghorror-20"" (or more likely a new site-specific tag) onto every Amazon link. This would bring in some additional revenue every time someone purchased a book via a link on this site. 

They could do similar things with other links as well. Amazon's simply the most obvious choice.

So my question is, would anyone have a problem with this?

I know I wouldn't mind, but I don't know how other people would react.

What does everyone think? Is this a horrible idea, a great idea, a waste of time?
",Derek Park,https://meta.stackexchange.com/users/159945,"@pbh


  The only place I could see this being a problem is when somebody posts their OWN affiliate link and gets it transformed into a SO affiliate link. Otherwise, I think it's a good idea, and maybe you could just transform the links not already affiliated.


I actually think that everyone else's affiliate links should already be filtered out (though I doubt that they currently are).  I think it's extremely uncool to post affiliate links on someone else's site, especially someone else's commercial site.
",Derek Park,https://meta.stackexchange.com/users/159945,http://meta.stackexchange.com/questions/10948/would-it-be-a-problem-if-all-amazon-links-were-converted-to-affiliate-links,TECHNOLOGY,meta.stackexchange.com,1.0,0.5,1.0,1.0,0.0,0.0,0.5,0.6666666666666666,0.5,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,0.5,1.0,Would it be a problem if all Amazon links were converted to affiliate links?,"I think one way Jeff and the stack overflow team can squeeze some extra money out of this site is to automatically convert all Amazon links published here into affiliate links, such as ""tag = codinghorror-20"" (or more likely a new site-specific tag) on each Amazon link. This will bring some extra revenue, with one book being purchased each time through a link to the site.","@pbh


  The only place I could see this being a problem is when somebody posts their OWN affiliate link and gets it transformed into a SO affiliate link. Otherwise, I think it's a good idea, and maybe you could just transform the links not already affiliated.


I actually think that everyone else's affiliate links should already be filtered out (though I doubt that they currently are).  I think it's extremely uncool to post affiliate links on someone else's site, especially someone else's commercial site.
"
940,940,1490,Amplifier damage caused by failed power supply capacitors,"MY QUESTION IS THIS:
Would failed power supply caps cause peripheral damage to the amp, preamp or control circuits ? Supposedly there is ""protection"" for ""DC offset, over current and over heat""

I have a Proton AM-656 amplifier with ""Dynamic Power on Demand"" which is a second higher voltage supply rail (switched to when needed) that creates 6db of headroom and 2 ohm stable. I did not think there was fault protection, turns out the schematic block diagram states there is.

One day with the amp power on I tightened/snugged up the speaker binding post. There was a single frayed speaker wire (unnoticed) that shorted. The amp proceed to billow smoke. I looked inside to find several power supply caps having oozed their electrolyte onto the circuit board. 

I am shopping to recap two of my other amps and was thinking of recapping the Proton, however I do not want to waste my time if there is likely to be damage to the circuits other than electrolytic capacitors.
",erick77,https://electronics.stackexchange.com/users/50159,"If you are going to recap, I can assume you have the tools to check the entire circuit (DMM, etc).  The only way to really know what went wrong is to start tracing through the circuit.  

You may need to get more parts than just the caps - if the transistors and other components were taken down at the same time, there could be quite a few more parts to buy.  Test all components first, get parts when you know exactly what you need to replace.  

Otherwise, I'm with Brian D on this!
",capacitor24,https://electronics.stackexchange.com/users/46623,http://electronics.stackexchange.com/questions/122902/amplifier-damage-caused-by-failed-power-supply-capacitors,TECHNOLOGY,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.6,0.5,0.5,0.0,1.0,Amplifier damage due to power capacitor failure,"MY QUESTION IS THIS:
Would failed power supply caps cause peripheral damage to the amp, preamp or control circuits ? Supposedly there is ""protection"" for ""DC offset, over current and over heat""

I have a Proton AM-656 amplifier with ""Dynamic Power on Demand"" which is a second higher voltage supply rail (switched to when needed) that creates 6db of headroom and 2 ohm stable. I did not think there was fault protection, turns out the schematic block diagram states there is.

One day with the amp power on I tightened/snugged up the speaker binding post. There was a single frayed speaker wire (unnoticed) that shorted. The amp proceed to billow smoke. I looked inside to find several power supply caps having oozed their electrolyte onto the circuit board. 

I am shopping to recap two of my other amps and was thinking of recapping the Proton, however I do not want to waste my time if there is likely to be damage to the circuits other than electrolytic capacitors.
","If you are going to recap, I can assume you have the tools to check the entire circuit (DMM, etc).  The only way to really know what went wrong is to start tracing through the circuit.  

You may need to get more parts than just the caps - if the transistors and other components were taken down at the same time, there could be quite a few more parts to buy.  Test all components first, get parts when you know exactly what you need to replace.  

Otherwise, I'm with Brian D on this!
"
3832,3832,6096,Flash 24fps vs 30fps,"I inherited a bunch of Flash animations that I am in charge of updating, maintaining, editing, etc.  They are really basic animations, really just sideshows of pictures with the occasional floating text.  My question is, some of them are 30fps and others are 24fps.  I am the kind of guy that likes standardization, so I would like to set them all the same.  There is no documentation as to why the person that originally created them used two different speeds (in fact I am not even sure if they were all made by the same person).

Any real advantage with one over the other?
",Taylor Huston,https://graphicdesign.stackexchange.com/users/4162,"A lot of LCD computer displays are locked at 60FPS*, so 30FPS fits best, fitting one animation frame perfectly into two display frames. 30FPS should look smoother than 24FPS or even 35FPS.

Fitting non-perfect frame rates can lead to juddering effects, as some kind of pulldown method is needed.

2:3 Pulldown used for movies shown on TV in the US

I'd use a frame rate that's perfectly divisible 60FPS. That means 15, 30 or 60FPS.

If, like Ben suggested, you're outputting to be displayed somewhere else and/or via a file, a different frame rate might be better.

Also, depending on your needs and requirements, you may want to reassess the use of Flash at all at some point soon â Flash's future looks pretty grim as a web format.

*I believe almost all flavours of OS X and Windows use 60FPS as the default LCD frame rate. Linux can apparently use other values easily, but 60FPS is still by far the most common frame rate for computers, including iPads and iPhones.
",Marc Edwards,https://graphicdesign.stackexchange.com/users/3901,http://graphicdesign.stackexchange.com/questions/7660/flash-24fps-vs-30fps,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,0.8888888888888888,24 fps flash vs. 30 FPS flash,"I have inherited a lot of Flash animations. I am responsible for updating, maintaining, editing, etc. they are very basic animations, only occasionally the side view of the picture with floating text appears. My problem is, some are 30 frames per second, some are 24 frames per second. I'm the kind of person who likes standardization, so I want them all to be the same. There is no documentation why the people who initially created them use two different speeds (in fact, I'm not even sure if they were all created by the same person).","A lot of LCD computer displays are locked at 60FPS*, so 30FPS fits best, fitting one animation frame perfectly into two display frames. 30FPS should look smoother than 24FPS or even 35FPS.

Fitting non-perfect frame rates can lead to juddering effects, as some kind of pulldown method is needed.

2:3 Pulldown used for movies shown on TV in the US

I'd use a frame rate that's perfectly divisible 60FPS. That means 15, 30 or 60FPS.

If, like Ben suggested, you're outputting to be displayed somewhere else and/or via a file, a different frame rate might be better.

Also, depending on your needs and requirements, you may want to reassess the use of Flash at all at some point soon â Flash's future looks pretty grim as a web format.

*I believe almost all flavours of OS X and Windows use 60FPS as the default LCD frame rate. Linux can apparently use other values easily, but 60FPS is still by far the most common frame rate for computers, including iPads and iPhones.
"
3808,3808,6053,"""All right, Johhny, it's time you ..........to bed.""","Could you possibly help me on this question please?

""All right, Johhny, it's time  you ..........to bed.""


went
would go
will be going
going to go


I would have gone for the word ""go"" but it is not in options.

Another similar question is that

"" Your hair is too long.It is time .............a haircut"" 

Thanks
",Mrt,https://ell.stackexchange.com/users/11631,"Not sure what the grammatical name for this is, but the correct answer is the simple past tense of the verb:


It's time you went to bed. 
It's time you got a haircut.


This might be considered a slightly pedantic construct. Most native speakers of English would probably be more inclined to say:


It's time for you to go to bed.
It's time for you to get a haircut.

",Eldgie in Phila,https://ell.stackexchange.com/users/11661,http://ell.stackexchange.com/questions/38525/its-time-you-to-bed,CULTURE,ell.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,"""Well, John, you should I'm sleeping. ""","Could you possibly help me on this question please?

""All right, Johhny, it's time  you ..........to bed.""


went
would go
will be going
going to go


I would have gone for the word ""go"" but it is not in options.

Another similar question is that

"" Your hair is too long.It is time .............a haircut"" 

Thanks
","Not sure what the grammatical name for this is, but the correct answer is the simple past tense of the verb:


It's time you went to bed. 
It's time you got a haircut.


This might be considered a slightly pedantic construct. Most native speakers of English would probably be more inclined to say:


It's time for you to go to bed.
It's time for you to get a haircut.

"
1398,1398,2205,Etiquette for posting civil and informative comments,"Sometimes I leave a comment like ""Stack Overflow is not your personal research assistant,"" but am accused of being rude.  How can I craft a comment that is seen as civil to the community and instructive to the OP?


What tone should I strike in comments?
What are some examples of bad comments and their better replacements?

",Robert Harvey,https://meta.stackexchange.com/users/102937,"What tone should I strike in comments?

The tone should be the similar to the tone you would strike toward a relatively new co-worker who stopped by your desk with a similar question.  You shouldn't assume ""tribal knowledge"" about how SO works, or what type of questions we like to see here.  The goal should be to help the questioner improve this and future questions.  Your comments should be ordered toward getting the information necessary to help the questioner solve his/her problem.

What are some examples of bad comments and their better replacements?

In my mind, this is the wrong question.  For many ""bad comments,"" it would most likely be better to not comment at all, and simply use the voting and moderation tools.

Ultimately, the answer isn't some sort of awk or perl script that will turn a rude comment into a constructive comment, but to change our attitudes from dealing with questions as efficiently as possible to dealing with human beings with questions.

The only thing more frustrating than a rude comment is a ""polite"" comment given through gritted teeth, or belied by every other aspect of the person's behavior.  A 30 minute hold time is not soothed by the recorded reminder that ""your call is very important to us"" every 20 seconds.

The challenge isn't about how to fake civility, it's to actually be civil.  To consider the questioner or answerer to be an actual human person with an actual problem rather than one more thing we have to deal with today.

If this is too high a bar for you to clear in responding, then maybe it's best for you to take this pitch and leave it for somebody else.

Having said that, there is some validity to ""fake it until you make it.""  That by going through the motions of active listening, civil phrasing, etc., that we can become more genuinely compassionate to others, and the other answers offer some tools to help us do that.  It's just important to remember that moving to more civil wording is a step in the journey, not the destination.

It's also the case that human relationships include snark and flashes of anger, and this includes SO.  But hopefully, this is not the exception rather than the rule.
",JohnMcG,https://meta.stackexchange.com/users/130994,http://meta.stackexchange.com/questions/138173/etiquette-for-posting-civil-and-informative-comments,TECHNOLOGY,meta.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,Etiquette for making civilized and informative comments,"Sometimes I leave a comment like, ""stack overflow is not your personal research assistant,"" but it will be accused of being rude. How can I write a comment that is considered polite to the community and instructive to the op?","What tone should I strike in comments?

The tone should be the similar to the tone you would strike toward a relatively new co-worker who stopped by your desk with a similar question.  You shouldn't assume ""tribal knowledge"" about how SO works, or what type of questions we like to see here.  The goal should be to help the questioner improve this and future questions.  Your comments should be ordered toward getting the information necessary to help the questioner solve his/her problem.

What are some examples of bad comments and their better replacements?

In my mind, this is the wrong question.  For many ""bad comments,"" it would most likely be better to not comment at all, and simply use the voting and moderation tools.

Ultimately, the answer isn't some sort of awk or perl script that will turn a rude comment into a constructive comment, but to change our attitudes from dealing with questions as efficiently as possible to dealing with human beings with questions.

The only thing more frustrating than a rude comment is a ""polite"" comment given through gritted teeth, or belied by every other aspect of the person's behavior.  A 30 minute hold time is not soothed by the recorded reminder that ""your call is very important to us"" every 20 seconds.

The challenge isn't about how to fake civility, it's to actually be civil.  To consider the questioner or answerer to be an actual human person with an actual problem rather than one more thing we have to deal with today.

If this is too high a bar for you to clear in responding, then maybe it's best for you to take this pitch and leave it for somebody else.

Having said that, there is some validity to ""fake it until you make it.""  That by going through the motions of active listening, civil phrasing, etc., that we can become more genuinely compassionate to others, and the other answers offer some tools to help us do that.  It's just important to remember that moving to more civil wording is a step in the journey, not the destination.

It's also the case that human relationships include snark and flashes of anger, and this includes SO.  But hopefully, this is not the exception rather than the rule.
"
629,629,992,What to do about students who ask for help too often?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
",Village,https://academia.stackexchange.com/users/600,"It looks like you have two different issues, it's easiest to discuss each of these separately.


Students will bring me some plagiarized work, showing it to me early,
as a sort of test if I will notice. It seems difficult to punish
plagiarism when the paper is not yet submitted.


This one is rough. You can't punish someone due to plagiarism before they submit work. The best policy, in my opinion, is twofold. 

First - if a student brings plagiarized work then you should simply say ""I'm sorry, I cannot help you with work that is not your own."" and point to you university's policy regarding academic dishonesty. Repeat offenders should be put on notice.

Second - If you grade the final assignments or are involved consider spending a bit more time plagiarize-checking these particular student's submissions. These students have shown that they were willing to claim other's work as their own, being a bit more stringent in checking their work for originality is, in my opinion, completely fair.


Students will bring in papers again and again, with little changes
put in at each stage, hoping their minimal effort each time will be
sufficient to reach their goal of a ""D"".


This sounds like a communication problem. After meeting with a student there should be no confusion about what will improve the student's work. For something like a paper it should be ""In order to improve this paper you should: extend the intro, go into more detail here, etc"" Students returning for additional assistance should have some sort of checklist that they should complete prior to returning for more assistance. Make this clear and obvious and, if there are multiple tutors a student could work with, something that is kept in some sort of notes system. 
",Nahkki,https://academia.stackexchange.com/users/18092,http://academia.stackexchange.com/questions/28504/what-to-do-about-students-who-ask-for-help-too-often,LIFE_ARTS,academia.stackexchange.com,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,1.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.0,1.0,What to do with students who often ask for help?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
","It looks like you have two different issues, it's easiest to discuss each of these separately.


Students will bring me some plagiarized work, showing it to me early,
as a sort of test if I will notice. It seems difficult to punish
plagiarism when the paper is not yet submitted.


This one is rough. You can't punish someone due to plagiarism before they submit work. The best policy, in my opinion, is twofold. 

First - if a student brings plagiarized work then you should simply say ""I'm sorry, I cannot help you with work that is not your own."" and point to you university's policy regarding academic dishonesty. Repeat offenders should be put on notice.

Second - If you grade the final assignments or are involved consider spending a bit more time plagiarize-checking these particular student's submissions. These students have shown that they were willing to claim other's work as their own, being a bit more stringent in checking their work for originality is, in my opinion, completely fair.


Students will bring in papers again and again, with little changes
put in at each stage, hoping their minimal effort each time will be
sufficient to reach their goal of a ""D"".


This sounds like a communication problem. After meeting with a student there should be no confusion about what will improve the student's work. For something like a paper it should be ""In order to improve this paper you should: extend the intro, go into more detail here, etc"" Students returning for additional assistance should have some sort of checklist that they should complete prior to returning for more assistance. Make this clear and obvious and, if there are multiple tutors a student could work with, something that is kept in some sort of notes system. 
"
2298,2298,3662,Kernel compilation and free space,"I am compiling linux kernel 3.0.1

My operating system is Ubuntu 11.04

The source is in /usr/src/linux-3.0.1

Though there is no free space remain in / the compilation is still going on .. !

What is happening exactly ?? Should I stop it ? 
",Vikram,https://superuser.com/users/121505,"Are you compiling as root?  I don't know if the free space reported by df takes into account the typical 5% superuser reservation.

Also it could be the kernel hasn't flushed the disk cache yet.

It is also possible your /usr is mounted on a separate partition.  This is quite likely if you took the defaults during your Ubuntu install (unless something has changed since the last time I used Ubuntu...)

If you run out of disk space and the compilation fails, free up some disk space and resume the compilation by issuing the make command again.

Bad idea to let / run out of space.  I would try to address that ASAP.
",LawrenceC,https://superuser.com/users/51705,http://superuser.com/questions/403022,TECHNOLOGY,superuser.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.4444444444444444,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,0.8888888888888888,Kernel compilation and free space,"I am compiling linux kernel 3.0.1

My operating system is Ubuntu 11.04

The source is in /usr/src/linux-3.0.1

Though there is no free space remain in / the compilation is still going on .. !

What is happening exactly ?? Should I stop it ? 
","Are you compiling as root?  I don't know if the free space reported by df takes into account the typical 5% superuser reservation.

Also it could be the kernel hasn't flushed the disk cache yet.

It is also possible your /usr is mounted on a separate partition.  This is quite likely if you took the defaults during your Ubuntu install (unless something has changed since the last time I used Ubuntu...)

If you run out of disk space and the compilation fails, free up some disk space and resume the compilation by issuing the make command again.

Bad idea to let / run out of space.  I would try to address that ASAP.
"
5749,5749,9100,Traveling into Brazil from Bolivia by land/bus,"I plan on travelling from Bolivia into Western Brazil (Caceres or Cuiaba in Mato Grosso) from Santa Cruz, Bolivia.  I have heard that there are a couple of border cities into which to pass over to Brazil. 

Does anyone know which is the safest/easiest way to go through?

If so, is travelling by bus the only way? I've heard there's also a train that leaves from Santa Cruz to Brazil, via Corumba? Is this currently running? Does anyone have experience travelling to Brazil like this?
",unknownprotocol,https://travel.stackexchange.com/users/9504,"There are buses from Santa Cruz to San Matias in Eastern Bolivia, on the border to Brazil. It takes around 15-18 hours on dirt roads. Once in Mato Grosso (on your way to CÃ¡ceres) the roads are very good and modern.
You won't easily find information on buses online, just go to the bus terminal once you're there in Santa Cruz and buy your ticket. Don't plan too tight as there are often very few buses per day between destinations in Bolivia, sometimes not even every day. It might also be at 6 am or similarly unlikely times.
Get your passport stamped in San Matias (exit stamp Bolivia) and in CÃ¡ceres (entry stamp Brazil), even though it's 100 km from the border. Note that the border office in San Matias isn't always open. On weekends, the official opening hours are 7:30 to 14:30 (as of November 2014). In Brazil it's 24h at the federal police.
You are not allowed to bring certain plant and animal products into Brazil, so try to finish your food before crossing the border. I wasn't checked, but it could happen and I suppose it's better to avoid trouble.
You have to take a taxi from San Matias to the border which should be no more than 7 Reals (if shared) or 15 Reals (single) (prices as of November 2014). Of course you could also pay in Bolivianos if you still have some. But you will need Reals to pay the bus from the border to CÃ¡ceres, a single ticket is 19 Reals, so exchange some money while in San Matias. There is an exchange office in town. You can also take a shared taxi, which should be 25 Reals and is much faster and more convenient as it can bring you directly to your destination in CÃ¡ceres, rather than the bus terminal. In my case, it brought me to the federal police for immigration first, waited for me, then we went to the bus terminal for onward travel at no additional cost. (Although not every taxi driver may be as nice and friendly.) 
Good luck to anyone on that route!
",Chris,https://travel.stackexchange.com/users/22926,http://travel.stackexchange.com/questions/22597/traveling-into-brazil-from-bolivia-by-land-bus,CULTURE,travel.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.8333333333333334,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,Land / bus from Bolivia to Brazil,"I plan on travelling from Bolivia into Western Brazil (Caceres or Cuiaba in Mato Grosso) from Santa Cruz, Bolivia.  I have heard that there are a couple of border cities into which to pass over to Brazil. 

Does anyone know which is the safest/easiest way to go through?

If so, is travelling by bus the only way? I've heard there's also a train that leaves from Santa Cruz to Brazil, via Corumba? Is this currently running? Does anyone have experience travelling to Brazil like this?
","There are buses from Santa Cruz to San Matias in Eastern Bolivia, on the border to Brazil. It takes around 15-18 hours on dirt roads. Once in Mato Grosso (on your way to CÃ¡ceres) the roads are very good and modern.
You won't easily find information on buses online, just go to the bus terminal once you're there in Santa Cruz and buy your ticket. Don't plan too tight as there are often very few buses per day between destinations in Bolivia, sometimes not even every day. It might also be at 6 am or similarly unlikely times.
Get your passport stamped in San Matias (exit stamp Bolivia) and in CÃ¡ceres (entry stamp Brazil), even though it's 100 km from the border. Note that the border office in San Matias isn't always open. On weekends, the official opening hours are 7:30 to 14:30 (as of November 2014). In Brazil it's 24h at the federal police.
You are not allowed to bring certain plant and animal products into Brazil, so try to finish your food before crossing the border. I wasn't checked, but it could happen and I suppose it's better to avoid trouble.
You have to take a taxi from San Matias to the border which should be no more than 7 Reals (if shared) or 15 Reals (single) (prices as of November 2014). Of course you could also pay in Bolivianos if you still have some. But you will need Reals to pay the bus from the border to CÃ¡ceres, a single ticket is 19 Reals, so exchange some money while in San Matias. There is an exchange office in town. You can also take a shared taxi, which should be 25 Reals and is much faster and more convenient as it can bring you directly to your destination in CÃ¡ceres, rather than the bus terminal. In my case, it brought me to the federal police for immigration first, waited for me, then we went to the bus terminal for onward travel at no additional cost. (Although not every taxi driver may be as nice and friendly.) 
Good luck to anyone on that route!
"
3644,3644,5815,Is it common to have a pressure shut off for Jet Water Pumps?,"I'm looking at installing a pump for a domestic water supply with a pressure tank.  I'd like to be able to determine if a pump will shut off once it has reached pressure.

I've seen several pumps installed which seem to shut off automatically but I can't seem to figure out if this is a standard feature or not because it doesn't seem to appear in their specifications.  For example, this grundfos pump is commonly used and I've seen other grundfos's shut off automatically at pressure.  Is this standard for a jet water pump?

http://www.supplyhouse.com/Grundfos-97855088-JP4-61ASI-Shallow-Well-Basic-Line-Stainless-Steel-Jet-Pump-115-230V-1-HP

I am asking because I'd like to try a different brand but I can not tell if it has a built in shut off:


http://www.amazon.com/gp/product/B00NAKPSRC?ref_=cm_cd_al_qh_dp_t
I've contacted the manufacturer, but with little response.  Is anyone familiar with jet pumps like this and what I should look for to fit this application?

Thanks.



EDIT:

After some time the manufacturer indicated that there is a port on the side for the pressure switch and sent a photo of one installed.  So now I know that's probably the standard way most jet pumps come so they can be externally configured to different PSI settings.


",user6972,https://diy.stackexchange.com/users/38472,"It is not a standard feature. The pump often hooks into a manifold that connects to the pressure tank and that has a check-valve, pressure gauge, pressure switch, tank drain valve, main shutoff valve, and over-pressure relief valve. The assembly looks like the following once assembled (note: check-valve not shown in this setup).



You will have to consult the manufacturer's spec sheets to see if it comes with an integral pressure switch. Even if the manufacturer won't respond, often they have spec sheets and manuals available online that will give you this info.

Note: the bottom pump is a no-brand Chinese manufacture pump, you might be able to trace it through Ali-Baba, but you'll have to take the Amazon description's word for what it does as there's not much else available about it online.
",Fiasco Labs,https://diy.stackexchange.com/users/7020,http://diy.stackexchange.com/questions/67830/is-it-common-to-have-a-pressure-shut-off-for-jet-water-pumps,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,Is pressure shut-off of the injection pump common?,"I'm looking at installing a pump for a domestic water supply with a pressure tank.  I'd like to be able to determine if a pump will shut off once it has reached pressure.

I've seen several pumps installed which seem to shut off automatically but I can't seem to figure out if this is a standard feature or not because it doesn't seem to appear in their specifications.  For example, this grundfos pump is commonly used and I've seen other grundfos's shut off automatically at pressure.  Is this standard for a jet water pump?

http://www.supplyhouse.com/Grundfos-97855088-JP4-61ASI-Shallow-Well-Basic-Line-Stainless-Steel-Jet-Pump-115-230V-1-HP

I am asking because I'd like to try a different brand but I can not tell if it has a built in shut off:


http://www.amazon.com/gp/product/B00NAKPSRC?ref_=cm_cd_al_qh_dp_t
I've contacted the manufacturer, but with little response.  Is anyone familiar with jet pumps like this and what I should look for to fit this application?

Thanks.



EDIT:

After some time the manufacturer indicated that there is a port on the side for the pressure switch and sent a photo of one installed.  So now I know that's probably the standard way most jet pumps come so they can be externally configured to different PSI settings.


","It is not a standard feature. The pump often hooks into a manifold that connects to the pressure tank and that has a check-valve, pressure gauge, pressure switch, tank drain valve, main shutoff valve, and over-pressure relief valve. The assembly looks like the following once assembled (note: check-valve not shown in this setup).



You will have to consult the manufacturer's spec sheets to see if it comes with an integral pressure switch. Even if the manufacturer won't respond, often they have spec sheets and manuals available online that will give you this info.

Note: the bottom pump is a no-brand Chinese manufacture pump, you might be able to trace it through Ali-Baba, but you'll have to take the Amazon description's word for what it does as there's not much else available about it online.
"
2408,2408,3844,Wiki-like tool for writing specifications and documentation,"I am looking for a wiki or wiki-like system for writing and managing specification and documentation for a software project. 

I know there are lots of wiki-implementations available, but are there some that are especially well-suited for this kind of task?

Actually it doesn't have to be a wiki, just a system that makes it easy to write and navigate specs and documentation, and which support change tracing.
",user35746,https://programmers.stackexchange.com/users/35746,"We're using LaTeX and SVN. Since LaTeX documents are just text files, it plays well with version control, unlike some binary or partially-binary formats.

You get all the advantages (and disadvantages, admittedly) of version control you're used to from using it with your code.

LaTeX takes a little setting up (to define your own styles/class), but once you've done so it's very good - you can concentrate solely on the content rather than its presentation (rather than being tempted to constantly tweak as you are with WYSIWYG), yet still get a slick, professional-looking PDF document at the end.
",Scott,https://programmers.stackexchange.com/users/17701,http://programmers.stackexchange.com/questions/105179/wiki-like-tool-for-writing-specifications-and-documentation,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.7777777777777778,0.0,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,Wiki like tools for writing specifications and documents,"I am looking for a wiki or wiki-like system for writing and managing specification and documentation for a software project. 

I know there are lots of wiki-implementations available, but are there some that are especially well-suited for this kind of task?

Actually it doesn't have to be a wiki, just a system that makes it easy to write and navigate specs and documentation, and which support change tracing.
","We're using LaTeX and SVN. Since LaTeX documents are just text files, it plays well with version control, unlike some binary or partially-binary formats.

You get all the advantages (and disadvantages, admittedly) of version control you're used to from using it with your code.

LaTeX takes a little setting up (to define your own styles/class), but once you've done so it's very good - you can concentrate solely on the content rather than its presentation (rather than being tempted to constantly tweak as you are with WYSIWYG), yet still get a slick, professional-looking PDF document at the end.
"
4148,4148,6616,"How to customize Windows ""Performance Monitor""?","I'm wondering if that's possible to set a customized action counter that is not listed as one of the counters? e.g. a batch script that measure a time for running my application, and then notify the real-time graph the time it took to load it. Also I'd like to set its frequency.

If possible, please let me know how to apply.

Thank you
",user986086,https://serverfault.com/users/132510,"You can create perfmon counters using .NET code and thus using PowerShell too. A moderate amount of coding is required.
",the-wabbit,https://serverfault.com/users/76595,http://serverfault.com/questions/497129,TECHNOLOGY,serverfault.com,0.7777777777777778,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,How do I customize the windows performance monitor?,I wonder if I can set a custom operation counter instead of listing it as one of them? eã A batch script that measures the time it takes to run my application and then tells the live graph to load it. I also want to set its frequency.,"You can use. Net code to create Perfmon counters, so you can also use PowerShell. Moderate coding is required."
3372,3372,5380,How to remove a directory and its contents using NSFileManager,"New to Objective C. I have created a few directories which contain pdf files for an iPhone app. How can I delete a directory and its contents using NSFileManager?

Do I need to loop through and remove the contents first? Any code samples would be much appreciated.

Thanks in advance.
",booboo-a-choo,https://stackoverflow.com/users/393465,"To start off, it would be wise to look through Apple's NSFileManager documentation for the iPhone: NSFileManager Class Reference. Second, look at NSFileManager's -removeItemAtPath:error: method and its documentation. That's what you're looking for.
",Itai Ferber,https://stackoverflow.com/users/169394,http://stackoverflow.com/questions/3664694/how-to-remove-a-directory-and-its-contents-using-nsfilemanager,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.7777777777777778,0.6666666666666667,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,How to use nsfilemanager to delete directories and their contents,New target C. I've created several directories that contain a PDF file for an iPhone application. How do I use nsfilemanager to delete directories and their contents?,"To start off, it would be wise to look through Apple's NSFileManager documentation for the iPhone: NSFileManager Class Reference. Second, look at NSFileManager's -removeItemAtPath:error: method and its documentation. That's what you're looking for.
"
3190,3190,5084,Twisted Fate: Do Wildcards (Q) apply the effects of Pick A Card (W)?,"Wildcards (Q):


  Twisted Fate throws 3 cards forward in an arc, dealing magic damage 60 / 110 / 160 / 210 / 260 (+ 65% AP) to enemies they pass through. 


Pick a Card (W):


  When first activated, cards flash over Twisted Fate's head in the following order: blue, then red, then gold (this cycle repeats itself). When he uses the ability again, he picks the current card over his head; the card picked converts his next basic attack within 6 seconds to deal magic damage and add a special effect. Twisted Fate has 6 seconds to select a card.


Do the Wildcard cards apply the same effect as the cards in Pick a Card?
",DropDeadSander - EUW,https://gaming.stackexchange.com/users/61976,"No, it doesn't work with his Q ability.
",Photon,https://gaming.stackexchange.com/users/87650,http://gaming.stackexchange.com/questions/184880/twisted-fate-do-wildcards-q-apply-the-effects-of-pick-a-card-w,CULTURE,gaming.stackexchange.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.5,1.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,0.5,0.6666666666666666,Twisted fate: does wildcard (q) apply the effect of selection card (W)?,"Wildcards (Q):


  Twisted Fate throws 3 cards forward in an arc, dealing magic damage 60 / 110 / 160 / 210 / 260 (+ 65% AP) to enemies they pass through. 


Pick a Card (W):


  When first activated, cards flash over Twisted Fate's head in the following order: blue, then red, then gold (this cycle repeats itself). When he uses the ability again, he picks the current card over his head; the card picked converts his next basic attack within 6 seconds to deal magic damage and add a special effect. Twisted Fate has 6 seconds to select a card.


Do the Wildcard cards apply the same effect as the cards in Pick a Card?
","No, it doesn't work with his Q ability.
"
5987,5987,9491,Would it be a problem if all Amazon links were converted to affiliate links?,"I'm thinking that one way Jeff and the Stack Overflow team could squeeze some extra money out of this site would be to automatically convert all Amazon links posted here into affiliate links, e.g. Stick ""tag=codinghorror-20"" (or more likely a new site-specific tag) onto every Amazon link. This would bring in some additional revenue every time someone purchased a book via a link on this site. 

They could do similar things with other links as well. Amazon's simply the most obvious choice.

So my question is, would anyone have a problem with this?

I know I wouldn't mind, but I don't know how other people would react.

What does everyone think? Is this a horrible idea, a great idea, a waste of time?
",Derek Park,https://meta.stackexchange.com/users/159945,"In my experience, affiliate links never pay out well. Perhaps with such a huge member base SO might do better.

But how often do you click a link from SO and buy the item right away? I have certainly bought one book I've seen mentioned here (and other places), but I didn't buy it straight away, I went back to Amazon a week later, searched for it and bought it.
",DisgruntledGoat,https://meta.stackexchange.com/users/37947,http://meta.stackexchange.com/questions/10948/would-it-be-a-problem-if-all-amazon-links-were-converted-to-affiliate-links,TECHNOLOGY,meta.stackexchange.com,1.0,0.8888888888888888,1.0,0.0,0.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,Would it be a problem if all Amazon links were converted to affiliate links?,"I think one way Jeff and the stack overflow team can squeeze some extra money out of this site is to automatically convert all Amazon links published here into affiliate links, such as ""tag = codinghorror-20"" (or more likely a new site-specific tag) on each Amazon link. This will bring some extra revenue, with one book being purchased each time through a link to the site.","In my experience, affiliate links never pay out well. Perhaps with such a huge member base SO might do better.

But how often do you click a link from SO and buy the item right away? I have certainly bought one book I've seen mentioned here (and other places), but I didn't buy it straight away, I went back to Amazon a week later, searched for it and bought it.
"
4042,4042,6453,how do i get rust stains off driveway,"I used fertilizer with iron and, unfortunately, didn't sweep adequately afterwards. Afterwards I ran my sprinklers and now my driveway and sidewalk are peppered with unsightly rust stains. What are the best ways to get it off? (By ""best"" I mean easiest and most efficient, while still being safe, inexpensive, and not too harmful to the nearby lawn.) Any suggestions?
",kmote,https://diy.stackexchange.com/users/3671,"Use a cleaning product called CLR also known as calcium,lime and rust remover. It is available at hardware stores and home centers.
",mikes,https://diy.stackexchange.com/users/5422,http://diy.stackexchange.com/questions/16054/how-do-i-get-rust-stains-off-my-driveway,LIFE_ARTS,diy.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,How can I get rid of the rust on the driveway,"I used iron fertilizer and unfortunately I didn't clean it up enough afterwards. Later I drove the sprinkler, and now my driveway and sidewalk are covered with ugly rust. What's the best way? (by ""best"" I mean the simplest, most effective, safe, cheap, and not too harmful to the nearby lawn) any suggestions?","Use a cleaning product called CLR also known as calcium,lime and rust remover. It is available at hardware stores and home centers.
"
1881,1881,2988,Amplifier damage caused by failed power supply capacitors,"MY QUESTION IS THIS:
Would failed power supply caps cause peripheral damage to the amp, preamp or control circuits ? Supposedly there is ""protection"" for ""DC offset, over current and over heat""

I have a Proton AM-656 amplifier with ""Dynamic Power on Demand"" which is a second higher voltage supply rail (switched to when needed) that creates 6db of headroom and 2 ohm stable. I did not think there was fault protection, turns out the schematic block diagram states there is.

One day with the amp power on I tightened/snugged up the speaker binding post. There was a single frayed speaker wire (unnoticed) that shorted. The amp proceed to billow smoke. I looked inside to find several power supply caps having oozed their electrolyte onto the circuit board. 

I am shopping to recap two of my other amps and was thinking of recapping the Proton, however I do not want to waste my time if there is likely to be damage to the circuits other than electrolytic capacitors.
",erick77,https://electronics.stackexchange.com/users/50159,"A more likely scenario is that the short circuit damaged the power transistors so they failed short circuit, and they in turn caused the capacitors to fail. If the amp uses discrete power transistors, these will be replaceable. If it's a custom IC or hybrid module, you're less likely to be able to find replacements.

Resistance measurements on the transistor pins (compare with the ""good"" channel) looking for collector-emitter shorts may help confirm this scenario, and show which transistors need replacing. Or if both channels measure the same, you may be lucky and re-capping will be OK.
",Brian Drummond,https://electronics.stackexchange.com/users/16324,http://electronics.stackexchange.com/questions/122902/amplifier-damage-caused-by-failed-power-supply-capacitors,TECHNOLOGY,electronics.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8333333333333334,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,1.0,1.0,Amplifier damage due to power capacitor failure,"MY QUESTION IS THIS:
Would failed power supply caps cause peripheral damage to the amp, preamp or control circuits ? Supposedly there is ""protection"" for ""DC offset, over current and over heat""

I have a Proton AM-656 amplifier with ""Dynamic Power on Demand"" which is a second higher voltage supply rail (switched to when needed) that creates 6db of headroom and 2 ohm stable. I did not think there was fault protection, turns out the schematic block diagram states there is.

One day with the amp power on I tightened/snugged up the speaker binding post. There was a single frayed speaker wire (unnoticed) that shorted. The amp proceed to billow smoke. I looked inside to find several power supply caps having oozed their electrolyte onto the circuit board. 

I am shopping to recap two of my other amps and was thinking of recapping the Proton, however I do not want to waste my time if there is likely to be damage to the circuits other than electrolytic capacitors.
","A more likely scenario is that the short circuit damaged the power transistors so they failed short circuit, and they in turn caused the capacitors to fail. If the amp uses discrete power transistors, these will be replaceable. If it's a custom IC or hybrid module, you're less likely to be able to find replacements.

Resistance measurements on the transistor pins (compare with the ""good"" channel) looking for collector-emitter shorts may help confirm this scenario, and show which transistors need replacing. Or if both channels measure the same, you may be lucky and re-capping will be OK.
"
6007,6007,9528,iOS: Change Device Volume,"Is there a way to change the volume of the device? I've seen several apps do it. 

I have a desktop version of the iOS app and the device will be able to be controlled to some extent over the network. One of the things I want to allow the user to do is change the device volume and then play a sound. This can help if you loose your iPhone in a crack in your couch again, but can't find it. 

Is there any way that you can do this without Apple getting angry?
",Tristan Seifert,https://stackoverflow.com/users/219515,"You cannot change device volume programatically, however MPVolumeView (volume slider) is there to change device volume but only through user interaction.

MPVolumeView is a control in toolbox, you need to add MediaPlayer.framework in your project then MPVolumeView will be displayed in toolbox in interface builder.

Edit 1: MPVolumeView uses the device volume which is also used for ringing volume. AVAudioPlayer is there if you want application level volume. In this case you can use volume property to set your application volume (not device volume) programatically. However, you can use UISlider control to get volume input from user and set to your AVAudioPlayer
",Waqas Raja,https://stackoverflow.com/users/334494,http://stackoverflow.com/questions/4859402/ios-change-device-volume,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,IOS: changing device volumes,"Is there a way to change the volume of the device? I've seen several apps do it. 

I have a desktop version of the iOS app and the device will be able to be controlled to some extent over the network. One of the things I want to allow the user to do is change the device volume and then play a sound. This can help if you loose your iPhone in a crack in your couch again, but can't find it. 

Is there any way that you can do this without Apple getting angry?
","You cannot change device volume programatically, however MPVolumeView (volume slider) is there to change device volume but only through user interaction.

MPVolumeView is a control in toolbox, you need to add MediaPlayer.framework in your project then MPVolumeView will be displayed in toolbox in interface builder.

Edit 1: MPVolumeView uses the device volume which is also used for ringing volume. AVAudioPlayer is there if you want application level volume. In this case you can use volume property to set your application volume (not device volume) programatically. However, you can use UISlider control to get volume input from user and set to your AVAudioPlayer
"
1712,1712,2711,Is it possible to Cap a GridFS collection?,"I'm trying to store my application results in a mongo database.  There are some issues to this, first we generate a lot of data because it is raw image files, up to 50MB per record and 5 records per second at full speed, that's worst case though not typical. This isn't a problem using gridFS. In the mongod.cfg we are using directoryPerDB: true and I create a symlink for the Results database folder to a dedicated SSD where all the results database is kept.  All the settings data is kept in a couple different databases on the OS drive, and the results data has a dedicated drive. This is all working great for our application.

My problem is filling up the results disk. I need to basically have a capped collection to a max size, and then delete only the oldest files.  But I don't see a way to do this with gridFS? Is there a setting  or something I'm missing that would allow capping this?  

I found this answer GridFS disk management but that seems to apply to mongod, and i don't think you can set a quota per database as the Results database is the only one I need to be limited.  

At this point I guess i will write a task that cleans the oldest files out periodically if the total is over a threshold limit, i'm just afraid this is not going to be very efficient.  Are there any recommendations on the best way to handle this?  
",trashrobber,https://stackoverflow.com/users/480819,"To make a long story short: you can not cap GridFS in a useful way. Here is why:

When you store a file in GridFS, it is split into chunks of 255kB, by default in a collection named fs.chunks, which absolutely can be capped by doing

db.createCollection(""fs.chunks"",{capped:true, size:52428800})


The capping would apply to those chunks, which are individual documents. So when you add a file which would make the fs.chunks to exceed its cap, only chunks of the oldest files would be removed. Another problem would be that the files metadata, which is stored in fs.files by default, would not be updated, leaving stale entries in fs.files for which no entries in fs.chunks are present any more, or â worse â only a fraction of the chunks are still present.

There are ways to overcome this (checking if the size in bytes of the chunks combined equals the length field of the fs.files document of the respective file, for example), but they are at least as complicated (and much slower!) as doing a check pre-insert wether the collection would exceed the threshold using the collections stats and delete as many of the oldest files as needed to fit the new file in without exceeding the threshold. 

The latter, by the way, is my suggestion on how to solve your problem.

Another solution would be to use a dedicated instance with the limitations applied in my answer to the question you mentioned.
",Markus W Mahlberg,https://stackoverflow.com/users/1296707,http://stackoverflow.com/questions/27550850/is-it-possible-to-cap-a-gridfs-collection,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,1.0,Can I set the upper limit on the gridfs collection?,"I'm trying to store my application results in a mongo database.  There are some issues to this, first we generate a lot of data because it is raw image files, up to 50MB per record and 5 records per second at full speed, that's worst case though not typical. This isn't a problem using gridFS. In the mongod.cfg we are using directoryPerDB: true and I create a symlink for the Results database folder to a dedicated SSD where all the results database is kept.  All the settings data is kept in a couple different databases on the OS drive, and the results data has a dedicated drive. This is all working great for our application.

My problem is filling up the results disk. I need to basically have a capped collection to a max size, and then delete only the oldest files.  But I don't see a way to do this with gridFS? Is there a setting  or something I'm missing that would allow capping this?  

I found this answer GridFS disk management but that seems to apply to mongod, and i don't think you can set a quota per database as the Results database is the only one I need to be limited.  

At this point I guess i will write a task that cleans the oldest files out periodically if the total is over a threshold limit, i'm just afraid this is not going to be very efficient.  Are there any recommendations on the best way to handle this?  
","To make a long story short: you can not cap GridFS in a useful way. Here is why:

When you store a file in GridFS, it is split into chunks of 255kB, by default in a collection named fs.chunks, which absolutely can be capped by doing

db.createCollection(""fs.chunks"",{capped:true, size:52428800})


The capping would apply to those chunks, which are individual documents. So when you add a file which would make the fs.chunks to exceed its cap, only chunks of the oldest files would be removed. Another problem would be that the files metadata, which is stored in fs.files by default, would not be updated, leaving stale entries in fs.files for which no entries in fs.chunks are present any more, or â worse â only a fraction of the chunks are still present.

There are ways to overcome this (checking if the size in bytes of the chunks combined equals the length field of the fs.files document of the respective file, for example), but they are at least as complicated (and much slower!) as doing a check pre-insert wether the collection would exceed the threshold using the collections stats and delete as many of the oldest files as needed to fit the new file in without exceeding the threshold. 

The latter, by the way, is my suggestion on how to solve your problem.

Another solution would be to use a dedicated instance with the limitations applied in my answer to the question you mentioned.
"
3597,3597,5742,Show UILabel with complete text or hide it,"I have a UI label say ""ABCDEFGH"". In iPhone 6 etc wider devices I can show the complete text. In small screen devices like iPhone 5, I see text as ""ABCD..."". I want the following:

if(complete text can be shown) 
{
    // show UILabel with text
} else // if text can not fit in, ""ABCD..."" case 
{    
    // hide the UILabel
}


How can I do this?
",Vinuta,https://stackoverflow.com/users/1155552,"You can get Screen's size like this : 

CGSize screenSize = [[UIScreen mainScreen] bounds].size;


And then put an if statement like this :

if (label.frame.size.width&gt;screenSize.width) { 
        //Use smaller label }
else {
        //use bigger label }

",Munahil,https://stackoverflow.com/users/327565,http://stackoverflow.com/questions/31168215/show-uilabel-with-complete-text-or-hide-it,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Show or hide uilabel with full text,"I have a user interface label that says ""abcdefgh."". On a wider range of devices, such as the iPhone 6, I can display full text. In a small screen device like the iPhone 5, I think of text as ""ABCD..."". I want to:","You can get Screen's size like this : 

CGSize screenSize = [[UIScreen mainScreen] bounds].size;


And then put an if statement like this :

if (label.frame.size.width&gt;screenSize.width) { 
        //Use smaller label }
else {
        //use bigger label }

"
989,989,1564,lisp function that adds x to the nth item of a list,"I need to write a lisp function that adds x to the nth item of a list. For example, (add 5 2 '(3 1 4 6 7)) returns (3 6 4 6 7). 

choosing nthitem is

(defun nthitem (n list)
  (cond ((equal n 1) (car list))
        (t (nthitem (-n 1) (cdr list)))))


and adding x to a list is:

(defun addto (x list)
  (cond ((null list) nil)
        (t (cons (+ x (car list)) 
                 (addto x (cdr list))))))


But i cannot combine these two together.
",leon0606,https://stackoverflow.com/users/2912696,"All you need is nth and setf:

emacs -Q, then evaluate the following:

(defun add-to-nth (x n ys)
  (when ys (setf (nth n ys) (+ x (nth n ys)))))

(setq foobar  '(1 2 3 4 5))
(add-to-nth 42 1 foobar)

C-h v foobar  ; =&gt;  (1 44 3 4 5)

",Drew,https://stackoverflow.com/users/729907,http://stackoverflow.com/questions/19549728/lisp-function-that-adds-x-to-the-nth-item-of-a-list,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Add x to the LISP function of item n of the list,"I need to write a lisp function that adds x to the nth item of a list. For example, (add 5 2 '(3 1 4 6 7)) returns (3 6 4 6 7). 

choosing nthitem is

(defun nthitem (n list)
  (cond ((equal n 1) (car list))
        (t (nthitem (-n 1) (cdr list)))))


and adding x to a list is:

(defun addto (x list)
  (cond ((null list) nil)
        (t (cons (+ x (car list)) 
                 (addto x (cdr list))))))


But i cannot combine these two together.
","All you need is nth and setf:

emacs -Q, then evaluate the following:

(defun add-to-nth (x n ys)
  (when ys (setf (nth n ys) (+ x (nth n ys)))))

(setq foobar  '(1 2 3 4 5))
(add-to-nth 42 1 foobar)

C-h v foobar  ; =&gt;  (1 44 3 4 5)

"
2048,2048,3266,Recorded video Frame using AVCaptureSession,"In my application i am using  AVCaptureSession to record video.

When recording done,I m getting video is of size 360 X 480.

I have set recording layer size is 320 X 568.

I am missing something, I tried but not getting where.

Can anyone guide me where should i change to get recording video with size of 320 X 568  

Here is my code,

Initialization

AVCaptureDevice* device = nil;
AVCaptureDeviceInput *captureInput = [AVCaptureDeviceInput deviceInputWithDevice:device error:nil];
AVCaptureVideoDataOutput *captureOutput = [[AVCaptureVideoDataOutput alloc] init];
captureOutput.alwaysDiscardsLateVideoFrames = YES; 



dispatch_queue_t queue;
queue = dispatch_queue_create(""cameraQueue"", NULL);
[captureOutput setSampleBufferDelegate:self queue:queue];
dispatch_release(queue);


// Set the video output to store frame in BGRA

NSString* key = (NSString*)kCVPixelBufferPixelFormatTypeKey; 
NSNumber* value = [NSNumber numberWithUnsignedInt:kCVPixelFormatType_32BGRA]; 
NSDictionary* videoSettings = [NSDictionary dictionaryWithObject:value forKey:key]; 
[captureOutput setVideoSettings:videoSettings]; 


//And we create a capture session

self.captureSession = [[AVCaptureSession alloc] init];
self.captureSession.sessionPreset = AVCaptureSessionPresetMedium;

if([self.captureSession respondsToSelector:@selector(addInput:)])
        [self.captureSession addInput:captureInput];
    if([self.captureSession respondsToSelector:@selector(addOutput:)])
        [self.captureSession addOutput:captureOutput];

/*We add the Custom Layer (We need to change the orientation of the layer so that the video is displayed correctly)*/
self.customLayer = [CALayer layer];
self.customLayer.frame = self.view.bounds;

self.customLayer.transform = CATransform3DRotate(CATransform3DIdentity, M_PI/2.0f, 0, 0, 1);
    self.customLayer.transform = CATransform3DScale(self.customLayer.transform,.7,.7,1);
    self.customLayer.transform = CATransform3DTranslate(self.customLayer.transform,-23,0,0);

self.customLayer.contentsGravity = kCAGravityResizeAspectFill;
[self.view.layer addSublayer:self.customLayer];
[self.captureSession startRunning];


//Initialization Over
",Nikunj,https://stackoverflow.com/users/1400686," if ([self.captureSession canSetSessionPreset:AVCaptureSessionPreset320*568]) 
    {
        [self.captureSession setSessionPreset:AVCaptureSessionPreset320*568];
    }


try this one.
",Jitendra,https://stackoverflow.com/users/2348998,http://stackoverflow.com/questions/16650356/recorded-video-frame-using-avcapturesession,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.8333333333333334,0.9,1.0,0.0,0.0,0.6666666666666666,Video frames recorded with avcapturesession,"In my application i am using  AVCaptureSession to record video.

When recording done,I m getting video is of size 360 X 480.

I have set recording layer size is 320 X 568.

I am missing something, I tried but not getting where.

Can anyone guide me where should i change to get recording video with size of 320 X 568  

Here is my code,

Initialization

AVCaptureDevice* device = nil;
AVCaptureDeviceInput *captureInput = [AVCaptureDeviceInput deviceInputWithDevice:device error:nil];
AVCaptureVideoDataOutput *captureOutput = [[AVCaptureVideoDataOutput alloc] init];
captureOutput.alwaysDiscardsLateVideoFrames = YES; 



dispatch_queue_t queue;
queue = dispatch_queue_create(""cameraQueue"", NULL);
[captureOutput setSampleBufferDelegate:self queue:queue];
dispatch_release(queue);


// Set the video output to store frame in BGRA

NSString* key = (NSString*)kCVPixelBufferPixelFormatTypeKey; 
NSNumber* value = [NSNumber numberWithUnsignedInt:kCVPixelFormatType_32BGRA]; 
NSDictionary* videoSettings = [NSDictionary dictionaryWithObject:value forKey:key]; 
[captureOutput setVideoSettings:videoSettings]; 


//And we create a capture session

self.captureSession = [[AVCaptureSession alloc] init];
self.captureSession.sessionPreset = AVCaptureSessionPresetMedium;

if([self.captureSession respondsToSelector:@selector(addInput:)])
        [self.captureSession addInput:captureInput];
    if([self.captureSession respondsToSelector:@selector(addOutput:)])
        [self.captureSession addOutput:captureOutput];

/*We add the Custom Layer (We need to change the orientation of the layer so that the video is displayed correctly)*/
self.customLayer = [CALayer layer];
self.customLayer.frame = self.view.bounds;

self.customLayer.transform = CATransform3DRotate(CATransform3DIdentity, M_PI/2.0f, 0, 0, 1);
    self.customLayer.transform = CATransform3DScale(self.customLayer.transform,.7,.7,1);
    self.customLayer.transform = CATransform3DTranslate(self.customLayer.transform,-23,0,0);

self.customLayer.contentsGravity = kCAGravityResizeAspectFill;
[self.view.layer addSublayer:self.customLayer];
[self.captureSession startRunning];


//Initialization Over
"," if ([self.captureSession canSetSessionPreset:AVCaptureSessionPreset320*568]) 
    {
        [self.captureSession setSessionPreset:AVCaptureSessionPreset320*568];
    }


try this one.
"
1631,1631,2556,"ListBox is selecting many items even in SelectionMode=""Single""","I have encountered something very strange, simple WPF application

&lt;Window x:Class=""ListBoxSelection.MainWindow""
        xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
        xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
        Title=""MainWindow"" Height=""350"" Width=""525""&gt;
    &lt;Grid&gt;
        &lt;ListBox ItemsSource=""{Binding Path=Strings}"" SelectionMode=""Single""/&gt;
    &lt;/Grid&gt;
&lt;/Window&gt;


with code behind

public class ViewModel
{
    public List&lt;string&gt; Strings { get; set; }

    public ViewModel ()
    {
        Strings = new List&lt;string&gt; ();
        Strings.Add (""A"");
        // add many items ...
        Strings.Add (""A"");
    }
}

/// &lt;summary&gt;
/// Interaction logic for MainWindow.xaml
/// &lt;/summary&gt;
public partial class MainWindow : Window
{
    public MainWindow ()
    {
        InitializeComponent ();

        DataContext = new ViewModel ();
    }
}


and when I click on a single item,



if I continue clicking items, they just aggregate. Clicking an already selected item does nothing. Scratching my head, I have databound lists to ListBoxes before, and have never seen this before. Running Win7 (64), VS2010, behaviour presents with .Net 3.5, .Net 3.5 Client Profile, .Net 4, and .Net 4 Client Profile.

Arg, I should mention I am expecting normal, default, single-select behaviour.
",johnny g,https://stackoverflow.com/users/189183,"I encountered this problem as well--as others have noted, .NET handles strings in a curious manner to improve memory management.  

My immediate workaround was to create a UniqueListItem class to be used in place of the strings I was planning to add to the listbox.  

class UniqueListItemObject
{
    private string _text;
    public string Text { get { return _text; } set { _text = value; } }

    public UniqueListItemObject(string input)
    {
        Text = input;
    }
    public UniqueListItemObject()
    {
        Text = string.Empty;
    }

    public override string ToString()
    {
        return Text;
    }
}


Because each instance of this object will get its own memory location, adding instances of this object to a listbox control instead of adding strings will result in unique selections, even if the strings displayed in the listbox are identical.

        yourListBox.Items.Add(new UniqueListItemObject(yourStringHere);


I can't say if this is the best solution (that depends on your project's requirements) but hopefully someone finds this helpful.
",Andy Pierre,https://stackoverflow.com/users/610848,http://stackoverflow.com/questions/3843784/listbox-is-selecting-many-items-even-in-selectionmode-single,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.7777777777777778,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,"Listbox is selecting many items, even in selectionmode = ""single""","I have encountered something very strange, simple WPF application

&lt;Window x:Class=""ListBoxSelection.MainWindow""
        xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
        xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
        Title=""MainWindow"" Height=""350"" Width=""525""&gt;
    &lt;Grid&gt;
        &lt;ListBox ItemsSource=""{Binding Path=Strings}"" SelectionMode=""Single""/&gt;
    &lt;/Grid&gt;
&lt;/Window&gt;


with code behind

public class ViewModel
{
    public List&lt;string&gt; Strings { get; set; }

    public ViewModel ()
    {
        Strings = new List&lt;string&gt; ();
        Strings.Add (""A"");
        // add many items ...
        Strings.Add (""A"");
    }
}

/// &lt;summary&gt;
/// Interaction logic for MainWindow.xaml
/// &lt;/summary&gt;
public partial class MainWindow : Window
{
    public MainWindow ()
    {
        InitializeComponent ();

        DataContext = new ViewModel ();
    }
}


and when I click on a single item,



if I continue clicking items, they just aggregate. Clicking an already selected item does nothing. Scratching my head, I have databound lists to ListBoxes before, and have never seen this before. Running Win7 (64), VS2010, behaviour presents with .Net 3.5, .Net 3.5 Client Profile, .Net 4, and .Net 4 Client Profile.

Arg, I should mention I am expecting normal, default, single-select behaviour.
","I encountered this problem as well--as others have noted, .NET handles strings in a curious manner to improve memory management.  

My immediate workaround was to create a UniqueListItem class to be used in place of the strings I was planning to add to the listbox.  

class UniqueListItemObject
{
    private string _text;
    public string Text { get { return _text; } set { _text = value; } }

    public UniqueListItemObject(string input)
    {
        Text = input;
    }
    public UniqueListItemObject()
    {
        Text = string.Empty;
    }

    public override string ToString()
    {
        return Text;
    }
}


Because each instance of this object will get its own memory location, adding instances of this object to a listbox control instead of adding strings will result in unique selections, even if the strings displayed in the listbox are identical.

        yourListBox.Items.Add(new UniqueListItemObject(yourStringHere);


I can't say if this is the best solution (that depends on your project's requirements) but hopefully someone finds this helpful.
"
5645,5645,8949,Is my interval training routine effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
",DigiKev,https://bicycles.stackexchange.com/users/3323,"Whether an interval training is effective or not depends mostly on your particulars relative to the interval. Heart rate is only a very inexact measure of effort, but you seem to be roughly in the ballpark. However, such quick switching between on/off interval state does not generally produce interval-like results and should be viewed as a single 30-minute interval at the average power of this period. 

A better gauge of interval quality would be this: how long can you keep up the effort? A more typical interval training might be e.g. 6-7 times 3-8 minute efforts, with 2-5 minute rests, at such intensity that you simply cannot complete another interval round.

A goal of ""strength and speed"" on the mountain is unspecific enough that you can be sure it's being helped somewhat, and in some way, by the intervals. However, it's counterproductive to do interval training and weight training both in one session. If you are still in shape to do weight training after your intervals, it means the intervals weren't done hard enough. Do intervals and weights on alternate days.
",ttarchala,https://bicycles.stackexchange.com/users/130,http://bicycles.stackexchange.com/questions/7801/is-my-interval-training-routine-effective-for-mountain-bike-training,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.6666666666666666,1.0,0.8888888888888888,Is my interval training effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
","Whether an interval training is effective or not depends mostly on your particulars relative to the interval. Heart rate is only a very inexact measure of effort, but you seem to be roughly in the ballpark. However, such quick switching between on/off interval state does not generally produce interval-like results and should be viewed as a single 30-minute interval at the average power of this period. 

A better gauge of interval quality would be this: how long can you keep up the effort? A more typical interval training might be e.g. 6-7 times 3-8 minute efforts, with 2-5 minute rests, at such intensity that you simply cannot complete another interval round.

A goal of ""strength and speed"" on the mountain is unspecific enough that you can be sure it's being helped somewhat, and in some way, by the intervals. However, it's counterproductive to do interval training and weight training both in one session. If you are still in shape to do weight training after your intervals, it means the intervals weren't done hard enough. Do intervals and weights on alternate days.
"
4488,4488,7117,How do I deal with a slow and undedicated colleague in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
",HOT,https://programmers.stackexchange.com/users/34092,"Keep records. Document every error you get when communicating with his side, when you asked him to fix and when (if ever) he did it. That is the only way I know of dealing with this situation. So when your manager comes to you asking why things are not progressing you can clearly show without being seen as a whiner or a bad colleague.
",OtÃ¡vio DÃ©cio,https://programmers.stackexchange.com/users/7380,http://programmers.stackexchange.com/questions/101528/how-do-i-deal-with-a-slow-and-undedicated-colleague-in-the-team,TECHNOLOGY,programmers.stackexchange.com,1.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.6666666666666666,0.0,1.0,How can I deal with a colleague who is slow-moving and lacks dedication in the team?,"I have been working on a new project. The project works like this: The end user can access a webapp using a link and he can add multiple systems on his network and manage that particular systems details. My part involves the front end and the webserver, which is done in python. My python actually communicates with another project which is entirely done in c &amp; c++. The c/c++ project is the main app which does all the functionality. My python sends the user request to it and displays the response from it to the user. 

I am very familiar with my work and I will finish it soon. Since that's not much work in it. And I am a person who loves to work. I spends most of the time in office and only go home when I feel sleepy.

The c/c++ app is managed by another colleague who has 5+ year experience and can do things much faster than me, but he never does it. May be he doesn't like to do it. His app crashes often when my python communicate with it or returns wrong values. It's full of bugs. Since my app depends on it, I am having a hard time building it. Instead of fixing the bugs, he asks me to slow down my work. He asks me to tell manager that my work needs a lot of time. He is asking me to fool the manager and even forcing me to work slowly like him.

During project meeting, when manager asks him about the bugs he says that he fixed everything and it works fine. Since he is my colleague, I couldn't tell anything to the manager. I obviously need to have a good relationship with my colleagues more than my manager, since most of the time we will be with our colleagues, not with the manager.

I am not able to tell the manager anything regarding this, since if manager asks him why, then he may think I complained about him to the manager. And he keeps on lying in the meeting. And since he fixes the bug slowly, it even slows down my work. Now I thought of working on the front-end part of my app  and finishing it off so that in the mean time he can make his project stable. Now he is asking me to tell the manager that my front end part require a lot of work and I may need more and more time, simply so that he can drag the project down. And the sad thing is our actual manager has gone to the US, so we have a temporary manager and this guy doesn't know about the project much, so the c,c++ just fools him.

Can anyone suggest me how I deal with this?
I wanted to finish off the project soon. How can I make him work even by maintaining a good relationship with him?

Responses to comments:


  If he's really deliberately misleading the company, you should report him to management.


I am new to this company and the other guy has been there for many years. And I have just started knowing my colleagues. If I directly go and complaint him, I don't think so I can make good relationship with my other colleagues. Even he has the power to mislead them. I am not telling he is a bad guy, he can do the work, but he is not doing it.


  Doesn't your company have any kind of bug tracking system ? 


Here actual bug tracking system isn't there. The company tries to finish off the project as soon as possible and gives it to the QA. And then fixes the bugs reported by QA. 


  This is why companies should give employees stock / options or some sort of ownership. That way you can literally tell the guy ""You are costing me monetary growth... don't you want to make money also?"".


The company has the stock options they have given me a 2500 share, mostly he too would have got some more.


  Seniority does deserve some benefit of a doubt. You really need to speak to him first and try to understand the problem. He may be out of his depth, you may be able to help him, there could easily be variables you are unaware of. It may be hard now, but you could easily make the situation a lot worse by jumping the gun. 


I even does it, first his app wasn't handling multiple requests at a time, he was using a queue to handle the requests I sent to him. I even suggested to him some of my ideas on it. He said he already had these ideas, and will be executing them. His explanations was: ""Everything require certain time to do and this is a project which may need two years to complete and we are asked to finish it in two months"". I used to have a hard time coding during first few weeks because of this bug. But now he fixed it. But he is using a single queue for a user requests and that is now slowing down the app, since it processes one request at a time.


  What is QA doing this whole time? Why aren't they reporting/confirming the status of the project(s)? 


The manager is the person who decides when to give to the QA. As of now it has not yet given to QA. He said we should give it by this month end. 
","Make records. Record every mistake you make when communicating with him, when you ask him to correct his mistake, and when he (if any) corrects his mistake. This is the only way I know to deal with this situation. So when your manager asks you why things are not going on, you can show it clearly, rather than being seen as a complainer or a bad colleague."
4665,4665,7390,"Was the Second Doctor's ""regeneration"" actually a regeneration?","I recently saw a mix up of all of the Doctors regeneration scenes.

When the second Doctor changes to the third (from Patrick Troughton to Jon Pertwee in ""The War Games, Part Ten"" (1969)), it is forced on him as punishment before being exiled to earth. The Doctor was not critically injured or dying. The transformation was the Time Lords doing.

Does this really count as one of the 12 regenerations? 
",Keo,https://scifi.stackexchange.com/users/16220,"Yep, it was his first regeneration
",L.J Rob,https://scifi.stackexchange.com/users/25111,http://scifi.stackexchange.com/questions/39036/was-the-second-doctors-regeneration-actually-a-regeneration,LIFE_ARTS,scifi.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.4444444444444444,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,0.0,0.0,0.0,1.0,"Is the second doctor's ""regeneration"" really regeneration?","I recently saw a mix up of all of the Doctors regeneration scenes.

When the second Doctor changes to the third (from Patrick Troughton to Jon Pertwee in ""The War Games, Part Ten"" (1969)), it is forced on him as punishment before being exiled to earth. The Doctor was not critically injured or dying. The transformation was the Time Lords doing.

Does this really count as one of the 12 regenerations? 
","Yes, this is his first rebirth"
2032,2032,3239,About the meaning of the names of f orbitals,"Our chemistry teacher encouraged us to study the history and naming of the orbitals on the web. (actually, our textbook did, but that's irrelevant to the problem) I easily could find the reason behind their naming, and what their names stood for. However, some sources stated that f as in f orbitals stands for fine, while others claimed it to be fundamental. Which of these two is correct? And why did scientists gave f orbitals that name? (as you're aware, they did it due to the f block elements' emission spectrum; my question is, what was the specification of their emission spectrum?) I'm sorry if the question looks stupid, but I can't figure it out myself.
",M.A.R.,https://chemistry.stackexchange.com/users/7448,"I would have to say ""f"" overwhelmingly stands for ""fundamental"" (not ""fine"").  

An early (1915) reference is ""Some Recent Discoveries in Spectrum Series"" Astrophysical Journal, vol. 41, p.323 


  Within each of these three systems there are, in general, four different types of series, known as ""principle"", ""sharp"" (second subordinate), ""diffuse"" (first subordinate), and ""fundamental"" (Bergmann).  These names are not always very appropriate; for instance the ""sharp"" series is often diffuse, the ""fundamental"" may be composed of the faintest lines in the spectrum, but this is not vital.


The fundamental series was discovered by Arno Bergmann in 1907, and is sometimes called the Bergmann series. It was named ""fundamental"" by William M. Hicks, I beleive in A Critical Study of Spectral Series. Part I: The Alkalies H and He (1911): ""F is the symbol for the new series (fundamental) as P.S.D. stand for those already known"" (page 57) and ""It was my first impression that this would be the same for all the alkalies and the .987 of the earlier discussion. It would be the basis of a fundamental series for each
element, and the letter F which has been attached to it had its origin in this idea."" (page 94).

The names existed before orbital theory.  There is no need to investigate f-block elements to observe excitations to f-orbitals.  Electrons of any elment can be excited to an f-orbital. In fact, Bergmann discovered the series in the sodium spectrum.  What was orginially known as the sharp series, were transition to s-orbitals, the primary series transitions to p-orbitals, etc. 

See The Origin of the s, p, d, f Orbital Labels for additional information. 
",DavePhD,https://chemistry.stackexchange.com/users/5160,http://chemistry.stackexchange.com/questions/21837/about-the-meaning-of-the-names-of-f-orbitals,SCIENCE,chemistry.stackexchange.com,0.6666666666666666,0.5,0.0,0.5,0.5,0.5,0.8333333333333334,0.6666666666666666,0.5,0.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,1.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,1.0,0.0,0.0,1.0,1.0,On the meaning of F orbital name,"Our chemistry teacher encourages us to learn the history and naming of tracks online. (in fact, our textbooks do, but it's not about the problem.) it's easy for me to find out why they are named and what their names represent. However, some sources say that f-as represents fines on the f-track, while others claim that this is fundamental. Which of these two is right? Why do scientists call the f orbital? As you know, they do this because of the emission spectrum of f-block element; my question is, what is the specification of their emission spectrum If the question looks stupid, I'm sorry, but I can't think of it myself.","I would have to say ""f"" overwhelmingly stands for ""fundamental"" (not ""fine"").  

An early (1915) reference is ""Some Recent Discoveries in Spectrum Series"" Astrophysical Journal, vol. 41, p.323 


  Within each of these three systems there are, in general, four different types of series, known as ""principle"", ""sharp"" (second subordinate), ""diffuse"" (first subordinate), and ""fundamental"" (Bergmann).  These names are not always very appropriate; for instance the ""sharp"" series is often diffuse, the ""fundamental"" may be composed of the faintest lines in the spectrum, but this is not vital.


The fundamental series was discovered by Arno Bergmann in 1907, and is sometimes called the Bergmann series. It was named ""fundamental"" by William M. Hicks, I beleive in A Critical Study of Spectral Series. Part I: The Alkalies H and He (1911): ""F is the symbol for the new series (fundamental) as P.S.D. stand for those already known"" (page 57) and ""It was my first impression that this would be the same for all the alkalies and the .987 of the earlier discussion. It would be the basis of a fundamental series for each
element, and the letter F which has been attached to it had its origin in this idea."" (page 94).

The names existed before orbital theory.  There is no need to investigate f-block elements to observe excitations to f-orbitals.  Electrons of any elment can be excited to an f-orbital. In fact, Bergmann discovered the series in the sodium spectrum.  What was orginially known as the sharp series, were transition to s-orbitals, the primary series transitions to p-orbitals, etc. 

See The Origin of the s, p, d, f Orbital Labels for additional information. 
"
2184,2184,3477,Why can't a Sefer Torah be written in Aramaic?,"
  In the Mishna, Megillah 1:8, Rabban Shimon ben Gamliel is quoted as having said that Greek is the only language, other than Hebrew, in which it is permissible to write sifrei Torah. Commenting on this, the Jerusalem Talmud (Megillah 71c) says that the sages checked and discovered that Greek is the only language into which it is possible to translate the Torah with its exact meaning.


Source: an answer to Translation to Greek

But why not Aramaic? I remember reading somewhere that it had ""sparks"" of holiness, the proof being that it is the language of the Gemara. It's also linguistically more similar to Hebrew than Greek, so it should be possible to get a good translation.
",Scimonster,https://judaism.stackexchange.com/users/5151,"Your question appears to be asking why it would not be kosher to use an Aramaic Torah scroll in lieu of a Hebrew one.  You may want to reword your question.  Throughout Jewish history and up until the present, Aramaic targumim have been recited in the synagogue alongside the traditional Hebrew Torah.  Currently the Jews of Yemen read from Targum Onkelos during the Torah reading.  However, the practice of solely reading from a scroll written in a language other than Hebrew, such as Aramaic or Greek, was never common practice.  There are many reasons for this, a few of which are given below.


The Talmud [Sotah 33] discusses praying in Aramaic instead of Hebrew and states that the angels do not understand Aramaic.  The message here is that Hebrew is preferable over Aramaic since it allows the person reciting it to have a closer connection to heaven.
This notion is further reinforced by the practice ×©× ×× ××§×¨× ×××× ×ª×¨××× [Berakhot 8a].  This is referring to the practice of twice reading the weekly Torah portion in Hebrew with the congregation, while reading once from the Targum.
There is a general concept in Rabbinic writings that Hebrew is the holy language in which the Torah was given to Moses on Mount Sinai.  Therefore, as a general rule we should be using Hebrew over any other language.

",Tim Biegeleisen,https://judaism.stackexchange.com/users/2889,http://judaism.stackexchange.com/questions/45330/why-cant-a-sefer-torah-be-written-in-aramaic,CULTURE,judaism.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Why can't the law of sever be written in Aramaic?,"
  In the Mishna, Megillah 1:8, Rabban Shimon ben Gamliel is quoted as having said that Greek is the only language, other than Hebrew, in which it is permissible to write sifrei Torah. Commenting on this, the Jerusalem Talmud (Megillah 71c) says that the sages checked and discovered that Greek is the only language into which it is possible to translate the Torah with its exact meaning.


Source: an answer to Translation to Greek

But why not Aramaic? I remember reading somewhere that it had ""sparks"" of holiness, the proof being that it is the language of the Gemara. It's also linguistically more similar to Hebrew than Greek, so it should be possible to get a good translation.
","Your question appears to be asking why it would not be kosher to use an Aramaic Torah scroll in lieu of a Hebrew one.  You may want to reword your question.  Throughout Jewish history and up until the present, Aramaic targumim have been recited in the synagogue alongside the traditional Hebrew Torah.  Currently the Jews of Yemen read from Targum Onkelos during the Torah reading.  However, the practice of solely reading from a scroll written in a language other than Hebrew, such as Aramaic or Greek, was never common practice.  There are many reasons for this, a few of which are given below.


The Talmud [Sotah 33] discusses praying in Aramaic instead of Hebrew and states that the angels do not understand Aramaic.  The message here is that Hebrew is preferable over Aramaic since it allows the person reciting it to have a closer connection to heaven.
This notion is further reinforced by the practice ×©× ×× ××§×¨× ×××× ×ª×¨××× [Berakhot 8a].  This is referring to the practice of twice reading the weekly Torah portion in Hebrew with the congregation, while reading once from the Targum.
There is a general concept in Rabbinic writings that Hebrew is the holy language in which the Torah was given to Moses on Mount Sinai.  Therefore, as a general rule we should be using Hebrew over any other language.

"
397,397,621,EBS volume on AWS,"I had an EBS volume of 30GB that was mounted as the rootfs for a ubuntu server. Due to space concerns I had to increase the size of the volume to 50. So I carried out the following steps:


  
  Take a snapshot of the EBS volume.
  Created a new EBS volume of 50GB.
  Restored the snapshot to the new volume.
  Power off my EC2 instance.
  Unmounted my old volume and mounted my new volume.
  


Every thing works fine. But when I do a df -h I get this:

Filesystem Size Used Avail Use% Mounted on
rootfs 30G 27G 1.1G 97% /
devtmpfs 1.9G 112K 1.9G 1% /dev
tmpfs 1.9G 0 1.9G 0% /dev/shm
/dev/xvde1 30G 27G 1.1G 97% /


And when I do fdisk -l I get this:

Disk /dev/xvde1: 53.7 GB, 53687091200 bytes.


Could some one help me with this?
",Adithya,https://stackoverflow.com/users/3488138,"I am no filesystem expert but your volume that you restored to is not formatted to utilize the 50 GB. In windows you need to expand the drive to utilize the full space of the larger Physical volume. You will need to find out the Linux command line version to make your xvde1 utilize the 50 GB. Ebs volumes are raw disks that need are not pre formatted.

!--------snapshot restored----------!------------raw blocks -------!

I will try to look into my onenote archive. I could of sworn that I documented this for one of my systems. Until then just look up expanding to larger ebs volume after snapshot restored. If I find it I will post it if not you need to search for it.
",SamMan,https://stackoverflow.com/users/2292245,http://stackoverflow.com/questions/22803687/ebs-volume-on-aws,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,EBS volume on AWS,"I had an EBS volume of 30GB that was mounted as the rootfs for a ubuntu server. Due to space concerns I had to increase the size of the volume to 50. So I carried out the following steps:


  
  Take a snapshot of the EBS volume.
  Created a new EBS volume of 50GB.
  Restored the snapshot to the new volume.
  Power off my EC2 instance.
  Unmounted my old volume and mounted my new volume.
  


Every thing works fine. But when I do a df -h I get this:

Filesystem Size Used Avail Use% Mounted on
rootfs 30G 27G 1.1G 97% /
devtmpfs 1.9G 112K 1.9G 1% /dev
tmpfs 1.9G 0 1.9G 0% /dev/shm
/dev/xvde1 30G 27G 1.1G 97% /


And when I do fdisk -l I get this:

Disk /dev/xvde1: 53.7 GB, 53687091200 bytes.


Could some one help me with this?
","I am no filesystem expert but your volume that you restored to is not formatted to utilize the 50 GB. In windows you need to expand the drive to utilize the full space of the larger Physical volume. You will need to find out the Linux command line version to make your xvde1 utilize the 50 GB. Ebs volumes are raw disks that need are not pre formatted.

!--------snapshot restored----------!------------raw blocks -------!

I will try to look into my onenote archive. I could of sworn that I documented this for one of my systems. Until then just look up expanding to larger ebs volume after snapshot restored. If I find it I will post it if not you need to search for it.
"
5418,5418,8603,Twisted pair cable twists and unwanted signals issue,"I am confused about one point I have read the following paragraph from the networking book.
âthe twists in the twisted pair cable are used to avoid the unwanted signals. For example one twist, one wire is closer to the noise source and the other is farther; in the next twist the reverse is true. Twisting makes its probable that both wires are equally affected by the unwanted signal. This means that the receiver which calculate the difference between the two receives no unwanted signal.â

Now ok I understood the purpose of twists but I am confused about how receiver will calculate the difference when it will receive the signal?. How unwanted signal will be eliminated ? 
Another thing that I want to make clear is ,  I am beginner please provide such an answer that can be understood.
",Zia ur Rahman,https://serverfault.com/users/44270,"Wikipedia has a good article on twisted pair (excerpt below):


  In balanced pair operation, the two
  wires carry equal and opposite signals
  and the destination detects the
  difference between the two. This is
  known as differential mode
  transmission. Noise sources introduce
  signals into the wires by coupling of
  electric or magnetic fields and tend
  to couple to both wires equally. The
  noise thus produces a common-mode
  signal which is cancelled at the
  receiver when the difference signal is
  taken. This method starts to fail when
  the noise source is close to the
  signal wires; the closer wire will
  couple with the noise more strongly
  and the common-mode rejection of the
  receiver will fail to eliminate it.
  This problem is especially apparent in
  telecommunication cables where pairs
  in the same cable lie next to each
  other for many miles. One pair can
  induce crosstalk in another and it is
  additive along the length of the
  cable. Twisting the pairs counters
  this effect as on each half twist the
  wire nearest to the noise-source is
  exchanged. Providing the interfering
  source remains uniform, or nearly so,
  over the distance of a single twist,
  the induced noise will remain
  common-mode. Differential signaling
  also reduces electromagnetic radiation
  from the cable, along with the
  associated attenuation allowing for
  greater distance between exchanges.

",tegbains,https://serverfault.com/users/7429,http://serverfault.com/questions/135421,TECHNOLOGY,serverfault.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Twisted twisted twisted pair cables and unwanted signal problems,"I am confused about one point I have read the following paragraph from the networking book.
âthe twists in the twisted pair cable are used to avoid the unwanted signals. For example one twist, one wire is closer to the noise source and the other is farther; in the next twist the reverse is true. Twisting makes its probable that both wires are equally affected by the unwanted signal. This means that the receiver which calculate the difference between the two receives no unwanted signal.â

Now ok I understood the purpose of twists but I am confused about how receiver will calculate the difference when it will receive the signal?. How unwanted signal will be eliminated ? 
Another thing that I want to make clear is ,  I am beginner please provide such an answer that can be understood.
","Wikipedia has a good article on twisted pair (excerpt below):


  In balanced pair operation, the two
  wires carry equal and opposite signals
  and the destination detects the
  difference between the two. This is
  known as differential mode
  transmission. Noise sources introduce
  signals into the wires by coupling of
  electric or magnetic fields and tend
  to couple to both wires equally. The
  noise thus produces a common-mode
  signal which is cancelled at the
  receiver when the difference signal is
  taken. This method starts to fail when
  the noise source is close to the
  signal wires; the closer wire will
  couple with the noise more strongly
  and the common-mode rejection of the
  receiver will fail to eliminate it.
  This problem is especially apparent in
  telecommunication cables where pairs
  in the same cable lie next to each
  other for many miles. One pair can
  induce crosstalk in another and it is
  additive along the length of the
  cable. Twisting the pairs counters
  this effect as on each half twist the
  wire nearest to the noise-source is
  exchanged. Providing the interfering
  source remains uniform, or nearly so,
  over the distance of a single twist,
  the induced noise will remain
  common-mode. Differential signaling
  also reduces electromagnetic radiation
  from the cable, along with the
  associated attenuation allowing for
  greater distance between exchanges.

"
4120,4120,6574,What does âbupkeâ mean?,"There was the following passage in the New Yorker's (August 27) article titled, âA scandal at the C.I.A. May be.â :


  In January I (David Shafer, novelist) filed a Freedom of Information Act request with the C.I.A., asking for any information relating to my grandfather and Thomas Whittemore and the events of June 1950. They took two months to give me bupkes. But to give me bupkes, they were required to invoke a FOIA exemption, and the exemption that C.I.A. involved were (b)(3), which means the records are protected by another federal statute, and (b)(1) ---


Though I was unable to find the definition of âbupkeâ in OED (10th ed.), OALD (2000), and Collins Cobuild (4th ed.) at hand, I happened to find its definition at bageldrive.com, which says âbupkeâ is;


  A mini-bagel deliciously baked to perfection with fully functional USB 2.0 flash memory and a shmeer. Itâs the worldâs first electronic bagel. The Bagel Drive is ideal for storing files, photos, video, music and all of your digital tchochkes.ãThe site also shows photos of USB attached to plastic bagel models.


What does bupke mean? Is it a flash memory in a bagel shape as described in bagldrive com.? Does it pass as the generic term of flash memory? 

Beside, I wonder why CIA takes bother of using such a funky shape of all flash memories to provide data to the requester.
",Yoichi Oishi,https://english.stackexchange.com/users/3119,"Is the question a joke?

If not, google bupke (or bupkis).  You will find descriptions such as the one on this page:


  bupkis (also bupkes, bupkus, bubkis, bubkes): emphatically nothing, as in He isn't worth bupkis (indeterminate, either 'beans' or 'goat droppings', possibly of Slavic, Vlach, or Greek origin; cf. Polish bobki 'animal droppings')[2] (MW, OED)


I'm guessing that what you cite is a description of a hard drive that looks something like a bupke.
",Drew,https://english.stackexchange.com/users/51214,http://english.stackexchange.com/questions/193855/what-does-bupke-mean,CULTURE,english.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,"What does ""bupke"" mean?","There was the following passage in the New Yorker's (August 27) article titled, âA scandal at the C.I.A. May be.â :


  In January I (David Shafer, novelist) filed a Freedom of Information Act request with the C.I.A., asking for any information relating to my grandfather and Thomas Whittemore and the events of June 1950. They took two months to give me bupkes. But to give me bupkes, they were required to invoke a FOIA exemption, and the exemption that C.I.A. involved were (b)(3), which means the records are protected by another federal statute, and (b)(1) ---


Though I was unable to find the definition of âbupkeâ in OED (10th ed.), OALD (2000), and Collins Cobuild (4th ed.) at hand, I happened to find its definition at bageldrive.com, which says âbupkeâ is;


  A mini-bagel deliciously baked to perfection with fully functional USB 2.0 flash memory and a shmeer. Itâs the worldâs first electronic bagel. The Bagel Drive is ideal for storing files, photos, video, music and all of your digital tchochkes.ãThe site also shows photos of USB attached to plastic bagel models.


What does bupke mean? Is it a flash memory in a bagel shape as described in bagldrive com.? Does it pass as the generic term of flash memory? 

Beside, I wonder why CIA takes bother of using such a funky shape of all flash memories to provide data to the requester.
","Is the question a joke?

If not, google bupke (or bupkis).  You will find descriptions such as the one on this page:


  bupkis (also bupkes, bupkus, bubkis, bubkes): emphatically nothing, as in He isn't worth bupkis (indeterminate, either 'beans' or 'goat droppings', possibly of Slavic, Vlach, or Greek origin; cf. Polish bobki 'animal droppings')[2] (MW, OED)


I'm guessing that what you cite is a description of a hard drive that looks something like a bupke.
"
1931,1931,3078,How to make a figure span on two columns in a scientific paper?,"If I just try to set the figure's size to 0.9\textwidth my figure will just end up on the right column, sized to be two-columns wide.

Has anyone done this before?
",levesque,https://tex.stackexchange.com/users/10,"From the TUG faq: use the starred versions figure* and table*. Unfortunately, they're somewhat limited in positioning.

Also, the same solution applies to equations. Just include them in a figure* environment. But I don't recommend doing this: it will look ugly and confusing. For an example, see this paper. (sorry, I couldn't find an example in arXiv)
",Mateus AraÃºjo,https://tex.stackexchange.com/users/1035,http://tex.stackexchange.com/questions/3173/how-to-make-a-figure-span-on-two-columns-in-a-scientific-paper,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.5,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.8888888888888888,"In scientific papers, how to build a digital span on two columns?","If I just try to set the size of my graph to 0.9 \ textwidth, my graph will end up in the right column, which is two columns wide.","From the TUG faq: use the starred versions figure* and table*. Unfortunately, they're somewhat limited in positioning.

Also, the same solution applies to equations. Just include them in a figure* environment. But I don't recommend doing this: it will look ugly and confusing. For an example, see this paper. (sorry, I couldn't find an example in arXiv)
"
2808,2808,4473,Tools to run a background process command line in windows?,"In linux we just need to append a &amp; and that's all.

What for windows?
",vps,https://serverfault.com/users/31877,"start /min cmd /c mycommand


If you want to run other jobs in the same shell you have to use powershell background jobs

If you want to hide the command window save a vbscript file with the following code(replacing the commands as needed) :

Set WshShell = CreateObject(""WScript.Shell"") 
WshShell.Run chr(34) &amp; ""C:\mycommand_path\mycommand and args"" &amp; Chr(34), 0
Set WshShell = Nothing


create a shortcut to this file and run this from the shell directly by double clicking it.  It sounds like what you are really after is job control.  Install the subsystem for unix to get the bash or ksh prompt and execute it from there if you want job control however it would not suprise me if running it as a background job causes issues.  You will probably want to run it as a background process instead.
",Jim B,https://serverfault.com/users/3528,http://serverfault.com/questions/121979,TECHNOLOGY,serverfault.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,A tool for running the background process command line in windows?,"In Linux, we only need to attach one & amp.","start /min cmd /c mycommand


If you want to run other jobs in the same shell you have to use powershell background jobs

If you want to hide the command window save a vbscript file with the following code(replacing the commands as needed) :

Set WshShell = CreateObject(""WScript.Shell"") 
WshShell.Run chr(34) &amp; ""C:\mycommand_path\mycommand and args"" &amp; Chr(34), 0
Set WshShell = Nothing


create a shortcut to this file and run this from the shell directly by double clicking it.  It sounds like what you are really after is job control.  Install the subsystem for unix to get the bash or ksh prompt and execute it from there if you want job control however it would not suprise me if running it as a background job causes issues.  You will probably want to run it as a background process instead.
"
3123,3123,4976,"Full height & width, fixed header, full content height with CSS","I have been searching for this on SO, but I just could not find something exactly similar.
What I am trying to achieve is to have a page, that is full in height and in width, but does have a fixed header. The content height needs to be the remaining area left, but that area needs to have a height of 100%, most of the html code found on SO is just using height: auto. Basically I want to do this so that I can style it: adding border etc. Here's the code so far:

&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Test&lt;/title&gt;
    &lt;style type=""text/css""&gt;
    body, html {
    height:100%;
    }

    body {
    margin:0;
    padding:0;
    }

    #header{
    height:50px; 
    background:green;
    width:100%; 
    }

    #wrapper {
    background:blue;
    position:relative;
    min-height:100%;
    height:auto !important;
    height:100%;
    }

    #content {
        margin: 10px;
        background-color: black;
        height: 100%;
        width: 100%;
border: 3px dashed gray;
    }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id=""wrapper""&gt;
    &lt;div id=""header""&gt;header&lt;/div&gt;
    &lt;div id=""content""&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;

",dandoen,https://stackoverflow.com/users/444146,"See: http://jsbin.com/agiyer

Note that if the content is too tall to fit inside #content, it will simply be hidden.

HTML:

&lt;div id=""header""&gt;header&lt;/div&gt;
&lt;div id=""content""&gt;content&lt;/div&gt;


CSS:

#header {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 50px; 
    background: green
}
#content {
    position: absolute;
    top: 50px;
    left: 0;
    bottom: 0;
    right: 0;
    border: 3px dashed gray;
    background: #ccc
}

",thirtydot,https://stackoverflow.com/users/405015,http://stackoverflow.com/questions/7104216/full-height-width-fixed-header-full-content-height-with-css,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,"Full height and full width, fixed header, full content height with CSS","I have been searching for this on SO, but I just could not find something exactly similar.
What I am trying to achieve is to have a page, that is full in height and in width, but does have a fixed header. The content height needs to be the remaining area left, but that area needs to have a height of 100%, most of the html code found on SO is just using height: auto. Basically I want to do this so that I can style it: adding border etc. Here's the code so far:

&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Test&lt;/title&gt;
    &lt;style type=""text/css""&gt;
    body, html {
    height:100%;
    }

    body {
    margin:0;
    padding:0;
    }

    #header{
    height:50px; 
    background:green;
    width:100%; 
    }

    #wrapper {
    background:blue;
    position:relative;
    min-height:100%;
    height:auto !important;
    height:100%;
    }

    #content {
        margin: 10px;
        background-color: black;
        height: 100%;
        width: 100%;
border: 3px dashed gray;
    }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id=""wrapper""&gt;
    &lt;div id=""header""&gt;header&lt;/div&gt;
    &lt;div id=""content""&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;

","See: http://jsbin.com/agiyer

Note that if the content is too tall to fit inside #content, it will simply be hidden.

HTML:

&lt;div id=""header""&gt;header&lt;/div&gt;
&lt;div id=""content""&gt;content&lt;/div&gt;


CSS:

#header {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 50px; 
    background: green
}
#content {
    position: absolute;
    top: 50px;
    left: 0;
    bottom: 0;
    right: 0;
    border: 3px dashed gray;
    background: #ccc
}

"
3329,3329,5314,Using deep learning for time series prediction,"I'm new in area of deep learning and for me first step was to read interesting articles from deeplearning.net site. In papers about deep learning, Hinton and others mostly talk about applying it to image problems. Can someone try to answer me can it be applied to problem of predicting time series values (financial, internet traffic,...) and what are important things that I should focus if it is possible?
",Vedran,https://stats.stackexchange.com/users/29672,"Alex Graves' Generating sequences with Recurrent Neural Networks uses recurrent networks and Long short term memory Cells to predict text and do handwriting synthesis.

Andrej Karpathy has written a blog about generating character level sequences from scratch. He uses RNNs in his tutorial.

For more examples, you should look at-
Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.
",Azrael,https://stats.stackexchange.com/users/64423,http://stats.stackexchange.com/questions/68662/using-deep-learning-for-time-series-prediction,SCIENCE,stats.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.5,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,0.8333333333333334,0.6666666666666666,0.5,0.6666666666666666,1.0,0.8,0.5,0.0,0.5,0.8333333333333334,Time series prediction using deep learning,"I am a novice in the field of deep learning. For me, the first step is to read interesting articles from the deep learning.net website. In the paper on deep learning, Hinton and others mainly discuss how to apply it to image problems. Can someone try to answer this question? It can be used to predict time series values (finance, network traffic,...) Is that a problem? If possible, what important things should I focus on?","Alex Graves' Generating sequences with Recurrent Neural Networks uses recurrent networks and Long short term memory Cells to predict text and do handwriting synthesis.

Andrej Karpathy has written a blog about generating character level sequences from scratch. He uses RNNs in his tutorial.

For more examples, you should look at-
Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.
"
5627,5627,8923,Two different analytic curves cannot intersect in infinitely many points,"A curve in Euclidean space $\mathbb{R}^n$, $n \geq 2$ is $analytic$ if the coordinates of its points $x= x_{1},...,x_{n}$ can be expressed as analytic functions of a real parameter $x_{i}=x_{i}(t)$, $i=1,...,n$ and $\alpha \leq t \leq \beta$ and the derivatives $x'(t_{0})$ do not simultaneously vanish for any $t_{0} \in [\alpha, \beta]$.
I search for a proof of the following fact:

If the set of intersection points of two analytic curves is infinite, then these curves coincide.

Can we prove the same as above if we relax the condition that the coordinates are analytic to the condition that the coordinates belong to the class $C^{\infty}$?

Edit: Thanks to below remark by Ramiro, to obtain the above implication, we have to assume that any two curves $K_{1}, K_{2}$ as in the question are such that $K_{1} \cap K_{2}$ is not another analytic curve.

2nd edit: As suggested Peter, we can reformulate our question as follows:
   Consider two immersed curves which are parameterized real analytically on compact intervals. If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
",Grzegorz Tomkowicz,https://mathoverflow.net/users/31376,"Let $f\colon [0,1]\to \mathbf R^n$ and $g\colon[0,1]\to\mathbf R^n$ parametrize your curves. The set $C$ of $t\in[0,1]$ such that there exists $s\in[0,1]$ with $f(t)=g(s)$ is a closed subset of $[0,1]$. More importantly, it is definable in the sense of model theory in the language âÂ called $\mathbf R_{\text{an}}$ â consisting of polynomial functions and so called restricted analytic functions, namely analytic functions defined over compact subsets of $\mathbf R^m$.

It is an important theorem (Gabrielov; Denef and van den Dries) that $\mathbf R_{\text{an}}$ is $o$-minimal. This means that definable subsets of the real line are finite unions of intervals. 

From there, one should be able to analyse the situation further when the coincidence set is infinite. I would conjecture that it can only be the union of one or two intervals. Ramiro gave an example with one interval, though more complicated examples are possible, e.g., of the form $s\mapsto F(u(s))$, $s\mapsto F(v(s))$, where $u,v\colon[0,1]\to\mathbf R$ are analytic and $F\colon\mathbf R\to\mathbf R^n$ is a fixed curve.  In particular, the set is a union of two intervals if $F$ is a parameterization of a circle and $u$ and $v$ are suitably chosen so as to draw two arcs which overlap twice.
",ACL,https://mathoverflow.net/users/10696,http://mathoverflow.net/questions/121602,SCIENCE,mathoverflow.net,0.6666666666666666,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.8888888888888888,Two different analytic curves cannot intersect at infinity,"A curve in Euclidean space $\mathbb{R}^n$, $n \geq 2$ is $analytic$ if the coordinates of its points $x= x_{1},...,x_{n}$ can be expressed as analytic functions of a real parameter $x_{i}=x_{i}(t)$, $i=1,...,n$ and $\alpha \leq t \leq \beta$ and the derivatives $x'(t_{0})$ do not simultaneously vanish for any $t_{0} \in [\alpha, \beta]$.
I search for a proof of the following fact:

If the set of intersection points of two analytic curves is infinite, then these curves coincide.

Can we prove the same as above if we relax the condition that the coordinates are analytic to the condition that the coordinates belong to the class $C^{\infty}$?

Edit: Thanks to below remark by Ramiro, to obtain the above implication, we have to assume that any two curves $K_{1}, K_{2}$ as in the question are such that $K_{1} \cap K_{2}$ is not another analytic curve.

2nd edit: As suggested Peter, we can reformulate our question as follows:
   Consider two immersed curves which are parameterized real analytically on compact intervals. If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
","Let $f\colon [0,1]\to \mathbf R^n$ and $g\colon[0,1]\to\mathbf R^n$ parametrize your curves. The set $C$ of $t\in[0,1]$ such that there exists $s\in[0,1]$ with $f(t)=g(s)$ is a closed subset of $[0,1]$. More importantly, it is definable in the sense of model theory in the language âÂ called $\mathbf R_{\text{an}}$ â consisting of polynomial functions and so called restricted analytic functions, namely analytic functions defined over compact subsets of $\mathbf R^m$.

It is an important theorem (Gabrielov; Denef and van den Dries) that $\mathbf R_{\text{an}}$ is $o$-minimal. This means that definable subsets of the real line are finite unions of intervals. 

From there, one should be able to analyse the situation further when the coincidence set is infinite. I would conjecture that it can only be the union of one or two intervals. Ramiro gave an example with one interval, though more complicated examples are possible, e.g., of the form $s\mapsto F(u(s))$, $s\mapsto F(v(s))$, where $u,v\colon[0,1]\to\mathbf R$ are analytic and $F\colon\mathbf R\to\mathbf R^n$ is a fixed curve.  In particular, the set is a union of two intervals if $F$ is a parameterization of a circle and $u$ and $v$ are suitably chosen so as to draw two arcs which overlap twice.
"
3284,3284,5237,"SQL server moved, now can't use as linked server","So I have a SQL server database that was controlled by an outside vendor.  It is hosted remotely.  Then he needed to move the server to a new host.  Now, I'm able to connect to the server manually from SSMS and I can add it as a linked server, but I can't USE it as a linked server, or even browse the servers catalogs.

My instance is 2000, and I assume the remote server is 2008 or 2008 R2.

When I try to use the server (try to update a stored proc that points to the linked server) I get the following error: 

Trying to browse the linked server's catalogs from SSMS throws this:


  Failed to retrieve data for this request.
  (Microsoft.SqlServer.Management.Sdk.Sfc)
  
  [DBNETLIB][ConnectionOpen (Connect()).]SQL Server does not exist or
  access denied. (Microsoft SQL Server, Error: 17)


A friend suggested I run Exec sys.sp_change_users_login 'Report', but it turns up no orphaned records, and anyway, I can login using the credentials, so that doesn't look like the problem.

EDIT: Can't connect at all with IP, but hostname connects then gives above error.  HUH?
",MAW74656,https://dba.stackexchange.com/users/1107,"I'm assuming that you are using a ""sql server login"" for the vendor's server, and you are using that when creating the linked server. 

When you use a linked server, a query running on your server connects to the vendor's server. If a firewall blocks your local server from connecting to the vendor's server, your connection attempt will fail. 

If connecting directly from your workstation to the vendor's server you go through a different firewall or no firewall, then the connection may succeed.

This scenario matches the behavior you describe. My usual tests would be:
1. Can I ping from my server to the vendor's server? Both by IP and by hostname? ping usually gets through firewalls.
2. Can I connect using SSMS from my server (using an RDP session) to the vendor's server? Both by IP and by hostname? 

If you can ping OK but not connect with SSMS, this usually indicates that the ports for SQL Server probably need to be opened on the firewall.

In short, check all of the firewalls involved. That would include any software firewall on your server or on the vendor's server, or any hardware firewall between them. 

In these situations, ping and traceroute are your friends. Ping and traceroute may help you locate the IP of the router that doesn't send your packets on to the vendor's server.
",darin strait,https://dba.stackexchange.com/users/6823,http://dba.stackexchange.com/questions/24188/sql-server-moved-now-cant-use-as-linked-server,TECHNOLOGY,dba.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,SQL server has been moved and cannot be used as a linked server at this time,"So I have a SQL server database that was controlled by an outside vendor.  It is hosted remotely.  Then he needed to move the server to a new host.  Now, I'm able to connect to the server manually from SSMS and I can add it as a linked server, but I can't USE it as a linked server, or even browse the servers catalogs.

My instance is 2000, and I assume the remote server is 2008 or 2008 R2.

When I try to use the server (try to update a stored proc that points to the linked server) I get the following error: 

Trying to browse the linked server's catalogs from SSMS throws this:


  Failed to retrieve data for this request.
  (Microsoft.SqlServer.Management.Sdk.Sfc)
  
  [DBNETLIB][ConnectionOpen (Connect()).]SQL Server does not exist or
  access denied. (Microsoft SQL Server, Error: 17)


A friend suggested I run Exec sys.sp_change_users_login 'Report', but it turns up no orphaned records, and anyway, I can login using the credentials, so that doesn't look like the problem.

EDIT: Can't connect at all with IP, but hostname connects then gives above error.  HUH?
","I'm assuming that you are using a ""sql server login"" for the vendor's server, and you are using that when creating the linked server. 

When you use a linked server, a query running on your server connects to the vendor's server. If a firewall blocks your local server from connecting to the vendor's server, your connection attempt will fail. 

If connecting directly from your workstation to the vendor's server you go through a different firewall or no firewall, then the connection may succeed.

This scenario matches the behavior you describe. My usual tests would be:
1. Can I ping from my server to the vendor's server? Both by IP and by hostname? ping usually gets through firewalls.
2. Can I connect using SSMS from my server (using an RDP session) to the vendor's server? Both by IP and by hostname? 

If you can ping OK but not connect with SSMS, this usually indicates that the ports for SQL Server probably need to be opened on the firewall.

In short, check all of the firewalls involved. That would include any software firewall on your server or on the vendor's server, or any hardware firewall between them. 

In these situations, ping and traceroute are your friends. Ping and traceroute may help you locate the IP of the router that doesn't send your packets on to the vendor's server.
"
1771,1771,2813,False positive Apache version in scanner results on Centos,"Recently I need to care a lot of false positive vulnerabilities in scanner results on Apache version.
Example of false positive vulnerability:

Apache 2.2 &lt; 2.2.16 Multiple Vulnerabilities


Our customers run scanners and they check Apache version related to the official Apache version numbering.

We use Centos, and the Apache version numbering is different from the official Apache version numbering.

For example now we install httpd-2.2.15-26.el6.centos.x86_64 and it includes all security patches released by Apache in recent versions.

The Centos Apache version numbering relies on the RedHat Apache version numbering and they do not change the base number (httpd-2.2.15) each update.
But scanners do not âunderstandâ this and check that 2.2.15 &lt; 2.2.16.

Can you point me to the good document that explains the RedHat Apache version numbering?

Do you know if exist scanner that âunderstandâ the RedHat Apache version numbering?
",Michael,https://security.stackexchange.com/users/24842,"What you're experiencing is a common problem.  Vulnerability scanners that rely upon service banners do not deal with vendors like Red Hat which backport security updates.  They are also prone to making assumptions about configuration that lead to false positives.

You may be able to improve the accuracy of the scan by running an credentialed scan.  If your scanner supports it, you can specify account credentials that it will use to log in and look at ""internal"" information.  For example, it can use 'rpm' to determine which actual Apache package is installed, and base its verdict upon that rather than the banner that the service prints to external scanners.  Such a scanner should have access to an up-to-date database that will tell it what the real issues are.

If your scanner won't do it, then the usual solution is to do it yourself.  You would need to look up whether you're running the newest version.  For example, @Rook points out that there are Apache vulnerabilities newer than the package you reference.  Looking at those vulnerabilities, you can pull the CVE ID and look it up in Red Hat's CVE Database. For example, their entry for CVE-2013-1862 points you to the errata RHSA-2013:0815 which says that httpd-2.2.15-28 contains fixes for that CVE.  It also points out that there's a newer RHBA release, so there's a newer package with bug (but not security) fixes.  Repeat that process for any other CVEs that you're concerned with and you can make an educated decision about whether you're patched despite what the banner says.  If the CentOS package is a direct correlation to the RHEL package, you should be fine - but the RHEL package was announced on 5/13, so I don't know how @Rook's cited 3/2 release date jibes with that.

(The shortest version, BTW, is ""yeah, this stuff is a known PITA."")
",gowenfawr,https://security.stackexchange.com/users/3365,http://security.stackexchange.com/questions/47711/false-positive-apache-version-in-scanner-results-on-centos,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Wrong positive Apache version in scanner results on CentOS,"Recently I need to care a lot of false positive vulnerabilities in scanner results on Apache version.
Example of false positive vulnerability:

Apache 2.2 &lt; 2.2.16 Multiple Vulnerabilities


Our customers run scanners and they check Apache version related to the official Apache version numbering.

We use Centos, and the Apache version numbering is different from the official Apache version numbering.

For example now we install httpd-2.2.15-26.el6.centos.x86_64 and it includes all security patches released by Apache in recent versions.

The Centos Apache version numbering relies on the RedHat Apache version numbering and they do not change the base number (httpd-2.2.15) each update.
But scanners do not âunderstandâ this and check that 2.2.15 &lt; 2.2.16.

Can you point me to the good document that explains the RedHat Apache version numbering?

Do you know if exist scanner that âunderstandâ the RedHat Apache version numbering?
","What you're experiencing is a common problem.  Vulnerability scanners that rely upon service banners do not deal with vendors like Red Hat which backport security updates.  They are also prone to making assumptions about configuration that lead to false positives.

You may be able to improve the accuracy of the scan by running an credentialed scan.  If your scanner supports it, you can specify account credentials that it will use to log in and look at ""internal"" information.  For example, it can use 'rpm' to determine which actual Apache package is installed, and base its verdict upon that rather than the banner that the service prints to external scanners.  Such a scanner should have access to an up-to-date database that will tell it what the real issues are.

If your scanner won't do it, then the usual solution is to do it yourself.  You would need to look up whether you're running the newest version.  For example, @Rook points out that there are Apache vulnerabilities newer than the package you reference.  Looking at those vulnerabilities, you can pull the CVE ID and look it up in Red Hat's CVE Database. For example, their entry for CVE-2013-1862 points you to the errata RHSA-2013:0815 which says that httpd-2.2.15-28 contains fixes for that CVE.  It also points out that there's a newer RHBA release, so there's a newer package with bug (but not security) fixes.  Repeat that process for any other CVEs that you're concerned with and you can make an educated decision about whether you're patched despite what the banner says.  If the CentOS package is a direct correlation to the RHEL package, you should be fine - but the RHEL package was announced on 5/13, so I don't know how @Rook's cited 3/2 release date jibes with that.

(The shortest version, BTW, is ""yeah, this stuff is a known PITA."")
"
437,437,677,PHP and MySQL calendar issue,"I'm writing trying to build a calendar right from scratch. I'm using the function written by David Walsh (see link) and it's great. 
He does a query for each day's cell.
But, I'm afraid that when the script's gonna have to run 30 queries in each render, it's gonna be sloooow. 

So, I was trying to think in another logic, for example, make a big query from X date to Y date at the begining of the script and then, at each day, check if that particular day has an event in the previous query. But I have no idea of how to do this...
So, if anyone can help, please shout!

Thanks.
",fedeisas,https://stackoverflow.com/users/227927,"Instead of

  /* keep going with days.... */ 
  for($list_day = 1; $list_day &lt;= $days_in_month; $list_day++):
      $calendar.= '&lt;td class=""calendar-day""&gt;';
      /* add in the day number */ 
      $calendar.= '&lt;div class=""day-number""&gt;'.$list_day.'&lt;/div&gt;';

      /** QUERY THE DATABASE FOR AN ENTRY FOR THIS DAY !!  
          IF MATCHES FOUND, PRINT THEM !! **/ 

      $calendar.= str_repeat('&lt;p&gt;&amp;nbsp;&lt;/p&gt;',2);
      $calendar.= '&lt;/td&gt;';
      if($running_day == 6):
          $calendar.= '&lt;/tr&gt;';
          if(($day_counter+1) != $days_in_month):
              $calendar.= '&lt;tr class=""calendar-row""&gt;';
          endif;
          $running_day = -1;
          $days_in_this_week = 0;
      endif;
      $days_in_this_week++; $running_day++; $day_counter++;
  endfor;


do

   /** QUERY THE DATABASE FOR AN ENTRY FOR THE PERIOD !!  
          IF MATCHES FOUND, STORE THEM !! **/ 
  $entries = getEntriesFromDB($month,$year);

  /* keep going with days.... */ 
  for($list_day = 1; $list_day &lt;= $days_in_month; $list_day++):
      $calendar.= '&lt;td class=""calendar-day""&gt;';
      /* add in the day number */ 
      $calendar.= '&lt;div class=""day-number""&gt;'.$list_day.'&lt;/div&gt;';
      if ($entries[$list_day]):
          /** ADD THE ENTRIES FOR THE DAY!! **/
      endif;
      $calendar.= str_repeat('&lt;p&gt;&amp;nbsp;&lt;/p&gt;',2);
      $calendar.= '&lt;/td&gt;';
      if($running_day == 6):
          $calendar.= '&lt;/tr&gt;';
          if(($day_counter+1) != $days_in_month):
              $calendar.= '&lt;tr class=""calendar-row""&gt;';
          endif;
          $running_day = -1;
          $days_in_this_week = 0;
      endif;
      $days_in_this_week++; $running_day++; $day_counter++;
  endfor;


More seriously, in the first case you'd have a query like

SELECT date,event from entries where date = $date


and now you'd have

SELECT date,event from entries where date between $date_minus_one_month and $date


Then store the results in an associative array, indexed by days.
",Vinko Vrsalovic,https://stackoverflow.com/users/5190,http://stackoverflow.com/questions/1873340/php-and-mysql-calendar-issue,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,PHP and MySQL calendar problems,"I'm writing trying to build a calendar right from scratch. I'm using the function written by David Walsh (see link) and it's great. 
He does a query for each day's cell.
But, I'm afraid that when the script's gonna have to run 30 queries in each render, it's gonna be sloooow. 

So, I was trying to think in another logic, for example, make a big query from X date to Y date at the begining of the script and then, at each day, check if that particular day has an event in the previous query. But I have no idea of how to do this...
So, if anyone can help, please shout!

Thanks.
","Instead of

  /* keep going with days.... */ 
  for($list_day = 1; $list_day &lt;= $days_in_month; $list_day++):
      $calendar.= '&lt;td class=""calendar-day""&gt;';
      /* add in the day number */ 
      $calendar.= '&lt;div class=""day-number""&gt;'.$list_day.'&lt;/div&gt;';

      /** QUERY THE DATABASE FOR AN ENTRY FOR THIS DAY !!  
          IF MATCHES FOUND, PRINT THEM !! **/ 

      $calendar.= str_repeat('&lt;p&gt;&amp;nbsp;&lt;/p&gt;',2);
      $calendar.= '&lt;/td&gt;';
      if($running_day == 6):
          $calendar.= '&lt;/tr&gt;';
          if(($day_counter+1) != $days_in_month):
              $calendar.= '&lt;tr class=""calendar-row""&gt;';
          endif;
          $running_day = -1;
          $days_in_this_week = 0;
      endif;
      $days_in_this_week++; $running_day++; $day_counter++;
  endfor;


do

   /** QUERY THE DATABASE FOR AN ENTRY FOR THE PERIOD !!  
          IF MATCHES FOUND, STORE THEM !! **/ 
  $entries = getEntriesFromDB($month,$year);

  /* keep going with days.... */ 
  for($list_day = 1; $list_day &lt;= $days_in_month; $list_day++):
      $calendar.= '&lt;td class=""calendar-day""&gt;';
      /* add in the day number */ 
      $calendar.= '&lt;div class=""day-number""&gt;'.$list_day.'&lt;/div&gt;';
      if ($entries[$list_day]):
          /** ADD THE ENTRIES FOR THE DAY!! **/
      endif;
      $calendar.= str_repeat('&lt;p&gt;&amp;nbsp;&lt;/p&gt;',2);
      $calendar.= '&lt;/td&gt;';
      if($running_day == 6):
          $calendar.= '&lt;/tr&gt;';
          if(($day_counter+1) != $days_in_month):
              $calendar.= '&lt;tr class=""calendar-row""&gt;';
          endif;
          $running_day = -1;
          $days_in_this_week = 0;
      endif;
      $days_in_this_week++; $running_day++; $day_counter++;
  endfor;


More seriously, in the first case you'd have a query like

SELECT date,event from entries where date = $date


and now you'd have

SELECT date,event from entries where date between $date_minus_one_month and $date


Then store the results in an associative array, indexed by days.
"
4741,4741,7521,Why are the Raspian repositories so out of date?,"I'm trying to install Owncloud, which is currently at version 6.0.3. However, Raspian's version is from about two years ago.

$ apt-cache show owncloud
Package: owncloud
Version: 4.0.4debian2-3.3


Similarly, Raspian deluge (1.3.3) is well over two years old.


Is this common for many Raspian packages?
Why does this repository lag behind so much?
Is there a way to get newer packages another repository, and/or would installing Pidora or Arch help?

",Sparhawk,https://raspberrypi.stackexchange.com/users/1278,"I know link updates are frowned upon, but this is an internal link to what you need. 

Half way down that answer it shows how you can select packages from Jessie repository so you can install the latest ones will be there.

http://raspberrypi.stackexchange.com/a/15061/894
",ppumkin,https://raspberrypi.stackexchange.com/users/894,http://raspberrypi.stackexchange.com/questions/18304/why-are-the-raspbian-repositories-so-out-of-date,TECHNOLOGY,raspberrypi.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Why is the raspan warehouse so out of date?,"I'm trying to install Owncloud, which is currently at version 6.0.3. However, Raspian's version is from about two years ago.

$ apt-cache show owncloud
Package: owncloud
Version: 4.0.4debian2-3.3


Similarly, Raspian deluge (1.3.3) is well over two years old.


Is this common for many Raspian packages?
Why does this repository lag behind so much?
Is there a way to get newer packages another repository, and/or would installing Pidora or Arch help?

","I know link updates are frowned upon, but this is an internal link to what you need. 

Half way down that answer it shows how you can select packages from Jessie repository so you can install the latest ones will be there.

http://raspberrypi.stackexchange.com/a/15061/894
"
946,946,1497,In what order are taxes applied,"Lets say we have a product that costs 100$ (net price). This product has 3 taxes that must be applied to it: 2 percentage taxes (e.g. 17% and 20%) and one fixed amount tax (e.g. +10$).

My question is - what math is done in this case?

Are the percentage taxes applied on the net price and summed or the first one is calculated and then the second one is done with the price we get after applying the first? When is the fixed amount tax applied? After the other two or the other two are done with net+fixed tax?
",karka91,https://money.stackexchange.com/users/6846,"This could be legislated to be different, but typically, the tax is applied on the net and summed.

$100 price

17% is $17

20% is $20

$10 flat tax

= $147
",Alex B,https://money.stackexchange.com/users/815,http://money.stackexchange.com/questions/16200/in-what-order-are-taxes-applied,LIFE_ARTS,money.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,In what order are taxes applied,"Lets say we have a product that costs 100$ (net price). This product has 3 taxes that must be applied to it: 2 percentage taxes (e.g. 17% and 20%) and one fixed amount tax (e.g. +10$).

My question is - what math is done in this case?

Are the percentage taxes applied on the net price and summed or the first one is calculated and then the second one is done with the price we get after applying the first? When is the fixed amount tax applied? After the other two or the other two are done with net+fixed tax?
","This could be legislated to be different, but typically, the tax is applied on the net and summed.

$100 price

17% is $17

20% is $20

$10 flat tax

= $147
"
1013,1013,1598,"Huffy Cranbrook 26"" Ladies' Cruiser crank / pedal / chain ""pop"" sound...?","Before you say it's a cheap bike, what more do you want... I get that! :D
But it's brand new, and as you pedal it... no matter the speed, you get a pop sound at a specific point on each rotation...

What could / should I do to help silence this sound and make the ride more enjoyable.

Please advise if you can!

VIDEO UPDATE:
I uploaded this video of the happenings ;)


                
            
",Joshua F. Rountree,https://bicycles.stackexchange.com/users/4032,"I have the exact same bike with the exact same problem. Took it back to Walmart to have it repaired. Same problem after I picked it up. Sounds like they just created a defective product and need to do a recall. Sucks because it's such a beautiful bike. 
",user10617,https://bicycles.stackexchange.com/users/10617,http://bicycles.stackexchange.com/questions/9307/huffy-cranbrook-26-ladies-cruiser-crank-pedal-chain-pop-sound,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,1.0,0.5,1.0,1.0,0.8,0.0,0.0,1.0,0.8333333333333334,"Hafi Cranbrook 26 ""women's cruiser crank / pedal / chain"" Bang...?","Before you say it's a cheap bike, what more do you want... I get that! :D
But it's brand new, and as you pedal it... no matter the speed, you get a pop sound at a specific point on each rotation...

What could / should I do to help silence this sound and make the ride more enjoyable.

Please advise if you can!

VIDEO UPDATE:
I uploaded this video of the happenings ;)


                
            
","I have the exact same bike with the exact same problem. Took it back to Walmart to have it repaired. Same problem after I picked it up. Sounds like they just created a defective product and need to do a recall. Sucks because it's such a beautiful bike. 
"
1352,1352,2130,ASP.NET MVC Update part of the model,"I have very complex model. The flow is like this:
- in controller I populate the model from the database
- in view I have several tabs. After I fill in the info on the first tab, the second tab enables (this works just fine) and on click on the second tab button I need to update some properties of the model. How can I do this WITHOUT calling the database again in order to populate the model on the controller? The model is very complex, so I can't store as ""hidden"" all the properties.  

I hope I managed to be clear enough. 
Thanks for any kind of help
",Sandra S.,https://stackoverflow.com/users/1685352,"I had the same situations with ASP.NET MVC. I used ViewBag's for sending the data in very magical ways, created Javascript strings and ran them with Html.Raw, used .executeSql in many places, done real magic. But after all I asked myself: is it worth the pain?

No matter you don't have enough time (i mean this!), I strongly recommend reading some good documents and try some tutorials before diving into the dark sea of work-arounds.

Don't forget, with a good design and using Model class' features well, you won't need work-arounds too much and this will give you, above all, happiness.

For your situation; the best place is to create a Helper class such as: 

public abstract class Helper&lt;T&gt; : WebViewPage&lt;T&gt;
{
    private dbContext db = new dbContext();

    public virtual whatEver yourUpdateOperation(int? id, string data)
    {
        // you can do your update operations here
        return whatEver;
    }
}


To apply this class to all your WebPages, change the line in your web.config file in your Views directory:

&lt;pages pageBaseType=""YourProject.HelperDirectory.Helper""&gt;


From now on you are able to call yourUpdateOperation from your Views such as:

@foreach (var item in Model)
{
&lt;tr&gt;
    &lt;td&gt;
    &lt;!-- View or operate things--&gt;
    &lt;/td&gt;
    @yourUpdateOperation(item.ID, data)
&lt;/tr&gt;
}


Hope this helps.
",Ä°smet Alkan,https://stackoverflow.com/users/1275577,http://stackoverflow.com/questions/14326382/asp-net-mvc-update-part-of-the-model,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.6666666666666666,Asp.net MVC update part of the model,"I have very complex model. The flow is like this:
- in controller I populate the model from the database
- in view I have several tabs. After I fill in the info on the first tab, the second tab enables (this works just fine) and on click on the second tab button I need to update some properties of the model. How can I do this WITHOUT calling the database again in order to populate the model on the controller? The model is very complex, so I can't store as ""hidden"" all the properties.  

I hope I managed to be clear enough. 
Thanks for any kind of help
","I had the same situations with ASP.NET MVC. I used ViewBag's for sending the data in very magical ways, created Javascript strings and ran them with Html.Raw, used .executeSql in many places, done real magic. But after all I asked myself: is it worth the pain?

No matter you don't have enough time (i mean this!), I strongly recommend reading some good documents and try some tutorials before diving into the dark sea of work-arounds.

Don't forget, with a good design and using Model class' features well, you won't need work-arounds too much and this will give you, above all, happiness.

For your situation; the best place is to create a Helper class such as: 

public abstract class Helper&lt;T&gt; : WebViewPage&lt;T&gt;
{
    private dbContext db = new dbContext();

    public virtual whatEver yourUpdateOperation(int? id, string data)
    {
        // you can do your update operations here
        return whatEver;
    }
}


To apply this class to all your WebPages, change the line in your web.config file in your Views directory:

&lt;pages pageBaseType=""YourProject.HelperDirectory.Helper""&gt;


From now on you are able to call yourUpdateOperation from your Views such as:

@foreach (var item in Model)
{
&lt;tr&gt;
    &lt;td&gt;
    &lt;!-- View or operate things--&gt;
    &lt;/td&gt;
    @yourUpdateOperation(item.ID, data)
&lt;/tr&gt;
}


Hope this helps.
"
4821,4821,7661,iOS: Change Device Volume,"Is there a way to change the volume of the device? I've seen several apps do it. 

I have a desktop version of the iOS app and the device will be able to be controlled to some extent over the network. One of the things I want to allow the user to do is change the device volume and then play a sound. This can help if you loose your iPhone in a crack in your couch again, but can't find it. 

Is there any way that you can do this without Apple getting angry?
",Tristan Seifert,https://stackoverflow.com/users/219515,"You can use a little trick: 

  MPMusicPlayerController* musicPlayer = [MPMusicPlayerController iPodMusicPlayer];
  musicPlayer.volume = 1; // device volume will be changed to maximum value

",Andrii Forkaliuk,https://stackoverflow.com/users/844522,http://stackoverflow.com/questions/4859402/ios-change-device-volume,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,IOS: changing device volumes,"Is there a way to change the volume of the device? I've seen several apps do it. 

I have a desktop version of the iOS app and the device will be able to be controlled to some extent over the network. One of the things I want to allow the user to do is change the device volume and then play a sound. This can help if you loose your iPhone in a crack in your couch again, but can't find it. 

Is there any way that you can do this without Apple getting angry?
","You can use a little trick: 

  MPMusicPlayerController* musicPlayer = [MPMusicPlayerController iPodMusicPlayer];
  musicPlayer.volume = 1; // device volume will be changed to maximum value

"
5293,5293,8407,Reading from /dev/random does not produce any data,"I often use the command

cat /dev/urandom | strings --bytes 1 | tr -d '\n\t ' | head --bytes 32


to generate pseudo-random passwords. This doesn't work with /dev/random.

Specifically


cat /dev/urandom | strings --bytes 1 | tr -d '\n\t ' produces output
cat  /dev/random | strings --bytes 1 produces output
cat  /dev/random | strings --bytes 1 | tr -d '\n\t  ' does not produce output


NB: When using /dev/random you may have to wiggle your mouse or press keys (e.g. ctrl, shift, etc.) to generate entropy.

Why does the last example not work? Does tr have some kind of large internal buffer that /dev/urandom fills quickly but /dev/random doesn't?

P.S. I'm using CentOS 6.5

cat /proc/version
Linux version 2.6.32-431.3.1.el6.x86_64 (mockbuild@c6b10.bsys.dev.centos.org) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) ) #1 SMP Fri Jan 3 21:39:27 UTC 2014

",Aaron J Lang,https://unix.stackexchange.com/users/18799,"Generating random numbers for many security applications requires sufficient entropy âÂ entropy measures how unpredictable the randomness is. A deterministic processor cannot generate entropy, so entropy must come from the outside âÂ either from a hardware component with non-deterministic behavior, or from other factors that are sufficiently hard to reproduce such as the timing of user actions (that's where wiggling the mouse comes in). Once sufficient entropy is available, cryptography can be used to generate a practically unlimited stream of random numbers.

Linux works by accummulating entropy in a pool, then using cryptography to produce acceptable random numbers both through /dev/random and /dev/urandom. The difference is that /dev/random applies an extremely conservative entropy calculation that reduces the estimate of the entropy in the pool for every byte that it generates, whereas /dev/urandom does not concern itself with the amount of entropy in the pool.

If the estimate of entropy in the pool is too low, /dev/random blocks until more entropy can be accumulated. This can severely cripple the rate at which /dev/random can produce output. This is what you're observing here. It has nothing to do with tr; but strings reads output with buffering, so it has to read a full buffer (a few kB) from /dev/random just to produce at least one byte of input.

/dev/urandom is perfectly acceptable for generating a cryptographic key, because entropy does not in fact decrease in any perceptible way. (If you keep your machine running for longer than the universe has existed, you can't neglect these considerations, but otherwise you're good.) There is only one case where /dev/urandom is not good, which is on a freshly installed system that hasn't had time to generate entropy yet, or a freshly booted system that boots from read-only media.

Elimitating strings from your boot chain will probably speed up your process:

&lt;/dev/random LC_ALL=C tr -dc '~-!'


But you can use /dev/urandom here, as long as you take care not to generate passwords on a system that hasn't had time to accummulate sufficient entropy. You can check the level of Linux's entropy pool in /proc/sys/kernel/random/entropy_avail (if you use /dev/random, the figure in this file will be conservative, possibly very much so).
",Gilles,https://unix.stackexchange.com/users/885,http://unix.stackexchange.com/questions/114878/reading-from-dev-random-does-not-produce-any-data,TECHNOLOGY,unix.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.7777777777777778,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,1.0,Reading from / dev / random does not produce any data,"I often use the command

cat /dev/urandom | strings --bytes 1 | tr -d '\n\t ' | head --bytes 32


to generate pseudo-random passwords. This doesn't work with /dev/random.

Specifically


cat /dev/urandom | strings --bytes 1 | tr -d '\n\t ' produces output
cat  /dev/random | strings --bytes 1 produces output
cat  /dev/random | strings --bytes 1 | tr -d '\n\t  ' does not produce output


NB: When using /dev/random you may have to wiggle your mouse or press keys (e.g. ctrl, shift, etc.) to generate entropy.

Why does the last example not work? Does tr have some kind of large internal buffer that /dev/urandom fills quickly but /dev/random doesn't?

P.S. I'm using CentOS 6.5

cat /proc/version
Linux version 2.6.32-431.3.1.el6.x86_64 (mockbuild@c6b10.bsys.dev.centos.org) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) ) #1 SMP Fri Jan 3 21:39:27 UTC 2014

","Generating random numbers for many security applications requires sufficient entropy âÂ entropy measures how unpredictable the randomness is. A deterministic processor cannot generate entropy, so entropy must come from the outside âÂ either from a hardware component with non-deterministic behavior, or from other factors that are sufficiently hard to reproduce such as the timing of user actions (that's where wiggling the mouse comes in). Once sufficient entropy is available, cryptography can be used to generate a practically unlimited stream of random numbers.

Linux works by accummulating entropy in a pool, then using cryptography to produce acceptable random numbers both through /dev/random and /dev/urandom. The difference is that /dev/random applies an extremely conservative entropy calculation that reduces the estimate of the entropy in the pool for every byte that it generates, whereas /dev/urandom does not concern itself with the amount of entropy in the pool.

If the estimate of entropy in the pool is too low, /dev/random blocks until more entropy can be accumulated. This can severely cripple the rate at which /dev/random can produce output. This is what you're observing here. It has nothing to do with tr; but strings reads output with buffering, so it has to read a full buffer (a few kB) from /dev/random just to produce at least one byte of input.

/dev/urandom is perfectly acceptable for generating a cryptographic key, because entropy does not in fact decrease in any perceptible way. (If you keep your machine running for longer than the universe has existed, you can't neglect these considerations, but otherwise you're good.) There is only one case where /dev/urandom is not good, which is on a freshly installed system that hasn't had time to generate entropy yet, or a freshly booted system that boots from read-only media.

Elimitating strings from your boot chain will probably speed up your process:

&lt;/dev/random LC_ALL=C tr -dc '~-!'


But you can use /dev/urandom here, as long as you take care not to generate passwords on a system that hasn't had time to accummulate sufficient entropy. You can check the level of Linux's entropy pool in /proc/sys/kernel/random/entropy_avail (if you use /dev/random, the figure in this file will be conservative, possibly very much so).
"
316,316,508,Is this function bijective?,"Consider the function $\theta:\{0,1\}\times\mathbb{N}\rightarrow\mathbb{Z}$ defined as $\theta(a,b) = a-2ab+b$. Is this function bijective?

For injective, I tried doing the contrapositive by supposing $\theta(a,b)=\theta(c,d)$, then $a-2ab+b=c-2cd+d$, but I have no idea where to go from there. I tried solving for a and b separately and plugging it back in, but that just turned into a huge algebraic mess.

I haven't figured what I'm going to do for surjective yet.

I'm not very good at this subject, so sorry if this is a stupid question. Any hints are appreciated, thanks.
",laser295,https://math.stackexchange.com/users/35378,"Formulas are nice, but let's find out what's really going on: $\theta(0,b)=b\,$ and $\theta(1,b)=1-b$. Much clearer. 

Could $x=1-y\,$ where $x$ and $y$ are natural numbers? Depends on what one means by natural number. It can certainly happen if we allow $0$ to be a natural number.  I am inclined to allow that, out of loyalty to logic, where it is a standard convention.  But I am in a minority. Certainly it cannot happen if $x$ and $y$ are positive.  

Finally, for surjectivity (love that word) is every integer of the form $x$ or $1-y$ where $x$ and $y$ are positive integers? Sure.
",AndrÃ© Nicolas,https://math.stackexchange.com/users/6312,http://math.stackexchange.com/questions/177385/is-the-function-thetaa-b-a-2abb-a-bijection-from-0-1-times-mathbbn,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,Is this function bijective?,"Consider the function $\theta:\{0,1\}\times\mathbb{N}\rightarrow\mathbb{Z}$ defined as $\theta(a,b) = a-2ab+b$. Is this function bijective?

For injective, I tried doing the contrapositive by supposing $\theta(a,b)=\theta(c,d)$, then $a-2ab+b=c-2cd+d$, but I have no idea where to go from there. I tried solving for a and b separately and plugging it back in, but that just turned into a huge algebraic mess.

I haven't figured what I'm going to do for surjective yet.

I'm not very good at this subject, so sorry if this is a stupid question. Any hints are appreciated, thanks.
","Formulas are nice, but let's find out what's really going on: $\theta(0,b)=b\,$ and $\theta(1,b)=1-b$. Much clearer. 

Could $x=1-y\,$ where $x$ and $y$ are natural numbers? Depends on what one means by natural number. It can certainly happen if we allow $0$ to be a natural number.  I am inclined to allow that, out of loyalty to logic, where it is a standard convention.  But I am in a minority. Certainly it cannot happen if $x$ and $y$ are positive.  

Finally, for surjectivity (love that word) is every integer of the form $x$ or $1-y$ where $x$ and $y$ are positive integers? Sure.
"
1524,1524,2397,Animation in UITableViewCell completes immediately,"I have a subclass of UITableViewCell with button inside of it. The button have clear backgroundColor with some border. I want to do a fill in animation starting from the center of the button. My problem is that animation completes immediately. Here's my code, I've tried doing this in 2 different ways.

- (void)goingButtonAnimation {
    UIView *goingButtonBackgroundView = [[UIView alloc] initWithFrame:CGRectMake(self.goingButton.center.x, self.goingButton.center.y, 0., 0.)];
    goingButtonBackgroundView.layer.cornerRadius = 2.;
    goingButtonBackgroundView.backgroundColor = [UIColor blackColor];
    [self insertSubview:goingButtonBackgroundView belowSubview:self.goingButton];

    [UIView animateWithDuration:2. animations:^{
        goingButtonBackgroundView.frame = self.goingButton.frame;
    }];
}


I've also tried this:

goingButtonBackgroundView.transform = CGAffineTransformMakeScale(0.1, 0.1);
[UIView animateWithDuration:2. animations:^{
    goingButtonBackgroundView.transform = CGAffineTransformMakeScale(1.0, 1.0);
    goingButtonBackgroundView.center = self.goingButton.center;
}];


But the animation completes immediately in each case. goingButtonAnimation method is called after tapping on self.goingButton
",nadol,https://stackoverflow.com/users/3241839,"My problem was that after calling goingButtonAnimation I called [self.tableView reloadData]
",nadol,https://stackoverflow.com/users/3241839,http://stackoverflow.com/questions/26662027/animation-in-uitableviewcell-completes-immediately,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.7777777777777778,The animation in uitableviewcell completes immediately,"I have a subclass of UITableViewCell with button inside of it. The button have clear backgroundColor with some border. I want to do a fill in animation starting from the center of the button. My problem is that animation completes immediately. Here's my code, I've tried doing this in 2 different ways.

- (void)goingButtonAnimation {
    UIView *goingButtonBackgroundView = [[UIView alloc] initWithFrame:CGRectMake(self.goingButton.center.x, self.goingButton.center.y, 0., 0.)];
    goingButtonBackgroundView.layer.cornerRadius = 2.;
    goingButtonBackgroundView.backgroundColor = [UIColor blackColor];
    [self insertSubview:goingButtonBackgroundView belowSubview:self.goingButton];

    [UIView animateWithDuration:2. animations:^{
        goingButtonBackgroundView.frame = self.goingButton.frame;
    }];
}


I've also tried this:

goingButtonBackgroundView.transform = CGAffineTransformMakeScale(0.1, 0.1);
[UIView animateWithDuration:2. animations:^{
    goingButtonBackgroundView.transform = CGAffineTransformMakeScale(1.0, 1.0);
    goingButtonBackgroundView.center = self.goingButton.center;
}];


But the animation completes immediately in each case. goingButtonAnimation method is called after tapping on self.goingButton
","My problem was that after calling goingButtonAnimation I called [self.tableView reloadData]
"
142,142,226,When are we first informed about Gerry Lane's profession?,"In World War Z, Brad Pitt plays the role of a former UN investigator named Gerry Lane. When are we first informed of this fact?

When I watched the film, I spent half the movie wondering who he was that he could get a helicopter to specially ferry him and his family out of the city. It was only when he spoke to the naval honcho that I found out that he was a former UN man. Is this the first instance of this information being revealed to the audience?

I can remember a conversation about his job when the Lanes are having breakfast. But I don't recall the UN being mentioned.
",coleopterist,https://movies.stackexchange.com/users/3650,"No, the scene when his daughter mentions him doing pancakes all the time. I think he replied, I've left my old job/or retired. Also the daughter asked him what was Martial Law, which tells us that he was former military or in some Defence organization.
",Rohan Naik,https://movies.stackexchange.com/users/5632,http://movies.stackexchange.com/questions/13714/when-are-we-first-informed-about-gerry-lanes-profession,LIFE_ARTS,movies.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,When did we first know about grey Lane's career?,"In World War Z, Brad Pitt plays the role of a former UN investigator named Gerry Lane. When are we first informed of this fact?

When I watched the film, I spent half the movie wondering who he was that he could get a helicopter to specially ferry him and his family out of the city. It was only when he spoke to the naval honcho that I found out that he was a former UN man. Is this the first instance of this information being revealed to the audience?

I can remember a conversation about his job when the Lanes are having breakfast. But I don't recall the UN being mentioned.
","No, his daughter mentioned that he had been making pancakes. I think he replied that I had resigned. The daughter also asked him what is martial law, which tells us that he was a soldier or in a national defense organization."
4155,4155,6626,Circuit to control a impulse solenoid valve from a movement detector,"I have a movement detector sensor that generate a pulse (3.3V TTL) for 60 seconds when something moves in front of it. On the other hand, I have a impulse solenoid valve that close on a negative voltage (-3.6V) and open on a positive voltage (+3.6V).

What would be the simplest and cheapest way to drive the solenoid from the movement detector?

The circuit or chip should produce +3.6V output for at least 30ms when the input signal goes to 3.3V and then produce -3.6V for at least 30ms when the input signal goes low (0V).

(I also have available a solenoid that work on 4.5V rather than 3.6V if this can help)

Links:

Valve

Movement detector

24/08/2013 Update

Inspired by the answer of Jim, will a circuit like this one work?


",Pat,https://electronics.stackexchange.com/users/27887,"Normally I wouldn't do a bespoke design (especially for free) but this problem has a lot of common themes with other questions being asked so I thought it would be a good exercise to go through it in the hope that my solution (or parts of it) could be used elsewhere. Apologies for its length. MOSFET types should be able to switch a few amps and be of the 'digital' type (low gate turn on voltages).

Problems:

(1) the solenoid valve requires a positive pulse and a negative pulse (of about 30mS) to open an close it. 

(2) the sensor outputs a single pulse of about 60 seconds.

(3) the Pump requires a 3v6 pulse at about 500mA

Assumptions:

(1) the pump valve stays ON or OFF depending on the last pulse

(2) You want to turn the valve ON at the beginning of the sensor pulse and OFF at the end.

I noticed the valve has only two wires so rather than positive and negative pulses its more reversing current direction. For a single supply that would suggest some form of changeover switch or an H bridge. I chose to go with a MOSFET H bridge and worked out from there.

The circuit:



THE H BRIDGE: Q3,Q4,Q5,Q6

MOSFETs Q3,Q4,Q5,Q6 and Diodes D1,D2,D3 and D4 form a fairly conventional H Bridge using P channel MOSFETS at the top and N channel at the bottom. IC1d is a CMOS schmitt inverter gate that switches the opposite sides of the bridge. A LOW on the gate turns  Q3 ON  and turns Q4 OFF. The inverter output (HIGH) turns ON Q6  and turns Q5 OFF. Current direction will be left to right through the valve (current forward). 

A HIGH on the Q4 MOSFET gate turns it Q4 ON but turns Q3 OFF . The output from the inverter (LOW) turns Q5 ON and turns Q6 OFF. The output current direction is now right to left. (Current reversed).

CURRENT PULSE POWER CONTROL: (Q1,Q2)

If the H bridge was powered all the time the valve would burn out. 

Q1 is normally held OFF by R1. This part of the circuit only allows the H Bridge to work when it is Q1 is turned ON. 

When the gate of Q2 is taken HIGH by the 30mS pulse it switches ON and pulls the gate of Q1 to ground, turning it ON as well. When the pulse returns to LOW it is turned OFF

TIMING CIRCUIT: (R3,C1, IC1b, IC1c and IC2a)

I could have used a simple 8 pin micro-controller for this section but chose to do it with with a few simple logic gates.

IC1a acts simply as an inverting buffer taking the 60 second pulse at its input. 

One of the inputs to the XOR gate is taken through a simple RC delay circuit (R3, C1). When there is a change in the state (HIGH-> LOW or LOW->HIGH) of the incoming pulse this RC delay will cause the output of the XOR gate to go HIGH for the delay period. (Dual edge triggered monostable)

Eventually the two inputs of the gate will be the same and then the output of the gate will go LOW. In other words we get a pulse after the rising AND falling edges of the input signal (frequency doubler). If we set this delay pulse to be about 30mS it is exactly what we require for the input to Q1,Q2.  

The direction of the current passing through the bridge is controlled by the input signal as it will be HIGH (detected) or LOW (timed out) at the time of the pulse.
",JIm Dearden,https://electronics.stackexchange.com/users/24182,http://electronics.stackexchange.com/questions/79871/circuit-to-control-a-impulse-solenoid-valve-from-a-movement-detector,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.6666666666666666,0.8888888888888888,The circuit of controlling pulse solenoid valve from motion detector,"I have a movement detector sensor that generate a pulse (3.3V TTL) for 60 seconds when something moves in front of it. On the other hand, I have a impulse solenoid valve that close on a negative voltage (-3.6V) and open on a positive voltage (+3.6V).

What would be the simplest and cheapest way to drive the solenoid from the movement detector?

The circuit or chip should produce +3.6V output for at least 30ms when the input signal goes to 3.3V and then produce -3.6V for at least 30ms when the input signal goes low (0V).

(I also have available a solenoid that work on 4.5V rather than 3.6V if this can help)

Links:

Valve

Movement detector

24/08/2013 Update

Inspired by the answer of Jim, will a circuit like this one work?


","Normally I wouldn't do a bespoke design (especially for free) but this problem has a lot of common themes with other questions being asked so I thought it would be a good exercise to go through it in the hope that my solution (or parts of it) could be used elsewhere. Apologies for its length. MOSFET types should be able to switch a few amps and be of the 'digital' type (low gate turn on voltages).

Problems:

(1) the solenoid valve requires a positive pulse and a negative pulse (of about 30mS) to open an close it. 

(2) the sensor outputs a single pulse of about 60 seconds.

(3) the Pump requires a 3v6 pulse at about 500mA

Assumptions:

(1) the pump valve stays ON or OFF depending on the last pulse

(2) You want to turn the valve ON at the beginning of the sensor pulse and OFF at the end.

I noticed the valve has only two wires so rather than positive and negative pulses its more reversing current direction. For a single supply that would suggest some form of changeover switch or an H bridge. I chose to go with a MOSFET H bridge and worked out from there.

The circuit:



THE H BRIDGE: Q3,Q4,Q5,Q6

MOSFETs Q3,Q4,Q5,Q6 and Diodes D1,D2,D3 and D4 form a fairly conventional H Bridge using P channel MOSFETS at the top and N channel at the bottom. IC1d is a CMOS schmitt inverter gate that switches the opposite sides of the bridge. A LOW on the gate turns  Q3 ON  and turns Q4 OFF. The inverter output (HIGH) turns ON Q6  and turns Q5 OFF. Current direction will be left to right through the valve (current forward). 

A HIGH on the Q4 MOSFET gate turns it Q4 ON but turns Q3 OFF . The output from the inverter (LOW) turns Q5 ON and turns Q6 OFF. The output current direction is now right to left. (Current reversed).

CURRENT PULSE POWER CONTROL: (Q1,Q2)

If the H bridge was powered all the time the valve would burn out. 

Q1 is normally held OFF by R1. This part of the circuit only allows the H Bridge to work when it is Q1 is turned ON. 

When the gate of Q2 is taken HIGH by the 30mS pulse it switches ON and pulls the gate of Q1 to ground, turning it ON as well. When the pulse returns to LOW it is turned OFF

TIMING CIRCUIT: (R3,C1, IC1b, IC1c and IC2a)

I could have used a simple 8 pin micro-controller for this section but chose to do it with with a few simple logic gates.

IC1a acts simply as an inverting buffer taking the 60 second pulse at its input. 

One of the inputs to the XOR gate is taken through a simple RC delay circuit (R3, C1). When there is a change in the state (HIGH-> LOW or LOW->HIGH) of the incoming pulse this RC delay will cause the output of the XOR gate to go HIGH for the delay period. (Dual edge triggered monostable)

Eventually the two inputs of the gate will be the same and then the output of the gate will go LOW. In other words we get a pulse after the rising AND falling edges of the input signal (frequency doubler). If we set this delay pulse to be about 30mS it is exactly what we require for the input to Q1,Q2.  

The direction of the current passing through the bridge is controlled by the input signal as it will be HIGH (detected) or LOW (timed out) at the time of the pulse.
"
2470,2470,3937,check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
",Oneb,https://stackoverflow.com/users/1012518,"The answer is simple: don't use regexes.

Use this approach:


iterate over each letter (of course, skip the last tree letters)

iterate over the next three letters and check for ascending order

if they all were ascending return true.

iterate over the next three letters and check for descending order

if they all were descending return false.


return false


In code, this would look like this (untested code):

public boolean checkForAscendingOrDescendingPart(String txt, int l)
{
    for (int i = 0; i &lt;= txt.length() - l; ++i)
    {
        boolean success = true;
        char c = txt.charAt(i);
        for (int j = 1; j &lt; l; ++j)
        {
            if (((char) c + j) != txt.charAt(i + j))
            {
                success = false;
                break;
            }
        }
        if (success) return true;

        success = true;

        for (int j = 1; j &lt; l; ++j)
        {
            if (((char) c - j) != txt.charAt(i + j))
            {
                success = false;
                break;
            }
        }
        if (success) return true;
    }
    return false;
}


Good luck!
StackOverflow :)
",Martijn Courteaux,https://stackoverflow.com/users/155137,http://stackoverflow.com/questions/12493931/check-if-a-string-has-four-consecutive-letters-in-ascending-or-descending-order,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,Check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
","The answer is simple: don't use regexes.

Use this approach:


iterate over each letter (of course, skip the last tree letters)

iterate over the next three letters and check for ascending order

if they all were ascending return true.

iterate over the next three letters and check for descending order

if they all were descending return false.


return false


In code, this would look like this (untested code):

public boolean checkForAscendingOrDescendingPart(String txt, int l)
{
    for (int i = 0; i &lt;= txt.length() - l; ++i)
    {
        boolean success = true;
        char c = txt.charAt(i);
        for (int j = 1; j &lt; l; ++j)
        {
            if (((char) c + j) != txt.charAt(i + j))
            {
                success = false;
                break;
            }
        }
        if (success) return true;

        success = true;

        for (int j = 1; j &lt; l; ++j)
        {
            if (((char) c - j) != txt.charAt(i + j))
            {
                success = false;
                break;
            }
        }
        if (success) return true;
    }
    return false;
}


Good luck!
StackOverflow :)
"
780,780,1241,Unable to Import Data,"I am following this tutorial,

but i am not able to get the right username and password to import data. How do I know what the username password is? By default I see tomcat6 as database and username and no password in the textbox. As i am following the tutorial I changed it to username: postgis and password: postgres.

How do I know what my username and password is?

EDIT

Import the data in PostGIS, which requires PostGIS connection.

UPDATE

Ok so i got the user and passwd but when I am trying to add the shapefile using the Shape File to PostGIS Importer Plugin and having made connection successfully, I am getting this error when I am adding the shapefile.

Connecting: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Connection succeeded.
Connection: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Destination: public.AllQuebecSpecies
Source File: /home/smaranh/development/Biodiversity/biodiversity/shapefile/AllQuebecSpecies
Shapefile type: Point
Postgis type: POINT[2]
Failed SQL begins: ""SET CLIENT_ENCODING TO UTF8;
SET STANDARD_CONFORMING_STRINGS TO ON;
BEGIN;
CREATE TABLE ""public"".""AllQuebecSpecies"" (gid serial PRIMARY KEY,
""family"" varchar(50),
""species"" varchar(50));
SELECT AddGeometryColumn('public','AllQuebecSpecies','the_geom','-1""
Failed in pgui_exec(): ERROR:  function addgeometrycolumn(unknown, unknown, unknown, unknown, unknown, integer) does not exist
LINE 7: SELECT AddGeometryColumn('public','AllQuebecSpecies','the_ge...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

Shapefile import failed.


Can somebody tell me where am I going wrong?
",Sam007,https://gis.stackexchange.com/users/4333,"Have you tried the username and password they show in the image when reading the documentation?  (admin/geoserver)


  When you first start the dashboard, it provides a reminder about the
  default password for accessing GeoServer [....] {followed by the image}


Otherwise, just above step 1 it says:


  Note
  
  The PostGIS database has been installed with unrestricted access for
  local users (users connecting from the same machine as the database is
  running). That means that it will accept any password you provide. If
  you need to connect from a remote computer, the password for the
  postgres user has been set to postgres.

",RyanDalton,https://gis.stackexchange.com/users/1072,http://gis.stackexchange.com/questions/25437/unable-to-import-data,TECHNOLOGY,gis.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.5555555555555556,0.6666666666666666,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.5333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,Unable to import data,"I am following this tutorial,

but i am not able to get the right username and password to import data. How do I know what the username password is? By default I see tomcat6 as database and username and no password in the textbox. As i am following the tutorial I changed it to username: postgis and password: postgres.

How do I know what my username and password is?

EDIT

Import the data in PostGIS, which requires PostGIS connection.

UPDATE

Ok so i got the user and passwd but when I am trying to add the shapefile using the Shape File to PostGIS Importer Plugin and having made connection successfully, I am getting this error when I am adding the shapefile.

Connecting: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Connection succeeded.
Connection: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Destination: public.AllQuebecSpecies
Source File: /home/smaranh/development/Biodiversity/biodiversity/shapefile/AllQuebecSpecies
Shapefile type: Point
Postgis type: POINT[2]
Failed SQL begins: ""SET CLIENT_ENCODING TO UTF8;
SET STANDARD_CONFORMING_STRINGS TO ON;
BEGIN;
CREATE TABLE ""public"".""AllQuebecSpecies"" (gid serial PRIMARY KEY,
""family"" varchar(50),
""species"" varchar(50));
SELECT AddGeometryColumn('public','AllQuebecSpecies','the_geom','-1""
Failed in pgui_exec(): ERROR:  function addgeometrycolumn(unknown, unknown, unknown, unknown, unknown, integer) does not exist
LINE 7: SELECT AddGeometryColumn('public','AllQuebecSpecies','the_ge...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

Shapefile import failed.


Can somebody tell me where am I going wrong?
","Have you tried the username and password they show in the image when reading the documentation?  (admin/geoserver)


  When you first start the dashboard, it provides a reminder about the
  default password for accessing GeoServer [....] {followed by the image}


Otherwise, just above step 1 it says:


  Note
  
  The PostGIS database has been installed with unrestricted access for
  local users (users connecting from the same machine as the database is
  running). That means that it will accept any password you provide. If
  you need to connect from a remote computer, the password for the
  postgres user has been set to postgres.

"
5128,5128,8158,Drywall - final joint compound coat,"While remodeling an older house (where nothing is quite straight) we used fiber glass mesh joint tape and 3 coats of joint compound. The first coat was applied with a 4 inch knife, the second with an 8 inch and ending the third on a 12 inch knife. I can still see the texture from the mesh tape I used on some of the joints.

I hoped that a coat of primer would level it off, but after using Kilz 2 primer I can still see the tape in some spots. :(

Sanding through the primer now proves difficult (doesn't work) with a medium grit sanding block.

Should I add another coat? I could never quite get the joint compound to adhere over the mesh tape. I've always been taught to go as thin as I can on the joint compound to reduce the sanding part. Did I go too thin? 

I'm hoping a second coat of primer and 2 coats of the final latex paint hides it, but I know this isn't the right answer. How can I fix this?



following what doresoom and shirlock said; i just applied a coat with the 12 inch knife practically against the wall (accidentally touching the wall with the handle once or twice) - more or less dragging the compound across the surface

this produced the result explained - about 1/32nd ? thickness of mud, covering the tape that i'll need to feather round the edges

i miss spoke earlier - i was using a sponge sanding block (not strait paper sand paper)

now that the primer has dried (did it saturday) its not as bad as i thought it was, but this is the right way to do it (not covering it with paint)

just as a side, we've used sherwin williams paint throughout the house and although its great paint (IMO) the plaster and lath walls that remain, even those repairs show through - and if those do, than this new work will... may as well do finish it right...

thanks for the help guys - i'll check this coat tomorrow and give a last one with the soap and water if it needs it.
",lsiunsuex,https://diy.stackexchange.com/users/1154,"I know this isn't the answer you want to hear, but I don't think priming and painting will hide the tape. 

Before you apply any more primer, I'd add another thicker coat of mud. Slather on the mud thick first - it doesn't have to be smooth. Then smooth it out by angling your 12"" knife so it's almost parallel with the drywall as you drag it along the surface. You'll have to press fairly firmly in order to avoid air gaps appearing in the thick coat you're smoothing out.

You may have to get a feel for it. If you push too hard and can see the tape again, redo that section until you get it just right.

Wait for the thicker coat to dry, then sand the edges as smooth as you can get them. Very carefully/lightly sand over area covering the tape if you didn't get it quite smooth. You may need to do a second coat along both sides of the thicker coat to make it join the drywall surface smoothly.
",Doresoom,https://diy.stackexchange.com/users/20,http://diy.stackexchange.com/questions/6985/drywall-final-joint-compound-coat,LIFE_ARTS,diy.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.5,1.0,0.5,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.6666666666666666,0.0,0.8888888888888888,Dry wall - final joint composite coating,"While remodeling an older house (where nothing is quite straight) we used fiber glass mesh joint tape and 3 coats of joint compound. The first coat was applied with a 4 inch knife, the second with an 8 inch and ending the third on a 12 inch knife. I can still see the texture from the mesh tape I used on some of the joints.

I hoped that a coat of primer would level it off, but after using Kilz 2 primer I can still see the tape in some spots. :(

Sanding through the primer now proves difficult (doesn't work) with a medium grit sanding block.

Should I add another coat? I could never quite get the joint compound to adhere over the mesh tape. I've always been taught to go as thin as I can on the joint compound to reduce the sanding part. Did I go too thin? 

I'm hoping a second coat of primer and 2 coats of the final latex paint hides it, but I know this isn't the right answer. How can I fix this?



following what doresoom and shirlock said; i just applied a coat with the 12 inch knife practically against the wall (accidentally touching the wall with the handle once or twice) - more or less dragging the compound across the surface

this produced the result explained - about 1/32nd ? thickness of mud, covering the tape that i'll need to feather round the edges

i miss spoke earlier - i was using a sponge sanding block (not strait paper sand paper)

now that the primer has dried (did it saturday) its not as bad as i thought it was, but this is the right way to do it (not covering it with paint)

just as a side, we've used sherwin williams paint throughout the house and although its great paint (IMO) the plaster and lath walls that remain, even those repairs show through - and if those do, than this new work will... may as well do finish it right...

thanks for the help guys - i'll check this coat tomorrow and give a last one with the soap and water if it needs it.
","I know this isn't the answer you want to hear, but I don't think priming and painting will hide the tape. 

Before you apply any more primer, I'd add another thicker coat of mud. Slather on the mud thick first - it doesn't have to be smooth. Then smooth it out by angling your 12"" knife so it's almost parallel with the drywall as you drag it along the surface. You'll have to press fairly firmly in order to avoid air gaps appearing in the thick coat you're smoothing out.

You may have to get a feel for it. If you push too hard and can see the tape again, redo that section until you get it just right.

Wait for the thicker coat to dry, then sand the edges as smooth as you can get them. Very carefully/lightly sand over area covering the tape if you didn't get it quite smooth. You may need to do a second coat along both sides of the thicker coat to make it join the drywall surface smoothly.
"
1839,1839,2918,"Facebook - Music, Books, Interests.. are they all included in ""Likes""?","I am trying to retrieve a list of users' interests. So I am making calls to the graph api to retrieve things like books, music, etc. It seems everything under ""Likes"" also includes everything listed under books, music, etc. Are their any exceptions, or can I just make one call to retrieve Likes?
",Andy Hin,https://stackoverflow.com/users/396077,"As you can find it on the API documentation, the ""Likes"" retrieve ""All the pages this user has liked"". You need the permission user_likes.

You just need to do the following request:

https://graph.facebook.com/ID/likes?access_token=TOKEN


where ID is the ID of the user and TOKEN is the token that you have received.

It will return An array of JSON objects containing like id, name, category and create_time fields.

Cheers
",Xavier Balloy,https://stackoverflow.com/users/670804,http://stackoverflow.com/questions/4951995/facebook-music-books-interests-are-they-all-included-in-likes,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,"Facebook- music, books, interests.. Are they all included in ""like""?","I'm trying to retrieve a list of users' interests. So I'm calling the graph API to retrieve books, music, and so on. It seems that all contents under ""likes"" also include all contents listed under books, music, etc. Do they have any exceptions, or can I just call once to retrieve likes?","As you can find it on the API documentation, the ""Likes"" retrieve ""All the pages this user has liked"". You need the permission user_likes.

You just need to do the following request:

https://graph.facebook.com/ID/likes?access_token=TOKEN


where ID is the ID of the user and TOKEN is the token that you have received.

It will return An array of JSON objects containing like id, name, category and create_time fields.

Cheers
"
1629,1629,2553,"Thermometer fluid is separated, defective?","I bought a thermometer from Cole-Parmer having kerosene as the fluid, and the fluid is broken up. The fluid in the bottom part goes up to about 10Â Â°C even though it is 20Â Â°C in the room, then there is a gap followed by fluid between 23Â Â°C and 25Â Â°C, then there is no fluid going all the way to the top where there is another small stretch of fluid. There is a short black rubber sleeve on the top of thermometer.

Does this mean the thermometer is defective or am I using it incorrectly, not âcalibratingâ it or something?
",Shaka Boom,https://chemistry.stackexchange.com/users/9663,"No, it is not defective, just slightly damaged, possibly from shipping. You should call customer service at Cole-Palmer and see if they will replace (or repair) the thermometer.

If not, there are 2 ways to fix it. I haven't tried either one, so I don't know how well they work.

If there is a bulb at the top and the thermometer is low range (under 150Â°C), then you would heat the thermometer in an upright position until all the bubbles are pushed up into the bulb. 

The other method is to cool the thermometer down until all the liquid is in the bottom bulb. The second method may not work if the liquid freezes before all the liquid has moved into the bulb.
",LDC3,https://chemistry.stackexchange.com/users/4934,http://chemistry.stackexchange.com/questions/27398/thermometer-fluid-is-separated-defective,SCIENCE,chemistry.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,"Thermometer liquid separation, defective?","I bought a thermometer from Cole Parmer with kerosene as a liquid, and the liquid was broken down. The bottom liquid rises to about 10 Â° C, even if the indoor temperature is 20 Â° C, then there's a gap between 23 Â° C and 25 Â° C, then there's the liquid, then there's no liquid going up to the top, there's a little liquid there. There is a short black rubber sleeve on the top of the thermometer.","No, it is not defective, just slightly damaged, possibly from shipping. You should call customer service at Cole-Palmer and see if they will replace (or repair) the thermometer.

If not, there are 2 ways to fix it. I haven't tried either one, so I don't know how well they work.

If there is a bulb at the top and the thermometer is low range (under 150Â°C), then you would heat the thermometer in an upright position until all the bubbles are pushed up into the bulb. 

The other method is to cool the thermometer down until all the liquid is in the bottom bulb. The second method may not work if the liquid freezes before all the liquid has moved into the bulb.
"
3214,3214,5126,Piezo as a switch to flash an led when disturbed,"An LED embedded in a small translucent item (say half the size of a pack of cards) that would flash on briefly if the object was disturbed or tipped over.
I immediately responded that a piezoelectric sensor/generator inside the object wired to an LED would do it.
However, when I tried to demonstrate this concept using a piezo buzzer I liberated from an old phone, I could only get the LED to register a dim blip when I smashed the piezo buzzer with a blunt object.
How would I ensure that a piezo sensor/generator would actually light up the LED adequately without the application of blunt force trauma.
As I mentioned, space would be an issue so no large parts, breadboards, or really complex circuitry.
I'm just trying to figure out the easiest and smallest way to accomplish this simple task.
Thanks a lot for any help you can give me!
",Rory O'Hare,https://electronics.stackexchange.com/users/6179,"I have done this myself to detect tiny vibrations from anyone touching my bike. It triggers an MCU to text me using a GM862GPS module.

The circuit uses a comparator whose inputs are set to be very close to each other. Then the vibration sensor can disturb the input voltages a little, causing the comparator to trigger.

The diodes are there just to make sure the vibration sensor doesn't generate too high a voltage. It may be possible to get rid of them, but I haven't actually checked.


",Rocketmagnet,https://electronics.stackexchange.com/users/1024,http://electronics.stackexchange.com/questions/22736/piezo-as-a-switch-to-flash-an-led-when-disturbed,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.5,0.6666666666666666,0.5,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8333333333333334,0.5,0.8333333333333334,0.7777777777777778,0.7,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,Piezoelectric as a switch flashes led when disturbed,"An LED embedded in a small translucent item (say half the size of a pack of cards) that would flash on briefly if the object was disturbed or tipped over.
I immediately responded that a piezoelectric sensor/generator inside the object wired to an LED would do it.
However, when I tried to demonstrate this concept using a piezo buzzer I liberated from an old phone, I could only get the LED to register a dim blip when I smashed the piezo buzzer with a blunt object.
How would I ensure that a piezo sensor/generator would actually light up the LED adequately without the application of blunt force trauma.
As I mentioned, space would be an issue so no large parts, breadboards, or really complex circuitry.
I'm just trying to figure out the easiest and smallest way to accomplish this simple task.
Thanks a lot for any help you can give me!
","I have done this myself to detect tiny vibrations from anyone touching my bike. It triggers an MCU to text me using a GM862GPS module.

The circuit uses a comparator whose inputs are set to be very close to each other. Then the vibration sensor can disturb the input voltages a little, causing the comparator to trigger.

The diodes are there just to make sure the vibration sensor doesn't generate too high a voltage. It may be possible to get rid of them, but I haven't actually checked.


"
2628,2628,4177,Are programming books in other languages useful for Python?,"I'm a self-taught intermediate Python programmer; I frequently come across popular books on software development and programming written in other languages (often Java). 

Typical examples:


Refactoring: Improving the Design of Existing Code
Design Patterns, Gang of Four
Test Driven Development: By Example
The Art of Unit Testing: With Examples in .NET


Generally speaking, how useful is it to read a book written for another language? Specifically, what about Python? Should one stick to language specific books? 

For example, a lot of people praise Design Patterns by the GOF, I've never read it because the model applies to other languages (after all Python is about anti-patterns, right?) yet I feel the urge to because of it's place in the CS literature cannon. 

Likewise, would The Art of Unit Testing: With Examples in .NET help a Python programmer learn unit testing even though the examples are in .Net? 
",Jason Wirth,https://programmers.stackexchange.com/users/21104,"Absolutely! It's actually very helpful to break away from your primary language occasionally because this lets you see programming concepts through a different lens which will allow you to gain new perspectives. 

What makes any software good, or high quality is never about the syntax or language of choice.  It's how that language is applied. Steve McConnell calls this programming into a language instead of programming in a language. 

McConnell wrote Code Complete, a book I highly recommend. He makes a specific note why the examples are in many different languages. One of the reasons is he wants the reader to focus on the concepts he is illustrating and not on the syntax.

The books in your list describes general concepts that would certainly be useful to any programmer, regardless of their language of choice.

Starting out you do want to focus on just being able to write code that compiles. It doesn't take very long to learn the syntax of a given language and with documentation and intellisense this takes even more away from how much you have to actually remember. Most languages can be learned within a few months. However, writing high quality software is a discipline and craftsmanship that takes years of practice and experience and even then there will always be room for improvement. Learning about design concepts such as how to make your software more testable, modular, loosely coupled etc. will open your eyes on how you look at code in general.

When you stop caring about syntax and can see code through a neutral lens then this will truly benefit you as a programmer.
",Despertar,https://programmers.stackexchange.com/users/47756,http://programmers.stackexchange.com/questions/195625/are-programming-books-in-other-languages-useful-for-python,TECHNOLOGY,programmers.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Are programming books in other languages useful for Python?,"I'm a self-taught intermediate Python programmer; I frequently come across popular books on software development and programming written in other languages (often Java). 

Typical examples:


Refactoring: Improving the Design of Existing Code
Design Patterns, Gang of Four
Test Driven Development: By Example
The Art of Unit Testing: With Examples in .NET


Generally speaking, how useful is it to read a book written for another language? Specifically, what about Python? Should one stick to language specific books? 

For example, a lot of people praise Design Patterns by the GOF, I've never read it because the model applies to other languages (after all Python is about anti-patterns, right?) yet I feel the urge to because of it's place in the CS literature cannon. 

Likewise, would The Art of Unit Testing: With Examples in .NET help a Python programmer learn unit testing even though the examples are in .Net? 
","Absolutely! It's actually very helpful to break away from your primary language occasionally because this lets you see programming concepts through a different lens which will allow you to gain new perspectives. 

What makes any software good, or high quality is never about the syntax or language of choice.  It's how that language is applied. Steve McConnell calls this programming into a language instead of programming in a language. 

McConnell wrote Code Complete, a book I highly recommend. He makes a specific note why the examples are in many different languages. One of the reasons is he wants the reader to focus on the concepts he is illustrating and not on the syntax.

The books in your list describes general concepts that would certainly be useful to any programmer, regardless of their language of choice.

Starting out you do want to focus on just being able to write code that compiles. It doesn't take very long to learn the syntax of a given language and with documentation and intellisense this takes even more away from how much you have to actually remember. Most languages can be learned within a few months. However, writing high quality software is a discipline and craftsmanship that takes years of practice and experience and even then there will always be room for improvement. Learning about design concepts such as how to make your software more testable, modular, loosely coupled etc. will open your eyes on how you look at code in general.

When you stop caring about syntax and can see code through a neutral lens then this will truly benefit you as a programmer.
"
3564,3564,5698,Windows Store Metro APP how to adapt to screen size,"I would like to know how to have my Metro Windows 8 app to adapt to the screen size.
In other term : a somewhat responsive design.

Using the simulator via Visual Studio 2013, I can test multiple screen and it seems my app is not behaving correctly at all.

I also used the simulator to see how some of Windows 8/8.1 built-in apps behaved : it's splendid and clean.

How can I achieve this much ?

I already found a partial answer for my grid : Windows 8 App Screen Layout

but it is not enough.

This picture shows what I am trying to do : 

http://image.noelshack.com/fichiers/2014/49/1417438224-stack.png

I need to keep that layout, in landscape mode preferably, whatever the screen solution is.

In Windows Phone, it seems to work like a charm : no need to do anything.

Thanks for the help !
",Mackovich,https://stackoverflow.com/users/3535408,"It's very basic XAML knowlege.

&lt;Grid&gt;
    &lt;Grid.ColumnDefinitions&gt;
    &lt;ColumnDefinition Width=""*""/&gt;
    &lt;ColumnDefinition Width=""Auto""/&gt;
    &lt;ColumnDefinition Width=""*""/&gt;
    &lt;/Grid.ColumnDefinitions&gt;
    &lt;Grid.RowDefinitions&gt;
    &lt;RowDefinition Height=""*""/&gt;
    &lt;RowDefinition Height=""Auto""/&gt;
    &lt;RowDefinition Height=""*""/&gt;
    &lt;/Grid.RowDefinitions&gt;


// Grid.Row=""1"" Grid.Column=""1"" - your grid with Login/Password. Use VerticalAligment=""Center"", HorizontalAligment=""Center"" 

// Grid.Row=""2"" Grid.Column=""2"" - your register button. Use VerticalAligment=""Bottom"", HorizontalAligment=""Right""

&lt;/Grid&gt;


Personally I'll recomment you to place ""Register"" button as link under ""Login"" button.
",crea7or,https://stackoverflow.com/users/1051830,http://stackoverflow.com/questions/27228900/windows-store-metro-app-how-to-adapt-to-screen-size,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.7333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,How the windows store Metro App adapts to screen size,"I would like to know how to have my Metro Windows 8 app to adapt to the screen size.
In other term : a somewhat responsive design.

Using the simulator via Visual Studio 2013, I can test multiple screen and it seems my app is not behaving correctly at all.

I also used the simulator to see how some of Windows 8/8.1 built-in apps behaved : it's splendid and clean.

How can I achieve this much ?

I already found a partial answer for my grid : Windows 8 App Screen Layout

but it is not enough.

This picture shows what I am trying to do : 

http://image.noelshack.com/fichiers/2014/49/1417438224-stack.png

I need to keep that layout, in landscape mode preferably, whatever the screen solution is.

In Windows Phone, it seems to work like a charm : no need to do anything.

Thanks for the help !
","It's very basic XAML knowlege.

&lt;Grid&gt;
    &lt;Grid.ColumnDefinitions&gt;
    &lt;ColumnDefinition Width=""*""/&gt;
    &lt;ColumnDefinition Width=""Auto""/&gt;
    &lt;ColumnDefinition Width=""*""/&gt;
    &lt;/Grid.ColumnDefinitions&gt;
    &lt;Grid.RowDefinitions&gt;
    &lt;RowDefinition Height=""*""/&gt;
    &lt;RowDefinition Height=""Auto""/&gt;
    &lt;RowDefinition Height=""*""/&gt;
    &lt;/Grid.RowDefinitions&gt;


// Grid.Row=""1"" Grid.Column=""1"" - your grid with Login/Password. Use VerticalAligment=""Center"", HorizontalAligment=""Center"" 

// Grid.Row=""2"" Grid.Column=""2"" - your register button. Use VerticalAligment=""Bottom"", HorizontalAligment=""Right""

&lt;/Grid&gt;


Personally I'll recomment you to place ""Register"" button as link under ""Login"" button.
"
813,813,1289,Refinance FHA 203k to conventional,"I am thinking of getting a streamlined FHA 203k loan for a home. The loan is for $101,300. The best offer I could find is 4% interest, but because of required insurance fees, I would pay $630.13 a month for 360 months. In the end, I will end up paying $226,846.8. I was told that after a year I could refinance to a conventional loan with a lower rate (currently at 3.75%) and ditch the mandatory FHA mortgage insurance fee (currently $113.05).

Assuming the interest would be lower than what I have now 4%, hopefully staying at 3.75%, would it be wise to refinance after a year so I can loose the $113.05 required mortgage insurance fee and hopefully lower my monthly payments or just keep the loan as it is. Since I guess the new refinance will take into account the original loan amount plus the interest. Please correct me if I am wrong. There is a $25 Hazard insurance fee in the monthly payment which I doubt I can get rid of.
",Rick,https://money.stackexchange.com/users/5730,"There is no guarantee that interest rates will stay at their historic lows. The Federal Reserve is ending their bond buying program, so rates will likely rise. It's also possible that for any number of reasons your home may lose value in the next year, so you won't be able to sell or refinance for several years more.

As with any market, you should make your decision based on the fundamental value of the deal to you personally, and you should not depend on being able to make a deal or refinance in the future. During the years that the housing bubble was inflating very few were considering what a downturn in the market would mean for them and the loans they couldn't afford.
",Nathan L,https://money.stackexchange.com/users/12089,http://money.stackexchange.com/questions/39190/refinance-fha-203k-to-conventional,LIFE_ARTS,money.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Refinance FHA 203K to traditional,"I am thinking of getting a streamlined FHA 203k loan for a home. The loan is for $101,300. The best offer I could find is 4% interest, but because of required insurance fees, I would pay $630.13 a month for 360 months. In the end, I will end up paying $226,846.8. I was told that after a year I could refinance to a conventional loan with a lower rate (currently at 3.75%) and ditch the mandatory FHA mortgage insurance fee (currently $113.05).

Assuming the interest would be lower than what I have now 4%, hopefully staying at 3.75%, would it be wise to refinance after a year so I can loose the $113.05 required mortgage insurance fee and hopefully lower my monthly payments or just keep the loan as it is. Since I guess the new refinance will take into account the original loan amount plus the interest. Please correct me if I am wrong. There is a $25 Hazard insurance fee in the monthly payment which I doubt I can get rid of.
","There is no guarantee that interest rates will stay at their historic lows. The Federal Reserve is ending their bond buying program, so rates will likely rise. It's also possible that for any number of reasons your home may lose value in the next year, so you won't be able to sell or refinance for several years more.

As with any market, you should make your decision based on the fundamental value of the deal to you personally, and you should not depend on being able to make a deal or refinance in the future. During the years that the housing bubble was inflating very few were considering what a downturn in the market would mean for them and the loans they couldn't afford.
"
5690,5690,9020,Open problems/questions in representation theory and around?,"What are open problems in representation theory?

What are the sources (books/papers/sites) discussing this?

Any kinds of problems/questions are welcome - big/small, vague/concrete.
Some estimation of difficulty and importance, as well as, small description, prerequisites and relevant references, ... are welcome.



To the best of my knowledge, there are NO good lists of representation theory problems on the web. E.g. the sites below contain lots of unsolved problem in other areas, but not in representation theory:

http://en.wikipedia.org/wiki/Unsolved_problems_in_mathematics

http://garden.irmacs.sfu.ca/

http://maven.smith.edu/~orourke/TOPP/

MO questions also discuss other fields, but not representation theory:

What are the big problems in probability theory?

What are some open problems in algebraic geometry?

What are some open problems in toric varieties?

More open problems

Open problems with monetary rewards

Open problems in Euclidean geometry?

Open Questions in Riemannian Geometry

What are some of the big open problems in 3-manifold theory?

Open problems in continued fractions theory
",Alexander Chervov,https://mathoverflow.net/users/10446,"There are many open problems on modular representation theory of finite groups. There is a well-known list of problems of R. Brauer which date to around 1960, about ordinary and modular representations of finite groups. There are other major conjectures ( Broue's Abelian defect group conjecture has already been mentioned in comments). There are Alperin's Weight conjecture, Dade's Projective Conjecture, the Isaacs-Navarro conjecture, and several related conjectures. This is only the tip of the iceberg (and only in one corner of representation theory).
",Geoff Robinson,https://mathoverflow.net/users/14450,http://mathoverflow.net/questions/96202,SCIENCE,mathoverflow.net,1.0,0.3333333333333333,1.0,0.0,1.0,0.0,0.6666666666666666,0.8333333333333334,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,0.6,0.0,0.0,0.0,0.6666666666666666,Open questions in representative theory?,"What are open problems in representation theory?

What are the sources (books/papers/sites) discussing this?

Any kinds of problems/questions are welcome - big/small, vague/concrete.
Some estimation of difficulty and importance, as well as, small description, prerequisites and relevant references, ... are welcome.



To the best of my knowledge, there are NO good lists of representation theory problems on the web. E.g. the sites below contain lots of unsolved problem in other areas, but not in representation theory:

http://en.wikipedia.org/wiki/Unsolved_problems_in_mathematics

http://garden.irmacs.sfu.ca/

http://maven.smith.edu/~orourke/TOPP/

MO questions also discuss other fields, but not representation theory:

What are the big problems in probability theory?

What are some open problems in algebraic geometry?

What are some open problems in toric varieties?

More open problems

Open problems with monetary rewards

Open problems in Euclidean geometry?

Open Questions in Riemannian Geometry

What are some of the big open problems in 3-manifold theory?

Open problems in continued fractions theory
","Many problems in the theory of modular representation of finite groups are open. There is a well-known list of R. Brauer's general and modular representations of finite groups, which can be traced back to about 1960. There are other main conjectures (broue's commutative defect group conjecture has been mentioned in the comments). There are Alperin's weight conjecture, Dade's projection conjecture, Isaac Navarro conjecture and some related conjectures. It's just the tip of the iceberg."
4134,4134,6598,50v capacitor in a 40v circuit,"I am Making a Power Supply, There is a 40v rail that needs a 10000uf cap, I was wondering if it is safe to use a 50v rated cap, Should i be worried that it is close to the Limit? The Brand of the capacitor is Elna. 
",liljoey112,https://electronics.stackexchange.com/users/46976,"Under full load you're close to 40V peak- you need to allow for high mains voltage and transformer regulation (voltage will rise under light load). 

50V should just be okay if transformer regulation is good (usually is for larger transformers). Elna is a good brand.
",Spehro Pefhany,https://electronics.stackexchange.com/users/35530,http://electronics.stackexchange.com/questions/182577/50v-capacitor-in-a-40v-circuit,TECHNOLOGY,electronics.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.5,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,50V capacitor in 40V circuit,I'm making a power supply. A 40V track needs a 10000uf cover. I want to know if it's safe to use a 50V rated cover. Should I worry about it approaching the limit? The brand of capacitor is Elna.,"At full load, you are close to 40V peak - you need to consider high supply voltage and transformer regulation (voltage will rise light load)."
984,984,1556,Real norms on vector spaces over finite fields,"I am interested in functions of the form $\psi: F^n \to \mathbb{R}^+$, where $F$ is a finite field, that have norm-like properties, e.g., $\psi(x+y) \le \psi(x) + \psi(y)$. Does anybody know if there is any literature on this area?
",Manos,https://math.stackexchange.com/users/11921,"The triangle inequality might allow some interesting functions, but positive homogeneity doesn't. A finite field has a prime characteristic, $p$. Positive homogeneity says $\psi(rx)=|r|\psi(x)$ for $r\in\mathbb{Q}$. To satisfy this property, $\psi(0)=\psi(px)=p\psi(x)$, which first says $\psi(0)=0$ and then $\psi(x)=0$ for all $x\in F$.
",robjohn,https://math.stackexchange.com/users/13854,http://math.stackexchange.com/questions/60015/real-norms-on-vector-spaces-over-finite-fields,SCIENCE,math.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,Real norm of vector space over finite field,"I'm interested in functions in the form $\ psi: f ^ n \ to \ mathbb {r} ^ + $, where $f $is a finite field with properties similar to the norm, such as $\ psi (x + y) / Le \ psi (x) + \ psi (y) $. Does anyone know if there is any literature on this?","The triangle inequality might allow some interesting functions, but positive homogeneity doesn't. A finite field has a prime characteristic, $p$. Positive homogeneity says $\psi(rx)=|r|\psi(x)$ for $r\in\mathbb{Q}$. To satisfy this property, $\psi(0)=\psi(px)=p\psi(x)$, which first says $\psi(0)=0$ and then $\psi(x)=0$ for all $x\in F$.
"
2200,2200,3507,hasoptedoutoffax field error on javascript remoting,"I'm getting the following error stating this is no field HasOptedOutOfFax for the Contact object, updating a contact using Javascript Remoting, I checked and that appears to be the correct field name:

[Error] Visualforce Remoting Exception: No such column 'HasOptedOutOfFax' on sobject of type Contact Object
    (anonymous function) (cordova, line 5180)
    error (VFRemote.js, line 116)
    (anonymous function) (VFRemote.js, line 132)
    fire (VFRemote.js, line 52)
    fireEvent (VFRemote.js, line 47)
    onProviderData (VFRemote.js, line 86)
    fire (VFRemote.js, line 52)
    fireEvent (VFRemote.js, line 47)
    onData (VFRemote.js, line 94)
    handleResponse (VFRemote.js, line 75)
    a (VFRemote.js, line 39)
    (anonymous function) (VFRemote.js, line 40)


EDIT: got this error again, seems to not be a one time random occurance.Here's the contact being saved from the javascript console:

AccountId: ""001i000000Viql2AAB""
Birthdate: ""1407456000000""
CreatedById: ""005i0000001xZVvAAM""
CreatedDate: 1407334537000
Department: ""Dept""
Description: ""Some desc""
DoNotCall: true
Email: ""aa@aa.com""
FirstName: ""test""
HasOptedOutOfEmail: false
HasOptedOutOfFax: false
HomePhone: ""4444444444""
Id: ""003i000001B0DssAAF""
IsDeleted: false
LastModifiedById: ""005i0000001xZVvAAM""
LastModifiedDate: 1407335320000
LastName: ""iphone1""
LastReferencedDate: 1407354811000
LastViewedDate: 1407354811000
MailingStreet: ""123 my street""
Name: ""iphone1""
OwnerId: ""005i0000001xZVvAAM""
RecordTypeId: ""012i00000019wOfAAI""
SystemModstamp: 1407335320000

",Phil B,https://salesforce.stackexchange.com/users/657,"Perhaps for some historical reason, Salesforce defaults the ""Contact Field-Level Security"" for that field and a few others to not visible in all profiles.

If you want to use that field you need to edit the profile or permission set that the User you are making the request via is using to make that field visible and not read-only.
",Keith C,https://salesforce.stackexchange.com/users/887,http://salesforce.stackexchange.com/questions/44322/hasoptedoutoffax-field-error-on-javascript-remoting,TECHNOLOGY,salesforce.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,1.0,Error in the hasopteoutofax field during JavaScript Remoting,"I'm getting the following error stating this is no field HasOptedOutOfFax for the Contact object, updating a contact using Javascript Remoting, I checked and that appears to be the correct field name:

[Error] Visualforce Remoting Exception: No such column 'HasOptedOutOfFax' on sobject of type Contact Object
    (anonymous function) (cordova, line 5180)
    error (VFRemote.js, line 116)
    (anonymous function) (VFRemote.js, line 132)
    fire (VFRemote.js, line 52)
    fireEvent (VFRemote.js, line 47)
    onProviderData (VFRemote.js, line 86)
    fire (VFRemote.js, line 52)
    fireEvent (VFRemote.js, line 47)
    onData (VFRemote.js, line 94)
    handleResponse (VFRemote.js, line 75)
    a (VFRemote.js, line 39)
    (anonymous function) (VFRemote.js, line 40)


EDIT: got this error again, seems to not be a one time random occurance.Here's the contact being saved from the javascript console:

AccountId: ""001i000000Viql2AAB""
Birthdate: ""1407456000000""
CreatedById: ""005i0000001xZVvAAM""
CreatedDate: 1407334537000
Department: ""Dept""
Description: ""Some desc""
DoNotCall: true
Email: ""aa@aa.com""
FirstName: ""test""
HasOptedOutOfEmail: false
HasOptedOutOfFax: false
HomePhone: ""4444444444""
Id: ""003i000001B0DssAAF""
IsDeleted: false
LastModifiedById: ""005i0000001xZVvAAM""
LastModifiedDate: 1407335320000
LastName: ""iphone1""
LastReferencedDate: 1407354811000
LastViewedDate: 1407354811000
MailingStreet: ""123 my street""
Name: ""iphone1""
OwnerId: ""005i0000001xZVvAAM""
RecordTypeId: ""012i00000019wOfAAI""
SystemModstamp: 1407335320000

","Perhaps for some historical reason, Salesforce defaults the ""Contact Field-Level Security"" for that field and a few others to not visible in all profiles.

If you want to use that field you need to edit the profile or permission set that the User you are making the request via is using to make that field visible and not read-only.
"
5681,5681,9008,"How do you pronounce ""but""?","In which context do you use the stressed bÊt and when do you use the unstressed bÉt? How often is that?
If you know about the website www.forvo.com, I think it's a shortcoming that speakers use only one of the two versions. 
",Theta30,https://english.stackexchange.com/users/5249,"Your question is related to phonology.

Usually all words have a stressed syllable, those who don't have such feature are usually monosyllables (they are typically function words or grammatical words/particles), and so they have a weak form and a strong form.

Those words are (I'll paste it from Wikipedia because I don't remember them all):


  a, am, an, and, are, as, at, be, been, but, can, could, do, does, for, from, had, has, have, he, her, him, his, just, me, must, of, shall, she, should, some, than, that, the, them, there, to, us, was, we, were, who, would, you


As you can see, ""but"" is on the list. The pronunciations you listed for it, [bÊt] and [bÉt], are respectively the strong form and the weak form.

Now, I don't remember exactly all the cases (I should look back in my notes because I did this at university), but usually the weak form is used in normal speech, unless you emphasize it then you use the strong form. Another distinction is between ""particle used at the end of the sentence"" vs. ""particle used before a noun"", for example:

I found what I'm looking for. --> [fÉË(r)]
I'm looking for money. ---------> [fÉ(r)]

Look here if you want to hear the pronunciation. (Check the BrE one, it gives the idea better.)
",Alenanno,https://english.stackexchange.com/users/6550,http://english.stackexchange.com/questions/21516/how-do-you-pronounce-but,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.6666666666666666,1.0,"How do you pronounce ""but""?","In which context do you use the stressed bÊt and when do you use the unstressed bÉt? How often is that?
If you know about the website www.forvo.com, I think it's a shortcoming that speakers use only one of the two versions. 
","Your question is related to phonology.

Usually all words have a stressed syllable, those who don't have such feature are usually monosyllables (they are typically function words or grammatical words/particles), and so they have a weak form and a strong form.

Those words are (I'll paste it from Wikipedia because I don't remember them all):


  a, am, an, and, are, as, at, be, been, but, can, could, do, does, for, from, had, has, have, he, her, him, his, just, me, must, of, shall, she, should, some, than, that, the, them, there, to, us, was, we, were, who, would, you


As you can see, ""but"" is on the list. The pronunciations you listed for it, [bÊt] and [bÉt], are respectively the strong form and the weak form.

Now, I don't remember exactly all the cases (I should look back in my notes because I did this at university), but usually the weak form is used in normal speech, unless you emphasize it then you use the strong form. Another distinction is between ""particle used at the end of the sentence"" vs. ""particle used before a noun"", for example:

I found what I'm looking for. --> [fÉË(r)]
I'm looking for money. ---------> [fÉ(r)]

Look here if you want to hear the pronunciation. (Check the BrE one, it gives the idea better.)
"
5966,5966,9456,How to center and fill main in html/css?,"I am trying to create a website that looks as following: http://i.stack.imgur.com/9YHAs.jpg
The header is working, but I cannot get the ""main"" to work and tried several options. I tried to float a png as image-background to the center and also tried with display:inline-block and background-color:white. My code is as following:

HTML:    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
        &lt;head&gt;
            &lt;title&gt;Home - Portfolio Daniek&lt;/title&gt;
            &lt;link rel=""stylesheet"" type=""text/css"" href=""normalize.css""&gt;
            &lt;link rel=""stylesheet"" type=""text/css"" href=""stylesheet.css""&gt;
            &lt;script src=""http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""&gt;&lt;/script&gt;
            &lt;script src=""menutoggle.js""&gt;&lt;/script&gt;
            &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1, maximum-scale=1""&gt;
        &lt;/head&gt;
        &lt;body class=""index""&gt;
            &lt;nav class=""clearfix""&gt;
                &lt;ul class=""clearfix""&gt;
                    &lt;li&gt;&lt;a href=""index.html""&gt;Home&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=""about.html""&gt;Over&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=""portfolio.html""&gt;Portfolio&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=""contact.html""&gt;Contact&lt;/a&gt;&lt;/li&gt;
                &lt;/ul&gt;
            &lt;a href=""#"" id=""pull""&gt;Menu&lt;/a&gt;
        &lt;/nav&gt;
        &lt;main class=""bg""&gt;
            &lt;p&gt;Hi&lt;/p&gt;
        &lt;/main&gt;
        &lt;/body&gt;
CSS:
    .bg {
        margin-top: 10%;
        margin-left: auto;
        margin-right: auto;
        width: 90%;
        height: 90%;
        color: white;
        background-image: url('bg.png');
    }


Anybody got any solutions how to get this to work?
",Daniek Schuiling,https://stackoverflow.com/users/4162900,"this Is a basic example of how one would do this:



body{background:url('http://jasonlefkowitz.net/wp-content/uploads/2013/07/Cute-Cats-cats-33440930-1280-800.jpg') no-repeat; background-size:100%; margin:0; overflow:hidden}
header{height:80px;width:100%; background:grey}
#main{width:90%; height:90%; position:absolute; background:rgba(255,255,255,0.5); margin:5%;}
&lt;body&gt;&lt;header&gt;&lt;/header&gt;&lt;div id=""main""&gt;&lt;/div&gt;&lt;/body&gt;



Click on the ""Full Page"" option to see how it would look

In your example you are using background-color:white, with that you could use opacity:0.5 but that would make everything in main translucent. when you want transparencyhtml backgrounds use rgba. 50% transparency white in rgba: background-color:rgba(255,255,255,0.5)
",DividedByZero,https://stackoverflow.com/users/3549636,http://stackoverflow.com/questions/26471310/how-to-center-and-fill-main-in-html-css,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.7777777777777778,0.6,1.0,0.0,0.0,0.6666666666666666,How to center main in HTML / CSS?,"I am trying to create a website that looks as following: http://i.stack.imgur.com/9YHAs.jpg
The header is working, but I cannot get the ""main"" to work and tried several options. I tried to float a png as image-background to the center and also tried with display:inline-block and background-color:white. My code is as following:

HTML:    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
        &lt;head&gt;
            &lt;title&gt;Home - Portfolio Daniek&lt;/title&gt;
            &lt;link rel=""stylesheet"" type=""text/css"" href=""normalize.css""&gt;
            &lt;link rel=""stylesheet"" type=""text/css"" href=""stylesheet.css""&gt;
            &lt;script src=""http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""&gt;&lt;/script&gt;
            &lt;script src=""menutoggle.js""&gt;&lt;/script&gt;
            &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1, maximum-scale=1""&gt;
        &lt;/head&gt;
        &lt;body class=""index""&gt;
            &lt;nav class=""clearfix""&gt;
                &lt;ul class=""clearfix""&gt;
                    &lt;li&gt;&lt;a href=""index.html""&gt;Home&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=""about.html""&gt;Over&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=""portfolio.html""&gt;Portfolio&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=""contact.html""&gt;Contact&lt;/a&gt;&lt;/li&gt;
                &lt;/ul&gt;
            &lt;a href=""#"" id=""pull""&gt;Menu&lt;/a&gt;
        &lt;/nav&gt;
        &lt;main class=""bg""&gt;
            &lt;p&gt;Hi&lt;/p&gt;
        &lt;/main&gt;
        &lt;/body&gt;
CSS:
    .bg {
        margin-top: 10%;
        margin-left: auto;
        margin-right: auto;
        width: 90%;
        height: 90%;
        color: white;
        background-image: url('bg.png');
    }


Anybody got any solutions how to get this to work?
","this Is a basic example of how one would do this:



body{background:url('http://jasonlefkowitz.net/wp-content/uploads/2013/07/Cute-Cats-cats-33440930-1280-800.jpg') no-repeat; background-size:100%; margin:0; overflow:hidden}
header{height:80px;width:100%; background:grey}
#main{width:90%; height:90%; position:absolute; background:rgba(255,255,255,0.5); margin:5%;}
&lt;body&gt;&lt;header&gt;&lt;/header&gt;&lt;div id=""main""&gt;&lt;/div&gt;&lt;/body&gt;



Click on the ""Full Page"" option to see how it would look

In your example you are using background-color:white, with that you could use opacity:0.5 but that would make everything in main translucent. when you want transparencyhtml backgrounds use rgba. 50% transparency white in rgba: background-color:rgba(255,255,255,0.5)
"
4187,4187,6678,Would it be a problem if all Amazon links were converted to affiliate links?,"I'm thinking that one way Jeff and the Stack Overflow team could squeeze some extra money out of this site would be to automatically convert all Amazon links posted here into affiliate links, e.g. Stick ""tag=codinghorror-20"" (or more likely a new site-specific tag) onto every Amazon link. This would bring in some additional revenue every time someone purchased a book via a link on this site. 

They could do similar things with other links as well. Amazon's simply the most obvious choice.

So my question is, would anyone have a problem with this?

I know I wouldn't mind, but I don't know how other people would react.

What does everyone think? Is this a horrible idea, a great idea, a waste of time?
",Derek Park,https://meta.stackexchange.com/users/159945,"I don't see this being a problem as long as terms &amp; conditions say that if anyone posts their own Amazon affiliate links they will be transformed to Stack Overflow links.
",Walter Rumsby,https://meta.stackexchange.com/users/145651,http://meta.stackexchange.com/questions/10948/would-it-be-a-problem-if-all-amazon-links-were-converted-to-affiliate-links,TECHNOLOGY,meta.stackexchange.com,1.0,0.7777777777777778,1.0,1.0,0.0,0.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,Would it be a problem if all Amazon links were converted to affiliate links?,"I think one way Jeff and the stack overflow team can squeeze some extra money out of this site is to automatically convert all Amazon links published here into affiliate links, such as ""tag = codinghorror-20"" (or more likely a new site-specific tag) on each Amazon link. This will bring some extra revenue, with one book being purchased each time through a link to the site.","I don't think it's a problem, as long as the terms and conditions say that if someone posts their Amazon affiliate links, they will convert them to stack overflow links."
1319,1319,2084,Are comments considered a form of documentation?,"When I am writing small scripts for myself, I stack my code high with comments (sometimes I comment more than I code). A lot of people I talk to say that I should be documenting these scripts, even though they are personal, so that if I ever do sell them, I would be ready. But aren't comments a form of documentation?

Wouldn't this:

$foo = ""bar""; # this is a comment
print $foo; # this prints ""bar""


be considered documentation, especially if a developer is using my code? Or is documentation considered to be outside of the code itself?
",Dynamic,https://programmers.stackexchange.com/users/34364,"They are a form of documentation, but remember that documentation is in the eye of the beholder....


For some, self documenting code is enough.  But that assumes a level of technical detail as the customer.  We should be careful thinking that this is enough, because our ego may tell us ""It is obvious what this code is doing"" but time can prove otherwise.  It also assumes you know in advance the skills of the reader.
For those looking at source code but with less technical expertise, comments could be ok.  But that assumes someone is looking at the source code.
If you're technical, but lacking the time to read all the source code, a technical manual could be what's required.
An if the user lacks technical skills, but just needs to know what is happening, user documentation is what's needed.


So the real question is who is your customer?  If you are, then self documenting code or comments is enough.  If it's for someone else, you might want to broaden how you document.
",MathAttack,https://programmers.stackexchange.com/users/46338,http://programmers.stackexchange.com/questions/148471/are-comments-considered-a-form-of-documentation,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,0.7777777777777778,Is the comment considered a document form?,"When I write small scripts for myself, I use comments (sometimes I have more than my code) to pile up the code very high. A lot of people I talked to said that I should record these scripts, even if they are personal, so if I really sell them, I'll be ready. But isn't comment a form of documentation?","They are a form of documentation, but remember that documentation is in the eye of the beholder....


For some, self documenting code is enough.  But that assumes a level of technical detail as the customer.  We should be careful thinking that this is enough, because our ego may tell us ""It is obvious what this code is doing"" but time can prove otherwise.  It also assumes you know in advance the skills of the reader.
For those looking at source code but with less technical expertise, comments could be ok.  But that assumes someone is looking at the source code.
If you're technical, but lacking the time to read all the source code, a technical manual could be what's required.
An if the user lacks technical skills, but just needs to know what is happening, user documentation is what's needed.


So the real question is who is your customer?  If you are, then self documenting code or comments is enough.  If it's for someone else, you might want to broaden how you document.
"
498,498,778,How do I grep for foo && !bar?,"I want to output all the lines in my source code which contain the string foo but don't contain the string bar.  I tried this:

find . -name ""*.[hc]pp"" | xargs grep -n foo | grep -x bar 


However this doesn't work as I expected. How can I use grep in this way?
",kfmfe04,https://superuser.com/users/44582,"You want the -v flag, not the -x flag.

Mnemonic: negative.
",Laurence Gonsalves,https://superuser.com/users/13190,http://superuser.com/questions/363762,TECHNOLOGY,superuser.com,0.7777777777777778,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How can I do for foo & & & & &! Bar?,"I want to output all the lines in my source code which contain the string foo but don't contain the string bar.  I tried this:

find . -name ""*.[hc]pp"" | xargs grep -n foo | grep -x bar 


However this doesn't work as I expected. How can I use grep in this way?
","You want the -v flag, not the -x flag.

Mnemonic: negative.
"
2890,2890,4597,Adjustable sample size in clinical trial,"Most clinical trials I see have a fixed sample size.  In some cases they have prior data that allows estimating the effect size and the variance or distribution of values, and calculate the sample size from that for a certain power.  In other cases it is just a guess.

Why wouldn't people run a clinical trial in which the sample size was determined during the trial?  (for example, by increasing it until the confidence interval narrowed to a certain size specified in advance)  Is there any reason this would not be a valid design?  Are there any examples of trials like that, and any references for designing a trial like that?
",Alex I,https://stats.stackexchange.com/users/43106,"Ideally that's the point of a Phase II trial. Results from these studies, often single-arm in design, are used for power calculations. Sometimes they experiment with dosing and eligibility criteria, the more moving parts in a Phase II study, the more of a gamble a Phase III study will be.

If a compound is showing to be promising a Data Monitoring Committee might recommend increasing enrollment or decreasing it appropriately. Sometimes it's about the risk of harm. If a compound is underpowered because the effect is not as powered as it was hoped to be, the DMC may end the study since the study subjects, by virtue of participating in the study, are exposing themselves to risk. Studies cannot go on perpetually as a matter of ethics.

Indeed there is a whole field of sequential adaptive trials that allows researchers to seamlessly transition from Phase II to Phase III studies. The statistical software package SeqTrial in S+ from Scott Emerson allows you to perform sample size calculations for a variety of alpha spending rules and effect sizes. 

The FDA's overreliance on ""traditional"" statistics is pretty against it, as it can affect the integrity of findings. It's actually a good principle in this case, and Tom Fleming has rallied against it in his paper ""Discerning Hype From Substance."" Basically, collating Phase II and Phase III study findings is rarely if ever appropriate, even when the protocols are similar (identical) between II and III. This is because the Phase III study only happened because Phase II looks/looked promising. So selection bias will affect the validity of those aggregated findings.
",AdamO,https://stats.stackexchange.com/users/8013,http://stats.stackexchange.com/questions/159373/adjustable-sample-size-in-clinical-trial,SCIENCE,stats.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Adjustable sample size in clinical trials,"Most clinical trials I see have a fixed sample size.  In some cases they have prior data that allows estimating the effect size and the variance or distribution of values, and calculate the sample size from that for a certain power.  In other cases it is just a guess.

Why wouldn't people run a clinical trial in which the sample size was determined during the trial?  (for example, by increasing it until the confidence interval narrowed to a certain size specified in advance)  Is there any reason this would not be a valid design?  Are there any examples of trials like that, and any references for designing a trial like that?
","Ideally that's the point of a Phase II trial. Results from these studies, often single-arm in design, are used for power calculations. Sometimes they experiment with dosing and eligibility criteria, the more moving parts in a Phase II study, the more of a gamble a Phase III study will be.

If a compound is showing to be promising a Data Monitoring Committee might recommend increasing enrollment or decreasing it appropriately. Sometimes it's about the risk of harm. If a compound is underpowered because the effect is not as powered as it was hoped to be, the DMC may end the study since the study subjects, by virtue of participating in the study, are exposing themselves to risk. Studies cannot go on perpetually as a matter of ethics.

Indeed there is a whole field of sequential adaptive trials that allows researchers to seamlessly transition from Phase II to Phase III studies. The statistical software package SeqTrial in S+ from Scott Emerson allows you to perform sample size calculations for a variety of alpha spending rules and effect sizes. 

The FDA's overreliance on ""traditional"" statistics is pretty against it, as it can affect the integrity of findings. It's actually a good principle in this case, and Tom Fleming has rallied against it in his paper ""Discerning Hype From Substance."" Basically, collating Phase II and Phase III study findings is rarely if ever appropriate, even when the protocols are similar (identical) between II and III. This is because the Phase III study only happened because Phase II looks/looked promising. So selection bias will affect the validity of those aggregated findings.
"
2178,2178,3470,"apache error and access logs are missing, what could be the cause and how can I recreate them?","I've been given a task to understand why 2 CentOS web servers running apache 2.2.3 are experiencing very high loads on specific occasions.
The first thing I checked was /var/log/messages but then I realized that rsyslog is turned off for some reason, so I started it and turned it on using chkconfig.
Then, I wanted to check apache error and access logs, so I browsed to /var/log/httpd but found the folder to be empty.
I've checked /etc/httpd/conf/httpd.conf and saw these lines:

ErrorLog logs/error_log
CustomLog logs/access_log combined


As far as I know it refers to /var/log/httpd/ but as said before the folder is empty.
While writing this question I've looked for the httpd version on the server and ran httpd -v and that's the response I got:

[root@domU-IP httpd]# httpd -v
Server version: Apache/2.2.3
Server built:   May  4 2011 06:51:15
Unable to open logs


My questions are:

 1. What could cause the logs to disappear? (It is possible they were never created in the first place)
 2. How can I recreate the logs and make sure data is written to them?
 3. Which permissions should be set on `/var/log/httpd`? (current permissions are: drwx------ 2 root root)


Thanks in advance
",Itai Ganot,https://serverfault.com/users/109833,"When path references in an Apache configuration are not absolute (i.e. don't start with /) they are relative to the directory set in the ServerRoot directive. A common default for the ServerRoot is  /etc/httpd making /etc/httpd/logs your log directory. 

Most packaged Apache versions create a symbolic link from /etc/httpd/logs to /var/log/httpd. Either the actual directory in /etc/httpd is missing (or the root filesystem is full) or the symbolic link may be missing in your setup.

Apache gets started by root and opens the log files as root before dropping privileges so those directory permissions on /var/log/httpd seem correct. 
",HBruijn,https://serverfault.com/users/37681,http://serverfault.com/questions/610620,TECHNOLOGY,serverfault.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,1.0,Apache errors and access logs are missing. What are the possible reasons and how to recreate them?,"I've been given a task to understand why 2 CentOS web servers running apache 2.2.3 are experiencing very high loads on specific occasions.
The first thing I checked was /var/log/messages but then I realized that rsyslog is turned off for some reason, so I started it and turned it on using chkconfig.
Then, I wanted to check apache error and access logs, so I browsed to /var/log/httpd but found the folder to be empty.
I've checked /etc/httpd/conf/httpd.conf and saw these lines:

ErrorLog logs/error_log
CustomLog logs/access_log combined


As far as I know it refers to /var/log/httpd/ but as said before the folder is empty.
While writing this question I've looked for the httpd version on the server and ran httpd -v and that's the response I got:

[root@domU-IP httpd]# httpd -v
Server version: Apache/2.2.3
Server built:   May  4 2011 06:51:15
Unable to open logs


My questions are:

 1. What could cause the logs to disappear? (It is possible they were never created in the first place)
 2. How can I recreate the logs and make sure data is written to them?
 3. Which permissions should be set on `/var/log/httpd`? (current permissions are: drwx------ 2 root root)


Thanks in advance
","When path references in an Apache configuration are not absolute (i.e. don't start with /) they are relative to the directory set in the ServerRoot directive. A common default for the ServerRoot is  /etc/httpd making /etc/httpd/logs your log directory. 

Most packaged Apache versions create a symbolic link from /etc/httpd/logs to /var/log/httpd. Either the actual directory in /etc/httpd is missing (or the root filesystem is full) or the symbolic link may be missing in your setup.

Apache gets started by root and opens the log files as root before dropping privileges so those directory permissions on /var/log/httpd seem correct. 
"
101,101,164,2 divs both 100% next to each other,"Quite simple question but tried about everything.

what i want is 2 (actually 5) divs next to eachother with the class ""container"" so i can make a horizontal 1page website. Each div has to be 100% wide. so 2 divs mean 2 screens next to eachother.

This is the css line i have now:

.container { width: 100%; float: left; display: inline; }


I cant get them to line up next to each other.

Here is a visual to make it more clear.

image url for bigger preview: http://www.luukratief.com/stackoverflow.png

The scrolling part is not the issue for me, just the placement of the divs.

Is this possible using percentages or is this simply not possible.
If so, please tell me how to do this with css.

Thanks in advance!
",Luuk,https://stackoverflow.com/users/691035,"You can make a container with 200% width and then put two divs inside of that element with 50% width so you will make sure that one div always gets the whole visitors screen width.

For example:

&lt;div class=""container""&gt;
    &lt;div class=""contentContainer""&gt;&lt;/div&gt;
    &lt;div class=""contentContainer""&gt;&lt;/div&gt;
&lt;/div&gt;


And CSS:

.container {
    width: 200%;
}

.contentContainer {
    width: 50%;
    float: left;
}

",Johan Davidsson,https://stackoverflow.com/users/734261,http://stackoverflow.com/questions/6597889/2-divs-both-100-next-to-each-other,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,"Two divs, two 100% together","Quite simple question but tried about everything.

what i want is 2 (actually 5) divs next to eachother with the class ""container"" so i can make a horizontal 1page website. Each div has to be 100% wide. so 2 divs mean 2 screens next to eachother.

This is the css line i have now:

.container { width: 100%; float: left; display: inline; }


I cant get them to line up next to each other.

Here is a visual to make it more clear.

image url for bigger preview: http://www.luukratief.com/stackoverflow.png

The scrolling part is not the issue for me, just the placement of the divs.

Is this possible using percentages or is this simply not possible.
If so, please tell me how to do this with css.

Thanks in advance!
","You can make a container with 200% width and then put two divs inside of that element with 50% width so you will make sure that one div always gets the whole visitors screen width.

For example:

&lt;div class=""container""&gt;
    &lt;div class=""contentContainer""&gt;&lt;/div&gt;
    &lt;div class=""contentContainer""&gt;&lt;/div&gt;
&lt;/div&gt;


And CSS:

.container {
    width: 200%;
}

.contentContainer {
    width: 50%;
    float: left;
}

"
1767,1767,2804,Simpler method to show $k(x)$ is NOT a primitive irreducible polynomial?,"Let $k(x) = x^2+2x+2$ be under $\mathbb Z_{11}[x]$. Determine if $k(x)$ is irreducible, and if so, determine if it is primitive.

Ok, I showed that $k(x)$ is irreducible since it it a quadratic and has no linear factors.

A field constructed with $k(x)$ would have order $11^2=121$...and so the multiplicative group would have $120$ elements. If $x$ generates this group under multiplication modulo $k(x)$, then I would know that $k(x)$ is primitive. However, I would have to calculate $x^1,x^2,...,x^{120}$ to show this...

I figured that it would be ridiculous for a question like this to result in $k(x)$ being primitive, but what if it were? Would I really have to calculate $x^1,x^2,...,x^{120}$ in order to demonstrate this? Is there a much more efficient way of solving a problem like this?
",Bobby Lee,https://math.stackexchange.com/users/122106,"A quadratic polynomial $k(x)\in\Bbb{Z}_{11}[x]$ is primitive, iff the (multiplicative) order of the coset
$$
\alpha=x+\langle k(x)\rangle
$$
in the field $\Bbb{Z}_{11}[x]/\langle k(x)\rangle=\Bbb{F}_{121}$ is $120$. By Lagrange's theorem the order is always a factor of $120$. Thus it is one of $\{1,2,3,4,5,6,8,10,12,15,20,24,30,40,60,120\}$. To speed up checking you can furthermore make the  observation that if $\alpha^{120/p}\neq1$ for all prime factors $p$ of $120$ (s0 $p=2,3$ or $5$), then the order has to be maximal, i.e. $\alpha$ is a primitive element (or $k(x)$ is a primitive polynomial). Of course, it may turn out that $\alpha$ is not primitive, in which case you will see evidence of this at some point.

In this task square-and-multiply is your friend. Do remember to use the equation
$$
k(\alpha)=0\Longleftrightarrow\alpha^2=-(2\alpha+2)=9\alpha+9
$$
in each step.
For example
$$
\begin{array}{rll}
\alpha^2&amp;=&amp;=-(2\alpha+2)\\
\alpha^4&amp;=(\alpha^2)^2=(2\alpha+2)^2=4\alpha^2+8\alpha+4&amp;=7
\end{array}
$$
I stop here, because we see that something slightly unexpected happened: $\alpha^4$ belongs to the prime field $\Bbb{Z}_{11}$. At this point I reveal that you can answer the question about primitivity simply by calculating the order of $7$ in the prime field. Leaving that to you!

With 20/20 hindsight we can see that the result about $\alpha^4$ is a consequence of the factorization (in $\Bbb{Z}_{11}[x]$ or actually already in $\Bbb{Z}[x]$)
$$
x^4+4=(x^4+4x^2+4)-4x^2=(x^2+2)^2-(2x)^2=(x^2+2x+2)(x^2-2x+2)
$$
showing that $k(x)$ is a factor of $x^4+4=x^4-7$.
",Jyrki Lahtonen,https://math.stackexchange.com/users/11619,http://math.stackexchange.com/questions/742706/simpler-method-to-show-kx-is-not-a-primitive-irreducible-polynomial,SCIENCE,math.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,A simple method to prove that $K (x) $is not a primitive irreducible polynomial?,"Let $k(x) = x^2+2x+2$ be under $\mathbb Z_{11}[x]$. Determine if $k(x)$ is irreducible, and if so, determine if it is primitive.

Ok, I showed that $k(x)$ is irreducible since it it a quadratic and has no linear factors.

A field constructed with $k(x)$ would have order $11^2=121$...and so the multiplicative group would have $120$ elements. If $x$ generates this group under multiplication modulo $k(x)$, then I would know that $k(x)$ is primitive. However, I would have to calculate $x^1,x^2,...,x^{120}$ to show this...

I figured that it would be ridiculous for a question like this to result in $k(x)$ being primitive, but what if it were? Would I really have to calculate $x^1,x^2,...,x^{120}$ in order to demonstrate this? Is there a much more efficient way of solving a problem like this?
","A quadratic polynomial $k(x)\in\Bbb{Z}_{11}[x]$ is primitive, iff the (multiplicative) order of the coset
$$
\alpha=x+\langle k(x)\rangle
$$
in the field $\Bbb{Z}_{11}[x]/\langle k(x)\rangle=\Bbb{F}_{121}$ is $120$. By Lagrange's theorem the order is always a factor of $120$. Thus it is one of $\{1,2,3,4,5,6,8,10,12,15,20,24,30,40,60,120\}$. To speed up checking you can furthermore make the  observation that if $\alpha^{120/p}\neq1$ for all prime factors $p$ of $120$ (s0 $p=2,3$ or $5$), then the order has to be maximal, i.e. $\alpha$ is a primitive element (or $k(x)$ is a primitive polynomial). Of course, it may turn out that $\alpha$ is not primitive, in which case you will see evidence of this at some point.

In this task square-and-multiply is your friend. Do remember to use the equation
$$
k(\alpha)=0\Longleftrightarrow\alpha^2=-(2\alpha+2)=9\alpha+9
$$
in each step.
For example
$$
\begin{array}{rll}
\alpha^2&amp;=&amp;=-(2\alpha+2)\\
\alpha^4&amp;=(\alpha^2)^2=(2\alpha+2)^2=4\alpha^2+8\alpha+4&amp;=7
\end{array}
$$
I stop here, because we see that something slightly unexpected happened: $\alpha^4$ belongs to the prime field $\Bbb{Z}_{11}$. At this point I reveal that you can answer the question about primitivity simply by calculating the order of $7$ in the prime field. Leaving that to you!

With 20/20 hindsight we can see that the result about $\alpha^4$ is a consequence of the factorization (in $\Bbb{Z}_{11}[x]$ or actually already in $\Bbb{Z}[x]$)
$$
x^4+4=(x^4+4x^2+4)-4x^2=(x^2+2)^2-(2x)^2=(x^2+2x+2)(x^2-2x+2)
$$
showing that $k(x)$ is a factor of $x^4+4=x^4-7$.
"
1997,1997,3190,Woocommerce: change user role after completing order,":)

I'm using wordpress with woocommerce, and I would like to automate the following step. When an order is completed, I would like to change the user role associated with that order id from 'customer' to 'subscriber'.



By searching around, I think I should be able to accomplish this by using a hook in functions.php:

add_action( 'woocommerce_order_status_completed', 'change_role_from_customer_to_subscriber' );


Then add the function:

function change_role_from_customer_to_subscriber($order_id){
// code to change role to subscriber
}


In the code, I think I need to do 2 things:
1) get the user id that is associated with that order id
2) change role of that user id to subscriber



I've tried a lot, but I couldn't get it to work (neither getting the right user id, nor changing the role of a user id). So any help would be appreciated! I've seen 2 related questions asked before on stack overflow, but unfortunately the answers there did not work for me. I hope someone can help me out!

Thanks a lot! :)


Edit:
Someone helped me out with the second part of the problem, so that's great news for me :)

Unfortunately, I still haven't figured out the first part: how to get the user id that is associated with the order id.
Any ideas?
",Rostam,https://wordpress.stackexchange.com/users/41126,"Looking through the code there is a very relevant example:

function woocommerce_paying_customer( $order_id ) {

    $order = new WC_Order( $order_id );

    if ( $order-&gt;user_id &gt; 0 ) {

        $old_spent = absint( get_user_meta( $order-&gt;user_id, '_money_spent', true ) );
        update_user_meta( $order-&gt;user_id, '_money_spent', $old_spent + $order-&gt;order_total );

        $old_count = absint( get_user_meta( $order-&gt;user_id, '_order_count', true ) );
        update_user_meta( $order-&gt;user_id, '_order_count', $old_count + 1 );
    }
}
add_action( 'woocommerce_order_status_completed', 'woocommerce_paying_customer' );


which reminds us that the $order_is passed to the woocommerce_order_status_completed hook. From the $order_id, you can create a new order object, with the user_id as a property.

Armed with that knowledge, I think we can just fix the inner guts of the function get a new user object from that user ID, and remove the old role and finally apply the new role.

function wpa_120656_convert_paying_customer( $order_id ) {

    $order = new WC_Order( $order_id );

    if ( $order-&gt;user_id &gt; 0 ) {
        update_user_meta( $order-&gt;user_id, 'paying_customer', 1 );
        $user = new WP_User( $order-&gt;user_id );

        // Remove role
        $user-&gt;remove_role( 'customer' ); 

        // Add role
        $user-&gt;add_role( 'subscriber' );
    }
}
add_action( 'woocommerce_order_status_completed', 'wpa_120656_convert_paying_customer' );

",helgatheviking,https://wordpress.stackexchange.com/users/6477,http://wordpress.stackexchange.com/questions/120656/woocommerce-change-user-role-after-completing-order,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Woomerce: change user role after order completion,":)

I'm using wordpress with woocommerce, and I would like to automate the following step. When an order is completed, I would like to change the user role associated with that order id from 'customer' to 'subscriber'.



By searching around, I think I should be able to accomplish this by using a hook in functions.php:

add_action( 'woocommerce_order_status_completed', 'change_role_from_customer_to_subscriber' );


Then add the function:

function change_role_from_customer_to_subscriber($order_id){
// code to change role to subscriber
}


In the code, I think I need to do 2 things:
1) get the user id that is associated with that order id
2) change role of that user id to subscriber



I've tried a lot, but I couldn't get it to work (neither getting the right user id, nor changing the role of a user id). So any help would be appreciated! I've seen 2 related questions asked before on stack overflow, but unfortunately the answers there did not work for me. I hope someone can help me out!

Thanks a lot! :)


Edit:
Someone helped me out with the second part of the problem, so that's great news for me :)

Unfortunately, I still haven't figured out the first part: how to get the user id that is associated with the order id.
Any ideas?
","Looking through the code there is a very relevant example:

function woocommerce_paying_customer( $order_id ) {

    $order = new WC_Order( $order_id );

    if ( $order-&gt;user_id &gt; 0 ) {

        $old_spent = absint( get_user_meta( $order-&gt;user_id, '_money_spent', true ) );
        update_user_meta( $order-&gt;user_id, '_money_spent', $old_spent + $order-&gt;order_total );

        $old_count = absint( get_user_meta( $order-&gt;user_id, '_order_count', true ) );
        update_user_meta( $order-&gt;user_id, '_order_count', $old_count + 1 );
    }
}
add_action( 'woocommerce_order_status_completed', 'woocommerce_paying_customer' );


which reminds us that the $order_is passed to the woocommerce_order_status_completed hook. From the $order_id, you can create a new order object, with the user_id as a property.

Armed with that knowledge, I think we can just fix the inner guts of the function get a new user object from that user ID, and remove the old role and finally apply the new role.

function wpa_120656_convert_paying_customer( $order_id ) {

    $order = new WC_Order( $order_id );

    if ( $order-&gt;user_id &gt; 0 ) {
        update_user_meta( $order-&gt;user_id, 'paying_customer', 1 );
        $user = new WP_User( $order-&gt;user_id );

        // Remove role
        $user-&gt;remove_role( 'customer' ); 

        // Add role
        $user-&gt;add_role( 'subscriber' );
    }
}
add_action( 'woocommerce_order_status_completed', 'wpa_120656_convert_paying_customer' );

"
1512,1512,2379,Tooltip : Mapping list of Tooltip values to list of functions while plotting,"How is it possible to map a list of Tooltip values to the functions being plotted?

For example:
Assume, f1[x], f2[x], f3[x]... are functions defined.
{t1, t2, t3, ...} are the list of tool-tips to display.

Then to plot:
Plot[ Tooltip[{f1[x], f2[x], ... }], {x, a, b}];
Which will just display the functions as tool-tip
OR
Plot[ {Tooltip[f1[x], t1], Tooltip[f2[x], t2], ...... }, {x, a, b}]

Which is the required behavior, but, is there another shorter or direct way of mapping the functions f1, f2, f3, ... to t1, t2, t3, .... rather than manually?
",user3330840,https://mathematica.stackexchange.com/users/27121,"funcs = {Sin[x], Cos[x], Sin[x] Cos[x]};
tips = {""t1"", ""t2"", ""t3""};

Plot[Thread[Tooltip[funcs, tips]], {x, -2 Pi, 2 Pi}, Evaluated -&gt; True]
Plot[Evaluate@Thread[Tooltip[funcs, tips]], {x, -2 Pi, 2 Pi}]
Plot[Evaluate@MapThread[Tooltip, {funcs, tips}], {x, -2 Pi, 2 Pi}]
Plot[Tooltip @@@ Transpose[{funcs, tips}], {x, -2 Pi, 2 Pi}, Evaluated -&gt; True]


all give


",kglr,https://mathematica.stackexchange.com/users/125,http://mathematica.stackexchange.com/questions/77723/tooltip-mapping-list-of-tooltip-values-to-list-of-functions-while-plotting,TECHNOLOGY,mathematica.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Tooltips: mapping a list of tooltip values to a list of functions when printing,"How is it possible to map a list of Tooltip values to the functions being plotted?

For example:
Assume, f1[x], f2[x], f3[x]... are functions defined.
{t1, t2, t3, ...} are the list of tool-tips to display.

Then to plot:
Plot[ Tooltip[{f1[x], f2[x], ... }], {x, a, b}];
Which will just display the functions as tool-tip
OR
Plot[ {Tooltip[f1[x], t1], Tooltip[f2[x], t2], ...... }, {x, a, b}]

Which is the required behavior, but, is there another shorter or direct way of mapping the functions f1, f2, f3, ... to t1, t2, t3, .... rather than manually?
","funcs = {Sin[x], Cos[x], Sin[x] Cos[x]};
tips = {""t1"", ""t2"", ""t3""};

Plot[Thread[Tooltip[funcs, tips]], {x, -2 Pi, 2 Pi}, Evaluated -&gt; True]
Plot[Evaluate@Thread[Tooltip[funcs, tips]], {x, -2 Pi, 2 Pi}]
Plot[Evaluate@MapThread[Tooltip, {funcs, tips}], {x, -2 Pi, 2 Pi}]
Plot[Tooltip @@@ Transpose[{funcs, tips}], {x, -2 Pi, 2 Pi}, Evaluated -&gt; True]


all give


"
4971,4971,7918,Drywall - final joint compound coat,"While remodeling an older house (where nothing is quite straight) we used fiber glass mesh joint tape and 3 coats of joint compound. The first coat was applied with a 4 inch knife, the second with an 8 inch and ending the third on a 12 inch knife. I can still see the texture from the mesh tape I used on some of the joints.

I hoped that a coat of primer would level it off, but after using Kilz 2 primer I can still see the tape in some spots. :(

Sanding through the primer now proves difficult (doesn't work) with a medium grit sanding block.

Should I add another coat? I could never quite get the joint compound to adhere over the mesh tape. I've always been taught to go as thin as I can on the joint compound to reduce the sanding part. Did I go too thin? 

I'm hoping a second coat of primer and 2 coats of the final latex paint hides it, but I know this isn't the right answer. How can I fix this?



following what doresoom and shirlock said; i just applied a coat with the 12 inch knife practically against the wall (accidentally touching the wall with the handle once or twice) - more or less dragging the compound across the surface

this produced the result explained - about 1/32nd ? thickness of mud, covering the tape that i'll need to feather round the edges

i miss spoke earlier - i was using a sponge sanding block (not strait paper sand paper)

now that the primer has dried (did it saturday) its not as bad as i thought it was, but this is the right way to do it (not covering it with paint)

just as a side, we've used sherwin williams paint throughout the house and although its great paint (IMO) the plaster and lath walls that remain, even those repairs show through - and if those do, than this new work will... may as well do finish it right...

thanks for the help guys - i'll check this coat tomorrow and give a last one with the soap and water if it needs it.
",lsiunsuex,https://diy.stackexchange.com/users/1154,"As the others have said, paint will not help your situation.  You will need to apply another coat of mud. The final coat can be applied using a 12 inch flat knife, but I personally like a 14 or 16 inch bow trowel. The idea is to have a thicker coat of mud over the tape and bevel or feather the edges out wide so you will not notice the small difference in thickness.  With a 12 inch knife, your joint should be about 16 to 18 inches wide. Push harder on the outside of the knife than on the inside/center of the joint. This will leave more mud in the center and feather the edges better. Do this on each side of the joint. 

Here is another tip for you.  For your last or final touch-up coat, mix a little extra water and some Ivory dish soap into your mud.  It will flow very easily, far less tiny air bubbles, and will sand out easy with little pressure. Never use sandpaper, use a 150 or 220 sanding sponge. Don't go crazy and strip it too much or you will expose the tape again. Smooth the center gently and feather out the edges more agressively.   Good luck
",shirlock homes,https://diy.stackexchange.com/users/386,http://diy.stackexchange.com/questions/6985/drywall-final-joint-compound-coat,LIFE_ARTS,diy.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.5555555555555556,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,1.0,Dry wall - final joint composite coating,"While remodeling an older house (where nothing is quite straight) we used fiber glass mesh joint tape and 3 coats of joint compound. The first coat was applied with a 4 inch knife, the second with an 8 inch and ending the third on a 12 inch knife. I can still see the texture from the mesh tape I used on some of the joints.

I hoped that a coat of primer would level it off, but after using Kilz 2 primer I can still see the tape in some spots. :(

Sanding through the primer now proves difficult (doesn't work) with a medium grit sanding block.

Should I add another coat? I could never quite get the joint compound to adhere over the mesh tape. I've always been taught to go as thin as I can on the joint compound to reduce the sanding part. Did I go too thin? 

I'm hoping a second coat of primer and 2 coats of the final latex paint hides it, but I know this isn't the right answer. How can I fix this?



following what doresoom and shirlock said; i just applied a coat with the 12 inch knife practically against the wall (accidentally touching the wall with the handle once or twice) - more or less dragging the compound across the surface

this produced the result explained - about 1/32nd ? thickness of mud, covering the tape that i'll need to feather round the edges

i miss spoke earlier - i was using a sponge sanding block (not strait paper sand paper)

now that the primer has dried (did it saturday) its not as bad as i thought it was, but this is the right way to do it (not covering it with paint)

just as a side, we've used sherwin williams paint throughout the house and although its great paint (IMO) the plaster and lath walls that remain, even those repairs show through - and if those do, than this new work will... may as well do finish it right...

thanks for the help guys - i'll check this coat tomorrow and give a last one with the soap and water if it needs it.
","As others have said, paint doesn't help your situation. You need another coat of mud. The last layer can use a 12 inch flat knife, but I personally like a 14 or 16 inch bow float. The purpose of this is to apply a thick layer of mud to the tape and bevel or widen the edges so that you don't notice any small differences in thickness. With a 12 inch knife, your joints should be 16 to 18 inches wide. Push harder on the outside of the knife than on the inside / center of the joint. This leaves more mud in the center and a smoother edge. Do this on each side of the connector."
1728,1728,2732,Mathematics of Ritardando,"Beyond feel &amp; experience, is there a rule conductors use for ritardando in terms of  (a) its rate, (b) its change in rate, and/or (c) the relationship between the final tempo and the tempo of the piece?

(In getting my software to execute a ritardando, I employed over four measures a measure-by-measure decrease in tempo, and what sounded ""right"" to me ultimately was decreasing the tempo by 4 bpm, then a further 9, then a further 16 (pleasing pattern) to arrive at 127/156 (close to 3/4) the original tempo.)


",commonhare,https://music.stackexchange.com/users/16938,"""...is there a rule conductors use for ritardando in terms of (a) its rate, (b) its change in rate, and/or (c) the relationship between the final tempo and the tempo of the piece?""

Not that I'm aware of. Such a rule would be of little value, because -- unless you're practicing with a drum machine, or other device that permits varying tempo -- there's generally no good way (other than feel) to for conductors or performers to accurately measure their tempo during a performance. They're certainly not likely to be thinking ""Now this beat has to be played 10% longer than the previous one, and the following beat has to be 17.4% longer than that...""

However, if I had to guess a general shape of a tempo curve in a ritard, they generally seem to be monotonically decreasing (you don't speed up again in the middle of a ritard), and concave downward (i.e., the most ritard'ing comes just before the end of the ritard). But to what degree this is true is up to the conductor or performers to decide.

On the other hand, about the most prescriptive that I've usually seen music notation get is poco rit. (just a little bit of ritardando), or molto rit. (much ritardando). And of course, the dashed line that Richard mentions, to indicate the duration of the ritard.

That said, I am interested in what the tempo curves of actual performances would look like. I know that approximate tempo maps can be created for real performances, and I'd be surprised if someone, somewhere, hasn't researched what these curves look like.
",Caleb Hines,https://music.stackexchange.com/users/10637,http://music.stackexchange.com/questions/27009/mathematics-of-ritardando,LIFE_ARTS,music.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Ritadando mathematics,"Beyond feel &amp; experience, is there a rule conductors use for ritardando in terms of  (a) its rate, (b) its change in rate, and/or (c) the relationship between the final tempo and the tempo of the piece?

(In getting my software to execute a ritardando, I employed over four measures a measure-by-measure decrease in tempo, and what sounded ""right"" to me ultimately was decreasing the tempo by 4 bpm, then a further 9, then a further 16 (pleasing pattern) to arrive at 127/156 (close to 3/4) the original tempo.)


","""...is there a rule conductors use for ritardando in terms of (a) its rate, (b) its change in rate, and/or (c) the relationship between the final tempo and the tempo of the piece?""

Not that I'm aware of. Such a rule would be of little value, because -- unless you're practicing with a drum machine, or other device that permits varying tempo -- there's generally no good way (other than feel) to for conductors or performers to accurately measure their tempo during a performance. They're certainly not likely to be thinking ""Now this beat has to be played 10% longer than the previous one, and the following beat has to be 17.4% longer than that...""

However, if I had to guess a general shape of a tempo curve in a ritard, they generally seem to be monotonically decreasing (you don't speed up again in the middle of a ritard), and concave downward (i.e., the most ritard'ing comes just before the end of the ritard). But to what degree this is true is up to the conductor or performers to decide.

On the other hand, about the most prescriptive that I've usually seen music notation get is poco rit. (just a little bit of ritardando), or molto rit. (much ritardando). And of course, the dashed line that Richard mentions, to indicate the duration of the ritard.

That said, I am interested in what the tempo curves of actual performances would look like. I know that approximate tempo maps can be created for real performances, and I'd be surprised if someone, somewhere, hasn't researched what these curves look like.
"
627,627,990,How can I span wallpapers over two monitors in Mac OS X?,"Is there any way to get a single wide desktop wallpaper to span a dual monitor setup in OS X?
",Todd Hunter,https://superuser.com/users/2508,"Without splitting the image by hand into two halves (one for each monitor)? Not currently.
",Chealion,https://superuser.com/users/1339,http://superuser.com/questions/6581,TECHNOLOGY,superuser.com,1.0,1.0,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,0.3333333333333333,1.0,How to span wallpaper on two displays in Mac OS X?,Is there a way to make a single wide desktop wallpaper across a dual monitor set on OS X?,"Without splitting the image by hand into two halves (one for each monitor)? Not currently.
"
4772,4772,7578,Failed to allocate memory - What is it trying to say?,"In my early days of programming I often used to get memory related fatal errors in the following format:

Fatal error: Allowed memory size of &lt;some big number&gt; bytes exhausted 
(tried to allocate &lt;some small number&gt; bytes) in /path/to/filename.php 
on line &lt;some line number&gt;


I'm a little embarrassed to state that even though I have figured out how to solve them and take steps to avoid them altogether, I'm still not quite sure what exactly does the message translate to in simple words.

For example, if I get a message such as:

Fatal error: Allowed memory size of 67108864 bytes exhausted (tried to allocate 4000 bytes) 
in ........ on line 34


As things stand at the moment, I assume it to be stating that the script consumes 67108864 bytes of data, but only 4000 bytes are available during runtime.


Am I right in my assumption?
If not, what's the correct interpretation?

",asprin,https://programmers.stackexchange.com/users/136389,"Your program has 67108864 bytes (~67MB) available to it at runtime, all of which it has filled. The specific allocation which took the total memory usage from &lt;67MB to >67MB was an allocation of 4000 bytes, which happened within the expression on line 34.

Basically, you're using too much memory, and all the interpreter can give you to help is the specific allocation which broke the camel's back. It could have been a one byte allocation, all that matters is that it took you over your memory limit.
",Phoshi,https://programmers.stackexchange.com/users/10502,http://programmers.stackexchange.com/questions/244758/failed-to-allocate-memory-what-is-it-trying-to-say,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.0,0.0,1.0,0.7777777777777778,Failed to allocate memory - what does it want to say?,"In my early days of programming I often used to get memory related fatal errors in the following format:

Fatal error: Allowed memory size of &lt;some big number&gt; bytes exhausted 
(tried to allocate &lt;some small number&gt; bytes) in /path/to/filename.php 
on line &lt;some line number&gt;


I'm a little embarrassed to state that even though I have figured out how to solve them and take steps to avoid them altogether, I'm still not quite sure what exactly does the message translate to in simple words.

For example, if I get a message such as:

Fatal error: Allowed memory size of 67108864 bytes exhausted (tried to allocate 4000 bytes) 
in ........ on line 34


As things stand at the moment, I assume it to be stating that the script consumes 67108864 bytes of data, but only 4000 bytes are available during runtime.


Am I right in my assumption?
If not, what's the correct interpretation?

","Your program has 67108864 bytes (~67MB) available to it at runtime, all of which it has filled. The specific allocation which took the total memory usage from &lt;67MB to >67MB was an allocation of 4000 bytes, which happened within the expression on line 34.

Basically, you're using too much memory, and all the interpreter can give you to help is the specific allocation which broke the camel's back. It could have been a one byte allocation, all that matters is that it took you over your memory limit.
"
2404,2404,3837,M2E setting file,"I just have installed M2E for my Eclipse IDE, I'd like to know how to create a setting file, which can be used to config maven for eclipse, contains infomation such as remote repository, etc. Whether I need to download maven and set maven_home to do that? 
Thanks!
",QuÃ¡ch ThiÃªn,https://stackoverflow.com/users/2148978,"in Eclipse go to: Window -> Preferences -> Maven -> Installation: select a file (your settings.xml) for global settings for the embedded installation. The file can be located everywhere you want (the .m2 repository folder is a good location) and must fit the settings.xml style you can find in the documentation.
",Simulant,https://stackoverflow.com/users/1515052,http://stackoverflow.com/questions/18954566/m2e-setting-file,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,M2e settings file,"I just installed M2e for my eclipse IDE, and I want to know how to create a setup file that can be used to configure Maven for eclipse, including remote repositories and other information. Do I need to download Maven and set up Maven home to do this?","in Eclipse go to: Window -> Preferences -> Maven -> Installation: select a file (your settings.xml) for global settings for the embedded installation. The file can be located everywhere you want (the .m2 repository folder is a good location) and must fit the settings.xml style you can find in the documentation.
"
1208,1208,1898,General error 1651 after a mysql migration,"I finished migration from 5.1 to 5.6, and (with the same queries as before) mysql complains right away about:


  General error: 1651 Query cache is disabled; restart the server with
  query_cache_type=1 to enable it


I don't want the query cache enabled (that's an app with lots of writting), and my file my.ini looks like this:

# The MySQL server
[mysqld]
# ... other parameters...

query_cache_type = 0
query_cache_size = 0


Also, on connect, my php connection wrapper always executes 

SET SESSION query_cache_type = OFF


What I don't understand is 


Why the parameters apparently do not work
Why does mysql even have to complain about a parameter that is disabled when it is the user's choice to do so.


Enlightment needed - Thanks!
",Sebas,https://dba.stackexchange.com/users/9583,"I think the SET SESSION query_cache_type = OFF is causing this. In the Query Cache Configuration page it states: 


  If you set query_cache_type at server startup (rather than at runtime with a SET statement), only the numeric values are permitted.


And since you are starting the server with cache disabled, there is no need to use that SET anyway.

As to why it throws an error (both with = OFF and = 0), it may have to do with this note in Server System Variables page:


  
  query_cache_type  
  
  
  ...
  
  If the server is started with query_cache_type set to 0, it does not acquire the query cache mutex at all, which means that the query cache cannot be enabled at runtime and there is reduced overhead in query execution.


My interpretation is that the variable has both Global and Session scope but only if it not set to off at startup.
",ypercubeáµá´¹,https://dba.stackexchange.com/users/993,http://dba.stackexchange.com/questions/42526/general-error-1651-after-a-mysql-migration,TECHNOLOGY,dba.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,0.8888888888888888,General error 1651 after MySQL migration,"I finished migration from 5.1 to 5.6, and (with the same queries as before) mysql complains right away about:


  General error: 1651 Query cache is disabled; restart the server with
  query_cache_type=1 to enable it


I don't want the query cache enabled (that's an app with lots of writting), and my file my.ini looks like this:

# The MySQL server
[mysqld]
# ... other parameters...

query_cache_type = 0
query_cache_size = 0


Also, on connect, my php connection wrapper always executes 

SET SESSION query_cache_type = OFF


What I don't understand is 


Why the parameters apparently do not work
Why does mysql even have to complain about a parameter that is disabled when it is the user's choice to do so.


Enlightment needed - Thanks!
","I think the SET SESSION query_cache_type = OFF is causing this. In the Query Cache Configuration page it states: 


  If you set query_cache_type at server startup (rather than at runtime with a SET statement), only the numeric values are permitted.


And since you are starting the server with cache disabled, there is no need to use that SET anyway.

As to why it throws an error (both with = OFF and = 0), it may have to do with this note in Server System Variables page:


  
  query_cache_type  
  
  
  ...
  
  If the server is started with query_cache_type set to 0, it does not acquire the query cache mutex at all, which means that the query cache cannot be enabled at runtime and there is reduced overhead in query execution.


My interpretation is that the variable has both Global and Session scope but only if it not set to off at startup.
"
3056,3056,4867,Generate a custom Enterprise WSDL,"I am trying to generate a WSDL that expose only some of my objects and methods. 

The Enterprise WSDL expose every object and method that my org has. 

I know that it could be possible ""cutting"" the generated XML by hand taking care the dependences, but is there any tool to resolve those dependences? or to regenerate a WSDL from other WSDL choosing the exposed methods?
",Martin Borthiry,https://salesforce.stackexchange.com/users/636,"The usual method is manual editing, although it should be possible to use the Eclipse IDE's WSDL editing mode to trim out the extra functions that you don't need. You'll still need to take care not to delete dependencies that are actually required, because Eclipse cannot validate what is or isn't necessary directly.
",sfdcfox,https://salesforce.stackexchange.com/users/2984,http://salesforce.stackexchange.com/questions/21544/generate-a-custom-enterprise-wsdl,TECHNOLOGY,salesforce.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.3333333333333333,0.6666666666666666,1.0,0.8888888888888888,Generate custom enterprise WSDL,"I am trying to generate a WSDL that expose only some of my objects and methods. 

The Enterprise WSDL expose every object and method that my org has. 

I know that it could be possible ""cutting"" the generated XML by hand taking care the dependences, but is there any tool to resolve those dependences? or to regenerate a WSDL from other WSDL choosing the exposed methods?
","The usual method is manual editing, although it should be possible to use the Eclipse IDE's WSDL editing mode to trim out the extra functions that you don't need. You'll still need to take care not to delete dependencies that are actually required, because Eclipse cannot validate what is or isn't necessary directly.
"
565,565,888,Spring security - Access to a controller method based on an attribute,"I'm configuring Spring Security across all my controllers.
I want some method executions to start only when ""my system is enabled"". This information is accessible from all over the controllers via a specific static method (I can make it non-static).
My point is that I want to avoid making an explicit check in java code at the beginning of every method.
How can I get there via Spring Security?
",Manu,https://stackoverflow.com/users/1490144,"One approach is to use a handler interceptor.

Here is general idea:

(1) Configure url patterns which you want to block:

&lt;util:list id=""sysEnableCheckUrlPatterns"" value-type=""java.lang.String""&gt;
    &lt;beans:value&gt;/module1/**&lt;/beans:value&gt;
    &lt;beans:value&gt;/module2/**&lt;/beans:value&gt;
&lt;/util:list&gt;


(2) Write an interceptor:

    public class SysEnableCheckInterceptor extends HandlerInterceptorAdapter {

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)
            throws Exception {


            /* 
                If system enabled then return true. Otherwise return false (and optionally write something in response)

            */
    }
}


(3) Configure that interceptor. In 3.1 you can do it as follows:

    @Configuration
public class AppConfig extends WebMvcConfigurerAdapter {

    @Resource(name=""sysEnableCheckUrlPatterns"")
    /* or use @Autowired or @Inject if you like */
    private String[] sysEnableCheckUrlPatterns;

    @Override
    public void addInterceptors(InterceptorRegistry registry) {

    registry.addInterceptor(new SysEnableCheckInterceptor()).addPathPatterns(sysEnableCheckUrlPatterns);

    }

}

",Ritesh,https://stackoverflow.com/users/530549,http://stackoverflow.com/questions/15514170/spring-security-access-to-a-controller-method-based-on-an-attribute,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Spring security - property based access controller method,"I'm configuring Spring Security across all my controllers.
I want some method executions to start only when ""my system is enabled"". This information is accessible from all over the controllers via a specific static method (I can make it non-static).
My point is that I want to avoid making an explicit check in java code at the beginning of every method.
How can I get there via Spring Security?
","One approach is to use a handler interceptor.

Here is general idea:

(1) Configure url patterns which you want to block:

&lt;util:list id=""sysEnableCheckUrlPatterns"" value-type=""java.lang.String""&gt;
    &lt;beans:value&gt;/module1/**&lt;/beans:value&gt;
    &lt;beans:value&gt;/module2/**&lt;/beans:value&gt;
&lt;/util:list&gt;


(2) Write an interceptor:

    public class SysEnableCheckInterceptor extends HandlerInterceptorAdapter {

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)
            throws Exception {


            /* 
                If system enabled then return true. Otherwise return false (and optionally write something in response)

            */
    }
}


(3) Configure that interceptor. In 3.1 you can do it as follows:

    @Configuration
public class AppConfig extends WebMvcConfigurerAdapter {

    @Resource(name=""sysEnableCheckUrlPatterns"")
    /* or use @Autowired or @Inject if you like */
    private String[] sysEnableCheckUrlPatterns;

    @Override
    public void addInterceptors(InterceptorRegistry registry) {

    registry.addInterceptor(new SysEnableCheckInterceptor()).addPathPatterns(sysEnableCheckUrlPatterns);

    }

}

"
4690,4690,7437,"Origin and meaning of ""The eagle flies at midnight""","
  The eagle flies at midnight.


What's the origin and meaning of this idiom?
",Anderson Silva,https://english.stackexchange.com/users/1446,"I've never heard it before, certainly not as some kind of common phrase - but it sounds to me like the sort of line you'd hear in a cheesy wartime spy movie.  Some sort of code phrase to inform your accomplices of your plans.
",thesunneversets,https://english.stackexchange.com/users/2181,http://english.stackexchange.com/questions/5305/origin-and-meaning-of-the-eagle-flies-at-midnight,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.7777777777777778,1.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.6666666666666666,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.4,0.0,0.0,1.0,0.7777777777777778,"The origin and significance of ""flying Nighthawk""","
  The eagle flies at midnight.


What's the origin and meaning of this idiom?
","I've never heard of it before, of course, it's not a common phrase, but in my opinion, it's like the lines you hear in a vulgar war time spy movie. Some code phrase to inform your partner of your plan."
4251,4251,6778,php mysql return wrong boolean result,"I have the following query :

'SELECT Active FROM tbUsers WHERE Id=55'


The Id is unique and I need just to know the status of the user if he's active yes or no. The Column Active is set as boolean in Mysql

When I tried to return the result like the following (using another php function) :

$result = $this-&gt;selectRow($db,""tbClass"",""Active"",""Id='$Id'"");
if($result) { return ""ok"" ; } else { return ""nok"" ;)


it returns 'ok' on both cases.
Any idea what's wrong with it ?

Here is the other function :

public function selectRow($db,$tableName,$field,$where) {
        if($where == """") {
            $query = ""SELECT $field FROM $tableName"";
        }
        else
        { $query = ""SELECT $field FROM $tableName WHERE $where""; }

        $result=$db-&gt;Qry($query);


        if ($result) {
            $no_of_rows =  $db-&gt;TotRows($result);
            if($no_of_rows == 1) {
                return $result;
            }
            if($no_of_rows == 0) {
                return '';
            }
            if($no_of_rows &lt; 0) {
                die('Invalid query: ' . $sender .""("".$query  .""): "".mysql_errno()."": "". mysql_error());
                return '';
            }
        } 
        else {
            die('Invalid query: ' . $sender ."": "" .$query."": "". mysql_errno()."": "". mysql_error());
            return '';
        }
    }


Qry Function is the following :

function Qry($sql) {
    if($result = mysqli_query($this-&gt;con,$sql) ) {
        return $result;
    }
    else 
    {
        $err = ""Error: "".$sql. "" :: "". mysqli_error;
        die(""$err"");
    }
}

",koul,https://stackoverflow.com/users/4297309,"I think you need to change this condition .

 $result=$db-&gt;Qry($query);



  always return you query object


Just remove this condition and 

You need to count number of affected row

&lt;?php

public function selectRow($db, $tableName, $field, $where) {
    if ($where == """") {
        $query = ""SELECT $field FROM $tableName"";
    } else {
        $query = ""SELECT $field FROM $tableName WHERE $where"";
    }

    $result = $db-&gt;Qry($query);



    $no_of_rows = $db-&gt;TotRows($result);
    if ($no_of_rows == 1) {
        return $result;
    }
    if ($no_of_rows == 0) {
        return FALSE;
    }
    if ($no_of_rows &lt; 0) {
        die('Invalid query: ' . $sender . ""("" . $query . ""): "" . mysql_errno() . "": "" . mysql_error());
        return FALSE;
    }
}

",Saty,https://stackoverflow.com/users/4662759,http://stackoverflow.com/questions/30592415/php-mysql-return-wrong-boolean-result,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,PHP MySQL returns wrong Boolean results,"I have the following query :

'SELECT Active FROM tbUsers WHERE Id=55'


The Id is unique and I need just to know the status of the user if he's active yes or no. The Column Active is set as boolean in Mysql

When I tried to return the result like the following (using another php function) :

$result = $this-&gt;selectRow($db,""tbClass"",""Active"",""Id='$Id'"");
if($result) { return ""ok"" ; } else { return ""nok"" ;)


it returns 'ok' on both cases.
Any idea what's wrong with it ?

Here is the other function :

public function selectRow($db,$tableName,$field,$where) {
        if($where == """") {
            $query = ""SELECT $field FROM $tableName"";
        }
        else
        { $query = ""SELECT $field FROM $tableName WHERE $where""; }

        $result=$db-&gt;Qry($query);


        if ($result) {
            $no_of_rows =  $db-&gt;TotRows($result);
            if($no_of_rows == 1) {
                return $result;
            }
            if($no_of_rows == 0) {
                return '';
            }
            if($no_of_rows &lt; 0) {
                die('Invalid query: ' . $sender .""("".$query  .""): "".mysql_errno()."": "". mysql_error());
                return '';
            }
        } 
        else {
            die('Invalid query: ' . $sender ."": "" .$query."": "". mysql_errno()."": "". mysql_error());
            return '';
        }
    }


Qry Function is the following :

function Qry($sql) {
    if($result = mysqli_query($this-&gt;con,$sql) ) {
        return $result;
    }
    else 
    {
        $err = ""Error: "".$sql. "" :: "". mysqli_error;
        die(""$err"");
    }
}

","I think you need to change this condition .

 $result=$db-&gt;Qry($query);



  always return you query object


Just remove this condition and 

You need to count number of affected row

&lt;?php

public function selectRow($db, $tableName, $field, $where) {
    if ($where == """") {
        $query = ""SELECT $field FROM $tableName"";
    } else {
        $query = ""SELECT $field FROM $tableName WHERE $where"";
    }

    $result = $db-&gt;Qry($query);



    $no_of_rows = $db-&gt;TotRows($result);
    if ($no_of_rows == 1) {
        return $result;
    }
    if ($no_of_rows == 0) {
        return FALSE;
    }
    if ($no_of_rows &lt; 0) {
        die('Invalid query: ' . $sender . ""("" . $query . ""): "" . mysql_errno() . "": "" . mysql_error());
        return FALSE;
    }
}

"
1517,1517,2385,What Range of Source Ports do web Browsers Use to Connect,"When my web browser connects to a website, the source port my end is a number like 27825, what range of ports can it use and how regularly does it change?
",h00j,https://webmasters.stackexchange.com/users/14478,"When you connect to a website you are connecting on port 80 which is the default port for all HTTP services, you can connect to websites that use other ports such as 8080 but you need to use http://domain.com:8080 unless they have the port 80 service redirect to another port.

Internal Loop backs

Now with this said and to answer your question, browsers establish connections on the remote host port that is setup on their server i.e port 80. Browsers do not communicate as far as I know on any other port unless the server its running on another port, if you are using a TCP monitor you will see Firefox, IE, Chrome etc operating on ports other than 80 then what your seeing is internal loop backs which these platforms use to communicate within the software. Take a look at TCP View from Microsoft you will notice that on the left side you have local port, and remote port. The local port is the internal loop back and the HTTP service is running on port 80 and that's how the data is being communicated externally.
",Simon Hayter,https://webmasters.stackexchange.com/users/20604,http://webmasters.stackexchange.com/questions/48904/what-range-of-source-ports-do-web-browsers-use-to-connect,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,1.0,The range of source ports that web browsers use to connect to,"When my web browser connects to a website, the source port my end is a number similar to 27825. What range of ports can it use and how regular is its change?","When you connect to a website you are connecting on port 80 which is the default port for all HTTP services, you can connect to websites that use other ports such as 8080 but you need to use http://domain.com:8080 unless they have the port 80 service redirect to another port.

Internal Loop backs

Now with this said and to answer your question, browsers establish connections on the remote host port that is setup on their server i.e port 80. Browsers do not communicate as far as I know on any other port unless the server its running on another port, if you are using a TCP monitor you will see Firefox, IE, Chrome etc operating on ports other than 80 then what your seeing is internal loop backs which these platforms use to communicate within the software. Take a look at TCP View from Microsoft you will notice that on the left side you have local port, and remote port. The local port is the internal loop back and the HTTP service is running on port 80 and that's how the data is being communicated externally.
"
4699,4699,7450,Driving electric cars through large pools of water,"The state of California is expected to be hit by a large storm in the coming days and there are frequently clogged drains in my town. I have an electric vehicle that seemed to handle driving through large puddles during the last storm but I was curious if anyone could tell me what the potential hazards are of driving an EV through a large standing pool of water. 

I don't need to worry about getting water in the engine (I think) since there is no air intake. There are fans that cool the battery if it gets too hot but I don't think that will be a problem during this storm.

EDIT: I have a Ford Focus
",Chris.Stover,https://mechanics.stackexchange.com/users/7751,"Electric cars use high tech lithium batteries. These batteries are dangerous in a variety of situations but they're also full of electronics to compensate. If anything at all bad happens (for example, a short circuit due to water) the battery itself will shut down, and you'll have to get the car towed.

Cars are expected to handle all kinds of weather and Ford is a reputable company. I would expect all high voltage power sources to be perfectly protected from water splashing up from the wheels which would mean shallow water is fine. If the water gets up into the doors though, then you might be in trouble.

Doing some research, I found someone who's nissan leaf that was submerged for an extended period it of time (the water was half way up the door, wheels totally under water) and the car computers had detected various faults and shut everything down. A mechanic cleaned things up as best they could and the car was able to start, but more errors were detected so they declared the car a write off.

My guess is that car could have been repaired if it was taken to a more competent mechanic, but most mechanics don't know anything about electric vehicles and they're not going to risk telling you everything is fixed when they honestly don't know.

Tesla says that there is no safety risk at all if the car is fully submerged in water, but obviously it would destroy the car just like happened with the Leaf. If the battery catches fire they recommend using ""large amounts"" of water to cool the batteries down. You're likely to need to keep the battery cool for up to 24 hours, so make sure you have a lot of water available to keep the batteries cool.

My understanding is water won't put out a lithium battery fire, but it should prevent the fire from spreading into neighbouring battery cells, and eventually the ones already burning will run out of fuel.
",Abhi Beckert,https://mechanics.stackexchange.com/users/2147,http://mechanics.stackexchange.com/questions/13505/driving-electric-cars-through-large-pools-of-water,CULTURE,mechanics.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Driving electric cars in a big pool,"California is expected to be hit by a major storm in the next few days, and my town is often clogged with sewers. I have an electric car that seems to be able to drive through a big puddle in the last storm, but I'm curious if anyone can tell me what the potential dangers of driving an electric car in a huge pool of water are.","Electric cars use high tech lithium batteries. These batteries are dangerous in a variety of situations but they're also full of electronics to compensate. If anything at all bad happens (for example, a short circuit due to water) the battery itself will shut down, and you'll have to get the car towed.

Cars are expected to handle all kinds of weather and Ford is a reputable company. I would expect all high voltage power sources to be perfectly protected from water splashing up from the wheels which would mean shallow water is fine. If the water gets up into the doors though, then you might be in trouble.

Doing some research, I found someone who's nissan leaf that was submerged for an extended period it of time (the water was half way up the door, wheels totally under water) and the car computers had detected various faults and shut everything down. A mechanic cleaned things up as best they could and the car was able to start, but more errors were detected so they declared the car a write off.

My guess is that car could have been repaired if it was taken to a more competent mechanic, but most mechanics don't know anything about electric vehicles and they're not going to risk telling you everything is fixed when they honestly don't know.

Tesla says that there is no safety risk at all if the car is fully submerged in water, but obviously it would destroy the car just like happened with the Leaf. If the battery catches fire they recommend using ""large amounts"" of water to cool the batteries down. You're likely to need to keep the battery cool for up to 24 hours, so make sure you have a lot of water available to keep the batteries cool.

My understanding is water won't put out a lithium battery fire, but it should prevent the fire from spreading into neighbouring battery cells, and eventually the ones already burning will run out of fuel.
"
1489,1489,2340,"Disk became full, had to force shutdown, now it doesn't boot","Don't know why I didn't get a warning about disk being almost full... It came down to zero free space and I couldn't do anything except force-shutdown it. I booted into Windows, deleted some files from OSX drive, but now on boot there is a progress bar every time and when it reaches the end (in 15 min), the computer shuts down.

I went into the recovery mode and tried to repair the disk, but it says ""The Disk Utility cannot repair the drive... backup files and reinstall the OS"" -- something like that.

I have a time machine backup but I'm currently not at home - going home in 3 weeks.

Is it ""normal"" that system gets borked like this because of full disk + force shutdown? Seems too fragile to me. I have Mavericks 10.9.4 on this system.

Is there anything I can do?
",davidhq,https://apple.stackexchange.com/users/51636,"The problem is that the system goes into a fail-safe mode when the directory structure cannot be presumed to be safe for a new write.

You did the correct triage step by booting into recovery mode and attempting to repair the volume with Disk Utility.

At this point, you should back up any files you need. Test that your backup is complete and run Disk Utility against it to make sure it's in a good state.

Then you can boot to recovery and erase the volume or perhaps use another tool to repair the volume. If the drive erases and takes a format - the problem was a directory (data) corruption and not a hardware issue. If the disk can't be erased, then you need to repair the machine before restoring your backup onto a clean install of the OS.

In your case, you could possibly back up the changed files since 3 weeks or just get a new external drive and use Disk Utility to clone the volume or terminal to copy what you can using rsync or another tool.
",bmike,https://apple.stackexchange.com/users/5472,http://apple.stackexchange.com/questions/138635/disk-became-full-had-to-force-shutdown-now-it-doesnt-boot,TECHNOLOGY,apple.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,1.0,The disk is full and must be forced to shut down. It cannot be started at this time,"Don't know why I didn't get a warning about disk being almost full... It came down to zero free space and I couldn't do anything except force-shutdown it. I booted into Windows, deleted some files from OSX drive, but now on boot there is a progress bar every time and when it reaches the end (in 15 min), the computer shuts down.

I went into the recovery mode and tried to repair the disk, but it says ""The Disk Utility cannot repair the drive... backup files and reinstall the OS"" -- something like that.

I have a time machine backup but I'm currently not at home - going home in 3 weeks.

Is it ""normal"" that system gets borked like this because of full disk + force shutdown? Seems too fragile to me. I have Mavericks 10.9.4 on this system.

Is there anything I can do?
","The problem is that the system goes into a fail-safe mode when the directory structure cannot be presumed to be safe for a new write.

You did the correct triage step by booting into recovery mode and attempting to repair the volume with Disk Utility.

At this point, you should back up any files you need. Test that your backup is complete and run Disk Utility against it to make sure it's in a good state.

Then you can boot to recovery and erase the volume or perhaps use another tool to repair the volume. If the drive erases and takes a format - the problem was a directory (data) corruption and not a hardware issue. If the disk can't be erased, then you need to repair the machine before restoring your backup onto a clean install of the OS.

In your case, you could possibly back up the changed files since 3 weeks or just get a new external drive and use Disk Utility to clone the volume or terminal to copy what you can using rsync or another tool.
"
2680,2680,4272,"Do Americans pronounce ""Ellen"" and ""Alan"" in the same way?","Do Americans pronounce ""Ellen"" and ""Alan"" in the same way? I am especially concerned with the first vowel.

EDIT:

Here is a quote that may be a case in point:


  Being a Brit also, the names ""Ellen"" and ""Alan"" tend to sound the same
  when spoken with an American tongue. It was just unfortunate that the
  child was very tom boyish and had an ambiguous sounding name


Context: discussion on why they chose a boy-looking girl for the movie ""Fatal Attraction""

Link: http://www.imdb.com/title/tt0093010/board/thread/186160978?d=186229310&amp;p=1#186229310
",brilliant,https://english.stackexchange.com/users/2270,"Americans don't pronounce them exactly the same.

However, some American dialects change the pronunciation of /Ã¦/ before /l/ in a way that I believe makes it sound more like /É/ to foreigners. In fact, in a few New Zealand and Australian dialects, these vowels become identical before /l/; see salary-celery merger; this merger would indeed also merge Allen and Ellen, but I don't believe it has happened in any American dialects.

UPDATE: the OP was asking why some Brits heard ""Allen"" when the actors in Fatal Attraction were saying ""Ellen"". I believe the pronunciation of /Él/ is nearly the same in the U.S. and the U.K., but if you're listening to an unfamiliar dialect, you rely more on context, and my guess is that the people watching got the name wrong because they were relying more on context and the girl playing Ellen looked somewhat like a boy.
",Peter Shor ,https://english.stackexchange.com/users/5754,http://english.stackexchange.com/questions/64225/do-americans-pronounce-ellen-and-alan-in-the-same-way,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.4444444444444444,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.0,0.8888888888888888,"Do Americans pronounce ""Allan"" the same way as ""Allan""?","Do Americans pronounce ""Ellen"" and ""Alan"" in the same way? I am especially concerned with the first vowel.

EDIT:

Here is a quote that may be a case in point:


  Being a Brit also, the names ""Ellen"" and ""Alan"" tend to sound the same
  when spoken with an American tongue. It was just unfortunate that the
  child was very tom boyish and had an ambiguous sounding name


Context: discussion on why they chose a boy-looking girl for the movie ""Fatal Attraction""

Link: http://www.imdb.com/title/tt0093010/board/thread/186160978?d=186229310&amp;p=1#186229310
","Americans don't pronounce them exactly the same.

However, some American dialects change the pronunciation of /Ã¦/ before /l/ in a way that I believe makes it sound more like /É/ to foreigners. In fact, in a few New Zealand and Australian dialects, these vowels become identical before /l/; see salary-celery merger; this merger would indeed also merge Allen and Ellen, but I don't believe it has happened in any American dialects.

UPDATE: the OP was asking why some Brits heard ""Allen"" when the actors in Fatal Attraction were saying ""Ellen"". I believe the pronunciation of /Él/ is nearly the same in the U.S. and the U.K., but if you're listening to an unfamiliar dialect, you rely more on context, and my guess is that the people watching got the name wrong because they were relying more on context and the girl playing Ellen looked somewhat like a boy.
"
4194,4194,6687,EXcel Web Access - web part Error,"I asked this related question in stack overflow, Hence this forum is dedicated for sharepoint, Thought to ask here!!

I got to know how to get the Excel using sharepoint Excel web access webpart. However I am getting an error ""Excel Services is unable to process the request. Wait a few minutes and try performing this operation again!!"" Even If I directly access the Excel from the document library also getting the same error!!
",Jithu,https://sharepoint.stackexchange.com/users/5462,"At the end got it working, In order to get rid off the error we need to activate the Excel services web service application proxy in web application service connections.

In case the above mentioned proxy is not available under the service connections, go ahead and create one. Need some help, its right here !!
",Jithu,https://sharepoint.stackexchange.com/users/5462,http://sharepoint.stackexchange.com/questions/22346/excel-web-access-web-part-error,TECHNOLOGY,sharepoint.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,0.6666666666666666,Excel web access web part error,"I asked this related question in stack overflow, Hence this forum is dedicated for sharepoint, Thought to ask here!!

I got to know how to get the Excel using sharepoint Excel web access webpart. However I am getting an error ""Excel Services is unable to process the request. Wait a few minutes and try performing this operation again!!"" Even If I directly access the Excel from the document library also getting the same error!!
","At the end got it working, In order to get rid off the error we need to activate the Excel services web service application proxy in web application service connections.

In case the above mentioned proxy is not available under the service connections, go ahead and create one. Need some help, its right here !!
"
388,388,610,Electric current of inductor,"I have a homework problem that was solved by our instructor: 

""Calculate the electric current of the inductor at \$t=0^+\$.""



He calculated \$1/30\$ but the answer sheet was says \$-1/30\$.

Which of them is correct? 

Our instructor's work:






",Michle Jordan,https://electronics.stackexchange.com/users/53796,"I agree with Andy. The voltage in the inductor is always 0 V and therefore iL remains at 0 A. The solution of your instructor doesn't make any sense and it's probably for a different problem.
",Roger C.,https://electronics.stackexchange.com/users/59075,http://electronics.stackexchange.com/questions/140212/electric-current-of-inductor,TECHNOLOGY,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Inductor current,"I have a homework problem that was solved by our instructor: 

""Calculate the electric current of the inductor at \$t=0^+\$.""



He calculated \$1/30\$ but the answer sheet was says \$-1/30\$.

Which of them is correct? 

Our instructor's work:






","I agree with Andy. The voltage in the inductor is always 0V, so il remains at 0A. Your teacher's solution doesn't make any sense. It may be to solve another problem."
2861,2861,4554,How to create an app/package whose sole functionality is to redirect?,"I want to create an app/package to be published on the appexchange.  The only functionality of that app/package will be to redirect the user to a configured URL in the app. This will happen once enterprise admin adds the app from the appexchange.

The redirect functionality is related to remote access via Oauth2. Once redirected to the URL, the URL endpoint will kick in and do all the further steps.

I do NOT want the admin of the enterprise to make any config e.g creating webtab or a link as a workaround to making some package. This SHOULD be done when the app is added.

In other words, can we make an app that does not contain any tab, but just a URL?

Also, Can we package remote access apps?
",auny,https://salesforce.stackexchange.com/users/2853,"I highly recommend you review Force.com Platform Fundamentals Workbook which has a complete tutorial on building an App. I think you'll find the answer to what constitutes an App there. To help you get the most benefit from Salesforce StackExchange, you may find it helpful to look at our FAQ which explains how to post effectively when you visit this site.

I'll add that I also believe you'd have also discovered the answers to your question through the many resources available to developers linked from the Wiki provided to you in the response to your previous post. 
",crmprogdev,https://salesforce.stackexchange.com/users/2212,http://salesforce.stackexchange.com/questions/11838/how-to-create-an-app-package-whose-sole-functionality-is-to-redirect,TECHNOLOGY,salesforce.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,0.7777777777777778,0.6666666666666667,0.3333333333333333,0.3333333333333333,0.0,1.0,How to create an application / package whose only function is redirection?,"I want to create an app/package to be published on the appexchange.  The only functionality of that app/package will be to redirect the user to a configured URL in the app. This will happen once enterprise admin adds the app from the appexchange.

The redirect functionality is related to remote access via Oauth2. Once redirected to the URL, the URL endpoint will kick in and do all the further steps.

I do NOT want the admin of the enterprise to make any config e.g creating webtab or a link as a workaround to making some package. This SHOULD be done when the app is added.

In other words, can we make an app that does not contain any tab, but just a URL?

Also, Can we package remote access apps?
","I highly recommend you review Force.com Platform Fundamentals Workbook which has a complete tutorial on building an App. I think you'll find the answer to what constitutes an App there. To help you get the most benefit from Salesforce StackExchange, you may find it helpful to look at our FAQ which explains how to post effectively when you visit this site.

I'll add that I also believe you'd have also discovered the answers to your question through the many resources available to developers linked from the Wiki provided to you in the response to your previous post. 
"
1956,1956,3117,Can the Mage Wars Warlock be played without any Demon cards?,"As the subject states, I was wondering if the Mage Wars Core Set comes with enough Fire type cards to allow the Warlock Mage to build a spellbook with absolutely no Demon cards. Without seeing the cards, I will assume that most, if not all of the other Dark magic cards are OK, but I would ultimately prefer a pure Fire Magic spellbook.

So as to preemptively answer the almost inevitable 'Why?', I will simply say that, as an orthodox Christian, my conscience doesn't allow me to play a game with such cards. I would prefer not to debate/explain this further, as I believe such a discussion is well beyond the scope of this site.
",DragonSlayer,https://boardgames.stackexchange.com/users/11553,"In the starting Core Set I would have to say that it would be a very tough if not an impossible feat to be able to play the Warlock without the Demon cards, as there is only one Flame type creature, but it just happens to also be a Demon.  So you would have to spend quite a bit of your deck points on the doubled points from creatures not being a dark or fire type.

This may be doable, as you may be able to counter balance with some of the powerful Flame attack spells that can really do some damage, especially when combined with an equipment called Elemental Wand, to allow you to bind and recast the attack spells each turn.
",JMoser,https://boardgames.stackexchange.com/users/11603,http://boardgames.stackexchange.com/questions/22585/can-the-mage-wars-warlock-be-played-without-any-demon-cards,CULTURE,boardgames.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.7777777777777778,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,Can mage warlocks use without demonic cards?,"As mentioned in the topic, I want to know if there are enough fire type cards in the mage war core set to let the mage build a magic book without devil cards. Without looking at the cards, I would assume that most, if not all, of the other dark magic cards would work, but I would eventually prefer a pure fire magic book.","In the starting Core Set I would have to say that it would be a very tough if not an impossible feat to be able to play the Warlock without the Demon cards, as there is only one Flame type creature, but it just happens to also be a Demon.  So you would have to spend quite a bit of your deck points on the doubled points from creatures not being a dark or fire type.

This may be doable, as you may be able to counter balance with some of the powerful Flame attack spells that can really do some damage, especially when combined with an equipment called Elemental Wand, to allow you to bind and recast the attack spells each turn.
"
4980,4980,7930,What to do with old connections when moving outlet to dedicated circuit?,"I would like to remove one of the outlets from a circuit, and run a dedicated wire to it from a separate breaker, placing it on it's own circuit.

When I disconnect the existing circuit from the receptical, that will leave pigtails for the old circuit.

What do I do with the pigtails from the old circuit that the outlet will no longer be wired to?  

-Do they need to stay in the box(which would mean they would be pigtailed in the box, but not connected to the outlet, and new wiring would also run into the box for the new circuit connected to the outlet)?

-Get pushed into the wall?

-What seems the safest thing: Remove the outlet, leave the pigtails in the box, and put a blank over it. Then cut a new hole for a new box for the receptacle and new wiring to go into.
",AaronLS,https://diy.stackexchange.com/users/5218,"Your best option, after having read the comments you provided, is to put a new branch circuit in for the Microwave, even though it is more difficult in your particular circumstance.  The microwave should have a 20amp circuit, because it runs at over 13 Amps.  14AWG wire is rated for 15 Amps, but for continuous loads the rating drops to 12 Amps (80 percent of non-continuous per NEC 210.20(A)).  You should also protect this new circuit with an GFCI outlet, especially if it is near a sink/water. Leave the 14 AWG wires connected in the back of the box so they feed the other outlets.
",Edwin,https://diy.stackexchange.com/users/8973,http://diy.stackexchange.com/questions/57790/what-to-do-with-old-connections-when-moving-outlet-to-dedicated-circuit,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.8,1.0,0.3333333333333333,0.6666666666666666,1.0,How to deal with the old connection when the socket is moved to a dedicated circuit?,"I would like to remove one of the outlets from a circuit, and run a dedicated wire to it from a separate breaker, placing it on it's own circuit.

When I disconnect the existing circuit from the receptical, that will leave pigtails for the old circuit.

What do I do with the pigtails from the old circuit that the outlet will no longer be wired to?  

-Do they need to stay in the box(which would mean they would be pigtailed in the box, but not connected to the outlet, and new wiring would also run into the box for the new circuit connected to the outlet)?

-Get pushed into the wall?

-What seems the safest thing: Remove the outlet, leave the pigtails in the box, and put a blank over it. Then cut a new hole for a new box for the receptacle and new wiring to go into.
","Your best choice, after reading the comments you provided, is to install a new branch circuit for the microwave oven, although it will be more difficult in your special case. The microwave oven should have a 20 amp circuit because it has an operating current of more than 13 amps. The 14AWG wire is rated at 15 Amps, but for continuous loads, the current rating is reduced to 12 amps (80% discontinuous according to NEC 210.20 (a)). You should also use GFCI outlets to protect this new circuit, especially near the sink / water. Connect the 14 AWG wire to the back of the box to power other outlets."
6001,6001,9521,Is this function bijective?,"Consider the function $\theta:\{0,1\}\times\mathbb{N}\rightarrow\mathbb{Z}$ defined as $\theta(a,b) = a-2ab+b$. Is this function bijective?

For injective, I tried doing the contrapositive by supposing $\theta(a,b)=\theta(c,d)$, then $a-2ab+b=c-2cd+d$, but I have no idea where to go from there. I tried solving for a and b separately and plugging it back in, but that just turned into a huge algebraic mess.

I haven't figured what I'm going to do for surjective yet.

I'm not very good at this subject, so sorry if this is a stupid question. Any hints are appreciated, thanks.
",laser295,https://math.stackexchange.com/users/35378,"Hint $\ $ Glue the bijections $\rm\ b = f_{\,0}(b):\Bbb N\to \Bbb N\ $ and $\rm\ 1\!-\!b = f_{\!\ 1}(b): \Bbb N\to\, {-}\Bbb N\cup \{0\}\ $ as below:

If $\rm\:S_0,\,S_1\:$ are disjoint subsets of $\,\Bbb Z\,$ and $\rm\:f_{\,i}(b) :\Bbb N\to S_i\,$  are bijections for $\rm\,i\in\{0,1\}\,$ then $\rm\:f(a,b):\{0,1\}\times\Bbb N \to S_0\!\cup S_1\,$ is a bijection for  $\rm\ f(a,b)\ =\ a\,f_{\!\ 1}(b) + (1\!-\!a)\,f_{\,0}(b)$
",Number,https://math.stackexchange.com/users/242,http://math.stackexchange.com/questions/177385/is-the-function-thetaa-b-a-2abb-a-bijection-from-0-1-times-mathbbn,SCIENCE,math.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.5,0.7777777777777778,1.0,0.7,1.0,0.3333333333333333,0.0,1.0,Is this function bijective?,"Consider the function $\theta:\{0,1\}\times\mathbb{N}\rightarrow\mathbb{Z}$ defined as $\theta(a,b) = a-2ab+b$. Is this function bijective?

For injective, I tried doing the contrapositive by supposing $\theta(a,b)=\theta(c,d)$, then $a-2ab+b=c-2cd+d$, but I have no idea where to go from there. I tried solving for a and b separately and plugging it back in, but that just turned into a huge algebraic mess.

I haven't figured what I'm going to do for surjective yet.

I'm not very good at this subject, so sorry if this is a stupid question. Any hints are appreciated, thanks.
","Hint $\ $ Glue the bijections $\rm\ b = f_{\,0}(b):\Bbb N\to \Bbb N\ $ and $\rm\ 1\!-\!b = f_{\!\ 1}(b): \Bbb N\to\, {-}\Bbb N\cup \{0\}\ $ as below:

If $\rm\:S_0,\,S_1\:$ are disjoint subsets of $\,\Bbb Z\,$ and $\rm\:f_{\,i}(b) :\Bbb N\to S_i\,$  are bijections for $\rm\,i\in\{0,1\}\,$ then $\rm\:f(a,b):\{0,1\}\times\Bbb N \to S_0\!\cup S_1\,$ is a bijection for  $\rm\ f(a,b)\ =\ a\,f_{\!\ 1}(b) + (1\!-\!a)\,f_{\,0}(b)$
"
4081,4081,6515,Rotating an object in OpenGL about it's centre,"Im writing a game for which, one of the models are loaded from an .obj file.

It's a model of a plane, and I want to rotate the propeller. The object file is broken into groups, and the propeller is identified, so that's all good.
I'm writing the game in C++ with OpenGl/GLFW
The drawing function is:

int win_width;
int win_height;
glfwGetWindowSize(&amp;win_width, &amp;win_height);
float win_aspect = (float)win_width / (float)win_height;
glViewport(0, 0, win_width, win_height);

glMatrixMode(GL_PROJECTION);
glLoadIdentity();
gluPerspective(90, win_aspect, 1, 100.0);

glMatrixMode(GL_MODELVIEW);
glLoadIdentity();
gluLookAt(0, 0, 30.0, 0, 0, 0, 0.0, 1.0, 0.0);

glEnable(GL_DEPTH);
glEnable(GL_DEPTH_TEST);
glEnable(GL_COLOR_MATERIAL);
glEnable(GL_NORMALIZE); 
glEnable(GL_LIGHTING);
glEnable(GL_LIGHT0);
glEnable(GL_LIGHT1);
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

glColor3f(0.0f, 0.0f, 0.0f);
int vertexIndex = 0, normalIndex;
glRotatef(90, 0, 1, 0);
glPushMatrix();
for(int a = 0; a &lt; (int)groups.size(); a++)
{
    if(groups[a].type == ""prop"")
    {
//Code for rotation
        glPopMatrix();
        glPushMatrix();
        float x,y,z;
        x = y = z = 0;
        int Count = 0;
        for(int k = 0; k &lt; groups[a].faces.size(); k++)
        {
            for(int p = 0; p &lt; groups[a].faces[k].vertices.size(); p++)
            {
                int _index = groups[a].faces[k].vertices[p];
                y += vertices[_index].Dimensions[_y] ;
                z += vertices[_index].Dimensions[_z];
                Count++;
            }
        }
        z /= Count;
        y /= Count;
        glTranslatef(0, -y, -z);
        glRotatef(angle, 1, 0, 0);
        glTranslatef(0, y, z);
    }
    for(int b = 0; b &lt; (int)groups[a].faces.size(); b++)
    {
        glBegin(GL_POLYGON);
        for(int c = 0; c &lt; (int)groups[a].faces[b].vertices.size(); c++)
        {
            vertexIndex = groups[a].faces[b].vertices[c];
            glVertex3d(vertices[vertexIndex].Dimensions[_x], vertices[vertexIndex].Dimensions[_y], vertices[vertexIndex].Dimensions[_z]);
        }
        glEnd();
    }
}
glPopMatrix();
glfwSwapBuffers();


Since I don't know the exact centre of the propeller, that's what the for loop before the rotation is for. It finds the average of the y and z co-ordinates.

After I find it, I translate to -y,-z , rotate it, and then translate back. This makes the propeller spin as I want it to, but it also rotates along the origin >.&lt;
http://people.sc.fsu.edu/~jburkardt/data/obj/cessna.obj &lt;- This is the object file.

groups is a vector of objects and each object has a vector of faces. I'm sure that the vertices and faces are being loaded correctly, since the whole model renders correctly.
",viraj,https://gamedev.stackexchange.com/users/9194,"OpenGL uses a column vector convention, which means the matrices must be applied in the opposite of the order in which you actually want the transformations to occur.  Just replace this: 

glTranslatef(0, -y, -z);
glRotatef(angle, 1, 0, 0);
glTranslatef(0, y, z);


with this:

glTranslatef(0, y, z);
glRotatef(angle, 1, 0, 0);
glTranslatef(0, -y, -z);


and that should fix it.
",Nathan Reed,https://gamedev.stackexchange.com/users/9894,http://gamedev.stackexchange.com/questions/18854/rotating-an-object-in-opengl-about-its-centre,TECHNOLOGY,gamedev.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Rotate objects around their center in OpenGL,"Im writing a game for which, one of the models are loaded from an .obj file.

It's a model of a plane, and I want to rotate the propeller. The object file is broken into groups, and the propeller is identified, so that's all good.
I'm writing the game in C++ with OpenGl/GLFW
The drawing function is:

int win_width;
int win_height;
glfwGetWindowSize(&amp;win_width, &amp;win_height);
float win_aspect = (float)win_width / (float)win_height;
glViewport(0, 0, win_width, win_height);

glMatrixMode(GL_PROJECTION);
glLoadIdentity();
gluPerspective(90, win_aspect, 1, 100.0);

glMatrixMode(GL_MODELVIEW);
glLoadIdentity();
gluLookAt(0, 0, 30.0, 0, 0, 0, 0.0, 1.0, 0.0);

glEnable(GL_DEPTH);
glEnable(GL_DEPTH_TEST);
glEnable(GL_COLOR_MATERIAL);
glEnable(GL_NORMALIZE); 
glEnable(GL_LIGHTING);
glEnable(GL_LIGHT0);
glEnable(GL_LIGHT1);
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

glColor3f(0.0f, 0.0f, 0.0f);
int vertexIndex = 0, normalIndex;
glRotatef(90, 0, 1, 0);
glPushMatrix();
for(int a = 0; a &lt; (int)groups.size(); a++)
{
    if(groups[a].type == ""prop"")
    {
//Code for rotation
        glPopMatrix();
        glPushMatrix();
        float x,y,z;
        x = y = z = 0;
        int Count = 0;
        for(int k = 0; k &lt; groups[a].faces.size(); k++)
        {
            for(int p = 0; p &lt; groups[a].faces[k].vertices.size(); p++)
            {
                int _index = groups[a].faces[k].vertices[p];
                y += vertices[_index].Dimensions[_y] ;
                z += vertices[_index].Dimensions[_z];
                Count++;
            }
        }
        z /= Count;
        y /= Count;
        glTranslatef(0, -y, -z);
        glRotatef(angle, 1, 0, 0);
        glTranslatef(0, y, z);
    }
    for(int b = 0; b &lt; (int)groups[a].faces.size(); b++)
    {
        glBegin(GL_POLYGON);
        for(int c = 0; c &lt; (int)groups[a].faces[b].vertices.size(); c++)
        {
            vertexIndex = groups[a].faces[b].vertices[c];
            glVertex3d(vertices[vertexIndex].Dimensions[_x], vertices[vertexIndex].Dimensions[_y], vertices[vertexIndex].Dimensions[_z]);
        }
        glEnd();
    }
}
glPopMatrix();
glfwSwapBuffers();


Since I don't know the exact centre of the propeller, that's what the for loop before the rotation is for. It finds the average of the y and z co-ordinates.

After I find it, I translate to -y,-z , rotate it, and then translate back. This makes the propeller spin as I want it to, but it also rotates along the origin >.&lt;
http://people.sc.fsu.edu/~jburkardt/data/obj/cessna.obj &lt;- This is the object file.

groups is a vector of objects and each object has a vector of faces. I'm sure that the vertices and faces are being loaded correctly, since the whole model renders correctly.
","OpenGL uses a column vector convention, which means the matrices must be applied in the opposite of the order in which you actually want the transformations to occur.  Just replace this: 

glTranslatef(0, -y, -z);
glRotatef(angle, 1, 0, 0);
glTranslatef(0, y, z);


with this:

glTranslatef(0, y, z);
glRotatef(angle, 1, 0, 0);
glTranslatef(0, -y, -z);


and that should fix it.
"
3361,3361,5363,Windows 7 batch search for email addresses,"Thanks in advance for your help. I have to do a task on my office computer which means I can't install any additional software, so I think a batch file might be the easiest way to do this even if it's not the most efficient (although I welcome other solutions that I might be able to do without installing software on my office computer). Also, please keep in mind that I have very little programming experience in your answers :)

Basically, I have a folder with a series of subfolders in it, each of these full of files of various types (text, emails, text-based pdfs, word docs). I also have a text file (or an excel column) with hundreds of email addresses in it. I want to use a batch file (or similar method) to run through each email address in the list and search against the contents of the various files in each folder like Windows Search does. Files which contain the search phrase should automatically be moved to a prespecified folder (possibly having to be renamed or put in a new subfolder as many of these files might have the same name). In the end, we should have one folder (as well as its subfolders) which contains no files which have any of the email addresses from the list in their contents, and another folder which only has files that has content containing the email addresses in their files (these can be in subfolders, or renamed, or whatever is most convenient, just not deleted).

(Since the list of email addresses is in Excel, another option I could entertain would be using some sort of VBA macro if that is capable of searching the contents of files within a folder recursively.)

I hope that this makes sense and I'm happy to clarify if it doesn't. Again, thanks for any help you can provide!
",Cliff Hansen,https://stackoverflow.com/users/2945724,"VBScript - Google for ""VBscript search file contents""
Results such as http://www.codeproject.com/Questions/524842/VbscriptplusToplussearchplusforplusaplusstringplus should help. Also if you're having trouble with the recursive folder search part http://blogs.technet.com/b/heyscriptingguy/archive/2004/10/20/how-can-i-get-a-list-of-all-the-files-in-a-folder-and-its-subfolders.aspx might help.

VBScript is nearly identical to VBA. That code can probably be modified to run inside Excel as a macro if you'd like.

I'd recommend using FileSystemObject and TextStreams instead of native VBA file operations if you might be dealing with unicode files.
",AndASM,https://stackoverflow.com/users/2250183,http://stackoverflow.com/questions/19731847/windows-7-batch-search-for-email-addresses,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8333333333333334,0.5,1.0,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,Windows 7 bulk search email address,"Thanks in advance for your help. I have to do a task on my office computer which means I can't install any additional software, so I think a batch file might be the easiest way to do this even if it's not the most efficient (although I welcome other solutions that I might be able to do without installing software on my office computer). Also, please keep in mind that I have very little programming experience in your answers :)

Basically, I have a folder with a series of subfolders in it, each of these full of files of various types (text, emails, text-based pdfs, word docs). I also have a text file (or an excel column) with hundreds of email addresses in it. I want to use a batch file (or similar method) to run through each email address in the list and search against the contents of the various files in each folder like Windows Search does. Files which contain the search phrase should automatically be moved to a prespecified folder (possibly having to be renamed or put in a new subfolder as many of these files might have the same name). In the end, we should have one folder (as well as its subfolders) which contains no files which have any of the email addresses from the list in their contents, and another folder which only has files that has content containing the email addresses in their files (these can be in subfolders, or renamed, or whatever is most convenient, just not deleted).

(Since the list of email addresses is in Excel, another option I could entertain would be using some sort of VBA macro if that is capable of searching the contents of files within a folder recursively.)

I hope that this makes sense and I'm happy to clarify if it doesn't. Again, thanks for any help you can provide!
","VBScript - Google for ""VBscript search file contents""
Results such as http://www.codeproject.com/Questions/524842/VbscriptplusToplussearchplusforplusaplusstringplus should help. Also if you're having trouble with the recursive folder search part http://blogs.technet.com/b/heyscriptingguy/archive/2004/10/20/how-can-i-get-a-list-of-all-the-files-in-a-folder-and-its-subfolders.aspx might help.

VBScript is nearly identical to VBA. That code can probably be modified to run inside Excel as a macro if you'd like.

I'd recommend using FileSystemObject and TextStreams instead of native VBA file operations if you might be dealing with unicode files.
"
2466,2466,3933,Do real and reactive energy exist?,"Are there any such things as real and reactive energies just like real and reactive power? if so, how is reactive energy dissipated?
",Sri,https://electronics.stackexchange.com/users/34625,"Energy is just power integrated over time, so real and reactive energy exists or not just like real and reactive power, respectively.

As for power, real power exists and reactive power is a mathematical convenience to simplify expressing certain things.  By using the mental shortcut of imagining imaginary power, we can simplify calculations and explain real observed parameters more easily than without.

Imaginary power doesn't exist, but the effects of it projected back to real power are real.  Large scale power grid producers and consumers are often rated in both the instantaneous real and imaginary power they are producing or consuming.  However, the same real observable characteristics can be explained other ways.  Explaining them in terms of imaginary power is merely a mental and mathematical convenience.
",Olin Lathrop,https://electronics.stackexchange.com/users/4512,http://electronics.stackexchange.com/questions/94594/do-real-and-reactive-energy-exist,TECHNOLOGY,electronics.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Is there any active and no function?,"Is there real energy and reactive energy, just like real power and reactive power? If so, how to dissipate reactive energy?","Energy is just power integrated over time, so real and reactive energy exists or not just like real and reactive power, respectively.

As for power, real power exists and reactive power is a mathematical convenience to simplify expressing certain things.  By using the mental shortcut of imagining imaginary power, we can simplify calculations and explain real observed parameters more easily than without.

Imaginary power doesn't exist, but the effects of it projected back to real power are real.  Large scale power grid producers and consumers are often rated in both the instantaneous real and imaginary power they are producing or consuming.  However, the same real observable characteristics can be explained other ways.  Explaining them in terms of imaginary power is merely a mental and mathematical convenience.
"
4523,4523,7168,What does (heated) mean in a chemical equation?,"I'm supposed to balance the following equation:

$\text{Potassium chlorate (heated) --&gt; Potassium chloride + Oxygen}$

But I don't understand what the (heated) means in front of the first element. Do I ignore it, or am I supposed to add another element to the reactants of the equation?
",Vishwa Iyer,https://chemistry.stackexchange.com/users/7490,"In terms of balancing the equation, the fact that heat must be supplied can be ignored.  It is just providing information about the conditions necessary to run the reaction.
",ron,https://chemistry.stackexchange.com/users/4231,http://chemistry.stackexchange.com/questions/15290/what-does-heated-mean-in-a-chemical-equation,SCIENCE,chemistry.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,What does (heating) mean in a chemical equation?,"I'm supposed to balance the following equation:

$\text{Potassium chlorate (heated) --&gt; Potassium chloride + Oxygen}$

But I don't understand what the (heated) means in front of the first element. Do I ignore it, or am I supposed to add another element to the reactants of the equation?
","In terms of the equilibrium equation, the fact that heat must be provided is negligible. It just provides information about the conditions required for the reaction."
1570,1570,2469,How to get the path of android installed application,"Hi I am new to Android and I want to know that how can we get the path of the installed application in android, So that we can open the file in our application by using that installed application.

for example:
I want to open the pdf file or doc file in my application but i require the path of that application which can open this file...

Please Help me 
Thanks in advance...
",Mak,https://stackoverflow.com/users/556869,"I used the Following Code to do this

private void openFile(File f)

    {

        // Create an Intent

        Intent intent = new Intent();
        intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);
        intent.setAction(android.content.Intent.ACTION_VIEW);

        // Category where the App should be searched


        // String category = new String(""android.intent.category.DEFAULT"");

        // Setting up the data and the type for the intent

        String type = getMIMEType(f);
        /*Uri startDir = Uri.fromFile(f);
        intent.setAction(Intent.ACTION_PICK);
        intent.setDataAndType(startDir, ""vnd.android.cursor.dir/*"");*/
        intent.setDataAndType(Uri.fromFile(f), type);

        // will start the activtiy found by android or show a dialog to select one

        startActivity(intent);//


        /**intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK+Intent.FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS);
        String theMIMEcategory = getMIMEcategory(type);
        intent.setDataAndType(Uri.fromFile(f),theMIMEcategory);
        try {
         startActivity(Intent.createChooser(intent,""Choose Applicaton""));
        } catch (Exception e) {
         //show error
        }
         */
    }

    /**

     * Returns the MIME type for the given file.
     *
     * @param f the file for which you want to determine the MIME type
     * @return the detected MIME type
     */
    private String getMIMEType(File f)
    {

        String end = f.getName().substring(f.getName().lastIndexOf(""."")+1, f.getName().length()).toLowerCase();

        String type = """";

        if(end.equals(""mp3"") || end.equals(""aac"") || end.equals(""aac"") || end.equals(""amr"") || end.equals(""mpeg"") || end.equals(""mp4"")) type = ""audio/*"";

        else if(end.equals(""jpg"") || end.equals(""gif"") || end.equals(""png"") || end.equals(""jpeg"")) type = ""image/*"";

        else if(end.equals(""pdf"")) type = ""application/pdf"";

        else if(end.equals(""xls"")) type = ""application/vnd.ms-excel"";

        else if(end.equals(""doc"")) type = ""application/msword"";

        else if(end.equals(""zip"")) type=""application/zip"";
        else {type=""*/*"" ;}



        //type += ""/*"";

        return type;

    }

    public static String getMIMEcategory(String aMIMEtype) {
        if (aMIMEtype!=null) {
            aMIMEtype = aMIMEtype.substring(0,aMIMEtype.lastIndexOf(""/"",aMIMEtype.length()-1))+""/*"";
        } else {
            aMIMEtype = ""*/*"";
        }
        return aMIMEtype;
    }'

",Mak,https://stackoverflow.com/users/556869,http://stackoverflow.com/questions/4552402/how-to-get-the-path-of-android-installed-application,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,How to get the path of Android installation application,"Hi I am new to Android and I want to know that how can we get the path of the installed application in android, So that we can open the file in our application by using that installed application.

for example:
I want to open the pdf file or doc file in my application but i require the path of that application which can open this file...

Please Help me 
Thanks in advance...
","I used the Following Code to do this

private void openFile(File f)

    {

        // Create an Intent

        Intent intent = new Intent();
        intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);
        intent.setAction(android.content.Intent.ACTION_VIEW);

        // Category where the App should be searched


        // String category = new String(""android.intent.category.DEFAULT"");

        // Setting up the data and the type for the intent

        String type = getMIMEType(f);
        /*Uri startDir = Uri.fromFile(f);
        intent.setAction(Intent.ACTION_PICK);
        intent.setDataAndType(startDir, ""vnd.android.cursor.dir/*"");*/
        intent.setDataAndType(Uri.fromFile(f), type);

        // will start the activtiy found by android or show a dialog to select one

        startActivity(intent);//


        /**intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK+Intent.FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS);
        String theMIMEcategory = getMIMEcategory(type);
        intent.setDataAndType(Uri.fromFile(f),theMIMEcategory);
        try {
         startActivity(Intent.createChooser(intent,""Choose Applicaton""));
        } catch (Exception e) {
         //show error
        }
         */
    }

    /**

     * Returns the MIME type for the given file.
     *
     * @param f the file for which you want to determine the MIME type
     * @return the detected MIME type
     */
    private String getMIMEType(File f)
    {

        String end = f.getName().substring(f.getName().lastIndexOf(""."")+1, f.getName().length()).toLowerCase();

        String type = """";

        if(end.equals(""mp3"") || end.equals(""aac"") || end.equals(""aac"") || end.equals(""amr"") || end.equals(""mpeg"") || end.equals(""mp4"")) type = ""audio/*"";

        else if(end.equals(""jpg"") || end.equals(""gif"") || end.equals(""png"") || end.equals(""jpeg"")) type = ""image/*"";

        else if(end.equals(""pdf"")) type = ""application/pdf"";

        else if(end.equals(""xls"")) type = ""application/vnd.ms-excel"";

        else if(end.equals(""doc"")) type = ""application/msword"";

        else if(end.equals(""zip"")) type=""application/zip"";
        else {type=""*/*"" ;}



        //type += ""/*"";

        return type;

    }

    public static String getMIMEcategory(String aMIMEtype) {
        if (aMIMEtype!=null) {
            aMIMEtype = aMIMEtype.substring(0,aMIMEtype.lastIndexOf(""/"",aMIMEtype.length()-1))+""/*"";
        } else {
            aMIMEtype = ""*/*"";
        }
        return aMIMEtype;
    }'

"
1726,1726,2730,Adjustable sample size in clinical trial,"Most clinical trials I see have a fixed sample size.  In some cases they have prior data that allows estimating the effect size and the variance or distribution of values, and calculate the sample size from that for a certain power.  In other cases it is just a guess.

Why wouldn't people run a clinical trial in which the sample size was determined during the trial?  (for example, by increasing it until the confidence interval narrowed to a certain size specified in advance)  Is there any reason this would not be a valid design?  Are there any examples of trials like that, and any references for designing a trial like that?
",Alex I,https://stats.stackexchange.com/users/43106,"I think AdamO's answer is great, but I think it's also  worth emphasizing out that this adaptive sample size design is how many (maybe even most? I've done theoretical work during internships at pharm companies, but can't say I've ever planned a real study...) clinical trials are run. 

That is to say, if a sequential design is used, initial patients are recruited and treated. Part way through the study, the currently collected data gets analyzed. Three possible actions can occur at this point: the data may show a statistically significant result and the study will be stopped because efficacy has been demonstrated, the data many statistically significantly show that there is no strong effect (for example, the upper end of the confidence interval is below some clinically significant threshold) and the study is stopped due to futility or the data is not yet conclusive (i.e. both a clinically significant effect and a clinically insignificant effect are contained in the confidence interval) in which more data will be collected. So you can see that in this case, the sample size is not fixed. 

An important note about this: you can't just run a standard test each time you ""check"" your data, otherwise you are doing multiple comparisons! Because the test statistics at different times should be positively correlated, it's not as big an issue as standard multiple comparison issues, but it still should be addressed for proper inference. Clinical trials, being regulated by the FDA, must state a plan for how they will address this (as @AdamO points out, SeqTrial provides software for this). However, often times academic researchers, not being regulated by the FDA, will continue to collect data until they find significance without adjusting for the fact that they are doing several comparisons. It's not the biggest abuse of statistical practice in research, but it still is an abuse. 
",Cliff AB,https://stats.stackexchange.com/users/76981,http://stats.stackexchange.com/questions/159373/adjustable-sample-size-in-clinical-trial,SCIENCE,stats.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Adjustable sample size in clinical trials,"Most clinical trials I see have a fixed sample size.  In some cases they have prior data that allows estimating the effect size and the variance or distribution of values, and calculate the sample size from that for a certain power.  In other cases it is just a guess.

Why wouldn't people run a clinical trial in which the sample size was determined during the trial?  (for example, by increasing it until the confidence interval narrowed to a certain size specified in advance)  Is there any reason this would not be a valid design?  Are there any examples of trials like that, and any references for designing a trial like that?
","I think AdamO's answer is great, but I think it's also  worth emphasizing out that this adaptive sample size design is how many (maybe even most? I've done theoretical work during internships at pharm companies, but can't say I've ever planned a real study...) clinical trials are run. 

That is to say, if a sequential design is used, initial patients are recruited and treated. Part way through the study, the currently collected data gets analyzed. Three possible actions can occur at this point: the data may show a statistically significant result and the study will be stopped because efficacy has been demonstrated, the data many statistically significantly show that there is no strong effect (for example, the upper end of the confidence interval is below some clinically significant threshold) and the study is stopped due to futility or the data is not yet conclusive (i.e. both a clinically significant effect and a clinically insignificant effect are contained in the confidence interval) in which more data will be collected. So you can see that in this case, the sample size is not fixed. 

An important note about this: you can't just run a standard test each time you ""check"" your data, otherwise you are doing multiple comparisons! Because the test statistics at different times should be positively correlated, it's not as big an issue as standard multiple comparison issues, but it still should be addressed for proper inference. Clinical trials, being regulated by the FDA, must state a plan for how they will address this (as @AdamO points out, SeqTrial provides software for this). However, often times academic researchers, not being regulated by the FDA, will continue to collect data until they find significance without adjusting for the fact that they are doing several comparisons. It's not the biggest abuse of statistical practice in research, but it still is an abuse. 
"
5871,5871,9299,Password hashes should run md5 thousands of time: really?,"I skimmed through How Companies Can Beef Up Password Security and I thought that several assertions were completely wrong, in particular:


Cryptographic hash (like md5) with salt are bad.
It isn't uncommon to break/crack unix shadow files.
To make a password hash I should run it over md5 or whatever hundreds or thousands of times.


The article suggests that salted hashes are too easy to break and you'd want to select a password hash because its computationally longer to check passwords so you can not do as many per second.

I think doing 3 is bad for security and 1 is in reality the best option. What do you guys think?
",acidzombie24,https://security.stackexchange.com/users/5575,"Why do you think 3 is bad for security? Really what you should be doing is using something like bcrypt to hash your passwords to avoid all this mess.

Bcrypt combines those properties. It hashes the password using a salt many times over to create a slow and secure hash function that produces cryptographically secure hashes.
",Oleksi,https://security.stackexchange.com/users/7680,http://security.stackexchange.com/questions/16121/password-hashes-should-run-md5-thousands-of-time-really,TECHNOLOGY,security.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.4444444444444444,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.3333333333333333,0.8888888888888888,1.0,0.8,0.6666666666666666,0.0,1.0,1.0,Password hash should run md5000 times: really?,"I skimmed through How Companies Can Beef Up Password Security and I thought that several assertions were completely wrong, in particular:


Cryptographic hash (like md5) with salt are bad.
It isn't uncommon to break/crack unix shadow files.
To make a password hash I should run it over md5 or whatever hundreds or thousands of times.


The article suggests that salted hashes are too easy to break and you'd want to select a password hash because its computationally longer to check passwords so you can not do as many per second.

I think doing 3 is bad for security and 1 is in reality the best option. What do you guys think?
","Why do you think 3 is bad for security? Really what you should be doing is using something like bcrypt to hash your passwords to avoid all this mess.

Bcrypt combines those properties. It hashes the password using a salt many times over to create a slow and secure hash function that produces cryptographically secure hashes.
"
1232,1232,1929,Is my interval training routine effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
",DigiKev,https://bicycles.stackexchange.com/users/3323,"To some extent whether it will be effective depends on your goal. Are you trying to develop endurance or speed?

There's an article at sportsci.org on the ""Effects of High Intensisty Intermittent Training on Maximum Oxygen Uptake and Endurance Performance"" which compares several different interval training techniques if Endurance is your goal. 
",nick3216,https://bicycles.stackexchange.com/users/3063,http://bicycles.stackexchange.com/questions/7801/is-my-interval-training-routine-effective-for-mountain-bike-training,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Is my interval training effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
","To some extent whether it will be effective depends on your goal. Are you trying to develop endurance or speed?

There's an article at sportsci.org on the ""Effects of High Intensisty Intermittent Training on Maximum Oxygen Uptake and Endurance Performance"" which compares several different interval training techniques if Endurance is your goal. 
"
1721,1721,2725,Unable to make Zsh not to suggest a fix for an alias,"I have an alias for

alias tdA='todo -a'


I get the following in Zsh

tdA          
zsh: correct 'tdA' to 'tda' [nyae]?


How can you make Zsh not to suggest a fix for an alias?
",LÃ©o LÃ©opold Hertz ì¤ì,https://serverfault.com/users/1944,"I've been using zsh for about 18 years now, and I must say I don't like the accepted solution. Here's why:

You need to figure out the source of the problem - determine why 'tda' is being offered as a correction option. What you have done is completely disabled spelling correction globally. This denies you some very nice functionality while trying to get rid of a tactical problem. It's like wanting to kill a fly in your house by setting off some dynamite just because you're too lazy to figure out where the fly swatter is: It may get rid of the problem, but you sacrifice a whole lot in return. :)

Until you can determine your zsh's current spell correction configuration, you should consider setting the value of the special shell variable $CORRECT_IGNORE to a value of 'tda'.

Here is the entry in the zsh man page:

   CORRECT_IGNORE
          If set, is treated as a pattern during spelling correction.  Any
          potential  correction  that matches the pattern is ignored.  For
          example, if the value is `_*' then completion functions  (which,
          by  convention,  have  names  beginning  with `_') will never be
          offered as spelling corrections.  The pattern does not apply the
          correction  of  file names, as applied by the CORRECT_ALL option
          (so with the example just given files beginning with `_' in  the
          current directory would still be completed).


This should help get you by until you can determine the source of where 'tda' is actually coming from. 

Also note that you can use the precommand modifier 'nocorrect' to disable spelling correction on a per-command basis. You could use this to do something a little hacky, but effective:

alias tdA=""nocorrect tda""
alias tda=""todo -a""


aliases are just tokens substituted into the command-line by zsh, and those substitutions are re-scanned for additional aliases. So the above should work.

Hopefully these alternatives give you a more selective approach to solving your problem, while still giving you the benefit of zsh's rich spelling correction features.

Good luck!
",Larold,https://serverfault.com/users/94048,http://serverfault.com/questions/21521,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,Unable to make Zsh not recommend repairing aliases,"I have an alias for

alias tdA='todo -a'


I get the following in Zsh

tdA          
zsh: correct 'tdA' to 'tda' [nyae]?


How can you make Zsh not to suggest a fix for an alias?
","I've been using zsh for about 18 years now, and I must say I don't like the accepted solution. Here's why:

You need to figure out the source of the problem - determine why 'tda' is being offered as a correction option. What you have done is completely disabled spelling correction globally. This denies you some very nice functionality while trying to get rid of a tactical problem. It's like wanting to kill a fly in your house by setting off some dynamite just because you're too lazy to figure out where the fly swatter is: It may get rid of the problem, but you sacrifice a whole lot in return. :)

Until you can determine your zsh's current spell correction configuration, you should consider setting the value of the special shell variable $CORRECT_IGNORE to a value of 'tda'.

Here is the entry in the zsh man page:

   CORRECT_IGNORE
          If set, is treated as a pattern during spelling correction.  Any
          potential  correction  that matches the pattern is ignored.  For
          example, if the value is `_*' then completion functions  (which,
          by  convention,  have  names  beginning  with `_') will never be
          offered as spelling corrections.  The pattern does not apply the
          correction  of  file names, as applied by the CORRECT_ALL option
          (so with the example just given files beginning with `_' in  the
          current directory would still be completed).


This should help get you by until you can determine the source of where 'tda' is actually coming from. 

Also note that you can use the precommand modifier 'nocorrect' to disable spelling correction on a per-command basis. You could use this to do something a little hacky, but effective:

alias tdA=""nocorrect tda""
alias tda=""todo -a""


aliases are just tokens substituted into the command-line by zsh, and those substitutions are re-scanned for additional aliases. So the above should work.

Hopefully these alternatives give you a more selective approach to solving your problem, while still giving you the benefit of zsh's rich spelling correction features.

Good luck!
"
2552,2552,4064,How to use multiple VLOOKUP with duplicate data?,"I have huge excel file. Column A has invoices(duplicate rows since each item in the invoice is a row), column B has SKU value of item bought(like 200ml, 300ml etc), column C has the brand bought(like Coca-Cola,Sprite etc) and column D has the no of items bought(like 10,15 etc).



The first table has is the dump file for all invoices and the intems bought

Now i want to find the No. of items bought given the condition that the brand is Coca-Cola, the SKU is 200ml and the invoice no. is XAX1X2X3 and display it in another cell.



Now in the second table, i want to match the invoice with the pack size and brand from first table and put the quantity in the empty cell

So the row that is highlighted in table 2 will show the value 3 cause invoice T1411031400114, pack size 200, brand coca-cola has Qty as 3.

I was thinking of using nested VLOOKUP but cant get the correct formula for it.

Any help will be appreciated.

Regards

Anand
",anand,https://stackoverflow.com/users/124075,"For a sample table like

+---+---------+--------+------+-----+--+---------+-------+------+-------+
|   |    A    |   B    |  C   |  D  |E |    F    |   G   |  H   |   I   |
+---+---------+--------+------+-----+--+---------+-------+------+-------+
| 1 | Invoice | Brand  | Size | Qty |  | Invoice | Brand | Size | Total |
| 2 | 31      | Coke   | 200  | 1   |  | 31      | Coke  | 200  | 3     |
| 3 | 31      | Coke   | 200  | 2   |  |         |       |      |       |
| 4 | 31      | Sprite | 300  | 4   |  |         |       |      |       |
| 5 | 31      | Fanta  | 100  | 3   |  |         |       |      |       |
| 6 | 31      | Coke   | 300  | 2   |  |         |       |      |       |
+---+---------+--------+------+-----+--+---------+-------+------+-------+


you would use in cell I2

=SUMPRODUCT(($D$2:$D$6)*(F2=$A$2:$A$6)*(G2=$B$2:$B$6)*(H2=$C$2:$C$6))


Hopefully this solves (at least part of) your problem.
This provides one of the many outputs of a PivotTable. Pros: the result is automatically updated (a PivotTable is not). Cons: one may not wish an automatic update (either to keep previous results, or for performance issues with large data sets).
",sancho.s,https://stackoverflow.com/users/2707864,http://stackoverflow.com/questions/25008387/how-to-use-multiple-vlookup-with-duplicate-data,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,1.0,How to use multiple vlookups with duplicate data?,"I have huge excel file. Column A has invoices(duplicate rows since each item in the invoice is a row), column B has SKU value of item bought(like 200ml, 300ml etc), column C has the brand bought(like Coca-Cola,Sprite etc) and column D has the no of items bought(like 10,15 etc).



The first table has is the dump file for all invoices and the intems bought

Now i want to find the No. of items bought given the condition that the brand is Coca-Cola, the SKU is 200ml and the invoice no. is XAX1X2X3 and display it in another cell.



Now in the second table, i want to match the invoice with the pack size and brand from first table and put the quantity in the empty cell

So the row that is highlighted in table 2 will show the value 3 cause invoice T1411031400114, pack size 200, brand coca-cola has Qty as 3.

I was thinking of using nested VLOOKUP but cant get the correct formula for it.

Any help will be appreciated.

Regards

Anand
","For a sample table like

+---+---------+--------+------+-----+--+---------+-------+------+-------+
|   |    A    |   B    |  C   |  D  |E |    F    |   G   |  H   |   I   |
+---+---------+--------+------+-----+--+---------+-------+------+-------+
| 1 | Invoice | Brand  | Size | Qty |  | Invoice | Brand | Size | Total |
| 2 | 31      | Coke   | 200  | 1   |  | 31      | Coke  | 200  | 3     |
| 3 | 31      | Coke   | 200  | 2   |  |         |       |      |       |
| 4 | 31      | Sprite | 300  | 4   |  |         |       |      |       |
| 5 | 31      | Fanta  | 100  | 3   |  |         |       |      |       |
| 6 | 31      | Coke   | 300  | 2   |  |         |       |      |       |
+---+---------+--------+------+-----+--+---------+-------+------+-------+


you would use in cell I2

=SUMPRODUCT(($D$2:$D$6)*(F2=$A$2:$A$6)*(G2=$B$2:$B$6)*(H2=$C$2:$C$6))


Hopefully this solves (at least part of) your problem.
This provides one of the many outputs of a PivotTable. Pros: the result is automatically updated (a PivotTable is not). Cons: one may not wish an automatic update (either to keep previous results, or for performance issues with large data sets).
"
6069,6069,9634,"What does ""to become controversial"" mean?","As a non-native speaker, I do not fully understand the meaning of the term ""to become controversial"" in the following text, which I have to translate into German:


  Where translators have made their presence felt they have become controversial, with those who characteristically intervene, seeking to domesticate texts, contrasted with those who foreignise, supposedly allowing other languages to alter our own.

",Patrick Oscity,https://english.stackexchange.com/users/12804,"I would like to expand upon their answers a bit.  Let's take the German word ""schadenfreude,"" which if you were to translate it into English would be ""pleasure derived from the misfortune of another.""  That would be about the shortest translation you could make for it, because English doesn't have a word specific to that definition.  Perhaps the shortest you could get without straying too far from the meaning would be ""sadistic pleasure,"" but that implies a degree of maliciousness to it and that the person getting the pleasure is causing the misfortune or pain.  

So, a translator translating from German to English has a choice to make when they come across the word: They can either translate the word as best they can or they can leave it as is. That's where the controversy arises.  If they translate the word then they usually will change the meaning of the text in some way, and if they leave it as is then they open the door to allow ""schadenfreude"" into the English lexicon (which is exactly what has happened with ""schadenfreude"").  So, you wind up with people who argue back and forth about what the correct way to do it is, i.e. a controversy.

To more directly answer your question, ""to become controversial"" means ""to become the source of argument or debate.""

I would imagine that if this was from an article or something like that, that it's from Britain, as they tend to get all huffy about polluting the Queen's English with your foreign tongue or whatever.  The other major English speaking countries don't really care that much.  US English has been corrupted by other languages for as long as it's been around, Canadian English has been corrupted by pretty much every language that has also creeped into US English but especially French, and I don't even want to know what language has corrupted Australian English to come up with words like ""kookaburra"" and ""kangaroo"" or to name a place something like ""Humpybong"" (I know it's mostly Aboriginal).
",Phoenix,https://english.stackexchange.com/users/7328,http://english.stackexchange.com/questions/50804/what-does-to-become-controversial-mean,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.7777777777777778,0.6666666666666666,0.5333333333333333,0.0,0.0,1.0,0.7777777777777778,"What does ""becoming controversial"" mean?","As a non-native speaker, I do not fully understand the meaning of the term ""to become controversial"" in the following text, which I have to translate into German:


  Where translators have made their presence felt they have become controversial, with those who characteristically intervene, seeking to domesticate texts, contrasted with those who foreignise, supposedly allowing other languages to alter our own.

","I would like to expand upon their answers a bit.  Let's take the German word ""schadenfreude,"" which if you were to translate it into English would be ""pleasure derived from the misfortune of another.""  That would be about the shortest translation you could make for it, because English doesn't have a word specific to that definition.  Perhaps the shortest you could get without straying too far from the meaning would be ""sadistic pleasure,"" but that implies a degree of maliciousness to it and that the person getting the pleasure is causing the misfortune or pain.  

So, a translator translating from German to English has a choice to make when they come across the word: They can either translate the word as best they can or they can leave it as is. That's where the controversy arises.  If they translate the word then they usually will change the meaning of the text in some way, and if they leave it as is then they open the door to allow ""schadenfreude"" into the English lexicon (which is exactly what has happened with ""schadenfreude"").  So, you wind up with people who argue back and forth about what the correct way to do it is, i.e. a controversy.

To more directly answer your question, ""to become controversial"" means ""to become the source of argument or debate.""

I would imagine that if this was from an article or something like that, that it's from Britain, as they tend to get all huffy about polluting the Queen's English with your foreign tongue or whatever.  The other major English speaking countries don't really care that much.  US English has been corrupted by other languages for as long as it's been around, Canadian English has been corrupted by pretty much every language that has also creeped into US English but especially French, and I don't even want to know what language has corrupted Australian English to come up with words like ""kookaburra"" and ""kangaroo"" or to name a place something like ""Humpybong"" (I know it's mostly Aboriginal).
"
4744,4744,7528,Why are the two buttons on the apple TV remote shaped differently (Menu & Play/Pause),"On the apple TV remote, I have realized that the two buttons have a different physical design. The menu button goes invward (convex) and the play/pause one is flatter/goes more outward.

I tried to figure out why with my common sense, but failed. Does someone know?

",nichochar,https://ux.stackexchange.com/users/41518,"Like mentioned, it's primarily to differentiate them without a visual. Another reason, and probably less so is that since the menu button is concave you're less likely to accidentally trigger it. So if you're playing a video and you accidentally trigger play/pause it's not so bad whereas triggering menu will take you out of the video completely.

Car remotes often follow a similar pattern. The unlock button is concave and the lock button is convex. 
",Tbolt,https://ux.stackexchange.com/users/45071,http://ux.stackexchange.com/questions/54999/why-are-the-two-buttons-on-the-apple-tv-remote-shaped-differently-menu-play-p,TECHNOLOGY,ux.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Why are the two buttons on the Apple TV remote different shapes (menu and play / pause),"On the Apple TV remote control, I realized that the physical design of the two buttons was different. The menu button is facing forward (convex), and the play / pause button is flatter / outward.","As mentioned before, it is mainly to distinguish them without visual effects. Another reason, perhaps less important, is that the menu button is concave and you are less likely to accidentally trigger it. So if you are playing a video, you accidentally trigger play / pause, which is not bad, and the trigger menu will let you completely exit the video."
4819,4819,7659,fetch PDO::FETCH_ASSOC multiple checkboxes,"usually i help people with whatever they need, this time i'm asking for your help.

i'm trying to get a specific row from my database after preforming multiple checkbox select  i spend 50 hours on that and i couldn't manage to do that.
each time i'm changing something in my code i get a different ERROR.
i was looking for an answer in every HTML page that exist on the INTERNET !

please show me the light..

here is a part of my form.... value means ""size"" of the toy



    &lt;div class=""""&gt;&lt;input type=""checkbox"" name=""toys[]"" value=""6X2"" /&gt;&lt;label&gt;&lt;/label&gt;&lt;/div&gt;
    &lt;div class=""""&gt;&lt;input type=""checkbox"" name=""toys[]"" value=""4X3"" /&gt;&lt;label&gt;&lt;/label&gt;&lt;/div&gt;
    &lt;div class=""""&gt;&lt;input type=""checkbox"" name=""toys[]"" value=""8X2.5"" /&gt;&lt;label&gt;&lt;/label&gt;&lt;/div&gt;&lt;/strike&gt;


here is the PHP code...

  if (isset($_POST['toys'])) {

     foreach($_POST['toys'] as $each_check) {

      }
  }

  $query = $db-&gt;query = 'SELECT * FROM `toys` WHERE SIZE = '.$each_check;   


echo ""&lt;table&gt;"";
    echo ""&lt;tr&gt;
            &lt;th&gt;ratio&lt;/th&gt;
            &lt;th&gt;size&lt;/th&gt;
            &lt;th&gt;built&lt;/th&gt;
            &lt;th&gt;description&lt;/th&gt;            
          &lt;/tr&gt;"";



while ($row = $query-&gt;fetch(PDO::FETCH_ASSOC)) 

        echo ""&lt;tr&gt;&lt;td&gt;"" . $row['ratio'] .
            ""&lt;/td&gt;&lt;td&gt;"" . $row['size'] .
            ""&lt;/td&gt;&lt;td&gt;"" . $row['built'] .
            ""&lt;/td&gt;&lt;td&gt;"" . $row['description'] .
            ""&lt;/td&gt;&lt;/tr&gt;"";
echo ""&lt;/table&gt;"";        

",Paco,https://stackoverflow.com/users/2912589,"This is so very far from being valid:

if (isset($_POST['toys'])) {

    foreach($_POST['toys'] as $each_check) {

    }
}

$query = $db-&gt;query = 'SELECT * FROM `toys` WHERE SIZE = '.$each_check;


More like:

if (isset($_POST['toys'])) {
    foreach($_POST['toys'] as $each_check) {
        $query = $db-&gt;query(""SELECT * FROM `toys` WHERE SIZE = '"".$each_check.""'"");
    }
}


But should be more like:

if (isset($_POST['toys'])) {
    $query = 'SELECT * FROM `toys` WHERE SIZE = ?';
    $sth = $db-&gt;prepare($query);
    foreach($_POST['toys'] as $each_check) {
        if( ! $sth-&gt;execute(array($each_check)) ) {
            die('MySQL Error: ' . var_export($sth-&gt;error_info(), TRUE);
        }
        while ($row = $sth-&gt;fetch(PDO::FETCH_ASSOC)) {
            // code here
        }
    }
}

",Sammitch,https://stackoverflow.com/users/1064767,http://stackoverflow.com/questions/19711710/fetch-pdofetch-assoc-multiple-checkboxes,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.7,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Fetch PDO:: fetch ABCD Assoc multiple check box,"usually i help people with whatever they need, this time i'm asking for your help.

i'm trying to get a specific row from my database after preforming multiple checkbox select  i spend 50 hours on that and i couldn't manage to do that.
each time i'm changing something in my code i get a different ERROR.
i was looking for an answer in every HTML page that exist on the INTERNET !

please show me the light..

here is a part of my form.... value means ""size"" of the toy



    &lt;div class=""""&gt;&lt;input type=""checkbox"" name=""toys[]"" value=""6X2"" /&gt;&lt;label&gt;&lt;/label&gt;&lt;/div&gt;
    &lt;div class=""""&gt;&lt;input type=""checkbox"" name=""toys[]"" value=""4X3"" /&gt;&lt;label&gt;&lt;/label&gt;&lt;/div&gt;
    &lt;div class=""""&gt;&lt;input type=""checkbox"" name=""toys[]"" value=""8X2.5"" /&gt;&lt;label&gt;&lt;/label&gt;&lt;/div&gt;&lt;/strike&gt;


here is the PHP code...

  if (isset($_POST['toys'])) {

     foreach($_POST['toys'] as $each_check) {

      }
  }

  $query = $db-&gt;query = 'SELECT * FROM `toys` WHERE SIZE = '.$each_check;   


echo ""&lt;table&gt;"";
    echo ""&lt;tr&gt;
            &lt;th&gt;ratio&lt;/th&gt;
            &lt;th&gt;size&lt;/th&gt;
            &lt;th&gt;built&lt;/th&gt;
            &lt;th&gt;description&lt;/th&gt;            
          &lt;/tr&gt;"";



while ($row = $query-&gt;fetch(PDO::FETCH_ASSOC)) 

        echo ""&lt;tr&gt;&lt;td&gt;"" . $row['ratio'] .
            ""&lt;/td&gt;&lt;td&gt;"" . $row['size'] .
            ""&lt;/td&gt;&lt;td&gt;"" . $row['built'] .
            ""&lt;/td&gt;&lt;td&gt;"" . $row['description'] .
            ""&lt;/td&gt;&lt;/tr&gt;"";
echo ""&lt;/table&gt;"";        

","This is so very far from being valid:

if (isset($_POST['toys'])) {

    foreach($_POST['toys'] as $each_check) {

    }
}

$query = $db-&gt;query = 'SELECT * FROM `toys` WHERE SIZE = '.$each_check;


More like:

if (isset($_POST['toys'])) {
    foreach($_POST['toys'] as $each_check) {
        $query = $db-&gt;query(""SELECT * FROM `toys` WHERE SIZE = '"".$each_check.""'"");
    }
}


But should be more like:

if (isset($_POST['toys'])) {
    $query = 'SELECT * FROM `toys` WHERE SIZE = ?';
    $sth = $db-&gt;prepare($query);
    foreach($_POST['toys'] as $each_check) {
        if( ! $sth-&gt;execute(array($each_check)) ) {
            die('MySQL Error: ' . var_export($sth-&gt;error_info(), TRUE);
        }
        while ($row = $sth-&gt;fetch(PDO::FETCH_ASSOC)) {
            // code here
        }
    }
}

"
3898,3898,6213,Can the Mage Wars Warlock be played without any Demon cards?,"As the subject states, I was wondering if the Mage Wars Core Set comes with enough Fire type cards to allow the Warlock Mage to build a spellbook with absolutely no Demon cards. Without seeing the cards, I will assume that most, if not all of the other Dark magic cards are OK, but I would ultimately prefer a pure Fire Magic spellbook.

So as to preemptively answer the almost inevitable 'Why?', I will simply say that, as an orthodox Christian, my conscience doesn't allow me to play a game with such cards. I would prefer not to debate/explain this further, as I believe such a discussion is well beyond the scope of this site.
",DragonSlayer,https://boardgames.stackexchange.com/users/11553,"Google ""mage wars Warlock strategy"" one of the results will be a 4 minute youtube video of a Warlock tearing a beastmaster apart, winning the game in 9 rounds, without summoning a single creature, demons or otherwise. 
",JSin,https://boardgames.stackexchange.com/users/13444,http://boardgames.stackexchange.com/questions/22585/can-the-mage-wars-warlock-be-played-without-any-demon-cards,CULTURE,boardgames.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,1.0,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,0.4444444444444444,0.3333333333333333,0.8888888888888888,0.7777777777777778,0.8,0.0,0.0,0.0,0.8888888888888888,Can mage warlocks use without demonic cards?,"As mentioned in the topic, I want to know if there are enough fire type cards in the mage war core set to let the mage build a magic book without devil cards. Without looking at the cards, I would assume that most, if not all, of the other dark magic cards would work, but I would eventually prefer a pure fire magic book.","Google ""mage wars Warlock strategy"" one of the results will be a 4 minute youtube video of a Warlock tearing a beastmaster apart, winning the game in 9 rounds, without summoning a single creature, demons or otherwise. 
"
2957,2957,4704,2 divs both 100% next to each other,"Quite simple question but tried about everything.

what i want is 2 (actually 5) divs next to eachother with the class ""container"" so i can make a horizontal 1page website. Each div has to be 100% wide. so 2 divs mean 2 screens next to eachother.

This is the css line i have now:

.container { width: 100%; float: left; display: inline; }


I cant get them to line up next to each other.

Here is a visual to make it more clear.

image url for bigger preview: http://www.luukratief.com/stackoverflow.png

The scrolling part is not the issue for me, just the placement of the divs.

Is this possible using percentages or is this simply not possible.
If so, please tell me how to do this with css.

Thanks in advance!
",Luuk,https://stackoverflow.com/users/691035,"you should use display: inline-block; instead of float anf then wrap all five divs in another container or use the body element and add white-space: nowrap to it.

If the design is incredibly pixel perfect, you can remove the actual ""word-spacing""  between the inline-blocks by removing the whitespace in the HTML or by giving them a negative right margin of about 0.25em; but if scrolling to new ""page"" you dn't notice it anyway..

Example Fiddle

HTML Code:

&lt;div class=""container"" id=""p1""&gt;Page 1 =&gt; &lt;a href=""#p2""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p2""&gt;Page 2 =&gt; &lt;a href=""#p3""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p3""&gt;Page 3 =&gt; &lt;a href=""#p4""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p4""&gt;Page 4 =&gt; &lt;a href=""#p5""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p5""&gt;Page 5 =&gt; &lt;a href=""#p1""&gt;Next page&lt;/a&gt;&lt;/div&gt; 


CSS:

html, body {margin: 0; padding: 0; height: 100%;}

body {white-space: nowrap;}

.container {
   display: inline-block;
   width: 100%;
   height: 100%;
}

.container {
   display: inline !ie7; /* for working inline-blocks in IE7 and below */
}

.container * {white-space: normal;}

#p1 {background: #fcf;}
#p2 {background: #ff0;}
#p3 {background: #cfc;}
#p4 {background: #abc;}
#p5 {background: #cba;}

",clairesuzy,https://stackoverflow.com/users/669044,http://stackoverflow.com/questions/6597889/2-divs-both-100-next-to-each-other,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8333333333333334,0.5,0.8333333333333334,1.0,0.8,1.0,0.0,0.5,0.8333333333333334,"Two divs, two 100% together","Quite simple question but tried about everything.

what i want is 2 (actually 5) divs next to eachother with the class ""container"" so i can make a horizontal 1page website. Each div has to be 100% wide. so 2 divs mean 2 screens next to eachother.

This is the css line i have now:

.container { width: 100%; float: left; display: inline; }


I cant get them to line up next to each other.

Here is a visual to make it more clear.

image url for bigger preview: http://www.luukratief.com/stackoverflow.png

The scrolling part is not the issue for me, just the placement of the divs.

Is this possible using percentages or is this simply not possible.
If so, please tell me how to do this with css.

Thanks in advance!
","you should use display: inline-block; instead of float anf then wrap all five divs in another container or use the body element and add white-space: nowrap to it.

If the design is incredibly pixel perfect, you can remove the actual ""word-spacing""  between the inline-blocks by removing the whitespace in the HTML or by giving them a negative right margin of about 0.25em; but if scrolling to new ""page"" you dn't notice it anyway..

Example Fiddle

HTML Code:

&lt;div class=""container"" id=""p1""&gt;Page 1 =&gt; &lt;a href=""#p2""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p2""&gt;Page 2 =&gt; &lt;a href=""#p3""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p3""&gt;Page 3 =&gt; &lt;a href=""#p4""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p4""&gt;Page 4 =&gt; &lt;a href=""#p5""&gt;Next page&lt;/a&gt;&lt;/div&gt;
&lt;div class=""container"" id=""p5""&gt;Page 5 =&gt; &lt;a href=""#p1""&gt;Next page&lt;/a&gt;&lt;/div&gt; 


CSS:

html, body {margin: 0; padding: 0; height: 100%;}

body {white-space: nowrap;}

.container {
   display: inline-block;
   width: 100%;
   height: 100%;
}

.container {
   display: inline !ie7; /* for working inline-blocks in IE7 and below */
}

.container * {white-space: normal;}

#p1 {background: #fcf;}
#p2 {background: #ff0;}
#p3 {background: #cfc;}
#p4 {background: #abc;}
#p5 {background: #cba;}

"
3035,3035,4842,Show UILabel with complete text or hide it,"I have a UI label say ""ABCDEFGH"". In iPhone 6 etc wider devices I can show the complete text. In small screen devices like iPhone 5, I see text as ""ABCD..."". I want the following:

if(complete text can be shown) 
{
    // show UILabel with text
} else // if text can not fit in, ""ABCD..."" case 
{    
    // hide the UILabel
}


How can I do this?
",Vinuta,https://stackoverflow.com/users/1155552,"As i mentioned in comment to use adjustsFontSizeToFitWidth = YES but it seems to be not good fit for your scenario. I will suggest you to check the screen sizes and set UILabel according to that.

CGSize deviceScreenSize = [[UIScreen mainScreen] bounds].size;

if(deviceScreenSize.height == 480){     //iPhone 4,4s Screen Size
// Write your code for UILabel Here.
}
if(deviceScreenSize.height == 568){    //iPhone 5,5s Screen Size
// Write your code for UILabel Here.
}
if(deviceScreenSize.height == 667){   //iPhone 6 Screen Size
// Write your code for UILabel Here.
}
if(deviceScreenSize.height == 736){  //iPhone 6s Screen Size
// Write your code for UILabel Here.
}


There might be some better way to do so.But i know this one only.
",Shivaay,https://stackoverflow.com/users/1865424,http://stackoverflow.com/questions/31168215/show-uilabel-with-complete-text-or-hide-it,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.4444444444444444,Show or hide uilabel with full text,"I have a user interface label that says ""abcdefgh."". On a wider range of devices, such as the iPhone 6, I can display full text. In a small screen device like the iPhone 5, I think of text as ""ABCD..."". I want to:","As i mentioned in comment to use adjustsFontSizeToFitWidth = YES but it seems to be not good fit for your scenario. I will suggest you to check the screen sizes and set UILabel according to that.

CGSize deviceScreenSize = [[UIScreen mainScreen] bounds].size;

if(deviceScreenSize.height == 480){     //iPhone 4,4s Screen Size
// Write your code for UILabel Here.
}
if(deviceScreenSize.height == 568){    //iPhone 5,5s Screen Size
// Write your code for UILabel Here.
}
if(deviceScreenSize.height == 667){   //iPhone 6 Screen Size
// Write your code for UILabel Here.
}
if(deviceScreenSize.height == 736){  //iPhone 6s Screen Size
// Write your code for UILabel Here.
}


There might be some better way to do so.But i know this one only.
"
4816,4816,7653,Adding seconds to mysql DateTime via php,"Im trying to add 12 seconds to a mysql datetime object via php.

My php code generates the following query: ""UPDATE Stats SET Usage = 1970-01-01 00:00:12"" however the query fails.

My php code is as follows:

public function UpdateTime($diffrence)
{
    $seconds = $diffrence / 1000;

    mysql_connect('localhost','user','pass') or die(""Unable to select host"");

    mysql_select_db('StatDB') or die(""Unable to select database"");

    $query  = ""SELECT * FROM Stats"";

    $result=mysql_query($query);

    $retVal = mysql_result($result,0,""Usage"");

    $oldTime = new DateTime($retVal);

    $oldTime-&gt;modify('+'. $seconds .' seconds');

    $from = date(""Y-m-d H:i:s"", strtotime($oldTime-&gt;format('Y-m-d H:i:s')));

    $query2  = ""UPDATE Stats SET Usage = $from"";
    echo $query2;

    $result2=mysql_query($query2);

    mysql_close();
}


Does anyone how I can fix this?

Thanks
",Ryuk,https://stackoverflow.com/users/1211548,"This is likely related to missing quotes in your query. Check out the answer to this question.

UPDATE Stats SET Usage = '1970-01-01 00:00:12'


You should surround the date time value passed in single quotes.
",Aiias,https://stackoverflow.com/users/2151120,http://stackoverflow.com/questions/15317063/adding-seconds-to-mysql-datetime-via-php,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Add seconds to MySQL datetime through PHP,"Im trying to add 12 seconds to a mysql datetime object via php.

My php code generates the following query: ""UPDATE Stats SET Usage = 1970-01-01 00:00:12"" however the query fails.

My php code is as follows:

public function UpdateTime($diffrence)
{
    $seconds = $diffrence / 1000;

    mysql_connect('localhost','user','pass') or die(""Unable to select host"");

    mysql_select_db('StatDB') or die(""Unable to select database"");

    $query  = ""SELECT * FROM Stats"";

    $result=mysql_query($query);

    $retVal = mysql_result($result,0,""Usage"");

    $oldTime = new DateTime($retVal);

    $oldTime-&gt;modify('+'. $seconds .' seconds');

    $from = date(""Y-m-d H:i:s"", strtotime($oldTime-&gt;format('Y-m-d H:i:s')));

    $query2  = ""UPDATE Stats SET Usage = $from"";
    echo $query2;

    $result2=mysql_query($query2);

    mysql_close();
}


Does anyone how I can fix this?

Thanks
","This is likely related to missing quotes in your query. Check out the answer to this question.

UPDATE Stats SET Usage = '1970-01-01 00:00:12'


You should surround the date time value passed in single quotes.
"
1549,1549,2431,How to get the path of android installed application,"Hi I am new to Android and I want to know that how can we get the path of the installed application in android, So that we can open the file in our application by using that installed application.

for example:
I want to open the pdf file or doc file in my application but i require the path of that application which can open this file...

Please Help me 
Thanks in advance...
",Mak,https://stackoverflow.com/users/556869,"This is not how things work in Android. To call another installed application, you'll have to do it with an Intent. Android will then select the application(s) best suited for what you're trying to do, and use them to open the file you need. In your example, the code would be something like this :

Intent intent = new Intent(Intent.ACTION_VIEW);
intent.setDataAndType(path, ""application/pdf"");
startActivity(Intent.createChooser(intent, ""Open PDF""));


Look at the Intent javadoc to have more explanations about that (the createChooser part is here to allow the user to choose between various apps if more than one can open the designated file)
",Valentin Rocher,https://stackoverflow.com/users/104117,http://stackoverflow.com/questions/4552402/how-to-get-the-path-of-android-installed-application,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,How to get the path of Android installation application,"Hi I am new to Android and I want to know that how can we get the path of the installed application in android, So that we can open the file in our application by using that installed application.

for example:
I want to open the pdf file or doc file in my application but i require the path of that application which can open this file...

Please Help me 
Thanks in advance...
","This is not how things work in Android. To call another installed application, you'll have to do it with an Intent. Android will then select the application(s) best suited for what you're trying to do, and use them to open the file you need. In your example, the code would be something like this :

Intent intent = new Intent(Intent.ACTION_VIEW);
intent.setDataAndType(path, ""application/pdf"");
startActivity(Intent.createChooser(intent, ""Open PDF""));


Look at the Intent javadoc to have more explanations about that (the createChooser part is here to allow the user to choose between various apps if more than one can open the designated file)
"
5623,5623,8918,How can I enable HttpOnly cookies in EE,"Update:
Thanks to Dom Stubbs, I have an extension to accomplish this now.  It is up on devot-ee and also up on GitHub.  Thanks Dom!

The Original Question

I am nearly through a security review of a new EE2 version of an existing EE1 site that I hope to launch soon.  One of the final issues remaining is to make the cookies HttpOnly.  I've tried doing that through this line in the apache config:

Header edit Set-Cookie ""(?i)^((?:(?!;\s?HttpOnly).)+)$"" ""$1; HttpOnly""


Using the dev tools in my browser I can see that it does indeed append HttpOnly to the Set-Cookie headers, but the issue then becomes that I cannot log in.  When I asked Ellislab they tell me that the cookies should not be being dealt with in javascript, which was what I expected the issue might be.

ExpressionEngine does not seem to use the session libraries from codeignitor, if it did I could set a config variable to turn httponly on, but it looks like the session handling code is in the expressionengine side of things.

The real question that I need answered is how can I make HttpOnly cookies work, but I guess that breaks down into some potential subquestions:


Am I missing an addon that would allow me to do this without a lot more heartache?Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Failing these, can anybody give me a hint as to where cookies are being set in expressionengine so I can dig in there and try to fix this?

",UltraBob,https://expressionengine.stackexchange.com/users/268,"For anyone else coming across this, ExpressionEngine 2.8.0 introduced a new config variable for httponly cookies, and it's set to 'yes' by default: http://ellislab.com/expressionengine/user-guide/general/system_configuration_overrides.html#cookie-httponly-config
",James Smith,https://expressionengine.stackexchange.com/users/182,http://expressionengine.stackexchange.com/questions/112/how-can-i-enable-httponly-cookies-in-ee,TECHNOLOGY,expressionengine.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,How to enable httponly cookies in EE,"Update:
Thanks to Dom Stubbs, I have an extension to accomplish this now.  It is up on devot-ee and also up on GitHub.  Thanks Dom!

The Original Question

I am nearly through a security review of a new EE2 version of an existing EE1 site that I hope to launch soon.  One of the final issues remaining is to make the cookies HttpOnly.  I've tried doing that through this line in the apache config:

Header edit Set-Cookie ""(?i)^((?:(?!;\s?HttpOnly).)+)$"" ""$1; HttpOnly""


Using the dev tools in my browser I can see that it does indeed append HttpOnly to the Set-Cookie headers, but the issue then becomes that I cannot log in.  When I asked Ellislab they tell me that the cookies should not be being dealt with in javascript, which was what I expected the issue might be.

ExpressionEngine does not seem to use the session libraries from codeignitor, if it did I could set a config variable to turn httponly on, but it looks like the session handling code is in the expressionengine side of things.

The real question that I need answered is how can I make HttpOnly cookies work, but I guess that breaks down into some potential subquestions:


Am I missing an addon that would allow me to do this without a lot more heartache?Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Failing these, can anybody give me a hint as to where cookies are being set in expressionengine so I can dig in there and try to fix this?

","For others, expressionengine 2.8.0 introduces a new configuration variable for httponly cookie s, and the default setting is ""yes"": http://ellislab.com/expressionengine/user guide/general/system \ u configuration \ u overrides.html"
5095,5095,8103,"How do you pronounce ""but""?","In which context do you use the stressed bÊt and when do you use the unstressed bÉt? How often is that?
If you know about the website www.forvo.com, I think it's a shortcoming that speakers use only one of the two versions. 
",Theta30,https://english.stackexchange.com/users/5249,"The word is similar to a and the (Ä vs. É and Ã°Ä vs. Ã°É).  The stressed bÊt tends to be used more when I am emphasizing that I am making a contrast:


  I would go, but  my parents won't let me. (whining teenager)


The unstressed bÉt is used more often when what I am saying is more important than the fact that there is a contrast:


  ...but I don't wanna go! (whining child)

",snumpy,https://english.stackexchange.com/users/6534,http://english.stackexchange.com/questions/21516/how-do-you-pronounce-but,CULTURE,english.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,1.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,"How do you pronounce ""but""?","In which context do you use the stressed bÊt and when do you use the unstressed bÉt? How often is that?
If you know about the website www.forvo.com, I think it's a shortcoming that speakers use only one of the two versions. 
","The word is similar to a and the (Ä vs. É and Ã°Ä vs. Ã°É).  The stressed bÊt tends to be used more when I am emphasizing that I am making a contrast:


  I would go, but  my parents won't let me. (whining teenager)


The unstressed bÉt is used more often when what I am saying is more important than the fact that there is a contrast:


  ...but I don't wanna go! (whining child)

"
4245,4245,6767,Etiquette for posting civil and informative comments,"Sometimes I leave a comment like ""Stack Overflow is not your personal research assistant,"" but am accused of being rude.  How can I craft a comment that is seen as civil to the community and instructive to the OP?


What tone should I strike in comments?
What are some examples of bad comments and their better replacements?

",Robert Harvey,https://meta.stackexchange.com/users/102937,"Another way to make a comment more friendly is, when possible, to cast it as a question rather than a statement.  Consider the difference between:


(Answer) doesn't work because of X.


and


When you do that, how do you account for the problem of X?


It could well be that X isn't a problem -- your assumption is wrong.  If you assert it you look bad; if you raise the question the poster isn't put on the defensive, and if it's a problem he can fix it (and thank you for the help).

I used to leave comments like the following that I thought were friendly and helpful:


This question/answer could be improved by adding (details/a source).


I realized that comments like the following got better results and also that I preferred them when on the receiving end:


Could you add more details about X?
Do you have a source?


This approach doesn't always work (e.g. for site policy).  It's also most important for the initial comment, before you and the other person are engaged in a dialogue.
",Monica Cellio,https://meta.stackexchange.com/users/162102,http://meta.stackexchange.com/questions/138173/etiquette-for-posting-civil-and-informative-comments,TECHNOLOGY,meta.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,1.0,Etiquette for making civilized and informative comments,"Sometimes I leave a comment like, ""stack overflow is not your personal research assistant,"" but it will be accused of being rude. How can I write a comment that is considered polite to the community and instructive to the op?","Another way to make a comment more friendly is, when possible, to cast it as a question rather than a statement.  Consider the difference between:


(Answer) doesn't work because of X.


and


When you do that, how do you account for the problem of X?


It could well be that X isn't a problem -- your assumption is wrong.  If you assert it you look bad; if you raise the question the poster isn't put on the defensive, and if it's a problem he can fix it (and thank you for the help).

I used to leave comments like the following that I thought were friendly and helpful:


This question/answer could be improved by adding (details/a source).


I realized that comments like the following got better results and also that I preferred them when on the receiving end:


Could you add more details about X?
Do you have a source?


This approach doesn't always work (e.g. for site policy).  It's also most important for the initial comment, before you and the other person are engaged in a dialogue.
"
1511,1511,2378,Is my session-less authentication system secure?,"So, I've created an authentication system. Poured over it for any kind of security flaws and tested the crap out of it. I think it's fairly secure, but there is one ""different"" by-design aspect of it that's not usual of a web authentication system. 

Basically, I wanted to make it so that authentication could be done without keeping track of each user's session. This means less load on the database, and trivial to scale and cache. Here are the ""secrets"" kept by the server:


A private-key is kept in the source code of the application
A randomly generated salt is kept for each user


To make it sessionless, but making forging cookies not easy, this is the format of my cookies

expires=expiretimestamp
secret=hash(privatekey + otherinfo + username + hashedpassword + expires)
username=username


(with otherinfo being things like IP address, browser info, etc and with hashedpassword=hash(username + salt + password + privatekey) 

My understanding is that forging login cookies (not cracking the passwords) requires:


Source code access to the application, or a way to trick it to spit out the private key
Read-only access to the database to get the salt and hashedpassword


Whereas the traditional session method requires:


Write and read access to the database (to inject the session, or trick the web app into doing it for you)
Possibly source code access depending on how it works


Anyway, does this seem overly insecure to anyone? Are there any ways for me to improve on it and make it more secure(while keeping with the stateless/sessionless model)? Are there any existing authentication systems which use this stateless model? 

Also, the hashing method can be basically anything, ranging from SHA256 to Blowfish
",Earlz,https://security.stackexchange.com/users/1398,"Your basic concept is not new: you want to have some state associated with the user, but you do not want to store that state yourself. Instead, you store it on the client (in a cookie). Since you want to protect against alterations of such a state (e.g. a client building a cookie from scratch), you need an integrity check, such as a Message Authentication Code. Your construction with a hash function is a crude MAC. It so happens that it is a weak MAC with the usual hash functions, because of the length extension attack.

If you want a MAC, use a strong one, and that means HMAC. It is standard and widespread.

Of course, storage of the secret key (for MAC computations) is a tricky point. Something embedded in the ""source code"" of the application exists as a file, which (by nature) the application can read, making it vulnerable to exploits which obtain illegal read access to arbitrary files. It would be better (but harder) to arrange for the MAC key to be obtained dynamically by the application through some local communication protocol (the application contacts a local server, which gives the key only to the application); that way, the key would only exist in the RAM of the application, not as a file readable with the access rights of the application. It would not be absolute protection (if your server gets thoroughly hacked, well, that's it) but it would be stronger in practice.

I see that you include the hashed password in the data which is MACed. This is a bit weird; you already have the MAC as authentication: the MAC proves that the cookie data is genuine, thus there is no need for further authentication.

Blowfish is not a hash function; it is a block cipher (or a type of fish) and, as such, cannot be used for hashing unless it is considerably modified, which would mean homemade cryptography, and that's not a good idea.



If you are offloading state on the client, you might want to offload state which the client himself should not know. This means that you may also need encryption. Combining encryption and MAC securely is not as easy as it seems; there are modes for that. I recommend EAX.



Be warned that not maintaining state makes you inherently weak against replay attacks. That's unavoidable. You can minimize the damage by using short validity ranges (e.g. a cookie expires within 15 minutes).
",Thomas Pornin,https://security.stackexchange.com/users/655,http://security.stackexchange.com/questions/24730/is-my-session-less-authentication-system-secure,TECHNOLOGY,security.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,1.0,Is my session free authentication system secure?,"So, I've created an authentication system. Poured over it for any kind of security flaws and tested the crap out of it. I think it's fairly secure, but there is one ""different"" by-design aspect of it that's not usual of a web authentication system. 

Basically, I wanted to make it so that authentication could be done without keeping track of each user's session. This means less load on the database, and trivial to scale and cache. Here are the ""secrets"" kept by the server:


A private-key is kept in the source code of the application
A randomly generated salt is kept for each user


To make it sessionless, but making forging cookies not easy, this is the format of my cookies

expires=expiretimestamp
secret=hash(privatekey + otherinfo + username + hashedpassword + expires)
username=username


(with otherinfo being things like IP address, browser info, etc and with hashedpassword=hash(username + salt + password + privatekey) 

My understanding is that forging login cookies (not cracking the passwords) requires:


Source code access to the application, or a way to trick it to spit out the private key
Read-only access to the database to get the salt and hashedpassword


Whereas the traditional session method requires:


Write and read access to the database (to inject the session, or trick the web app into doing it for you)
Possibly source code access depending on how it works


Anyway, does this seem overly insecure to anyone? Are there any ways for me to improve on it and make it more secure(while keeping with the stateless/sessionless model)? Are there any existing authentication systems which use this stateless model? 

Also, the hashing method can be basically anything, ranging from SHA256 to Blowfish
","Your basic concept is not new: you want to have some state associated with the user, but you do not want to store that state yourself. Instead, you store it on the client (in a cookie). Since you want to protect against alterations of such a state (e.g. a client building a cookie from scratch), you need an integrity check, such as a Message Authentication Code. Your construction with a hash function is a crude MAC. It so happens that it is a weak MAC with the usual hash functions, because of the length extension attack.

If you want a MAC, use a strong one, and that means HMAC. It is standard and widespread.

Of course, storage of the secret key (for MAC computations) is a tricky point. Something embedded in the ""source code"" of the application exists as a file, which (by nature) the application can read, making it vulnerable to exploits which obtain illegal read access to arbitrary files. It would be better (but harder) to arrange for the MAC key to be obtained dynamically by the application through some local communication protocol (the application contacts a local server, which gives the key only to the application); that way, the key would only exist in the RAM of the application, not as a file readable with the access rights of the application. It would not be absolute protection (if your server gets thoroughly hacked, well, that's it) but it would be stronger in practice.

I see that you include the hashed password in the data which is MACed. This is a bit weird; you already have the MAC as authentication: the MAC proves that the cookie data is genuine, thus there is no need for further authentication.

Blowfish is not a hash function; it is a block cipher (or a type of fish) and, as such, cannot be used for hashing unless it is considerably modified, which would mean homemade cryptography, and that's not a good idea.



If you are offloading state on the client, you might want to offload state which the client himself should not know. This means that you may also need encryption. Combining encryption and MAC securely is not as easy as it seems; there are modes for that. I recommend EAX.



Be warned that not maintaining state makes you inherently weak against replay attacks. That's unavoidable. You can minimize the damage by using short validity ranges (e.g. a cookie expires within 15 minutes).
"
4572,4572,7243,Question about thermodynamic conjugate quantities,"I've come across the Onsager reciprocal principle. It's almost clear, except for thermodynamic conjugate quantities - what's that, physical meaning (except the formal definitions: $X_i = -\frac{1}{k}\frac{\partial S}{\partial x_i}$, which isn't clear) and why:

\begin{equation}
  \langle X_i\cdot x_k\rangle = \delta_{ik}
\end{equation}

The Wikipedia is lack for references in this article.
",m0nhawk,https://physics.stackexchange.com/users/6735,"Thermodynamic conjugate variables are pairs of variables $x_i$, $X_i$ where the product $X_i\cdot dx_i$ has the dimension of energy and actually appears as a term in the infinitesimal variation of energy, free energy, or work such as $dE$.

In the pair, one quantity is intensive and the other is extensive.

The best example is pressure and volume because $p\,dV$ is a term in $dE$. Analogously, temperature and entropy because of $T\,dS$, chemical potential and particle number because of $\mu \,dN$, and many electric, magnetic, gravitational, and surface tension examples exist.

If you have 
$$ dE = \dots + p\,dV, $$
it's easy to see that $p$ is the partial derivative of $E$ with respect to $V$. This role of $p,V$ may be reverted if you consider $H=E+pV$ instead of $E$ i.e. substitute $E = H-pV$. Then you will get
$$dH = \dots - V\,dp.$$
This ""Lagrange duality"" may be applied to any pair.
",LuboÅ¡ Motl,https://physics.stackexchange.com/users/1236,http://physics.stackexchange.com/questions/41961/question-about-thermodynamic-conjugate-quantities,SCIENCE,physics.stackexchange.com,0.4444444444444444,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,On the conjugate quantity of thermodynamics,"I met the Onsager principle of reciprocity. It's almost clear, except for the thermodynamic conjugation - what that is, the physical meaning (except for the formal definition: $X AI I = - \ frac {1} {K} \ frac {\ partial s} {\ partial x AI I} $, which is not clear) and why:","Thermodynamic conjugate variables are pairs of variables $x_i$, $X_i$ where the product $X_i\cdot dx_i$ has the dimension of energy and actually appears as a term in the infinitesimal variation of energy, free energy, or work such as $dE$.

In the pair, one quantity is intensive and the other is extensive.

The best example is pressure and volume because $p\,dV$ is a term in $dE$. Analogously, temperature and entropy because of $T\,dS$, chemical potential and particle number because of $\mu \,dN$, and many electric, magnetic, gravitational, and surface tension examples exist.

If you have 
$$ dE = \dots + p\,dV, $$
it's easy to see that $p$ is the partial derivative of $E$ with respect to $V$. This role of $p,V$ may be reverted if you consider $H=E+pV$ instead of $E$ i.e. substitute $E = H-pV$. Then you will get
$$dH = \dots - V\,dp.$$
This ""Lagrange duality"" may be applied to any pair.
"
845,845,1343,How many domains can you configure on a Sun M5000 system?,"We have a few Sun M5000 servers with the following configuration:


Each system has 2 system boards each containing 2 x 2.5Ghz quad core processors
Each system board has 16GB of RAM
Each system has 4 x 300GB disks


I would like to know how many hardware domains can I configure per system? Do I need one system board per domain (implying a total of 2 domains), or can I create 4 domains, each with one cpu each?
",Andre Miller,https://serverfault.com/users/5339,"The maximum number of domains on an M5000 is four.

http://www.sun.com/servers/midrange/m5000/specs.xml
",Kevin Kuphal,https://serverfault.com/users/3657,http://serverfault.com/questions/50465,TECHNOLOGY,serverfault.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,How many domains can be configured on a sun m5000 system?,"We have a few Sun M5000 servers with the following configuration:


Each system has 2 system boards each containing 2 x 2.5Ghz quad core processors
Each system board has 16GB of RAM
Each system has 4 x 300GB disks


I would like to know how many hardware domains can I configure per system? Do I need one system board per domain (implying a total of 2 domains), or can I create 4 domains, each with one cpu each?
","The maximum number of domains on an M5000 is four.

http://www.sun.com/servers/midrange/m5000/specs.xml
"
726,726,1156,How to determine directions of vectors of an electromagnetic wave,"I did an exercise which probably is quite popular,
in which you draw an electromagnetic wave and prove that it should
propagate at the speed of light $1 \over \sqrt {\mu_0\epsilon_0}$ using Farday's law and Ampere's law.

Basically if this is the wave: 




Let's say the E-field (red) is in the X direction, the B-Field (blue) is in the Y direction,
and the velocity of the wave is in the Z direction.

You take for example for ampere's law a surface in the ZY plane with a length L
equal to the amplitude of the wave,
and a width equal to $\lambda\over 4$
You do a similar thing with Faraday's law and you get the speed of light,
assuming you know that the E-field and B-field propagate in this manner.

I got the right answer but I wondered about this:
Let's say I only had the E-field and I know the wave propagates at the speed of light, I assume this is enough information to draw the B-field at each point.

But how will I know the direction? Both Faraday's law and Ampere's law say you need a closed loop integral and the rules I've been taught say
you go over the loop in a clockwise direction for example and take the 
normal to the surface according to the right hand rule etc.

But clockwise and counter-clockwise direction don't really give me much information in this case, so how can I determine the direction of the B-field
if I only have the E-field?
",fiftyeight,https://physics.stackexchange.com/users/6743,"$ {\bf E} \times {\bf B}$  (which is the Poynting vector multiplied by $\mu_0$) should be in the direction of wave motion.

I you want an aide-memoire, if you imagine taking a screwdriver and turning a (standard) screw in the direction of ${\bf E}$ towards ${\bf B}$, then the wave should be travelling in the direction that the screw is driven (either in or out).
",Rob Jeffries,https://physics.stackexchange.com/users/43351,http://physics.stackexchange.com/questions/20970/how-to-determine-directions-of-vectors-of-an-electromagnetic-wave,SCIENCE,physics.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,How to determine the direction of electromagnetic wave vector,"I did an exercise which probably is quite popular,
in which you draw an electromagnetic wave and prove that it should
propagate at the speed of light $1 \over \sqrt {\mu_0\epsilon_0}$ using Farday's law and Ampere's law.

Basically if this is the wave: 




Let's say the E-field (red) is in the X direction, the B-Field (blue) is in the Y direction,
and the velocity of the wave is in the Z direction.

You take for example for ampere's law a surface in the ZY plane with a length L
equal to the amplitude of the wave,
and a width equal to $\lambda\over 4$
You do a similar thing with Faraday's law and you get the speed of light,
assuming you know that the E-field and B-field propagate in this manner.

I got the right answer but I wondered about this:
Let's say I only had the E-field and I know the wave propagates at the speed of light, I assume this is enough information to draw the B-field at each point.

But how will I know the direction? Both Faraday's law and Ampere's law say you need a closed loop integral and the rules I've been taught say
you go over the loop in a clockwise direction for example and take the 
normal to the surface according to the right hand rule etc.

But clockwise and counter-clockwise direction don't really give me much information in this case, so how can I determine the direction of the B-field
if I only have the E-field?
","$ {\bf E} \times {\bf B}$  (which is the Poynting vector multiplied by $\mu_0$) should be in the direction of wave motion.

I you want an aide-memoire, if you imagine taking a screwdriver and turning a (standard) screw in the direction of ${\bf E}$ towards ${\bf B}$, then the wave should be travelling in the direction that the screw is driven (either in or out).
"
434,434,674,"If you attempt to predict a Roulette wheel $n$ times, what's the probability you'll get $5$ in a row at some point?","I'm talking about a Roulette wheel with $38$ equally probable outcomes. Someone mentioned that he guessed the correct number five times in a row, and said that this was surprising because the probability of this happening was $$\left(\frac{1}{38}\right)^5$$

This is true if you only play the game $5$ times. However, if you play it more than $5$ times there's a higher (should be much higher?) probability that you'll get $5$ in a row at some point. 

I was thinking about how surprised this person should be at their streak of $m$ correct guesses given that they play $n$ games, each with probability $p$ of success. It makes intuitive sense that their surprise should be proportional to $1/q$ (or maybe $\log(1/q)$ since $1$ in a billion doesn't surprise you $10$ times more than $1$ in $100$ million), where $q$ is the probability that they get at least one streak of $m$ correct guesses at some point in their $n$ games. 

So, with the Roulette example I was thinking about, $p=1/38$ and $m=5$. 

I tried to find an explicit formula for $q$ in terms of $n$, and encountered some difficulty, because of the non-independence of ""getting a streak in the first five tries"" and ""getting a streak in tries $2$ through $6$"" (if the first is a failure, it's much more  likely that the second will be too). 



In summary, two questions:


How do I find the probability that you get $5$ correct guesses in a row at some point if you play $n$ games of Roulette?
More generally, what is the probability that you get $m$ successes at some point in a series of $n$ events, each with probability $p$ of success? 


The variables satisfy $\,\,\,m,n \in \mathbb{N}$, $\,\,\,m\leq n$, $\,\,\,p \in \mathbb{R}$, $\,\,\,0 \leq p \leq 1$.



If we write the answer to the second question as a function $q(m,n,p)$, then we can say that $q$ should be increasing with $n$, decreasing with $m$, and increasing with $p$. It should equal $p^n$ when $m=n$ and should equal $1$ when $p=1$ and $0$ when $p=0$. 

I feel as though this should be a basic probability problem, but I'm having trouble solving it. Maybe some kind of recursive approach would work? Given $q(n,m,p)$, I think I could write $q(n+1,m,p)$ using the probability that the last $m-1$ results are all successes ...
",Zubin Mukerjee,https://math.stackexchange.com/users/111946,"You have a six-state system.
State 1: Not on a run.  Either you haven't started, or the last guess was wrong.
State 2: The last guess was correct.
State 3: The last two guesses were correct.
State 4: The last three guesses were correct.
State 5: The last four guesses were correct.
State 6: You have a 5-in-a-row.
The transition matrix is 
$$A=\left(\begin{array}{cccccc}
1-p&amp;p&amp;0&amp;0&amp;0&amp;0\\
1-p&amp;0&amp;p&amp;0&amp;0&amp;0\\
1-p&amp;0&amp;0&amp;p&amp;0&amp;0\\
1-p&amp;0&amp;0&amp;0&amp;p&amp;0\\
1-p&amp;0&amp;0&amp;0&amp;0&amp;p\\
0&amp;0&amp;0&amp;0&amp;0&amp;1
\end{array}\right)$$
The initial vector is $\vec{v}=(1,0,0,0,0,0)$
To find the probabilities after $n$ rounds, calculate $\vec{v}A^n$
",Michael,https://math.stackexchange.com/users/81790,http://math.stackexchange.com/questions/1081447/if-you-attempt-to-predict-a-roulette-wheel-n-times-whats-the-probability-you,SCIENCE,math.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,0.0,1.0,0.8333333333333334,0.5,0.8333333333333334,0.8888888888888888,0.6,1.0,0.0,0.5,1.0,"If you try to predict the N $times of a roulette wheel, what's the probability that you'll get five dollars in a row at some point?","I'm talking about a Roulette wheel with $38$ equally probable outcomes. Someone mentioned that he guessed the correct number five times in a row, and said that this was surprising because the probability of this happening was $$\left(\frac{1}{38}\right)^5$$

This is true if you only play the game $5$ times. However, if you play it more than $5$ times there's a higher (should be much higher?) probability that you'll get $5$ in a row at some point. 

I was thinking about how surprised this person should be at their streak of $m$ correct guesses given that they play $n$ games, each with probability $p$ of success. It makes intuitive sense that their surprise should be proportional to $1/q$ (or maybe $\log(1/q)$ since $1$ in a billion doesn't surprise you $10$ times more than $1$ in $100$ million), where $q$ is the probability that they get at least one streak of $m$ correct guesses at some point in their $n$ games. 

So, with the Roulette example I was thinking about, $p=1/38$ and $m=5$. 

I tried to find an explicit formula for $q$ in terms of $n$, and encountered some difficulty, because of the non-independence of ""getting a streak in the first five tries"" and ""getting a streak in tries $2$ through $6$"" (if the first is a failure, it's much more  likely that the second will be too). 



In summary, two questions:


How do I find the probability that you get $5$ correct guesses in a row at some point if you play $n$ games of Roulette?
More generally, what is the probability that you get $m$ successes at some point in a series of $n$ events, each with probability $p$ of success? 


The variables satisfy $\,\,\,m,n \in \mathbb{N}$, $\,\,\,m\leq n$, $\,\,\,p \in \mathbb{R}$, $\,\,\,0 \leq p \leq 1$.



If we write the answer to the second question as a function $q(m,n,p)$, then we can say that $q$ should be increasing with $n$, decreasing with $m$, and increasing with $p$. It should equal $p^n$ when $m=n$ and should equal $1$ when $p=1$ and $0$ when $p=0$. 

I feel as though this should be a basic probability problem, but I'm having trouble solving it. Maybe some kind of recursive approach would work? Given $q(n,m,p)$, I think I could write $q(n+1,m,p)$ using the probability that the last $m-1$ results are all successes ...
","You have a six-state system.
State 1: Not on a run.  Either you haven't started, or the last guess was wrong.
State 2: The last guess was correct.
State 3: The last two guesses were correct.
State 4: The last three guesses were correct.
State 5: The last four guesses were correct.
State 6: You have a 5-in-a-row.
The transition matrix is 
$$A=\left(\begin{array}{cccccc}
1-p&amp;p&amp;0&amp;0&amp;0&amp;0\\
1-p&amp;0&amp;p&amp;0&amp;0&amp;0\\
1-p&amp;0&amp;0&amp;p&amp;0&amp;0\\
1-p&amp;0&amp;0&amp;0&amp;p&amp;0\\
1-p&amp;0&amp;0&amp;0&amp;0&amp;p\\
0&amp;0&amp;0&amp;0&amp;0&amp;1
\end{array}\right)$$
The initial vector is $\vec{v}=(1,0,0,0,0,0)$
To find the probabilities after $n$ rounds, calculate $\vec{v}A^n$
"
872,872,1384,What are the major differences between evangelical Christianity and Mormonism?,"I'm looking for concrete theological beliefs and practices on where they differ. Christians say that Mormons aren't Christian and yet Mormons call themselves Christian. So it can be quite hard to tell for a everyday person who is who and what is what. 
",JCab,https://christianity.stackexchange.com/users/3639,"Simply put Evangelicals differ over at least three primary things:

1. The Nature of Jesus

Evangelicals believe Jesus to be God - of one being with Father, God from God, Light from Light, true God from true God, etc... Mormons do not. Mormons believe Jesus to be divine, but a separate person from the Father. Evangelicals tend to subscribe to the historic creeds of the church - Nicene, Apostles, etc... - and are almost invariably Trinitarian.  (I cannot say that I have ever run across a non-Trinitarian Evangelical, but as it is a movement and not a denomination, there are always exceptions).

Note: In the comments, there was a notion that the creeds only adhered to the ""Catholic"" church.  Insofar as ""catholic"" is understood as ""universal"" or ""what most people think of when they think of 'mainstream' Christianity, that is accurate.  If that were taken to mean the 'Roman Catholic Church,' that would be precise, but inaccurate, in that most Protestants and Orthodox also subscribe to the Creeds and to the Trinitarian formulations thereof.

2. The nature of the ""Bible""

Evangelicals consider the canon to be closed. Mormons have their own scriptures composed well after the period.

3. The nature of soteriology

Evangelicals, by and large, believe salvation to be solely the gift of God. We believe that all who are saved entire into eternal relationship with God. Mormons believe that people are rewarded according to the nature of the covenant they believed.
",Affable Geek,https://christianity.stackexchange.com/users/1039,http://christianity.stackexchange.com/questions/12256/what-are-the-major-differences-between-evangelical-christianity-and-mormonism,CULTURE,christianity.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,What is the main difference between evangelical Christianity and Mormonism?,"I am looking for specific theological beliefs and practical differences. Christians say that Mormons are not Christians, but they call themselves Christians. So for an ordinary person, it's hard to distinguish who is who and what.","Simply put Evangelicals differ over at least three primary things:

1. The Nature of Jesus

Evangelicals believe Jesus to be God - of one being with Father, God from God, Light from Light, true God from true God, etc... Mormons do not. Mormons believe Jesus to be divine, but a separate person from the Father. Evangelicals tend to subscribe to the historic creeds of the church - Nicene, Apostles, etc... - and are almost invariably Trinitarian.  (I cannot say that I have ever run across a non-Trinitarian Evangelical, but as it is a movement and not a denomination, there are always exceptions).

Note: In the comments, there was a notion that the creeds only adhered to the ""Catholic"" church.  Insofar as ""catholic"" is understood as ""universal"" or ""what most people think of when they think of 'mainstream' Christianity, that is accurate.  If that were taken to mean the 'Roman Catholic Church,' that would be precise, but inaccurate, in that most Protestants and Orthodox also subscribe to the Creeds and to the Trinitarian formulations thereof.

2. The nature of the ""Bible""

Evangelicals consider the canon to be closed. Mormons have their own scriptures composed well after the period.

3. The nature of soteriology

Evangelicals, by and large, believe salvation to be solely the gift of God. We believe that all who are saved entire into eternal relationship with God. Mormons believe that people are rewarded according to the nature of the covenant they believed.
"
4635,4635,7352,"What is the Goal of ""Hot Network Questions""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
",jmac,https://meta.stackexchange.com/users/209637,"The ideal hot questions list would present the best posts of the network that are of interest to a wider population than only experts on that subject. The hot questions are shown to a much broader audience than the source site alone, showing them very specialized posts that they won't understand is not really useful.

I think drawing some attention to the larger SE network is one important role of the hot questions list, but I don't see recruitment of new users as its main purpose. It raises awareness of other sites that the users might not have noticed otherwise, and ideally it showcases some good content, and that might lead to some users staying on the site. But the whole mechanism is not targeted enough to be very effective in that regard, the hot questions list is shown to a large population where only a tiny part is likely an expert in the subject of one specific site. I think the best ways to recruit new users need to be targeted, e.g. recommendation from a colleague or a link to the site in a place frequented by experts on that topic.

The hot questions list becomes problematic when it identifies questions that are popular, but are not really of a high quality. When the algorithm identifies a question where the community of the source sites thinks the content is not very good and maybe even a bit embarrassing for the site, there is a problem. The questions should have popular appeal, but they should still be something even experts are not embarrassed to have as a showcase for their site. Often an excellent answer alone can raise a mediocre questions to something that deserves a place in the hot questions list.

So what the algorithm should identify are questions (and their answers) that are considered good by the source community, and of interest to a much broader audience. Looking at how many users click on entries in the hot questions list is a good way to judge the broader appeal, I think. But I also think that the quality aspect needs to be considered as well. The best way I can think of to examine this would be to look at the difference in voting between users active on the site and users that arrive at the question from the hot questions list. If the source community votes very differently than the ""outsiders"" looking at the question, this might indicate a problem.
",Mad Scientist,https://meta.stackexchange.com/users/151385,http://meta.stackexchange.com/questions/219922/what-is-the-goal-of-hot-network-questions,TECHNOLOGY,meta.stackexchange.com,1.0,0.5555555555555556,1.0,0.0,0.0,0.0,0.6666666666666666,0.4444444444444444,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,1.0,"What is the goal of ""network hot issues""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
","The ideal hot questions list would present the best posts of the network that are of interest to a wider population than only experts on that subject. The hot questions are shown to a much broader audience than the source site alone, showing them very specialized posts that they won't understand is not really useful.

I think drawing some attention to the larger SE network is one important role of the hot questions list, but I don't see recruitment of new users as its main purpose. It raises awareness of other sites that the users might not have noticed otherwise, and ideally it showcases some good content, and that might lead to some users staying on the site. But the whole mechanism is not targeted enough to be very effective in that regard, the hot questions list is shown to a large population where only a tiny part is likely an expert in the subject of one specific site. I think the best ways to recruit new users need to be targeted, e.g. recommendation from a colleague or a link to the site in a place frequented by experts on that topic.

The hot questions list becomes problematic when it identifies questions that are popular, but are not really of a high quality. When the algorithm identifies a question where the community of the source sites thinks the content is not very good and maybe even a bit embarrassing for the site, there is a problem. The questions should have popular appeal, but they should still be something even experts are not embarrassed to have as a showcase for their site. Often an excellent answer alone can raise a mediocre questions to something that deserves a place in the hot questions list.

So what the algorithm should identify are questions (and their answers) that are considered good by the source community, and of interest to a much broader audience. Looking at how many users click on entries in the hot questions list is a good way to judge the broader appeal, I think. But I also think that the quality aspect needs to be considered as well. The best way I can think of to examine this would be to look at the difference in voting between users active on the site and users that arrive at the question from the hot questions list. If the source community votes very differently than the ""outsiders"" looking at the question, this might indicate a problem.
"
2813,2813,4479,"Just found out my internet was routing through a proxy, how screwed am I?","I checked my internet setting today and it seem that everything has being going through some proxy server for the last few weeks.  How screwed am I?

Could they get my internet login password?  All my files on Dropbox?  I buy things online too, is my credit card compromised?

EDIT:

The IP of the proxy is 85.214.85.193, but on my other computer which was also proxied the IP was something different (I forgot to write it down).
",Bill,https://security.stackexchange.com/users/6615,"This all depends on the proxy itself. A proxy intercepts, and redirects. Everything going towards the Internet was intercepted, but it doesn't mean that all was readable. When you log into certain sites (banks, to buy something) most use SSL which means that, unless the proxy was intercepting with a trusted certificate, most data would be encrypted. If in the event the proxy intercepted SSL, and was capable of forging a certificate, or making you believe a certificate was trusted, then you're data is readable. You would have gotten a certificate error via your browser: ""Warning this site uses an untrusted certificate..."" 

Can you elaborate more on the proxy server. E.g. the IP (if possible). Some ISPs use proxies (rare) to cache and provide content quicker.

ADDED

The IP space belongs to Strato in Germany http://bgp.he.net/net/85.214.0.0/15#_whois and is listed in a lot of ""free proxy"" like sites. The bigger question for you is, how did your machine manage to get proxied in the first place. This is likely caused by some form of malware that made its way onto your machine if you did not configure that proxy. As noted, SSL could have been stripped so that is something to take into consideration.

Personally, I would try and determine how my machine got compromised, I would clean it up, preferably re-install from a clean source, then go and change all my passwords AFTER the fact I cleaned up. (Makes no sense to type much via way of credentials when you don't know what's on your machine)
",munkeyoto,https://security.stackexchange.com/users/26299,http://security.stackexchange.com/questions/47880/just-found-out-my-internet-was-routing-through-a-proxy-how-screwed-am-i,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.7777777777777778,I just found out that my network is routed through a proxy. What am I doing?,"I checked my internet setting today and it seem that everything has being going through some proxy server for the last few weeks.  How screwed am I?

Could they get my internet login password?  All my files on Dropbox?  I buy things online too, is my credit card compromised?

EDIT:

The IP of the proxy is 85.214.85.193, but on my other computer which was also proxied the IP was something different (I forgot to write it down).
","This all depends on the proxy itself. A proxy intercepts, and redirects. Everything going towards the Internet was intercepted, but it doesn't mean that all was readable. When you log into certain sites (banks, to buy something) most use SSL which means that, unless the proxy was intercepting with a trusted certificate, most data would be encrypted. If in the event the proxy intercepted SSL, and was capable of forging a certificate, or making you believe a certificate was trusted, then you're data is readable. You would have gotten a certificate error via your browser: ""Warning this site uses an untrusted certificate..."" 

Can you elaborate more on the proxy server. E.g. the IP (if possible). Some ISPs use proxies (rare) to cache and provide content quicker.

ADDED

The IP space belongs to Strato in Germany http://bgp.he.net/net/85.214.0.0/15#_whois and is listed in a lot of ""free proxy"" like sites. The bigger question for you is, how did your machine manage to get proxied in the first place. This is likely caused by some form of malware that made its way onto your machine if you did not configure that proxy. As noted, SSL could have been stripped so that is something to take into consideration.

Personally, I would try and determine how my machine got compromised, I would clean it up, preferably re-install from a clean source, then go and change all my passwords AFTER the fact I cleaned up. (Makes no sense to type much via way of credentials when you don't know what's on your machine)
"
3569,3569,5704,How can I make my iPad apps retina in Xcode 5 iOS7,"Not long ago I started learning Objective-C with an interest of developing apps. I have just started my first app and I have no clue how to make my app retina. I made the design in photoshop and exported it as a png @ 2,048 x 1,536 but however the size of my storyboard is only 1,024 x 768. I have read somewhere on the internet that you need two story boards but I am not sure how to link everything together. I would really appreciate it if someone could help me.
",user2989426,https://stackoverflow.com/users/2989426,"I am new to iOS development too. This link has been a huge help on questions related to this. https://developer.apple.com/library/ios/documentation/iPhone/Conceptual/iPhoneOSProgrammingGuide/App-RelatedResources/App-RelatedResources.html

You can pull up the same thing in the Xcode documentation by searching ""app-related"".
",Jeremy,https://stackoverflow.com/users/3058318,http://stackoverflow.com/questions/21129482/how-can-i-make-my-ipad-apps-retina-in-xcode-5-ios7,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,1.0,0.0,0.0,0.8888888888888888,How to make my iPad app retina in Xcode 5ios7,"Not long ago, I began to learn Objective-C, interested in developing applications. I've just started my first app, and I don't know how to make my app retina. I did this design in Photoshop and exported it as PNG @ 2048x 1536, but my storyboard is only 1024x768. I read on the Internet that you need a two-story blackboard, but I don't know how to connect everything. I would appreciate it if someone could help me.","I am new to iOS development too. This link has been a huge help on questions related to this. https://developer.apple.com/library/ios/documentation/iPhone/Conceptual/iPhoneOSProgrammingGuide/App-RelatedResources/App-RelatedResources.html

You can pull up the same thing in the Xcode documentation by searching ""app-related"".
"
4606,4606,7303,Is it possible to have a convergent subsequence of a divergent sequence?,"Is it possible to have a convergent subsequence of a divergent sequence? Thanks!
",eChung00,https://math.stackexchange.com/users/92974,"It depends on your definition of divergence:  If you mean non-convergent, then the answer is yes; If you mean that the sequence ""goes to infinity"", than the answer is no.
",User,https://math.stackexchange.com/users/125635,http://math.stackexchange.com/questions/494623/is-it-possible-to-have-a-convergent-subsequence-of-a-divergent-sequence,SCIENCE,math.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,Is it possible for convergent subsequences of divergent sequences?,Is it possible for convergent subsequences of divergent sequences? Thank you!,"It depends on your definition of divergence: if you mean non convergence, then the answer is yes; if you mean sequence ""going to infinity,"" then the answer is No."
4331,4331,6897,Is it appropriate to e-mail a researcher asking about progress on a follow-up paper?,"Recently, I saw an online presentation by a researcher and professor regarding a series of recently published papers. At the end, she mentioned she was working on a follow-up paper, regarding such and such... I have checked for it, and it has still not been published.

Perhaps it was a dead-end, and abandoned. Would it be appropriate to ask the professor about the progess made, and whether it has been abandoned, or when it will be published?
",JNS,https://academia.stackexchange.com/users/15736,"Certainly this is appropriate, especially if you indicate who you are and why you are interested. Researchers are interested in spreading their results far and wide to get citations.

The worst that can happen is that the research is not yet quite publication-ready, and the author prefers not to share it yet, to avoid academic claim-jumping. If so, you may get exactly this explanation, or no answer at all.

The best, conversely, would be that this could actually lead to a fruitful discussion and/or even collaboration.
",Stephan Kolassa,https://academia.stackexchange.com/users/4140,http://academia.stackexchange.com/questions/21577/is-it-appropriate-to-e-mail-a-researcher-asking-about-progress-on-a-follow-up-pa,LIFE_ARTS,academia.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.5555555555555556,0.7777777777777778,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,1.0,Email the researchers to see if it's appropriate for the follow-up paper to progress?,"Recently, I saw a researcher and professor giving a speech on a series of recently published papers on the Internet. Finally, she mentioned that she was working on a follow-up document about... I checked it. It's not published yet.","Certainly this is appropriate, especially if you indicate who you are and why you are interested. Researchers are interested in spreading their results far and wide to get citations.

The worst that can happen is that the research is not yet quite publication-ready, and the author prefers not to share it yet, to avoid academic claim-jumping. If so, you may get exactly this explanation, or no answer at all.

The best, conversely, would be that this could actually lead to a fruitful discussion and/or even collaboration.
"
1410,1410,2219,"What's the name of the characteristic of being ""open hearted""?","I can not think of any another good phrase to describe the sense, ""Open Hearted"". This characteristic is like one who does not posses the nature of being stubborn, who has the ability to listen and in certain cases accept others' theories though they can be in opposite of his own theory. A good example would be if a person is capable of admitting if there is some bad customs in his own religion and he does not fall back to admit it in front of others and change the custom in his regular life. What is the name of this characteristic?
",Mistu4u,https://ell.stackexchange.com/users/91,"The phrase you're looking for is actually ""open-minded"".  When one is open-minded, they're willing to listen to other opinions and, if properly convinced, change their beliefs.  The opposite of this would be closed-minded, like when you enter into a discussion with someone and they refuse to hear anything you have to say or change their mind.

""Open-hearted"" would be more like someone who is very generous and caring, and is always there to give a helping hand.  

Definitions for each: 

Open-hearted:


  
  kindly and warm
  disclosing intentions and thoughts clearly; candid
  


Open-minded:


  Receptive to new and different ideas or the opinions of others. See Synonyms at broad-minded.

",WendiKidd,https://ell.stackexchange.com/users/289,http://ell.stackexchange.com/questions/3516/whats-the-name-of-the-characteristic-of-being-open-hearted,CULTURE,ell.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,"What is the name of ""open mind""?","I can't think of another good word to describe the feeling, ""open mind."". It's like a person who doesn't have a stubborn nature. He has the ability to listen and in some cases accept other people's theories, even though they may be contrary to his own. A good example is if a person can admit that there are some bad customs in his own religion, and he will not shrink from admitting in front of others, and change the customs in his normal life. What's the name of this feature?","The phrase you're looking for is actually ""open-minded"".  When one is open-minded, they're willing to listen to other opinions and, if properly convinced, change their beliefs.  The opposite of this would be closed-minded, like when you enter into a discussion with someone and they refuse to hear anything you have to say or change their mind.

""Open-hearted"" would be more like someone who is very generous and caring, and is always there to give a helping hand.  

Definitions for each: 

Open-hearted:


  
  kindly and warm
  disclosing intentions and thoughts clearly; candid
  


Open-minded:


  Receptive to new and different ideas or the opinions of others. See Synonyms at broad-minded.

"
3471,3471,5535,Problem with passing control to Preference activity,"i created application in that it will call preference from main activity based on  menu option
it is done using  Explicit intent  but it not working . when clicking the menu item
calling activity

public boolean onCreateOptionsMenu(Menu menu)
{
    super.onCreateOptionsMenu(menu);

    menu.add(0,  Menu.FIRST+1, Menu.NONE, ""Refresh"");
    menu.add(0, Menu.FIRST+3, Menu.NONE, ""Set Preferences"");

    return true;
}

public boolean onOptionItemSelected(MenuItem item)
{
    switch(item.getItemId()) 
    {
        case Menu.FIRST+1:
            Intent intent =new Intent(this,userpreferences.class);
            startActivityForResult(intent,this.USER_PREFERENCES);
            return true;

        case Menu.FIRST+3:

            return true;    
    }

    return false;
}


preference xml

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;PreferenceScreen xmlns:android=""http://schemas.android.com/apk/res/android""&gt;
    &lt;CheckBoxPreference
        android:key=""AUTO_UPDATE"" android:title=""update automatically""
        android:summary=""update automatically"" android:defaultValue=""true"" /&gt;
    &lt;ListPreference android:key=""MINIMUM_MARK"" android:title=""minimum mark""     
        android:summary=""enter the minimum mark of the student"" 
        android:defaultValue=""30"" android:entries = ""@array/minimumMarks""   
        android:entryValues=""@array/minimum_mark_values"" 
        android:dialogTitle=""Check the minimum mark required"" /&gt;
&lt;/PreferenceScreen&gt;


Preference activity

package com.xml.parse;

import android.os.Bundle;
import android.preference.PreferenceActivity;

public class userpreferences extends PreferenceActivity
{
    public void onCreate(Bundle savedInstanceState)
    {
        super.onCreate(savedInstanceState);
        addPreferencesFromResource(R.xml.preferences);
    }
}


some body plz tell me to do better or correct way

Regards,

Kariyachan
",DroidBot,https://stackoverflow.com/users/482604,"Do not use startActivityForResult() -- startActivity() is fine. Here is a sample project showing the use of an options menu item to open a PreferenceActivity.
",CommonsWare,https://stackoverflow.com/users/115145,http://stackoverflow.com/questions/4084433/problem-with-passing-control-to-preference-activity,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.3333333333333333,0.0,0.0,1.0,0.5,0.6666666666666666,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,1.0,1.0,1.0,There was a problem passing control to the preference activity,"i created application in that it will call preference from main activity based on  menu option
it is done using  Explicit intent  but it not working . when clicking the menu item
calling activity

public boolean onCreateOptionsMenu(Menu menu)
{
    super.onCreateOptionsMenu(menu);

    menu.add(0,  Menu.FIRST+1, Menu.NONE, ""Refresh"");
    menu.add(0, Menu.FIRST+3, Menu.NONE, ""Set Preferences"");

    return true;
}

public boolean onOptionItemSelected(MenuItem item)
{
    switch(item.getItemId()) 
    {
        case Menu.FIRST+1:
            Intent intent =new Intent(this,userpreferences.class);
            startActivityForResult(intent,this.USER_PREFERENCES);
            return true;

        case Menu.FIRST+3:

            return true;    
    }

    return false;
}


preference xml

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;PreferenceScreen xmlns:android=""http://schemas.android.com/apk/res/android""&gt;
    &lt;CheckBoxPreference
        android:key=""AUTO_UPDATE"" android:title=""update automatically""
        android:summary=""update automatically"" android:defaultValue=""true"" /&gt;
    &lt;ListPreference android:key=""MINIMUM_MARK"" android:title=""minimum mark""     
        android:summary=""enter the minimum mark of the student"" 
        android:defaultValue=""30"" android:entries = ""@array/minimumMarks""   
        android:entryValues=""@array/minimum_mark_values"" 
        android:dialogTitle=""Check the minimum mark required"" /&gt;
&lt;/PreferenceScreen&gt;


Preference activity

package com.xml.parse;

import android.os.Bundle;
import android.preference.PreferenceActivity;

public class userpreferences extends PreferenceActivity
{
    public void onCreate(Bundle savedInstanceState)
    {
        super.onCreate(savedInstanceState);
        addPreferencesFromResource(R.xml.preferences);
    }
}


some body plz tell me to do better or correct way

Regards,

Kariyachan
","Do not use startActivityForResult() -- startActivity() is fine. Here is a sample project showing the use of an options menu item to open a PreferenceActivity.
"
924,924,1461,"How to change the formating of the title of a ""Listing"" from roman to arabic?","I recently stepped out of my comfort bounds and decided to add some Code snippets to my paper.  I was able to get everything working fine and looking good, except the actual title.  Everything else in my Document uses arabic, i.e. Figure 2.3, Table 4.5, etc... for some reason when I insert the Code (Using lstlisting), the published version becomes ""Listing III.1: code title"".

I tried using the same setup in my pre-amble as the figures, tables, and equations:

    \renewcommand\lstlistingname{\arabic{chapter}.\arabic{lstnumber}}


However, that removes the ""Listing"" portion and instead gives me ""3.1 III.1: code title"".  Obviously I am not wise enough with the \renewcommand? or is there another setting I should be changing?

Here is the pre-amble I was trying to copy:

\newcommand{\updateCounters}{\renewcommand{\thefigure}{\arabic{chapter}.\arabic{figure}}%
\renewcommand{\thetable}{\arabic{chapter}.\arabic{table}}%
\renewcommand{\theequation}{\arabic{chapter}.\arabic{equation}}%


Thanks!
",Biaspoint,https://tex.stackexchange.com/users/2590,"a complete example makes it easier to help!

\documentclass[openany]{book}
\usepackage{listings}
\AtBeginDocument{%
  \renewcommand\lstlistingname{My Listing}
  \renewcommand\thelstlisting{\thesection.\arabic{lstlisting}}}

\begin{document}

\lstlistoflistings

\chapter{dummy}
\section{More dummy}

\begin{lstlisting}[caption=bar]
 foo
\end{lstlisting}

\end{document}


Herbert
",Herbert,https://tex.stackexchange.com/users/2478,http://tex.stackexchange.com/questions/7379/how-to-change-the-formating-of-the-title-of-a-listing-from-roman-to-arabic,TECHNOLOGY,tex.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.7777777777777778,How do I change the format of the list title from Roman to Arabic?,"I recently stepped out of my comfort bounds and decided to add some Code snippets to my paper.  I was able to get everything working fine and looking good, except the actual title.  Everything else in my Document uses arabic, i.e. Figure 2.3, Table 4.5, etc... for some reason when I insert the Code (Using lstlisting), the published version becomes ""Listing III.1: code title"".

I tried using the same setup in my pre-amble as the figures, tables, and equations:

    \renewcommand\lstlistingname{\arabic{chapter}.\arabic{lstnumber}}


However, that removes the ""Listing"" portion and instead gives me ""3.1 III.1: code title"".  Obviously I am not wise enough with the \renewcommand? or is there another setting I should be changing?

Here is the pre-amble I was trying to copy:

\newcommand{\updateCounters}{\renewcommand{\thefigure}{\arabic{chapter}.\arabic{figure}}%
\renewcommand{\thetable}{\arabic{chapter}.\arabic{table}}%
\renewcommand{\theequation}{\arabic{chapter}.\arabic{equation}}%


Thanks!
","a complete example makes it easier to help!

\documentclass[openany]{book}
\usepackage{listings}
\AtBeginDocument{%
  \renewcommand\lstlistingname{My Listing}
  \renewcommand\thelstlisting{\thesection.\arabic{lstlisting}}}

\begin{document}

\lstlistoflistings

\chapter{dummy}
\section{More dummy}

\begin{lstlisting}[caption=bar]
 foo
\end{lstlisting}

\end{document}


Herbert
"
3690,3690,5880,Piezo as a switch to flash an led when disturbed,"An LED embedded in a small translucent item (say half the size of a pack of cards) that would flash on briefly if the object was disturbed or tipped over.
I immediately responded that a piezoelectric sensor/generator inside the object wired to an LED would do it.
However, when I tried to demonstrate this concept using a piezo buzzer I liberated from an old phone, I could only get the LED to register a dim blip when I smashed the piezo buzzer with a blunt object.
How would I ensure that a piezo sensor/generator would actually light up the LED adequately without the application of blunt force trauma.
As I mentioned, space would be an issue so no large parts, breadboards, or really complex circuitry.
I'm just trying to figure out the easiest and smallest way to accomplish this simple task.
Thanks a lot for any help you can give me!
",Rory O'Hare,https://electronics.stackexchange.com/users/6179,"The trick is to get some feedback oscillation. I once built one of these using a trusty spring from a mechanical pencil. Attach the spring to a pager motor inside a grounded aluminum housing.

When the spring hits the foil it will cause a vibration that will last for an random, but short period of time.

The challenge is calibrating the pager motor so that the spring gets a little extra kit; but shuts off most of time.
",Mikhail,https://electronics.stackexchange.com/users/5925,http://electronics.stackexchange.com/questions/22736/piezo-as-a-switch-to-flash-an-led-when-disturbed,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.5333333333333333,1.0,0.0,0.6666666666666666,1.0,Piezoelectric as a switch flashes led when disturbed,"An LED embedded in a small translucent item (say half the size of a pack of cards) that would flash on briefly if the object was disturbed or tipped over.
I immediately responded that a piezoelectric sensor/generator inside the object wired to an LED would do it.
However, when I tried to demonstrate this concept using a piezo buzzer I liberated from an old phone, I could only get the LED to register a dim blip when I smashed the piezo buzzer with a blunt object.
How would I ensure that a piezo sensor/generator would actually light up the LED adequately without the application of blunt force trauma.
As I mentioned, space would be an issue so no large parts, breadboards, or really complex circuitry.
I'm just trying to figure out the easiest and smallest way to accomplish this simple task.
Thanks a lot for any help you can give me!
","The trick is to get some feedback oscillation. I once built one of these using a trusty spring from a mechanical pencil. Attach the spring to a pager motor inside a grounded aluminum housing.

When the spring hits the foil it will cause a vibration that will last for an random, but short period of time.

The challenge is calibrating the pager motor so that the spring gets a little extra kit; but shuts off most of time.
"
1592,1592,2508,OpenLayers and TInyOWS WFS won't load - 'InvalidParameterValue',"I've got a tinyows on localhost that works fine (both through browser GetFeature and QGIS). But my OpenLayers code fails. I've checked here:
Display a WFS layer with OpenLayers and here : How to add a simple WFS layer from GeoServer to OpenLayers map?
and other similar questions to no avail. Can anyone help?

Here is the code:

    wfs = new OpenLayers.Layer.Vector(""Editable Features"", {
    strategies : [new OpenLayers.Strategy.Fixed(), saveStrategy],
    projection: new OpenLayers.Projection(""EPSG:4326""),
    protocol: new OpenLayers.Protocol.WFS({
        version: ""1.1.0"",
        srsName: ""EPSG:4326"",
        url: ""http://localhost/cgi-bin/tinyows"",
        featurePrefix: ""tows"",
        featureNS :  ""http://www.tinyows.org/"",
        featureType: ""trad"",
        geometryName: ""wkb_geometry"",
        schema: ""http://127.0.0.1/cgi-bin/tinyows?service=WFS&amp;version=1.1.0&amp;request=DescribeFeatureType&amp;Typename=tows:trad""
    })
}); 

map.addLayers([gphy, wfs]);


Here is the xml according to Firebug:

&lt;wfs:GetFeature xmlns:wfs=""http://www.opengis.net/wfs"" service=""WFS"" version=""1.1.0"" xsi:schemaLocation=""http://www.opengis.net/wfs http://schemas.opengis.net/wfs/1.1.0/wfs.xsd"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;





Here is the post response according to firebug:

&lt;?xml version='1.0' encoding='UTF-8'?&gt;
&lt;ows:ExceptionReport
  xmlns='http://www.opengis.net/ows'
  xmlns:ows='http://www.opengis.net/ows'
  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
  xsi:schemaLocation='http://www.opengis.net/ows http://schemas.opengis.net/ows/1.0.0/owsExceptionReport.xsd'
  version='1.1.0' language='en'&gt;
&lt;ows:Exception exceptionCode='InvalidParameterValue' locator='request'&gt;
&lt;ows:ExceptionText&gt;XML request isn't valid&lt;/ows:ExceptionText&gt;
&lt;/ows:Exception&gt;
&lt;/ows:ExceptionReport&gt;


Here is the tinyows config file:

&lt;tinyows online_resource=""http://127.0.0.1/cgi-bin/tinyows""
     schema_dir=""/usr/local/tinyows/schema/""&gt;
&lt;pg host=""127.0.0.1"" user=""postgres"" password=""****"" dbname=""****"" port=""5432""/&gt;
&lt;metadata name=""TinyOWS Server""
       title=""TinyOWS Server - Demo Service"" /&gt;
&lt;layer retrievable=""1""
    writable=""1""
    ns_prefix=""tows""
    ns_uri=""http://www.tinyows.org/""
    name=""trad""
    title=""TrÃ¤d"" /&gt;
&lt;/tinyows&gt;


Can anyone help?

Thanks in advance
",user10895,https://gis.stackexchange.com/users/10895,"Oops - turns out I had the wrong schema_dir in tinyows.xml. I changed 
    /usr/local/tinyows/schema/
to /usr/share/tinyows/schema and now it's loading fine. Maybe someone could update the config file example on http://mapserver.org/tinyows/configfile.html ?
",user10895,https://gis.stackexchange.com/users/10895,http://gis.stackexchange.com/questions/54038/openlayers-and-tinyows-wfs-wont-load-invalidparametervalue,TECHNOLOGY,gis.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.5,0.6666666666666666,0.6666666666666666,0.6,0.5,0.0,0.5,0.6666666666666666,"Openlayers and tinyows WFS will not load - ""invalidparametervalue""","I've got a tinyows on localhost that works fine (both through browser GetFeature and QGIS). But my OpenLayers code fails. I've checked here:
Display a WFS layer with OpenLayers and here : How to add a simple WFS layer from GeoServer to OpenLayers map?
and other similar questions to no avail. Can anyone help?

Here is the code:

    wfs = new OpenLayers.Layer.Vector(""Editable Features"", {
    strategies : [new OpenLayers.Strategy.Fixed(), saveStrategy],
    projection: new OpenLayers.Projection(""EPSG:4326""),
    protocol: new OpenLayers.Protocol.WFS({
        version: ""1.1.0"",
        srsName: ""EPSG:4326"",
        url: ""http://localhost/cgi-bin/tinyows"",
        featurePrefix: ""tows"",
        featureNS :  ""http://www.tinyows.org/"",
        featureType: ""trad"",
        geometryName: ""wkb_geometry"",
        schema: ""http://127.0.0.1/cgi-bin/tinyows?service=WFS&amp;version=1.1.0&amp;request=DescribeFeatureType&amp;Typename=tows:trad""
    })
}); 

map.addLayers([gphy, wfs]);


Here is the xml according to Firebug:

&lt;wfs:GetFeature xmlns:wfs=""http://www.opengis.net/wfs"" service=""WFS"" version=""1.1.0"" xsi:schemaLocation=""http://www.opengis.net/wfs http://schemas.opengis.net/wfs/1.1.0/wfs.xsd"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;





Here is the post response according to firebug:

&lt;?xml version='1.0' encoding='UTF-8'?&gt;
&lt;ows:ExceptionReport
  xmlns='http://www.opengis.net/ows'
  xmlns:ows='http://www.opengis.net/ows'
  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
  xsi:schemaLocation='http://www.opengis.net/ows http://schemas.opengis.net/ows/1.0.0/owsExceptionReport.xsd'
  version='1.1.0' language='en'&gt;
&lt;ows:Exception exceptionCode='InvalidParameterValue' locator='request'&gt;
&lt;ows:ExceptionText&gt;XML request isn't valid&lt;/ows:ExceptionText&gt;
&lt;/ows:Exception&gt;
&lt;/ows:ExceptionReport&gt;


Here is the tinyows config file:

&lt;tinyows online_resource=""http://127.0.0.1/cgi-bin/tinyows""
     schema_dir=""/usr/local/tinyows/schema/""&gt;
&lt;pg host=""127.0.0.1"" user=""postgres"" password=""****"" dbname=""****"" port=""5432""/&gt;
&lt;metadata name=""TinyOWS Server""
       title=""TinyOWS Server - Demo Service"" /&gt;
&lt;layer retrievable=""1""
    writable=""1""
    ns_prefix=""tows""
    ns_uri=""http://www.tinyows.org/""
    name=""trad""
    title=""TrÃ¤d"" /&gt;
&lt;/tinyows&gt;


Can anyone help?

Thanks in advance
","Oops - turns out I had the wrong schema_dir in tinyows.xml. I changed 
    /usr/local/tinyows/schema/
to /usr/share/tinyows/schema and now it's loading fine. Maybe someone could update the config file example on http://mapserver.org/tinyows/configfile.html ?
"
1080,1080,1706,How to fix a dpkg broken by the Brother MFC-7340 deb driver,"I'm getting an apt-get error that says

E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.

The brmfc7340lpr is a printer driver -- it's a local deb file. Doing a dpkg or apt-get purge doesn't work, neither does apt-get install -f .

How do I reinstall a package from a local deb file?

Output:

box-name% sudo apt-get upgrade
[sudo] password for username: 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo apt-get purge brmfc7340lpr
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo dpkg --purge brmfc7340lpr 
dpkg: error processing brmfc7340lpr (--purge):
 Package is in a very bad inconsistent state - you should
 reinstall it before attempting a removal.
Errors were encountered while processing:
 brmfc7340lpr
box-name% sudo dpkg --install brmfc7340lpr-2.0.2-1.i386.deb
Selecting previously deselected package brmfc7340lpr.
(Reading database ... 725204 files and directories currently installed.)
Preparing to replace brmfc7340lpr 2.0.2-1 (using .../brmfc7340lpr-2.0.2-1.i386.deb) ...
Unpacking replacement brmfc7340lpr ...
start: Unknown job: lpd
dpkg: warning: subprocess old post-removal script returned error exit status 1
dpkg - trying script from the new package instead ...
start: Unknown job: lpd
dpkg: error processing brmfc7340lpr-2.0.2-1.i386.deb (--install):
 subprocess new post-removal script returned error exit status 1
start: Unknown job: lpd
dpkg: error while cleaning up:
 subprocess new post-removal script returned error exit status 1
Errors were encountered while processing:
brmfc7340lpr-2.0.2-1.i386.deb
box-name% sudo apt-get install -f                                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% 

",Roman A. Taycher,https://askubuntu.com/users/669,"Riccardo's solution should work, I am guessing the problem lies here:

start: Unknown job: lpd

Guess 1: It looks like the deb is trying to restart a service which isn't running and erroring out. Try installing the lpr package from the repositories and then installing the deb and see if that works.

Guess 2: It sounds like you're trying to install a deb from a website for a brother 7340 printer: This page might be a good starting point if you want to split it off into another question.
",Jorge Castro,https://askubuntu.com/users/235,http://askubuntu.com/questions/5058/how-to-fix-a-dpkg-broken-by-the-brother-mfc-7340-deb-driver,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.6,1.0,0.0,0.6666666666666666,1.0,How to fix the dpkg damaged by brother mfc-7340 DEB driver,"I'm getting an apt-get error that says

E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.

The brmfc7340lpr is a printer driver -- it's a local deb file. Doing a dpkg or apt-get purge doesn't work, neither does apt-get install -f .

How do I reinstall a package from a local deb file?

Output:

box-name% sudo apt-get upgrade
[sudo] password for username: 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo apt-get purge brmfc7340lpr
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo dpkg --purge brmfc7340lpr 
dpkg: error processing brmfc7340lpr (--purge):
 Package is in a very bad inconsistent state - you should
 reinstall it before attempting a removal.
Errors were encountered while processing:
 brmfc7340lpr
box-name% sudo dpkg --install brmfc7340lpr-2.0.2-1.i386.deb
Selecting previously deselected package brmfc7340lpr.
(Reading database ... 725204 files and directories currently installed.)
Preparing to replace brmfc7340lpr 2.0.2-1 (using .../brmfc7340lpr-2.0.2-1.i386.deb) ...
Unpacking replacement brmfc7340lpr ...
start: Unknown job: lpd
dpkg: warning: subprocess old post-removal script returned error exit status 1
dpkg - trying script from the new package instead ...
start: Unknown job: lpd
dpkg: error processing brmfc7340lpr-2.0.2-1.i386.deb (--install):
 subprocess new post-removal script returned error exit status 1
start: Unknown job: lpd
dpkg: error while cleaning up:
 subprocess new post-removal script returned error exit status 1
Errors were encountered while processing:
brmfc7340lpr-2.0.2-1.i386.deb
box-name% sudo apt-get install -f                                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% 

","Riccardo's solution should work, I am guessing the problem lies here:

start: Unknown job: lpd

Guess 1: It looks like the deb is trying to restart a service which isn't running and erroring out. Try installing the lpr package from the repositories and then installing the deb and see if that works.

Guess 2: It sounds like you're trying to install a deb from a website for a brother 7340 printer: This page might be a good starting point if you want to split it off into another question.
"
6006,6006,9527,"What does ""flattens"" mean in this context?","I have an assignment for Programming Fundamentals (we are using Python 3.4), and some questions are sometimes not really obvious to understand, maybe because my English is not so good.

Two of the introductory questions of our last assignment were: 


Write a function that âflattensâ its input list.
Write a function that accepts a list that contains nested lists and returns the âdepthâ
of the list.


Sincerely I am not understanding exactly what they are asking. Can someone explain me?
",nbro,https://ell.stackexchange.com/users/9470,"Guessing a bit, as I'm not a programmer...


""Flatten the list""
Two possibilities, so I would really check with the test setter...  


Empty the list, ready to start the task (most likely)
Take the nested lists &amp; concatenate them into one list (less likely)

""depth of the list""
Again, I see two possibilities &amp; I have no idea as to which may be more appropriate ...


Calculate the total number of list lines, including all nested lists  
Calculate the number of levels used in the nesting.



A coder might know better.
",Tetsujin,https://ell.stackexchange.com/users/11747,http://ell.stackexchange.com/questions/39008/what-does-flattens-mean-in-this-context,CULTURE,ell.stackexchange.com,1.0,0.8333333333333334,0.5,1.0,1.0,1.0,0.8333333333333334,0.8333333333333334,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.5,0.6666666666666666,0.8333333333333334,0.6,0.0,0.0,0.0,0.6666666666666666,"In this case, what does ""flattening"" mean?","I have an assignment for Programming Fundamentals (we are using Python 3.4), and some questions are sometimes not really obvious to understand, maybe because my English is not so good.

Two of the introductory questions of our last assignment were: 


Write a function that âflattensâ its input list.
Write a function that accepts a list that contains nested lists and returns the âdepthâ
of the list.


Sincerely I am not understanding exactly what they are asking. Can someone explain me?
","Guessing a bit, as I'm not a programmer...


""Flatten the list""
Two possibilities, so I would really check with the test setter...  


Empty the list, ready to start the task (most likely)
Take the nested lists &amp; concatenate them into one list (less likely)

""depth of the list""
Again, I see two possibilities &amp; I have no idea as to which may be more appropriate ...


Calculate the total number of list lines, including all nested lists  
Calculate the number of levels used in the nesting.



A coder might know better.
"
3055,3055,4866,How soon after baking can you refrigerate freshly made fruit pies?,"How soon after baking a fresh fruit custard pie can I refrigerate it? Must it be at room temperature before it's put in the fridge?
",Deedee,https://cooking.stackexchange.com/users/36628,"Basically you want to avoid heating up the contents of your refrigerator. That's pretty much the only concern, protecting your other food items.

How long it will take a given pie to cool depends on a lot of factors, but I'd say wait half an hour minimum after pulling from the oven. 

It will still be warm at that point, but probably not enough to appreciably warm your fridge. 
",Preston,https://cooking.stackexchange.com/users/17063,http://cooking.stackexchange.com/questions/58802/how-soon-after-baking-can-you-refrigerate-freshly-made-fruit-pies,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,How long after baking can you refrigerate the fresh fruit pie?,How long after baking a fresh fruit cream pie can I refrigerate it? Must it be at room temperature before putting it in the refrigerator?,"Basically you want to avoid heating up the contents of your refrigerator. That's pretty much the only concern, protecting your other food items.

How long it will take a given pie to cool depends on a lot of factors, but I'd say wait half an hour minimum after pulling from the oven. 

It will still be warm at that point, but probably not enough to appreciably warm your fridge. 
"
2560,2560,4074,Find cron jobs that run between given times,"Is it possible to find all entries in a crontab that run between time X and time Y without having to parse the cron time entries myself? I'm mainly concerned with time hour and  minute, not so much the other 3 time fields.
",frankc,https://stackoverflow.com/users/275455,"Anything is possible but you will have to parse crontab yourself.

There are no simple answers, but just because I can here's a partial solution in bash.

    #!/bin/bash

    start=""${1-0:0}""
    end=""${2-0:0}""
    start_hour=$(cut -d: -f1 &lt;&lt;&lt;""$start"")
    end_hour=$(cut -d: -f1 &lt;&lt;&lt;""$end"")
    start_min=$(cut -d: -f2 &lt;&lt;&lt;""$start"")
    end_min=$(cut -d: -f2 &lt;&lt;&lt;""$end"")

    # leading zeroes would be bad
    let start_hour=10#${start_hour}
    let end_hour=10#${end_hour}
    let start_min=10#${start_min}
    let end_min=10#${end_min}

    cat /etc/crontab | \
            grep -v ^\# | \
            grep -E -v '^([a-zA-Z]+)' | \
            awk '{print $1, $2, $7}' | \
    while read line ; do
            if [ ! -z ""$line"" ] ; then
                    h=$(cut -d' ' -f2 &lt;&lt;&lt;""$line"")
                    m=$(cut -d' ' -f1 &lt;&lt;&lt;""$line"")
                    cmd=$(cut -d' ' -f3- &lt;&lt;&lt;""$line"")

                    if [ ""$h"" = '*' ] || ( [ $h -ge $start_hour ] &amp;&amp; [ $h -le $end_hour ] ) ; then
                            if [ ""$m"" = '*' ] || ( [ $m -ge $start_min ] &amp;&amp; [ $m -le $end_min ] ) ; then
                                    echo $cmd
                            fi
                    fi
            fi
    done


Call like

cron_between 09:00 16:59


This certainly won't work for complex time specifications (e.g. */2) and only reports on the first part of the command. All of this can be corrected, but probably you'd be better off doing it in perl or something.
",Sorpigal,https://stackoverflow.com/users/180736,http://stackoverflow.com/questions/4053463/find-cron-jobs-that-run-between-given-times,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.6666666666666666,0.8888888888888888,Find cron jobs running between given times,"Can you find all the entries running between time x and time y in crontab without having to analyze the cron time entries yourself? My main concerns are time hours and minutes, not the other three time domains.","Anything is possible but you will have to parse crontab yourself.

There are no simple answers, but just because I can here's a partial solution in bash.

    #!/bin/bash

    start=""${1-0:0}""
    end=""${2-0:0}""
    start_hour=$(cut -d: -f1 &lt;&lt;&lt;""$start"")
    end_hour=$(cut -d: -f1 &lt;&lt;&lt;""$end"")
    start_min=$(cut -d: -f2 &lt;&lt;&lt;""$start"")
    end_min=$(cut -d: -f2 &lt;&lt;&lt;""$end"")

    # leading zeroes would be bad
    let start_hour=10#${start_hour}
    let end_hour=10#${end_hour}
    let start_min=10#${start_min}
    let end_min=10#${end_min}

    cat /etc/crontab | \
            grep -v ^\# | \
            grep -E -v '^([a-zA-Z]+)' | \
            awk '{print $1, $2, $7}' | \
    while read line ; do
            if [ ! -z ""$line"" ] ; then
                    h=$(cut -d' ' -f2 &lt;&lt;&lt;""$line"")
                    m=$(cut -d' ' -f1 &lt;&lt;&lt;""$line"")
                    cmd=$(cut -d' ' -f3- &lt;&lt;&lt;""$line"")

                    if [ ""$h"" = '*' ] || ( [ $h -ge $start_hour ] &amp;&amp; [ $h -le $end_hour ] ) ; then
                            if [ ""$m"" = '*' ] || ( [ $m -ge $start_min ] &amp;&amp; [ $m -le $end_min ] ) ; then
                                    echo $cmd
                            fi
                    fi
            fi
    done


Call like

cron_between 09:00 16:59


This certainly won't work for complex time specifications (e.g. */2) and only reports on the first part of the command. All of this can be corrected, but probably you'd be better off doing it in perl or something.
"
4578,4578,7258,Is ZIP archive capable of storing permissions?,"I am using Maven Assembly plugin to bundle my application along with configuration/settings files. It allows to specify persmissions to be stored along with files, which is quite convenient.

Still I never found a confirmation, that ZIP archive is capable of storing UNIX permissions. Is it? (please, post some proof if you answer either yes or no).
",user1065145,https://serverfault.com/users/149491,"Yes,


Create you deployment.
Transfer it to another machine.
Deploy the application.
Compare the permissions on the reference machine with the lab machine.


Profit!
",Iain,https://serverfault.com/users/9517,http://serverfault.com/questions/585817,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Can zip archive store permissions?,"I am using the Maven assembly plug-in to bundle my application with a configuration / settings file. It allows you to specify the people to store with the file, which is very convenient.","Yes,


Create you deployment.
Transfer it to another machine.
Deploy the application.
Compare the permissions on the reference machine with the lab machine.


Profit!
"
853,853,1360,Is pretending to want to trade before playing a monopoly card objectionable?,"In Settlers of Catan, I sometimes try to ask people if they want to trade a certain resource, tricking them into revealing the approximate amount of that resource in everyone's hand. After this I play the monopoly card. This has on some occasions not been received very well.

Is this fair play?
",Matthijs Wessels,https://boardgames.stackexchange.com/users/117,"Yes, it's lame :P.

But at my table you wouldn't be reprimanded, but expect future trade to get a little more difficult. This is an awesome way to get the rest to gang up on you.
",Powertieke,https://boardgames.stackexchange.com/users/121,http://boardgames.stackexchange.com/questions/577/is-pretending-to-want-to-trade-before-playing-a-monopoly-card-objectionable,CULTURE,boardgames.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.0,0.5,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,Is it offensive to pretend to trade before playing Monopoly?,"Among the settlers in katan, I sometimes try to ask people if they want to exchange certain resources and cheat them to reveal the approximate amount of resources in each person's hands. After that, I played Monopoly. This is not well accepted in some cases.","Yes, it's lame :P.

But at my table you wouldn't be reprimanded, but expect future trade to get a little more difficult. This is an awesome way to get the rest to gang up on you.
"
2735,2735,4357,"Is there any way to customize vmware's ""Easy Install"" of ubuntu?","VMWare has a feature when creating new VMs called Easy Install, that will show you a small wizard asking you the minimum things needed and then will install the entire OS without you needing to do anything.

When installing Ubuntu server, it only asks you the details of the default user (Full name, username, password and repeat password) and then installs ubuntu with the default options and packages.

I'd like to know if I can tell it to install some extra packages, run custom commands before finishing the installation or using another apt repository than the default one.

BTW if it matters, I'm using VMware Player 5.0.0 on Ubuntu 11.10 amd64, and I'm planning to install Ubuntu 11.10 amd64 server as a guest.
",Carlos CampderrÃ³s,https://superuser.com/users/126729,"I don't think there is any way to customize the Easy Install option, but you can perform a regular install to make the changes you need. When creating the virtual machine you will need to select the option ""I will install the operating system later"".

Once the VM has been created, right click on it in the menu and select ""Virtual Machine Settings..."" from the pop-up menu. Next, click on ""CD/DVD (IDE)"" in the left pane, then ""Use an ISO image file:"" in the right pane and browse to your ISO file.

Now when you power on the VM it should automatically boot from the ISO file and perform a regular install, which will allow you to make additional customizations.
",Craig Dodd,https://superuser.com/users/168442,http://superuser.com/questions/495295,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,1.0,0.0,0.0,0.8888888888888888,"Is there any way to customize Ubuntu ""easy install"" for VMware?","VMWare has a feature when creating new VMs called Easy Install, that will show you a small wizard asking you the minimum things needed and then will install the entire OS without you needing to do anything.

When installing Ubuntu server, it only asks you the details of the default user (Full name, username, password and repeat password) and then installs ubuntu with the default options and packages.

I'd like to know if I can tell it to install some extra packages, run custom commands before finishing the installation or using another apt repository than the default one.

BTW if it matters, I'm using VMware Player 5.0.0 on Ubuntu 11.10 amd64, and I'm planning to install Ubuntu 11.10 amd64 server as a guest.
","I don't think there is any way to customize the Easy Install option, but you can perform a regular install to make the changes you need. When creating the virtual machine you will need to select the option ""I will install the operating system later"".

Once the VM has been created, right click on it in the menu and select ""Virtual Machine Settings..."" from the pop-up menu. Next, click on ""CD/DVD (IDE)"" in the left pane, then ""Use an ISO image file:"" in the right pane and browse to your ISO file.

Now when you power on the VM it should automatically boot from the ISO file and perform a regular install, which will allow you to make additional customizations.
"
276,276,442,Why did they choose Barabbas?,"John 19:38 - 40 (NLT)


  38 âWhat is truth?â Pilate asked. Then he went out again to the people
  and told them, âHe is not guilty of any crime. 39 But you have a
  custom of asking me to release one prisoner each year at Passover.
  Would you like me to release this âKing of the Jewsâ?â
  
  40 But they shouted back, âNo! Not this man. We want Barabbas!â
  (Barabbas was a revolutionary.)


Why were they so messed up that they would choose the rebellious, murderous Barabbas over the innocent Son of God?
",Andrew,https://christianity.stackexchange.com/users/65,"Mark 15:7-15


  7 And among the rebels in prison, who had committed murder in the insurrection, there was a man called Barabbas. 8 And the crowd came up and began to ask Pilate to do as he usually did for them. 9 And he answered them, saying, âDo you want me to release for you the King of the Jews?â 10 For he perceived that pit was out of envy that the chief priests had delivered him up. 11 But the chief priests stirred up the crowd to have him release for them Barabbas instead. 12 And Pilate again said to them, âThen what shall I do with the man you call the King of the Jews?â 13 And they cried out again, âCrucify him.â 14 And Pilate said to them, âWhy, what evil has he done?â But they shouted all the more, âCrucify him.â 15 So Pilate, wishing to satisfy the crowd, released for them Barabbas, and having scourged Jesus, he delivered him to be crucified.


As Mark's version of this event emphasizes, the crowd was driven to cry for Barabbas by the chief priests who were at the root of the push to have Jesus killed. Why would they choose Barabbas as their alternative to prevent Jesus' release? The biggest factor, of course, is that Jesus was a problem for them - he spoke against them repeatedly, criticized their teaching and their ways, and taught many things that contradicted what they taught. 

But on the specifics of why the chief priests would choose Barabbas, I think there's a pretty easy answer to reason out, even if the Bible doesn't explicitly detail it. Barabbas, as John mentions, was a revolutionary. That meant he was trouble, but not for the chief priests. He was trouble for the Romans. He wanted to resist Roman occupation and authority in the name of Jewish freedom. It's not hard to get an oppressed people to cheer for someone who wants to end their oppression. This would have been a win-win in the eyes of the chief priests, because they were getting rid of a man who threatened to compromise their authority in exchange for a man who threatened to compromise the authority of their oppressors.
",asfallows,https://christianity.stackexchange.com/users/168,http://christianity.stackexchange.com/questions/7043/why-did-they-choose-barabbas,CULTURE,christianity.stackexchange.com,1.0,0.8333333333333334,0.5,1.0,0.0,0.5,0.6666666666666666,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.8333333333333334,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why did they choose Barabbas?,"John 19:38 - 40 (NLT)


  38 âWhat is truth?â Pilate asked. Then he went out again to the people
  and told them, âHe is not guilty of any crime. 39 But you have a
  custom of asking me to release one prisoner each year at Passover.
  Would you like me to release this âKing of the Jewsâ?â
  
  40 But they shouted back, âNo! Not this man. We want Barabbas!â
  (Barabbas was a revolutionary.)


Why were they so messed up that they would choose the rebellious, murderous Barabbas over the innocent Son of God?
","Mark 15:7-15


  7 And among the rebels in prison, who had committed murder in the insurrection, there was a man called Barabbas. 8 And the crowd came up and began to ask Pilate to do as he usually did for them. 9 And he answered them, saying, âDo you want me to release for you the King of the Jews?â 10 For he perceived that pit was out of envy that the chief priests had delivered him up. 11 But the chief priests stirred up the crowd to have him release for them Barabbas instead. 12 And Pilate again said to them, âThen what shall I do with the man you call the King of the Jews?â 13 And they cried out again, âCrucify him.â 14 And Pilate said to them, âWhy, what evil has he done?â But they shouted all the more, âCrucify him.â 15 So Pilate, wishing to satisfy the crowd, released for them Barabbas, and having scourged Jesus, he delivered him to be crucified.


As Mark's version of this event emphasizes, the crowd was driven to cry for Barabbas by the chief priests who were at the root of the push to have Jesus killed. Why would they choose Barabbas as their alternative to prevent Jesus' release? The biggest factor, of course, is that Jesus was a problem for them - he spoke against them repeatedly, criticized their teaching and their ways, and taught many things that contradicted what they taught. 

But on the specifics of why the chief priests would choose Barabbas, I think there's a pretty easy answer to reason out, even if the Bible doesn't explicitly detail it. Barabbas, as John mentions, was a revolutionary. That meant he was trouble, but not for the chief priests. He was trouble for the Romans. He wanted to resist Roman occupation and authority in the name of Jewish freedom. It's not hard to get an oppressed people to cheer for someone who wants to end their oppression. This would have been a win-win in the eyes of the chief priests, because they were getting rid of a man who threatened to compromise their authority in exchange for a man who threatened to compromise the authority of their oppressors.
"
5781,5781,9161,Is research a viable business model?,"I have had the suspicion that it may be for a while and apparently not all is a product of my mind. Let me quote from an answer:


  In my experience, in UK and other European countries, the research
  funding comes from successful proposals to the relevant funding
  bodies. There are research centres that were established and keep
  going only because the staff there constantly submits project
  proposals (somebody told me that the success rate is 1 out of 5 or
  maybe even lower).


There are two questions here.


Can a company feasibly focus on obtaining funds in publicly funded research (as a business model) successfully enough to ""survive""?
Can such a company be started (nearly) from scratch?


In short, the company would be exactly like a research institute (or institution) except that it would be private.

Reasons why question 1 may not be feasible:


I don't see any company doing this kind of thing, i.e. there may be some, but there are not many, which means that it may be hard. It's a bad sign.
Public funds seem to be assigned to public entities, while companies can benefit from the collaboration and synergy, but they are expected to get their funding from their work as companies (searching for customers, etc.) In this case the customers would be the partners in the projects and the society itself, but again, this seems to be an ""innovative"" (maybe naÃ¯ve, or even plain stupid) idea.
Research is a means for something, not an end on itself, that's why the business model should be on something else (point two) and that's why such a company would raise eyebrows on the mere idea of its existence. It may even be against some kind of tacit rule or even written laws.


Reasons why question 2 may not be feasible:


No previous history of success of the company, or products or anything means zero (or negative) trustworthiness and no projects assigned to the company.
No partners would like to associate with the company in a project for the reasons in point 1.
The most similar case I can think of are spin-off companies that are created from successful research labs, not from scratch.
OMG so much communism! Go to kickstarter you hippie!


As an example, a possible scenario that could be close to this: Someone writes a paper about a software system that does something not very novel in the state of the art but in a way that is very different from an architectural point of view, leading to good results in practical terms. In short: in theory nothing is new, in practice what was just a dream is now a reality. What is done remains the same in theory, but how it is done is completely different in practice (and now it works). Unfortunately only a proof of concept (PoC) can reasonably be implemented.

Would it be feasible to request funds to continue the development of this PoC (still very far from a commercial product) as a start-up or that simply doesn't make sense?
",Trylks,https://academia.stackexchange.com/users/7571,"In Europe, companies exist that primarily live from FP7 or, now, H2020 funding. They rarely contribute much to projects in terms of research, but often handle tangential issues, such as project management, dissemination, marketing, or association with standardization bodies. Their model works because (1) they do things that none of the research partners actually wants to do, and (2) because they are often SMEs, which is generally politically helpful to get your funding proposals accepted. Further, as writing grant proposals is their core business, they usually also have grant writing experts that have the time to actually keep up with the various changes that the european commission is constantly applying to its programmes and rules (something that many researchers struggle to find the time for).

Formally, these companies often camouflage as either consultancies or technology spinoffs. That is, you will not find it on their web page that their core business model is actually to milk grant programmes, as this is strictly against official funding rules (as a company, you can only apply for funding if you plan to commercialise the results, and you are not supposed to make a profit from the project itself). In practice, the project officers seem to tolerate these businesses - for now.


  Can such a company be started (nearly) from scratch?


You will need a reasonable amount of seed money, as the H2020 rules require proof that an organization applying for grants has enough financial stability to likely survive over the typically 3-year project duration. I know from one startup that wanted to participate in a project (for actual technology reasons) which was in fact struggling to cross this hurdle. However, if you have the required seed funding, I see no reason why you would not be able to start such a business. Whether it is a smart business idea is a different question, given that you are basically living off of a loophole in the current funding practices, and you can never tell how long this loophole will stay open.

Edit:

I just saw that I missed this question:


  Would it be feasible to request funds to continue the development of this PoC (still very far from a commercial product) as a start-up or that simply doesn't make sense?


Yes, at least in Europe there are funding sources for exactly this kind of case. You should inform yourself about the concept of Technology Readiness Levels (TRLs, slide 4), and the different kinds of funding available for each TRL. If you look at this presentation and go to slide 32, there is an overview over different funding instruments in H2020 depending on the maturity of the idea.
",xLeitix,https://academia.stackexchange.com/users/10094,http://academia.stackexchange.com/questions/23676/is-research-a-viable-business-model,LIFE_ARTS,academia.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,0.5555555555555556,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.8,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,Is research a viable business model?,"I have had the suspicion that it may be for a while and apparently not all is a product of my mind. Let me quote from an answer:


  In my experience, in UK and other European countries, the research
  funding comes from successful proposals to the relevant funding
  bodies. There are research centres that were established and keep
  going only because the staff there constantly submits project
  proposals (somebody told me that the success rate is 1 out of 5 or
  maybe even lower).


There are two questions here.


Can a company feasibly focus on obtaining funds in publicly funded research (as a business model) successfully enough to ""survive""?
Can such a company be started (nearly) from scratch?


In short, the company would be exactly like a research institute (or institution) except that it would be private.

Reasons why question 1 may not be feasible:


I don't see any company doing this kind of thing, i.e. there may be some, but there are not many, which means that it may be hard. It's a bad sign.
Public funds seem to be assigned to public entities, while companies can benefit from the collaboration and synergy, but they are expected to get their funding from their work as companies (searching for customers, etc.) In this case the customers would be the partners in the projects and the society itself, but again, this seems to be an ""innovative"" (maybe naÃ¯ve, or even plain stupid) idea.
Research is a means for something, not an end on itself, that's why the business model should be on something else (point two) and that's why such a company would raise eyebrows on the mere idea of its existence. It may even be against some kind of tacit rule or even written laws.


Reasons why question 2 may not be feasible:


No previous history of success of the company, or products or anything means zero (or negative) trustworthiness and no projects assigned to the company.
No partners would like to associate with the company in a project for the reasons in point 1.
The most similar case I can think of are spin-off companies that are created from successful research labs, not from scratch.
OMG so much communism! Go to kickstarter you hippie!


As an example, a possible scenario that could be close to this: Someone writes a paper about a software system that does something not very novel in the state of the art but in a way that is very different from an architectural point of view, leading to good results in practical terms. In short: in theory nothing is new, in practice what was just a dream is now a reality. What is done remains the same in theory, but how it is done is completely different in practice (and now it works). Unfortunately only a proof of concept (PoC) can reasonably be implemented.

Would it be feasible to request funds to continue the development of this PoC (still very far from a commercial product) as a start-up or that simply doesn't make sense?
","In Europe, companies exist that primarily live from FP7 or, now, H2020 funding. They rarely contribute much to projects in terms of research, but often handle tangential issues, such as project management, dissemination, marketing, or association with standardization bodies. Their model works because (1) they do things that none of the research partners actually wants to do, and (2) because they are often SMEs, which is generally politically helpful to get your funding proposals accepted. Further, as writing grant proposals is their core business, they usually also have grant writing experts that have the time to actually keep up with the various changes that the european commission is constantly applying to its programmes and rules (something that many researchers struggle to find the time for).

Formally, these companies often camouflage as either consultancies or technology spinoffs. That is, you will not find it on their web page that their core business model is actually to milk grant programmes, as this is strictly against official funding rules (as a company, you can only apply for funding if you plan to commercialise the results, and you are not supposed to make a profit from the project itself). In practice, the project officers seem to tolerate these businesses - for now.


  Can such a company be started (nearly) from scratch?


You will need a reasonable amount of seed money, as the H2020 rules require proof that an organization applying for grants has enough financial stability to likely survive over the typically 3-year project duration. I know from one startup that wanted to participate in a project (for actual technology reasons) which was in fact struggling to cross this hurdle. However, if you have the required seed funding, I see no reason why you would not be able to start such a business. Whether it is a smart business idea is a different question, given that you are basically living off of a loophole in the current funding practices, and you can never tell how long this loophole will stay open.

Edit:

I just saw that I missed this question:


  Would it be feasible to request funds to continue the development of this PoC (still very far from a commercial product) as a start-up or that simply doesn't make sense?


Yes, at least in Europe there are funding sources for exactly this kind of case. You should inform yourself about the concept of Technology Readiness Levels (TRLs, slide 4), and the different kinds of funding available for each TRL. If you look at this presentation and go to slide 32, there is an overview over different funding instruments in H2020 depending on the maturity of the idea.
"
2477,2477,3948,Etiquette for posting civil and informative comments,"Sometimes I leave a comment like ""Stack Overflow is not your personal research assistant,"" but am accused of being rude.  How can I craft a comment that is seen as civil to the community and instructive to the OP?


What tone should I strike in comments?
What are some examples of bad comments and their better replacements?

",Robert Harvey,https://meta.stackexchange.com/users/102937,"The other two answers are quite good, so this is more of a clarification than a complete answer.

Considering the example:


  Question: ""I'm trying to xxx and it's not working.""
  
  unfriendly: ""Look, we're not mind readers here. What do you mean it's not working?""
  
  neutral: ""What did you expect to see, and what did you see instead?""
  
  friendly: ""Sorry to hear that... I hope we can help you! But we need a bit more information. What did you expect to see, and what did you see instead?""


I think one thing that's being missed here is the sheer scale of Stack Overflow. Civility is always required when commenting, but big cities are less overtly friendly than small towns because there are certain realities about the scale of the population and amounts of time available. Would you rather write one baroque, florid ultra-friendly comment to a single user, or three civil-but-direct comments to three different users? Which choice best achieves the goals of Stack Exchange?

I can't recommend frequently adding a bunch of noisy, unnecessary, non-content ""friendly"" words to a comment, words that everyone on the Internet has to read through and parse before getting to the actual information in the comment. This isn't what Stack Exchange is about.*

Therefore, favor the short neutral comment response. Never be rude, but get to the point quickly and efficiently so we can help as many people as possible get answers to their questions. That's what we are here to do.

* Now, if we could pare it down to one additional word instead of the seventeen in the above example, perhaps that'd work.
",Jeff Atwood,https://meta.stackexchange.com/users/1,http://meta.stackexchange.com/questions/138173/etiquette-for-posting-civil-and-informative-comments,TECHNOLOGY,meta.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,1.0,Etiquette for making civilized and informative comments,"Sometimes I leave a comment like, ""stack overflow is not your personal research assistant,"" but it will be accused of being rude. How can I write a comment that is considered polite to the community and instructive to the op?","The other two answers are quite good, so this is more of a clarification than a complete answer.

Considering the example:


  Question: ""I'm trying to xxx and it's not working.""
  
  unfriendly: ""Look, we're not mind readers here. What do you mean it's not working?""
  
  neutral: ""What did you expect to see, and what did you see instead?""
  
  friendly: ""Sorry to hear that... I hope we can help you! But we need a bit more information. What did you expect to see, and what did you see instead?""


I think one thing that's being missed here is the sheer scale of Stack Overflow. Civility is always required when commenting, but big cities are less overtly friendly than small towns because there are certain realities about the scale of the population and amounts of time available. Would you rather write one baroque, florid ultra-friendly comment to a single user, or three civil-but-direct comments to three different users? Which choice best achieves the goals of Stack Exchange?

I can't recommend frequently adding a bunch of noisy, unnecessary, non-content ""friendly"" words to a comment, words that everyone on the Internet has to read through and parse before getting to the actual information in the comment. This isn't what Stack Exchange is about.*

Therefore, favor the short neutral comment response. Never be rude, but get to the point quickly and efficiently so we can help as many people as possible get answers to their questions. That's what we are here to do.

* Now, if we could pare it down to one additional word instead of the seventeen in the above example, perhaps that'd work.
"
1945,1945,3100,Could fish in plastic bags filled with water float like that?,"I saw this gif earlier and it bothered me how the plastic water bags with fish in it are not submerged in water like they would if we don't do anything special with the water inside and outside the bag:



Then I read the comments on the corresponding Imgur page (I'm not affiliated with the post), asked my friends and figured that this could actually happen in some unusual conditions. I'm not very knowledgeable in physics, but from what I know, the sea water would have to be extremely salty so as to push out the plastic bags. Also the bags themselves must be very tight, so that the plastic material which they are made of contracts to form a spherical shape. Fish may not feel very well, as it might mean increased pressure inside the bag.

The spherical shape of the bags could probably be achieved with just high external pressure, but I'm not sure what could make the bags take a form of a drop. Perhaps if that little bit of air we see was actually so much lighter than the air outside the bags, that it would stretch up the whole bag and even raise its contents above water like that.

Are my guesses correct? What other effects could cause the illustrated state of things?
",user1306322,https://physics.stackexchange.com/users/14198,"It looks like a bit of artistic licence was taken (gosh :-) ).  You are correct that, the bags would not float that high up -- at least if I'm correctly viewing them as having only a tiny air pocket at the top.  

The physics is simple: take the total mass of the bag+fish+bagwater, and calculate the equivalent volume of seawater for the same mass.  That's how much volume the bag must displace, so if the bag 'assembly' has low enough density, the remainder of the bag's volume will be above the seawater surface.  It's identical to the way icebergs float.  

As a pal of mine says in situations like this,  ""because movie science magic"" .
",Carl Witthoft,https://physics.stackexchange.com/users/29202,http://physics.stackexchange.com/questions/148532/could-fish-in-plastic-bags-filled-with-water-float-like-that,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Can fish in plastic bags filled with water float like that?,"I saw this gif earlier and it bothered me how the plastic water bags with fish in it are not submerged in water like they would if we don't do anything special with the water inside and outside the bag:



Then I read the comments on the corresponding Imgur page (I'm not affiliated with the post), asked my friends and figured that this could actually happen in some unusual conditions. I'm not very knowledgeable in physics, but from what I know, the sea water would have to be extremely salty so as to push out the plastic bags. Also the bags themselves must be very tight, so that the plastic material which they are made of contracts to form a spherical shape. Fish may not feel very well, as it might mean increased pressure inside the bag.

The spherical shape of the bags could probably be achieved with just high external pressure, but I'm not sure what could make the bags take a form of a drop. Perhaps if that little bit of air we see was actually so much lighter than the air outside the bags, that it would stretch up the whole bag and even raise its contents above water like that.

Are my guesses correct? What other effects could cause the illustrated state of things?
","It looks like a bit of artistic licence was taken (gosh :-) ).  You are correct that, the bags would not float that high up -- at least if I'm correctly viewing them as having only a tiny air pocket at the top.  

The physics is simple: take the total mass of the bag+fish+bagwater, and calculate the equivalent volume of seawater for the same mass.  That's how much volume the bag must displace, so if the bag 'assembly' has low enough density, the remainder of the bag's volume will be above the seawater surface.  It's identical to the way icebergs float.  

As a pal of mine says in situations like this,  ""because movie science magic"" .
"
3500,3500,5581,iOS: Change Device Volume,"Is there a way to change the volume of the device? I've seen several apps do it. 

I have a desktop version of the iOS app and the device will be able to be controlled to some extent over the network. One of the things I want to allow the user to do is change the device volume and then play a sound. This can help if you loose your iPhone in a crack in your couch again, but can't find it. 

Is there any way that you can do this without Apple getting angry?
",Tristan Seifert,https://stackoverflow.com/users/219515,"Using iPodMusicPlayer would affect the actual iPod volume setting as well. If you want to avoid that, use this:

#import &lt;MediaPlayer/MediaPlayer.h&gt;
// ...
MPMusicPlayerController *musicPlayer = [MPMusicPlayerController applicationMusicPlayer];
musicPlayer.volume = 1.0f; 


As the user holex correctly mentioned the property volume in MPMusicPlayerController is deprecated in iOS 7.
",ceriseche,https://stackoverflow.com/users/1304971,http://stackoverflow.com/questions/4859402/ios-change-device-volume,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,IOS: changing device volumes,"Is there a way to change the volume of the device? I've seen several apps do it. 

I have a desktop version of the iOS app and the device will be able to be controlled to some extent over the network. One of the things I want to allow the user to do is change the device volume and then play a sound. This can help if you loose your iPhone in a crack in your couch again, but can't find it. 

Is there any way that you can do this without Apple getting angry?
","Using iPodMusicPlayer would affect the actual iPod volume setting as well. If you want to avoid that, use this:

#import &lt;MediaPlayer/MediaPlayer.h&gt;
// ...
MPMusicPlayerController *musicPlayer = [MPMusicPlayerController applicationMusicPlayer];
musicPlayer.volume = 1.0f; 


As the user holex correctly mentioned the property volume in MPMusicPlayerController is deprecated in iOS 7.
"
4960,4960,7898,Adding Data to Multiple Tables Using Single Query,"I want to add data to multiple tables using a single INSERT INTO query, can I do this?

Please guide me and provide me syntax if this is possible.
",butt,https://dba.stackexchange.com/users/41629,"As Thomas points out, if your goal is to ensure that the operation is atomic (both inserts either work or fail in unison) then what you are looking for is transactions like so:

BEGIN TRANSACTION
INSERT INTO &lt;table1&gt; ...
INSERT INTO &lt;table1&gt; ...
COMMIT TRANSACTION


The official documentation for this is at http://msdn.microsoft.com/en-us/library/ms174377.aspx but you would be better off finding a good book/tutorial if you are a beginner as that documentation is more geared towards reference and knowledge expansion use rather and initial learning. For extra complications see ""XACT_ABORT"" (http://msdn.microsoft.com/en-gb/library/ms188792.aspx) &amp; other transaction behaviour controlling options, and look into TRY/CATCH (added in SQL2005) for more flexible exception handling.

You can insert/update multiple tables at once while looking like you are updating a simple single object by using views with INSTEAD OF triggers (http://msdn.microsoft.com/en-us/library/ms175521.aspx) - essentially you define a view that merges the data from the tables as needed and create a trigger that handles the complications of insert and update operations (translating actions upon the view into actions upon the base tables (and potentially others)).

If you consider the individual stores in a partitioned tables to be separate entities then this can fit the description of a single operation on (what looks like) a single object affecting many tables at once.

This is of course fairly generic information: for something more specific you'll need to describe much more precisely in your question what you are trying to achieve (and why, which may be relevant for suggesting alternatives). As it stands your question may be closed for being too vague.
",David Spillett,https://dba.stackexchange.com/users/61,http://dba.stackexchange.com/questions/69006/adding-data-to-multiple-tables-using-single-query,TECHNOLOGY,dba.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,Adding data to multiple tables using a single query,I want to use an insert into query to add data to multiple tables. Can I do this?,"As Thomas points out, if your goal is to ensure that the operation is atomic (both inserts either work or fail in unison) then what you are looking for is transactions like so:

BEGIN TRANSACTION
INSERT INTO &lt;table1&gt; ...
INSERT INTO &lt;table1&gt; ...
COMMIT TRANSACTION


The official documentation for this is at http://msdn.microsoft.com/en-us/library/ms174377.aspx but you would be better off finding a good book/tutorial if you are a beginner as that documentation is more geared towards reference and knowledge expansion use rather and initial learning. For extra complications see ""XACT_ABORT"" (http://msdn.microsoft.com/en-gb/library/ms188792.aspx) &amp; other transaction behaviour controlling options, and look into TRY/CATCH (added in SQL2005) for more flexible exception handling.

You can insert/update multiple tables at once while looking like you are updating a simple single object by using views with INSTEAD OF triggers (http://msdn.microsoft.com/en-us/library/ms175521.aspx) - essentially you define a view that merges the data from the tables as needed and create a trigger that handles the complications of insert and update operations (translating actions upon the view into actions upon the base tables (and potentially others)).

If you consider the individual stores in a partitioned tables to be separate entities then this can fit the description of a single operation on (what looks like) a single object affecting many tables at once.

This is of course fairly generic information: for something more specific you'll need to describe much more precisely in your question what you are trying to achieve (and why, which may be relevant for suggesting alternatives). As it stands your question may be closed for being too vague.
"
823,823,1306,Different tyre width (front and back),"Out of necessity, I had to put an 1.26"" (32mm) rear tyre on my bike where the front tyre is only 1.1"" (28mm) wide (and the bike came with 1.1"" tyres when I bought it). Are there any advantages or disadvantages of this, shall I try to get an 1.1"" tyre for the rear wheel ASAP or is it safe this way?
",TamÃ¡s,https://bicycles.stackexchange.com/users/482,"Riding with a larger tire in the front provides certain advantages. I do this for two reasons:


Less slipping and sliding in the snow: With a bigger tire in the front you get more friction with the ground. This is important because your front tire is a lot more likley to flip you over then your rear because your rear tire has more weight on it.
Vertical cracks: The reason I keep a larger tire on now that it is warmer is to avoid falling due to vertical cracks and my tire getting stuck in them. Basically if your tire can't fit in the crack you can't get stuck in it and flip over.

",Chris Belsole,https://bicycles.stackexchange.com/users/1473,http://bicycles.stackexchange.com/questions/3727/different-tyre-width-front-and-back,CULTURE,bicycles.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,Different tire width (front and rear),"Because of necessity, I had to install a 1.26-inch (32mm) rear tire on my bike. The front tire was only 1.1-inch (28mm) wide (and when I bought my bike, it came with a 1.1-inch tire). Do you have any advantages or disadvantages? Should I replace the rear wheel with a 1.1-inch tire as soon as possible or is it safe?","Riding with a larger tire in the front provides certain advantages. I do this for two reasons:


Less slipping and sliding in the snow: With a bigger tire in the front you get more friction with the ground. This is important because your front tire is a lot more likley to flip you over then your rear because your rear tire has more weight on it.
Vertical cracks: The reason I keep a larger tire on now that it is warmer is to avoid falling due to vertical cracks and my tire getting stuck in them. Basically if your tire can't fit in the crack you can't get stuck in it and flip over.

"
2612,2612,4155,Add authors as footnote in lncs,"please, I was asked to modify the .tex file of a manuscript. The problem is that I want to add ""supervised by ..."" as a footnote and when use \footnote{supervised by ...} in \author{} it does not work. I use a Latex lncs format. Thank you!
",Sofiane,https://tex.stackexchange.com/users/46464,"You might want to \protect the \footnote command. This one worked for me:

\documentclass{llncs}

\begin{document}

\title{LaTeX Template for Your LNCS Paper}

\author{Author 1\protect\footnote{Supervised by Author 9}, Author 2}

\institute{Lab, University, Address}
\maketitle

\begin{abstract}
Abstract is here.
\end{abstract}

\section{Introduction}\label{sec:Introduction}

The rest goes here.

\end{document}

",AndreÃ¯ Kostyrka,https://tex.stackexchange.com/users/19642,http://tex.stackexchange.com/questions/161232/add-authors-as-footnote-in-lncs,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Add author as footnote in LNCS,"Please, I was asked to revise a manuscript's. Tex file. The problem is, I want to add ""supervisor..."" As a footnote, when using \ footnote {supervised by }It doesn't work. I use the latex LNCS format. Thank you very much!","You might want to \protect the \footnote command. This one worked for me:

\documentclass{llncs}

\begin{document}

\title{LaTeX Template for Your LNCS Paper}

\author{Author 1\protect\footnote{Supervised by Author 9}, Author 2}

\institute{Lab, University, Address}
\maketitle

\begin{abstract}
Abstract is here.
\end{abstract}

\section{Introduction}\label{sec:Introduction}

The rest goes here.

\end{document}

"
4054,4054,6471,Tools to run a background process command line in windows?,"In linux we just need to append a &amp; and that's all.

What for windows?
",vps,https://serverfault.com/users/31877,"There is no equivalent. You could install cygwin and do the same thing. Or you could make a service that runs your application : srvany or other tools will do this for you. Keep in mind that not all Windows applications will properly run in these ways.
",mfinni,https://serverfault.com/users/29373,http://serverfault.com/questions/121979,TECHNOLOGY,serverfault.com,1.0,1.0,1.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,0.0,1.0,A tool for running the background process command line in windows?,"In Linux, we only need to attach one & amp.","There is no equivalent. You could install cygwin and do the same thing. Or you could make a service that runs your application : srvany or other tools will do this for you. Keep in mind that not all Windows applications will properly run in these ways.
"
5484,5484,8704,Who counters Jayce top lane besides Yorick?,"I'm aware that Yorick and Cho'Gath are both good counters for Jayce (in Top Lane) but who else might be a good matchup and why?
",Eddie,https://gaming.stackexchange.com/users/29370,"Jayce is an early game menace. He can be ranged which gives him sustain in his own way. Because he is able to push you away and zone you it makes it difficult to harrass him. But he can harrass you all he pleases. And gap closers at early levels tend to have highcooldowns making it so you give Jayce a window of opportunity when you initiate with it. I play Jayce almost every game and within the laning phase I usually go 4-1.  When it come to champs that counter him its difficult tp find one since Jayce can keep his distance or be up close if he so chooses.
",user48012,https://gaming.stackexchange.com/users/48012,http://gaming.stackexchange.com/questions/77029/who-counters-jayce-top-lane-besides-yorick,CULTURE,gaming.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.0,0.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.7777777777777778,0.6,0.0,0.6666666666666666,0.3333333333333333,0.7777777777777778,"Who's dealing with Jess in the top floor lane, except York?","I know that both joric and jogat are good rivals for Joyce, but who else are good rivals and why?","Jess is an early game threat. He can maintain distance in his own way. Because he can push you away and surround you, it's hard to make him feel bad. But he can torture you at will. And early stage gap reducers tend to have a high cooldown, so when you start using it, you give jayce a window of opportunity. I play against Jess in almost every game and I usually lead 4-1 in the Lanin phase. It's hard to find one when the champion is against him, because Jess can keep a distance, if he wants, he can keep a close distance."
3768,3768,6000,"Origin and meaning of ""The eagle flies at midnight""","
  The eagle flies at midnight.


What's the origin and meaning of this idiom?
",Anderson Silva,https://english.stackexchange.com/users/1446,"This is something my father would say when it was pay day just then the eagle flies or the eagle has flown or will fly on a date. He was born in 1903
",user100472,https://english.stackexchange.com/users/100472,http://english.stackexchange.com/questions/5305/origin-and-meaning-of-the-eagle-flies-at-midnight,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.4666666666666667,0.0,0.0,0.0,0.6666666666666666,"The origin and significance of ""flying Nighthawk""","
  The eagle flies at midnight.


What's the origin and meaning of this idiom?
","This is something my father would say when it was pay day just then the eagle flies or the eagle has flown or will fly on a date. He was born in 1903
"
2426,2426,3867,Question about thermodynamic conjugate quantities,"I've come across the Onsager reciprocal principle. It's almost clear, except for thermodynamic conjugate quantities - what's that, physical meaning (except the formal definitions: $X_i = -\frac{1}{k}\frac{\partial S}{\partial x_i}$, which isn't clear) and why:

\begin{equation}
  \langle X_i\cdot x_k\rangle = \delta_{ik}
\end{equation}

The Wikipedia is lack for references in this article.
",m0nhawk,https://physics.stackexchange.com/users/6735,"The fundamental quantity in thermodynamics is entropy, which is a function of $n$-variables $S=S(x_1, x_2,...,x_n)$. For instance, for a simple mono-component system $S=S(U,V,N)$ where $U$ is internal energy, $V$ is volume, and $N$ composition.

Taking the differential

$$\mathrm{d}S = \sum_i \left( \frac{\partial S}{\partial x_i}\right)_{j \neq i} \mathrm{d}x_i = \sum_i F_i \mathrm{d}x_i$$

The quantities $F_i \equiv ({\partial S}/{\partial x_i})_{j \neq i} $ are intensive entropic parameters and measure the change in entropy when variables change. For instance the intensive entropic parameter $(1/T)$ gives the change on entropy due to a change in the energy $U$.

Using the thermodynamic theory of fluctuations it can be shown that

$$F_i = k \left( \frac{\partial \ln P}{\partial x_i}\right)$$

where $P$ is the probability of a fluctuation in the variables near an equilibrium state.

Using the definition of average

$$\langle A \rangle = \int A P \mathrm{d}x_1  \mathrm{d}x_2 \cdots \mathrm{d}x_n$$

the demonstration of the central result of linear nonequilibrium thermodynamics

$$\langle F_i \cdot x_j \rangle = -k \delta_{ij} $$

is direct although it needs first the use of $(\partial \ln P / \partial x_i)P = \partial P / \partial x_i$ in the integrand and next integration by parts.

What Wikipedia makes is to rewrite this central result using the new quantities $X_i \equiv - F_i / k$ but the physically important quantities are the $F_i$ often also called in this context thermodynamic forces or affinities.
",juanrga,https://physics.stackexchange.com/users/12998,http://physics.stackexchange.com/questions/41961/question-about-thermodynamic-conjugate-quantities,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,On the conjugate quantity of thermodynamics,"I met the Onsager principle of reciprocity. It's almost clear, except for the thermodynamic conjugation - what that is, the physical meaning (except for the formal definition: $X AI I = - \ frac {1} {K} \ frac {\ partial s} {\ partial x AI I} $, which is not clear) and why:","The fundamental quantity in thermodynamics is entropy, which is a function of $n$-variables $S=S(x_1, x_2,...,x_n)$. For instance, for a simple mono-component system $S=S(U,V,N)$ where $U$ is internal energy, $V$ is volume, and $N$ composition.

Taking the differential

$$\mathrm{d}S = \sum_i \left( \frac{\partial S}{\partial x_i}\right)_{j \neq i} \mathrm{d}x_i = \sum_i F_i \mathrm{d}x_i$$

The quantities $F_i \equiv ({\partial S}/{\partial x_i})_{j \neq i} $ are intensive entropic parameters and measure the change in entropy when variables change. For instance the intensive entropic parameter $(1/T)$ gives the change on entropy due to a change in the energy $U$.

Using the thermodynamic theory of fluctuations it can be shown that

$$F_i = k \left( \frac{\partial \ln P}{\partial x_i}\right)$$

where $P$ is the probability of a fluctuation in the variables near an equilibrium state.

Using the definition of average

$$\langle A \rangle = \int A P \mathrm{d}x_1  \mathrm{d}x_2 \cdots \mathrm{d}x_n$$

the demonstration of the central result of linear nonequilibrium thermodynamics

$$\langle F_i \cdot x_j \rangle = -k \delta_{ij} $$

is direct although it needs first the use of $(\partial \ln P / \partial x_i)P = \partial P / \partial x_i$ in the integrand and next integration by parts.

What Wikipedia makes is to rewrite this central result using the new quantities $X_i \equiv - F_i / k$ but the physically important quantities are the $F_i$ often also called in this context thermodynamic forces or affinities.
"
2430,2430,3875,How can I upload video on Youtube and pause or resume it?,"I need a software, an Youtube Uploader for Ubuntu. I need to pause and resume the uploading when I want. Sorry for my English but I'm italian!
",Mistero5050-ArmeF,https://askubuntu.com/users/77105,"Unfortunately, no, you can't pause your upload. If the server is not receiving data within a specific time then the upload will be aborted.  

However, I've been using YouTube for a long time, and there's no third party program that can pause and resume uploading videos, you may want to convert your videos to a smaller file size.

To convert videos you can use Transmageddon.  You can install it fro USC.



Also take a look at HandBrake.
",Mitch,https://askubuntu.com/users/59676,http://askubuntu.com/questions/163739/how-can-i-upload-video-on-youtube-and-pause-or-resume-it,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,How do I upload videos on youtube and pause or continue?,"I need a software, a YouTube upload for Ubuntu. I need to pause and continue uploading when I need to. Sorry for my English, but I am Italian!","Unfortunately, no, you can't pause your upload. If the server is not receiving data within a specific time then the upload will be aborted.  

However, I've been using YouTube for a long time, and there's no third party program that can pause and resume uploading videos, you may want to convert your videos to a smaller file size.

To convert videos you can use Transmageddon.  You can install it fro USC.



Also take a look at HandBrake.
"
4211,4211,6713,Counter-warding: how to know where wards are?,"Pro players seem to have some sixth sense when counter-warding, but I always seem to fail. For observer wards, you can try the usual ward spots (runes/rosh/hills).... however, if your five-man push fails because the enemy saw you coming, there are a lot of possible ward spots you may have walked by. And how about countering sentry wards to protect a riki/gondar/brood?
",Robert Fraser,https://gaming.stackexchange.com/users/3074,"It is pretty complex answering here without posting a tons of images. So I copy only the summary picture and suggest you to read this well written guide: Wardposition Guide on PlayDota. It contains a lot of in-game screenshots that explain in detail the positioning.


Red Pins: Wards with runesight
Orange Pins: Wards to block creep camps
Pink Pins: Wards to monitor important places
Blue Pins: Wards with basesight



",Drake,https://gaming.stackexchange.com/users/730,http://gaming.stackexchange.com/questions/47787/counter-warding-how-to-know-where-wards-are,CULTURE,gaming.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.8333333333333334,1.0,0.9,1.0,0.0,0.0,1.0,How to know where the ward is?,"The pros seem to have a sixth sense on the counter attack, but I always seem to fail. For the observer ward, you can try the usual ward point (Rune / Rose / Hill).... However, if your 5-man push fails because the enemy sees you coming, there are many possible ward locations that you may have passed. So, how to protect a Ricky / gonda / cub against the sentry?","The answer here is rather complicated, not releasing a lot of pictures. So I just copied this summary picture and suggested that you read this well written guide: wardposition guide on playdota. It contains many screenshots of the game, explaining the location in detail."
3480,3480,5552,Can I use debdelta to install/update single package?,"debdelta-upgrade can be used to upgrade whole system, while saving time and bandwidth.The debdelta-upgrade man page says,

debdelta-upgrade  -  Downloads  all deltas that may be used to 'apt-get
upgrade', and apply them.


But can I use debdelta or debdelta-upgrade to install/update single package?
",Registered User,https://askubuntu.com/users/184942,"debdelta works by downloading incremental changes between packages and patching the installed data. In theory you could:


Install the original version of a package (using apt-cache policy and the apt-get install package==version syntax)
Upgrade with debdelta


But that's a silly idea. The sum filesize of the original archive plus all the incremental updates will be far in excess of an updated package. Plus the CPU time required to install it is much higher.

If you have a locally centralised copy of packages (like an out-of-date mirror), I can start to appreciate why you might want to do this but again, if there's more than one client computer involved, updating that mirror seems like a better solution.



Purely from a syntax point of view, this is from man debdelta-upgrade:

debdelta-upgrade [OPTION]... [PACKAGE] ...


You can specify one or many packages if you want to limit the upgrade.
",Oli,https://askubuntu.com/users/449,http://askubuntu.com/questions/437376/can-i-use-debdelta-to-install-update-single-package,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,1.0,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Can I use debdelta to install / update individual packages?,"debdelta-upgrade can be used to upgrade whole system, while saving time and bandwidth.The debdelta-upgrade man page says,

debdelta-upgrade  -  Downloads  all deltas that may be used to 'apt-get
upgrade', and apply them.


But can I use debdelta or debdelta-upgrade to install/update single package?
","debdelta works by downloading incremental changes between packages and patching the installed data. In theory you could:


Install the original version of a package (using apt-cache policy and the apt-get install package==version syntax)
Upgrade with debdelta


But that's a silly idea. The sum filesize of the original archive plus all the incremental updates will be far in excess of an updated package. Plus the CPU time required to install it is much higher.

If you have a locally centralised copy of packages (like an out-of-date mirror), I can start to appreciate why you might want to do this but again, if there's more than one client computer involved, updating that mirror seems like a better solution.



Purely from a syntax point of view, this is from man debdelta-upgrade:

debdelta-upgrade [OPTION]... [PACKAGE] ...


You can specify one or many packages if you want to limit the upgrade.
"
4159,4159,6630,"What does ""to become controversial"" mean?","As a non-native speaker, I do not fully understand the meaning of the term ""to become controversial"" in the following text, which I have to translate into German:


  Where translators have made their presence felt they have become controversial, with those who characteristically intervene, seeking to domesticate texts, contrasted with those who foreignise, supposedly allowing other languages to alter our own.

",Patrick Oscity,https://english.stackexchange.com/users/12804,"What this is trying to say is ""when a translator makes their presence felt, that act generates controversy"". That is, a translator who makes their own changes to the text that might not be justified by the original, causes people to become upset about those changes. 
",Mr. Shiny and New å®å®,https://english.stackexchange.com/users/380,http://english.stackexchange.com/questions/50804/what-does-to-become-controversial-mean,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,"What does ""becoming controversial"" mean?","As a non-native speaker, I do not fully understand the meaning of the term ""to become controversial"" in the following text, which I have to translate into German:


  Where translators have made their presence felt they have become controversial, with those who characteristically intervene, seeking to domesticate texts, contrasted with those who foreignise, supposedly allowing other languages to alter our own.

","When a translator senses their existence, this behavior will be controversial. In other words, if a translator makes changes to the original that may not conform to the original, it will cause people to be uneasy about these changes."
1057,1057,1662,Problems Binding MouseDoubleClick via M-V-MV Design Pattern,"I have the following snippet of code in an .xaml file:

&lt;TreeView MouseDoubleClick=""TreeView_MouseDoubleClick"" ItemsSource=""{Binding MyList}""&gt;
  &lt;TreeView.ItemContainerStyle&gt;
    &lt;Style TargetType=""{x:Type TreeViewItem}""&gt;
      &lt;Setter Property=""IsExpanded"" Value=""{Binding IsExpanded, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""IsSelected"" Value=""{Binding IsSelected, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""FontWeight"" Value=""Normal"" /&gt;
      &lt;Style.Triggers&gt;
        &lt;Trigger Property=""IsSelected"" Value=""True""&gt;
          &lt;Setter Property=""FontWeight"" Value=""Bold"" /&gt;
        &lt;/Trigger&gt;
      &lt;/Style.Triggers&gt;
    &lt;/Style&gt;
  &lt;/TreeView.ItemContainerStyle&gt;


As you can see, when you ""MouseDoubleClick"" on an item in the TreeView it will execute the code in the code behind...namely...

private void TreeView_MouseDoubleClick(object sender, System.Windows.Input.MouseButtonEventArgs e)
{
    try
    {
        MessageBox.Show(((TreeViewWithViewModelDemo.LoadOnDemand.HtmlFileViewModel)(((System.Windows.Controls.TreeView)(sender)).SelectedValue)).HtmlFileName);
    }
    catch
    {
    }
}


I'm trying to follow the Model-View-ViewModel Design Pattern and would like to move the implementation of this MouseDoubleClick event away from the View and into the ViewModel.

I understand that if I was using a command I would use {Binding Command=""Select""} (or something similar that implements the ICommand interface) but I cannot seem to find the syntax for this particular issue since it is not a command button.

Can someone help me out?

Thanks
",Ann Sanderson,https://stackoverflow.com/users/1161283,"Using MVVM doesn't mean there mustn't be any code in the code-behind file. It just means moving all the associated logic into the viewmodel. You could just implement necessary double-click method on the viewmodel, and call it from the code behind like this:

_viewModel.MouseDoubleClickOnTree();


Also, I'd recommend looking at this topic: MVVM C# WPF binding mouse double click
",Dmitry Reznik,https://stackoverflow.com/users/838302,http://stackoverflow.com/questions/9811538/problems-binding-mousedoubleclick-via-m-v-mv-design-pattern,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,1.0,0.0,1.0,Binding mousedoubleclick with m-v-mv design pattern,"I have the following snippet of code in an .xaml file:

&lt;TreeView MouseDoubleClick=""TreeView_MouseDoubleClick"" ItemsSource=""{Binding MyList}""&gt;
  &lt;TreeView.ItemContainerStyle&gt;
    &lt;Style TargetType=""{x:Type TreeViewItem}""&gt;
      &lt;Setter Property=""IsExpanded"" Value=""{Binding IsExpanded, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""IsSelected"" Value=""{Binding IsSelected, Mode=TwoWay}"" /&gt;
      &lt;Setter Property=""FontWeight"" Value=""Normal"" /&gt;
      &lt;Style.Triggers&gt;
        &lt;Trigger Property=""IsSelected"" Value=""True""&gt;
          &lt;Setter Property=""FontWeight"" Value=""Bold"" /&gt;
        &lt;/Trigger&gt;
      &lt;/Style.Triggers&gt;
    &lt;/Style&gt;
  &lt;/TreeView.ItemContainerStyle&gt;


As you can see, when you ""MouseDoubleClick"" on an item in the TreeView it will execute the code in the code behind...namely...

private void TreeView_MouseDoubleClick(object sender, System.Windows.Input.MouseButtonEventArgs e)
{
    try
    {
        MessageBox.Show(((TreeViewWithViewModelDemo.LoadOnDemand.HtmlFileViewModel)(((System.Windows.Controls.TreeView)(sender)).SelectedValue)).HtmlFileName);
    }
    catch
    {
    }
}


I'm trying to follow the Model-View-ViewModel Design Pattern and would like to move the implementation of this MouseDoubleClick event away from the View and into the ViewModel.

I understand that if I was using a command I would use {Binding Command=""Select""} (or something similar that implements the ICommand interface) but I cannot seem to find the syntax for this particular issue since it is not a command button.

Can someone help me out?

Thanks
","Using MVVM doesn't mean there mustn't be any code in the code-behind file. It just means moving all the associated logic into the viewmodel. You could just implement necessary double-click method on the viewmodel, and call it from the code behind like this:

_viewModel.MouseDoubleClickOnTree();


Also, I'd recommend looking at this topic: MVVM C# WPF binding mouse double click
"
4372,4372,6954,A deferred capital gains tax similar to the real estate 1031 Exchange but for securities reinvestment?,"I am looking for a way to transfer a stock that has done well into a safer investment (like an index fund). I assume the only way I can do this is sell the stock, pay the tax owing, and buy new stock.

I do remember reading something about you can transfer the ownership of the stock (e.g. into a Children's Trust) but not sure if that is realistic.

I know the 1031 Exchange is a real estate tax benefit to encourage reinvestment in property and I just wondered if there is anything similar for securities. 
",Mr. Tony Jessup,https://money.stackexchange.com/users/22148,"Sale of a stock creates a capital gain. It can be offset with losses, up to $3000 more than the gains. It can be deferred when held within a retirement account. 
When you gift appreciated stock, the basis follows. So when I gifted my daughter's trust shares, there was still tax due upon sale. The kiddy tax helped reduce but not eliminate it. And there was no quotes around ownership. The money is gone, her account is for college. 

No 1031 exchange exists for stock. 
",JoeTaxpayer,https://money.stackexchange.com/users/187,http://money.stackexchange.com/questions/39137/a-deferred-capital-gains-tax-similar-to-the-real-estate-1031-exchange-but-for-se,LIFE_ARTS,money.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.6666666666666667,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,"Deferred capital gains tax similar to real estate 1031 exchange, but securities reinvestment?","I am looking for a way to transfer a stock that has done well into a safer investment (like an index fund). I assume the only way I can do this is sell the stock, pay the tax owing, and buy new stock.

I do remember reading something about you can transfer the ownership of the stock (e.g. into a Children's Trust) but not sure if that is realistic.

I know the 1031 Exchange is a real estate tax benefit to encourage reinvestment in property and I just wondered if there is anything similar for securities. 
","Sale of a stock creates a capital gain. It can be offset with losses, up to $3000 more than the gains. It can be deferred when held within a retirement account. 
When you gift appreciated stock, the basis follows. So when I gifted my daughter's trust shares, there was still tax due upon sale. The kiddy tax helped reduce but not eliminate it. And there was no quotes around ownership. The money is gone, her account is for college. 

No 1031 exchange exists for stock. 
"
365,365,575,How valuable is studying cognitive psychology for UX?,"I am starting my second year in grad school and thinking about what to study. One thing that I know is good to have a grasp of is cognitive psychology. But I would like to get someones perspective.

Have you studied cognitive psychology? Either 1 class or more... and what did that give you?
",JeroenEijkhof,https://ux.stackexchange.com/users/793,"Designers/Architects can benefit by learning more about how people process, learn, remember information and understanding internal mental states.
Because Cognitive Psychology is all about internal mental states and process, where the user get bored, perception etc.
One simple answer to the question of ""How valuable is studying cognitive psychology for UX,HCI?"" is that there is already
agreement about the importance of both topics to
computer science education in general.  For example,
the report of the ACM/IEEE-CS Joint Curriculum Task
Force [2] clearly identifies human-computer
communication as one of the nine core areas of
computer science.  In this core topic the report authors
include both computer graphics and human-computer
interaction as related topics.  Furthermore, the authors
of the report point out that cognitive psychology is an
important supporting discipline for three of the nine
core areas of computer science, including artificial
intelligence and human-computer communication.

Human-Computer Interaction and Cognitive Psychology in Visualization
Education.
",Abdul Wakeel,https://ux.stackexchange.com/users/5942,http://ux.stackexchange.com/questions/5534/how-valuable-is-studying-cognitive-psychology-for-ux,TECHNOLOGY,ux.stackexchange.com,0.6666666666666666,0.8888888888888888,1.0,0.0,0.0,0.0,0.6666666666666666,0.5555555555555556,1.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.5333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,How valuable is cognitive psychology to user experience?,"In my second year of graduate school, I was thinking about what to learn. One thing I know is that I have a good grasp of cognitive psychology. But I want to know some people's views.","Designers/Architects can benefit by learning more about how people process, learn, remember information and understanding internal mental states.
Because Cognitive Psychology is all about internal mental states and process, where the user get bored, perception etc.
One simple answer to the question of ""How valuable is studying cognitive psychology for UX,HCI?"" is that there is already
agreement about the importance of both topics to
computer science education in general.  For example,
the report of the ACM/IEEE-CS Joint Curriculum Task
Force [2] clearly identifies human-computer
communication as one of the nine core areas of
computer science.  In this core topic the report authors
include both computer graphics and human-computer
interaction as related topics.  Furthermore, the authors
of the report point out that cognitive psychology is an
important supporting discipline for three of the nine
core areas of computer science, including artificial
intelligence and human-computer communication.

Human-Computer Interaction and Cognitive Psychology in Visualization
Education.
"
956,956,1513,Setting up Exim to forward mail,"I'm trying to setup Exim on a fresh CentOS install so that it will receive mail for a collection of given addresses, and forward the mail respectively to another address. For example, receiving mail from me@example.com would be forwarded to me@gmail.com.

I figure this should be fairly straight forward... I had this working before with Sendmail, using the virtusertable - is there something similar I can do with Exim?

I'd also like to be able to send mail, but only for mail being sent from the local machine (i.e., from applications running on the server) - I don't need/want a publicly available SMTP server.

Are there any other settings I should bear in mind to make sure the mail server is secure? (i.e., prevent relaying) I'm assuming that it will be secure out of the box.

Thanks.
",Joe Freeman,https://serverfault.com/users/3199,"You will need to use a redirect router.  Read the Exim Router specification, as it can do many things and thus can get quite complex.  

Basically, you will need to set something up like this (untested)



sender_redirect:
  driver = redirect
  data = ${lookup{$sender_address}lsearch{/etc/exim4/sender_redirects}}



Then create a file in /etc/exim4/sender_redirects that contains the redirects in a line-separated colon-delimited format, like this:


me@example.com: me@gmail.com

",Gavin McTaggart,https://serverfault.com/users/3174,http://serverfault.com/questions/10279,TECHNOLOGY,serverfault.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.3333333333333333,0.5555555555555556,0.7777777777777778,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.7777777777777778,Set exim to forward mail,"I'm trying to setup Exim on a fresh CentOS install so that it will receive mail for a collection of given addresses, and forward the mail respectively to another address. For example, receiving mail from me@example.com would be forwarded to me@gmail.com.

I figure this should be fairly straight forward... I had this working before with Sendmail, using the virtusertable - is there something similar I can do with Exim?

I'd also like to be able to send mail, but only for mail being sent from the local machine (i.e., from applications running on the server) - I don't need/want a publicly available SMTP server.

Are there any other settings I should bear in mind to make sure the mail server is secure? (i.e., prevent relaying) I'm assuming that it will be secure out of the box.

Thanks.
","You will need to use a redirect router.  Read the Exim Router specification, as it can do many things and thus can get quite complex.  

Basically, you will need to set something up like this (untested)



sender_redirect:
  driver = redirect
  data = ${lookup{$sender_address}lsearch{/etc/exim4/sender_redirects}}



Then create a file in /etc/exim4/sender_redirects that contains the redirects in a line-separated colon-delimited format, like this:


me@example.com: me@gmail.com

"
1334,1334,2103,Should a woman avoid singing in front of her husband while she is a niddah?,"Should a woman avoid singing in front of her husband while she is a niddah? Is it strictly prohibited or just inadvisable? (Obviously I am not talking about deliberately seductive songs.)
",SAH,https://judaism.stackexchange.com/users/1516,"Per Rabbi Shimon Eider's Sefer Hilchos Nidah one should ""refrain from listening to his wife's singing when she is a Niddah.""
",Gershon Gold,https://judaism.stackexchange.com/users/200,http://judaism.stackexchange.com/questions/14716/should-a-woman-avoid-singing-in-front-of-her-husband-while-she-is-a-niddah,CULTURE,judaism.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.7,0.0,0.0,0.6666666666666666,0.8888888888888888,Should a woman avoid singing in front of her husband?,"Should a woman avoid singing in front of her husband? Is this strictly prohibited or not desirable? (obviously, I'm not talking about songs that deliberately tempt people.)","Per Rabbi Shimon Eider's Sefer Hilchos Nidah one should ""refrain from listening to his wife's singing when she is a Niddah.""
"
56,56,83,Saving TinyMCE Base64 images with dragonfly,"I am using tinymce-rails-imageupload plugin with dragonfly.

When the image is uploaded via separate form in popup window, it behaves as expected (save image in datastore). 

But when the user drag-drop or paste image into TinyMCE, the imageupload plugin allows it. I tried to find a way to disable this behavior, but apparently there is no straightforward way to disable allowing image upload, while disallowing the past/drag-drop behavior. So I gave up on that..

Now, I'm trying to save BASE64 image in TinyMCE's content.

In controller:

def store_file
  @image = Resource.new :res_image =&gt; params[:file]
  @image.save
  render json: {
    image: {
      url: @image.res_image.remote_url
    }
  }, content_type: ""text/html""
end

def create
  @entry = Entry.new(params[:entry])

  # iterate through tinyMCE field params[:entry][:message]
    # if image tag is found
      # if value of src tag starts with ""data:""
        # then replace it with the output of
        # Resource.create_image_from_base64(extracted_base64_value)
      # end if
    # end if
  # end iteration

  begin
    @entry.save!
    flash[:success] = ""Entry was successfully created.""
    redirect_to entries_path
  rescue Mongoid::Errors::Validations =&gt; e
    render :action =&gt; ""new""
  end
end


In Resource model, I would have something like:

image_accessor :res_image

field :res_image_uid,      type: String
field :res_image_name,     type: String

def create_image_from_base64(base_64_encoded_data)
  file = File.open('temp.png', 'wb') do|f|
   f.write(Base64.decode64(base_64_encoded_data))
  end

  resource = # create Resource with temp file

  file.close

  resource.res_image.remote_url
end


Questions:


How to create ""Entry with file""?
Is there a better approach for handling pasted/dragged-droped base64 images in TinyMCE with dragonfly?

",Annie,https://stackoverflow.com/users/1712065,"Even if it is an old question:

look at this: https://groups.google.com/forum/#!topic/dragonfly-users/xNWIwZf5-_Y
",Florian Eck,https://stackoverflow.com/users/3320112,http://stackoverflow.com/questions/17549740/saving-tinymce-base64-images-with-dragonfly,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.3333333333333333,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.5,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8333333333333334,0.5,0.8333333333333334,0.8333333333333334,0.7,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,Save TinyMCE Base64 image with dragonfly,"I am using tinymce-rails-imageupload plugin with dragonfly.

When the image is uploaded via separate form in popup window, it behaves as expected (save image in datastore). 

But when the user drag-drop or paste image into TinyMCE, the imageupload plugin allows it. I tried to find a way to disable this behavior, but apparently there is no straightforward way to disable allowing image upload, while disallowing the past/drag-drop behavior. So I gave up on that..

Now, I'm trying to save BASE64 image in TinyMCE's content.

In controller:

def store_file
  @image = Resource.new :res_image =&gt; params[:file]
  @image.save
  render json: {
    image: {
      url: @image.res_image.remote_url
    }
  }, content_type: ""text/html""
end

def create
  @entry = Entry.new(params[:entry])

  # iterate through tinyMCE field params[:entry][:message]
    # if image tag is found
      # if value of src tag starts with ""data:""
        # then replace it with the output of
        # Resource.create_image_from_base64(extracted_base64_value)
      # end if
    # end if
  # end iteration

  begin
    @entry.save!
    flash[:success] = ""Entry was successfully created.""
    redirect_to entries_path
  rescue Mongoid::Errors::Validations =&gt; e
    render :action =&gt; ""new""
  end
end


In Resource model, I would have something like:

image_accessor :res_image

field :res_image_uid,      type: String
field :res_image_name,     type: String

def create_image_from_base64(base_64_encoded_data)
  file = File.open('temp.png', 'wb') do|f|
   f.write(Base64.decode64(base_64_encoded_data))
  end

  resource = # create Resource with temp file

  file.close

  resource.res_image.remote_url
end


Questions:


How to create ""Entry with file""?
Is there a better approach for handling pasted/dragged-droped base64 images in TinyMCE with dragonfly?

","Even if it is an old question:

look at this: https://groups.google.com/forum/#!topic/dragonfly-users/xNWIwZf5-_Y
"
3163,3163,5036,Is the intersection of two star-shaped sets star-shaped?,"Is the intersection of two star-shaped sets star-shaped?

I don't think so but can't think of an example.
",user24883,https://math.stackexchange.com/users/24883,"HINT: A star-shaped set is connected. A $+$ sign is star-shaped. Find a way to position two of them so that the intersection is a two-point set.
",Brian M. Scott,https://math.stackexchange.com/users/12042,http://math.stackexchange.com/questions/200152/is-the-intersection-of-two-star-shaped-sets-star-shaped,SCIENCE,math.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Is the intersection of two stars star shaped?,"Is the intersection of two star-shaped sets star-shaped?

I don't think so but can't think of an example.
","HINT: A star-shaped set is connected. A $+$ sign is star-shaped. Find a way to position two of them so that the intersection is a two-point set.
"
4230,4230,6746,Sketch3: how do you draw a fan shape?,"I'd like to have a circle divided into 4 fans, each of them is identical, if I draw the fan using edit tool, it is quite hard to get a perfect circle when four fans are combined.

Is there any trick to do this?

What I am trying to achieve is drawing a slice of a pie chart.

",CarmeloS,https://graphicdesign.stackexchange.com/users/30784,"Hereâs one way to do it:


Draw a circle and some rectangles.
Snap the rectangles to the center of the circle.
Drag out points as needed.
Select the circle.
Choose Use As Mask from the Layer menu.
The rectangles should now be masked by the circle.



",Marc Edwards,https://graphicdesign.stackexchange.com/users/3901,http://graphicdesign.stackexchange.com/questions/46297/sketch3-how-do-you-draw-a-fan-shape,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.0,1.0,Sketch 3: how do you draw a fan?,"I want to divide a circle into four fans. Each fan is the same. If I draw a fan with the editing tool, it's difficult to draw a perfect circle when the four fans are combined.","Hereâs one way to do it:


Draw a circle and some rectangles.
Snap the rectangles to the center of the circle.
Drag out points as needed.
Select the circle.
Choose Use As Mask from the Layer menu.
The rectangles should now be masked by the circle.



"
5648,5648,8956,How do you delete a fork on Bitbucket?,"I've forked a repo on Bitbucket, it was a mistake, I want to delete the fork.

Rather than go through the hassle of merging it back in (which would be misleading as I haven't made any changes, anyway) I'd just like to delete it. 

I can't see a front-end option in Bitbucket for this, but there must be one... right?

Thanks!
",Richard,https://stackoverflow.com/users/806539,"Considering that a BitBucket fork simply create a repo on the BitBucket side, the simplest way to delete said fork is... simply delete the BitBucket repository.

(Update May 2014)

See Deleting a Bitbucket Repository:


Log into your Bitbucket account.
Navigate to the repository you want to delete.
Click the repository's  settings icon.
Choose Delete Repository from the left-hand navigation.
The system displays the deletion dialog.
(Optional) Enter a URL in the Redirect to field.
Future users who try to access your repository are sent to this new URL.
Press Delete repository.


Example:


",VonC,https://stackoverflow.com/users/6309,http://stackoverflow.com/questions/6870144/how-do-you-delete-a-fork-on-bitbucket,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,How to delete the fork on bitbucket?,"I've forked a repo on Bitbucket, it was a mistake, I want to delete the fork.

Rather than go through the hassle of merging it back in (which would be misleading as I haven't made any changes, anyway) I'd just like to delete it. 

I can't see a front-end option in Bitbucket for this, but there must be one... right?

Thanks!
","Considering that a BitBucket fork simply create a repo on the BitBucket side, the simplest way to delete said fork is... simply delete the BitBucket repository.

(Update May 2014)

See Deleting a Bitbucket Repository:


Log into your Bitbucket account.
Navigate to the repository you want to delete.
Click the repository's  settings icon.
Choose Delete Repository from the left-hand navigation.
The system displays the deletion dialog.
(Optional) Enter a URL in the Redirect to field.
Future users who try to access your repository are sent to this new URL.
Press Delete repository.


Example:


"
3426,3426,5451,Is there any documentation about using Client ID / Token with REST API to access Group and Professional Editions?,"I have seen information about using Token with SOAP API, but REST API documentations doesn't say anything about it. Did anybody find useful hints on getting Token to work with Rest API?
",Mark Kofman,https://salesforce.stackexchange.com/users/55,"
  If you have  a partner app you should now be able to get your OAuth
  client whitelisted for api access, talk to your contact in the partner
  group.


Source: Does the REST API support Client ID?
",Daniel Ballinger,https://salesforce.stackexchange.com/users/102,http://salesforce.stackexchange.com/questions/6/is-there-any-documentation-about-using-client-id-token-with-rest-api-to-access,TECHNOLOGY,salesforce.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.5555555555555556,0.8888888888888888,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Is there documentation on using client ID / token and rest API to access groups and professional editions?,"I've seen information about using token in the soap API, but the rest API documentation doesn't say anything about it. Has anyone found a useful hint for token to use the rest API?","
  If you have  a partner app you should now be able to get your OAuth
  client whitelisted for api access, talk to your contact in the partner
  group.


Source: Does the REST API support Client ID?
"
1727,1727,2731,Ad layout for programs - Illustrator or InDesign,"today I'm looking for some advice from folks who have laid out event programs. 

In this case, the client (a local nonprofit) has a famous keynote speaker at their event, and have solicited donations from local businesses. Each donation over a certain level = a full page ad in the program for the event. Most of them are ""Congratulations to  on your anniversary"", etc. with a company logo sitting somewhere (the businesses that send in their own camera-ready artwork will just have them dropped into place). 

I'm going to be laying each ad out in a template so they look consistent; my question to the GD crowd is, ""Should I lay the template out in Illustrator and bring each ad individually in to InDesign or should I create a template page for an ad in InDesign and lay each ad out in InDesign?""

Based on your experience, what are the pros and cons of each approach? Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for) but I lose a certain amount of flexibility once I hit InDesign (the program will ultimately be laid out in InDesign).
",lawndartcatcher,https://graphicdesign.stackexchange.com/users/575,"If it was me I'd do the artwork for the individual ad's in InDesign, save them as individual PDFs and then import them into the 'event program' InDesign document.

InDesign is a page layout program and that is exactly what it should be used for, layout.  Try to keep Illustrator for creating complex vector artwork only. InDesign's typesetting tools are far superior and quicker to work with than Illustrator's, this is no coincidence.

I sometimes visit other ad agencies and chuckle when I see designers using Illustrator, or god forbid an old copy of Freehand, to create copy heavy double page spreads.  Usually the designers in question are Luddites who miss rubbing down Letraset and reprography.
",mousebat,https://graphicdesign.stackexchange.com/users/14618,http://graphicdesign.stackexchange.com/questions/20355/ad-layout-for-programs-illustrator-or-indesign,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,Program advertising layout - illustration or illustration,"today I'm looking for some advice from folks who have laid out event programs. 

In this case, the client (a local nonprofit) has a famous keynote speaker at their event, and have solicited donations from local businesses. Each donation over a certain level = a full page ad in the program for the event. Most of them are ""Congratulations to  on your anniversary"", etc. with a company logo sitting somewhere (the businesses that send in their own camera-ready artwork will just have them dropped into place). 

I'm going to be laying each ad out in a template so they look consistent; my question to the GD crowd is, ""Should I lay the template out in Illustrator and bring each ad individually in to InDesign or should I create a template page for an ad in InDesign and lay each ad out in InDesign?""

Based on your experience, what are the pros and cons of each approach? Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for) but I lose a certain amount of flexibility once I hit InDesign (the program will ultimately be laid out in InDesign).
","If it was me I'd do the artwork for the individual ad's in InDesign, save them as individual PDFs and then import them into the 'event program' InDesign document.

InDesign is a page layout program and that is exactly what it should be used for, layout.  Try to keep Illustrator for creating complex vector artwork only. InDesign's typesetting tools are far superior and quicker to work with than Illustrator's, this is no coincidence.

I sometimes visit other ad agencies and chuckle when I see designers using Illustrator, or god forbid an old copy of Freehand, to create copy heavy double page spreads.  Usually the designers in question are Luddites who miss rubbing down Letraset and reprography.
"
3382,3382,5392,"How do you create the vertical endless scrolling view in HTC WorldClock.apk, when setting the alarm?","In the WorldClock.apk of a HTC Sense Android phone, when a user wants to set the alarm, the user would see a black pop-up showing three vertical dials (value pickers, value selectors, etc). Those three vertical dials all can scroll up/down and cycle through the valid values.

One is for hours, one is for minutes, and one is for AM or PM. There are no button, other than Done and Cancel. The vertical scrolling sliders is the one thing I'm looking for in the Android SDK Reference, and is the one I wanted to create.


What are the vertical scrolling dials (number picker, sliding thing) called? What name?
What class should I use to create it in Java?
Is there anything else like it?


Note, it is not for Windows Phone. It's an Android phone with the HTC Sense app, WorldClock.apk.

Also note that I'm trying to obtain a picture of the Alarm Clock sliders on my HTC phone. But it's really hard when no one else has a digital camera for me to borrow.
",tom_mai78101,https://stackoverflow.com/users/1016891,"I suppose what you want is a wheel like this:
http://code.google.com/p/android-wheel/

I have use it in my project, really help.
",David Guo,https://stackoverflow.com/users/467005,http://stackoverflow.com/questions/7925669/how-do-you-create-the-vertical-endless-scrolling-view-in-htc-worldclock-apk-whe,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5,1.0,0.0,0.0,0.6666666666666666,"When setting an alarm, how do I create a vertical, endless scrolling view in HTC worldclock.apk?","In the WorldClock.apk of a HTC Sense Android phone, when a user wants to set the alarm, the user would see a black pop-up showing three vertical dials (value pickers, value selectors, etc). Those three vertical dials all can scroll up/down and cycle through the valid values.

One is for hours, one is for minutes, and one is for AM or PM. There are no button, other than Done and Cancel. The vertical scrolling sliders is the one thing I'm looking for in the Android SDK Reference, and is the one I wanted to create.


What are the vertical scrolling dials (number picker, sliding thing) called? What name?
What class should I use to create it in Java?
Is there anything else like it?


Note, it is not for Windows Phone. It's an Android phone with the HTC Sense app, WorldClock.apk.

Also note that I'm trying to obtain a picture of the Alarm Clock sliders on my HTC phone. But it's really hard when no one else has a digital camera for me to borrow.
","I suppose what you want is a wheel like this:
http://code.google.com/p/android-wheel/

I have use it in my project, really help.
"
818,818,1296,Does the question mark mean this is a question?,"Imagine the following written conversation, as recently occurred via SMS between me and a friend (edited for brevity):


  A: What are you going to do today?
  
  B:  I don't know.  Go shopping?


What is the meaning of the question mark in the reply?  Is person B asking a question of person A?  If so, why would person B expect person A to know the answer in this case? If not, why use the question mark?
",Flimzy,https://ell.stackexchange.com/users/69,"I interpret this as B's question to himself, not to A, meaning ""maybe I should consider going shopping?""  And it's probably not even a real question, although the vocal pattern is the same as for a question; when written, a question mark at the end is the only way to indicate that intonation.
",barbara beeton,https://ell.stackexchange.com/users/39,http://ell.stackexchange.com/questions/1042/does-the-question-mark-mean-this-is-a-question,CULTURE,ell.stackexchange.com,0.8888888888888888,0.5555555555555556,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Does the question mark mean it's a problem?,"Imagine the following written conversation, as recently occurred via SMS between me and a friend (edited for brevity):


  A: What are you going to do today?
  
  B:  I don't know.  Go shopping?


What is the meaning of the question mark in the reply?  Is person B asking a question of person A?  If so, why would person B expect person A to know the answer in this case? If not, why use the question mark?
","I interpret this as B's question to himself, not to A, meaning ""maybe I should consider going shopping?""  And it's probably not even a real question, although the vocal pattern is the same as for a question; when written, a question mark at the end is the only way to indicate that intonation.
"
5895,5895,9336,How to fix a dpkg broken by the Brother MFC-7340 deb driver,"I'm getting an apt-get error that says

E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.

The brmfc7340lpr is a printer driver -- it's a local deb file. Doing a dpkg or apt-get purge doesn't work, neither does apt-get install -f .

How do I reinstall a package from a local deb file?

Output:

box-name% sudo apt-get upgrade
[sudo] password for username: 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo apt-get purge brmfc7340lpr
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo dpkg --purge brmfc7340lpr 
dpkg: error processing brmfc7340lpr (--purge):
 Package is in a very bad inconsistent state - you should
 reinstall it before attempting a removal.
Errors were encountered while processing:
 brmfc7340lpr
box-name% sudo dpkg --install brmfc7340lpr-2.0.2-1.i386.deb
Selecting previously deselected package brmfc7340lpr.
(Reading database ... 725204 files and directories currently installed.)
Preparing to replace brmfc7340lpr 2.0.2-1 (using .../brmfc7340lpr-2.0.2-1.i386.deb) ...
Unpacking replacement brmfc7340lpr ...
start: Unknown job: lpd
dpkg: warning: subprocess old post-removal script returned error exit status 1
dpkg - trying script from the new package instead ...
start: Unknown job: lpd
dpkg: error processing brmfc7340lpr-2.0.2-1.i386.deb (--install):
 subprocess new post-removal script returned error exit status 1
start: Unknown job: lpd
dpkg: error while cleaning up:
 subprocess new post-removal script returned error exit status 1
Errors were encountered while processing:
brmfc7340lpr-2.0.2-1.i386.deb
box-name% sudo apt-get install -f                                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% 

",Roman A. Taycher,https://askubuntu.com/users/669,"You can always (re)install a package using dpkg:

dpkg --install local-file.deb


In order to make a ""clean room"" installation, you can first purge the package and then install it again:

dpkg --purge brmfc7340lpr
dpkg --install brmfc7340lpr*.deb


You might need to add option --force-depends during purge, if some other package depends on brmfc7340lpr.

Update: Based on the transcript you posted, it seems that the
 brmfc7340lpr package cannot be (re)installed because its
 post-removal script is erroring out.

Those files are stored in directory /var/lib/dpkg/info; for each
package X, there can be any one of these scripts:


X.postinst run after the package has been installed, e.g., to
start services provided by the package.
X.prerm run before removing/purging the package, e.g., to
ensure that daemons provided by the package are stopped.
X.postrm run after the package has been removed, e.g., to
signal any service optionally using the package that it is no
longer available.  (For instance, a printer driver package might
want to signal cpus/lpr to remove printers depending on that
specific driver.)


Now, this brmfc7340lpr package seems to try to (re)start the lpd
printer daemon upon removal, which won't work as Ubuntu uses CUPS
instead: you should definitely look for a CUPS-compatible printer
driver -- see the link in Jorge Castro's answer. (I think this is a
bug in the package, as it should not restart the lpd service
unconditionally, but just reload it if it's already running.)

The best option to go forward comes from this launchpad
answer:

ln -s /etc/init.d/cpus /etc/init.d/lpd


This will effectively (re)start CUPS when the lpd service is instead
searched for.

Otherwise, I only see two options, both rather unpleasant:


Either edit the /var/lib/dpkg/info/brmfc7340lpr.postrm script,
and comment out the line that is invoking /etc/init.d/lpd start
(or restart or stop), (e.g., just replace it with /bin/true).
Another option is to just place exit 0 as the first non-comment
line in the script. This would be my favorite, but requires a bit
of confidence with editing shell scripts.
Install lpr, purge the brmfc6340lpr package, purge lpr: this
requires a bit of attention as lpr conflicts with the default
Ubuntu printer spooling system CUPS:

a. sudo aptitude install lpr (this will remove cups-bsd and
  ubuntu-desktop as a side effect)

b. sudo aptitude purge brmfc7340lpr lpr (should work now)

c. sudo aptitude install cups-bsd ubuntu-desktop (restore system
  to its original state)

",Riccardo Murri,https://askubuntu.com/users/325,http://askubuntu.com/questions/5058/how-to-fix-a-dpkg-broken-by-the-brother-mfc-7340-deb-driver,TECHNOLOGY,askubuntu.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to fix the dpkg damaged by brother mfc-7340 DEB driver,"I'm getting an apt-get error that says

E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.

The brmfc7340lpr is a printer driver -- it's a local deb file. Doing a dpkg or apt-get purge doesn't work, neither does apt-get install -f .

How do I reinstall a package from a local deb file?

Output:

box-name% sudo apt-get upgrade
[sudo] password for username: 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo apt-get purge brmfc7340lpr
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo dpkg --purge brmfc7340lpr 
dpkg: error processing brmfc7340lpr (--purge):
 Package is in a very bad inconsistent state - you should
 reinstall it before attempting a removal.
Errors were encountered while processing:
 brmfc7340lpr
box-name% sudo dpkg --install brmfc7340lpr-2.0.2-1.i386.deb
Selecting previously deselected package brmfc7340lpr.
(Reading database ... 725204 files and directories currently installed.)
Preparing to replace brmfc7340lpr 2.0.2-1 (using .../brmfc7340lpr-2.0.2-1.i386.deb) ...
Unpacking replacement brmfc7340lpr ...
start: Unknown job: lpd
dpkg: warning: subprocess old post-removal script returned error exit status 1
dpkg - trying script from the new package instead ...
start: Unknown job: lpd
dpkg: error processing brmfc7340lpr-2.0.2-1.i386.deb (--install):
 subprocess new post-removal script returned error exit status 1
start: Unknown job: lpd
dpkg: error while cleaning up:
 subprocess new post-removal script returned error exit status 1
Errors were encountered while processing:
brmfc7340lpr-2.0.2-1.i386.deb
box-name% sudo apt-get install -f                                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% 

","You can always (re)install a package using dpkg:

dpkg --install local-file.deb


In order to make a ""clean room"" installation, you can first purge the package and then install it again:

dpkg --purge brmfc7340lpr
dpkg --install brmfc7340lpr*.deb


You might need to add option --force-depends during purge, if some other package depends on brmfc7340lpr.

Update: Based on the transcript you posted, it seems that the
 brmfc7340lpr package cannot be (re)installed because its
 post-removal script is erroring out.

Those files are stored in directory /var/lib/dpkg/info; for each
package X, there can be any one of these scripts:


X.postinst run after the package has been installed, e.g., to
start services provided by the package.
X.prerm run before removing/purging the package, e.g., to
ensure that daemons provided by the package are stopped.
X.postrm run after the package has been removed, e.g., to
signal any service optionally using the package that it is no
longer available.  (For instance, a printer driver package might
want to signal cpus/lpr to remove printers depending on that
specific driver.)


Now, this brmfc7340lpr package seems to try to (re)start the lpd
printer daemon upon removal, which won't work as Ubuntu uses CUPS
instead: you should definitely look for a CUPS-compatible printer
driver -- see the link in Jorge Castro's answer. (I think this is a
bug in the package, as it should not restart the lpd service
unconditionally, but just reload it if it's already running.)

The best option to go forward comes from this launchpad
answer:

ln -s /etc/init.d/cpus /etc/init.d/lpd


This will effectively (re)start CUPS when the lpd service is instead
searched for.

Otherwise, I only see two options, both rather unpleasant:


Either edit the /var/lib/dpkg/info/brmfc7340lpr.postrm script,
and comment out the line that is invoking /etc/init.d/lpd start
(or restart or stop), (e.g., just replace it with /bin/true).
Another option is to just place exit 0 as the first non-comment
line in the script. This would be my favorite, but requires a bit
of confidence with editing shell scripts.
Install lpr, purge the brmfc6340lpr package, purge lpr: this
requires a bit of attention as lpr conflicts with the default
Ubuntu printer spooling system CUPS:

a. sudo aptitude install lpr (this will remove cups-bsd and
  ubuntu-desktop as a side effect)

b. sudo aptitude purge brmfc7340lpr lpr (should work now)

c. sudo aptitude install cups-bsd ubuntu-desktop (restore system
  to its original state)

"
725,725,1155,Defining a persistent static route on Mac OS X,"How does one define a static route on MacOS X which persists through reboots? The only suggestion I've found on Google advises setting up a launchd service to run at boot, which seems like a horrible hack (does it survive a network restart without rebooting, for instance?)

To set up the route I need temporarily, I can run the following:

route add -net ${network} ${gateway} ${netmask}


How would I make this persist?
",Charles Duffy,https://serverfault.com/users/38326,"I have to disagree on the order of goodness - if the OP uses launchd (either with a manually created plist or one created with lingon), they can have it run at boot. If they use an AppleScript based solution like RouteSplit, they won't be able to run it without a user logged in.

Charles, I'm curious, why does using an OS vendor sanctioned tool like launchd seem hackish to you?
",Joe Block,https://serverfault.com/users/7837,http://serverfault.com/questions/124954,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8333333333333334,0.3333333333333333,0.8333333333333334,1.0,0.6,0.0,0.0,0.3333333333333333,1.0,Defining persistent static routes on Mac OS X,"How to define a static route on Mac OS X that persists during restart? The only advice I find on Google is to set up a startup service to run at startup, which looks like a terrible hack attack (for example, can it survive without restarting the network?)","I have to disagree on the order of goodness - if the OP uses launchd (either with a manually created plist or one created with lingon), they can have it run at boot. If they use an AppleScript based solution like RouteSplit, they won't be able to run it without a user logged in.

Charles, I'm curious, why does using an OS vendor sanctioned tool like launchd seem hackish to you?
"
1769,1769,2808,How do I find the most populous cities in the world?,"I am attempting to plot the most populous cities on a world map.

Currently, I have the line of code:

numberofpeople = 
  Map[{#, Length[CityData[#, ""Population""]]} &amp;, CityData[All]];


which should give me the City name, and the population. However, when I type in the line of code

Reverse[SortBy[numberofpeople, Last]][[1 ;; 20]]


I am getting odd data, which is that the most populous cities have 1 person. 

Could somebody debug my code, and answer any future questions I have on the matter?
Much appreciated.

EDIT: How do I plot these points on a World Map? Currently I have

Graphics[{EdgeForm[Black], , CountryData[#, ""SchematicPolygon""]} &amp; /@ 
  CountryData[]]

but I have no idea what goes between the points.
",user9876,https://mathematica.stackexchange.com/users/9876,"I was gonna post this as a comment but it'll be too long. As Mr. Wizard has shown you how to obtain the most popluar cities, here is how to plot them:

 Graphics[{{White, EdgeForm[Black],  CountryData[#, ""FullPolygon""] &amp; /@ CountryData[]}, 
{PointSize[Large], Red,    Tooltip[Point[Reverse[CityData[#, ""Coordinates""]]], 
          CityData[#, ""Name""]] &amp; /@ largeCities}}]




Here, largeCities are the names of the cities without their populations. So you can do something like 

largeCities = Take[SortBy[numberofpeople, Last] // Reverse, 20][[All, 1]]

",RunnyKine,https://mathematica.stackexchange.com/users/5709,http://mathematica.stackexchange.com/questions/34456/how-do-i-find-the-most-populous-cities-in-the-world,TECHNOLOGY,mathematica.stackexchange.com,0.8333333333333334,0.6666666666666666,0.0,1.0,0.5,1.0,0.6666666666666666,0.5,0.5,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8333333333333334,1.0,0.5,1.0,1.0,0.9,1.0,0.0,0.0,0.8333333333333334,How can I find the most populous city in the world?,"I am attempting to plot the most populous cities on a world map.

Currently, I have the line of code:

numberofpeople = 
  Map[{#, Length[CityData[#, ""Population""]]} &amp;, CityData[All]];


which should give me the City name, and the population. However, when I type in the line of code

Reverse[SortBy[numberofpeople, Last]][[1 ;; 20]]


I am getting odd data, which is that the most populous cities have 1 person. 

Could somebody debug my code, and answer any future questions I have on the matter?
Much appreciated.

EDIT: How do I plot these points on a World Map? Currently I have

Graphics[{EdgeForm[Black], , CountryData[#, ""SchematicPolygon""]} &amp; /@ 
  CountryData[]]

but I have no idea what goes between the points.
","I was gonna post this as a comment but it'll be too long. As Mr. Wizard has shown you how to obtain the most popluar cities, here is how to plot them:

 Graphics[{{White, EdgeForm[Black],  CountryData[#, ""FullPolygon""] &amp; /@ CountryData[]}, 
{PointSize[Large], Red,    Tooltip[Point[Reverse[CityData[#, ""Coordinates""]]], 
          CityData[#, ""Name""]] &amp; /@ largeCities}}]




Here, largeCities are the names of the cities without their populations. So you can do something like 

largeCities = Take[SortBy[numberofpeople, Last] // Reverse, 20][[All, 1]]

"
1521,1521,2391,"What does ""pie"" mean in the following sentence?","I once saw a sentence: 


  I will go to a restaurant for pie.


Native speakers didn't correct this sentence. I don't know why. I would say ""I will go to a restaurant to eat a pie"". But maybe that sentence was right. Could you please explain to me what that (first) sentence means?
",user5369,https://ell.stackexchange.com/users/5369,"In American everyday language it's correct. You can hear people saying: Let's go for pizza/pie/ice-cream/dessert, instead of saying: some/ a piece of pie, etc. Don't forget that all these words are also considered uncountable, therefore don't need the indefinite article a/an.
",Vic,https://ell.stackexchange.com/users/4858,http://ell.stackexchange.com/questions/20276/what-does-pie-mean-in-the-following-sentence,CULTURE,ell.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.8888888888888888,"What does ""Pai"" mean in the following sentence?","I once saw a sentence: 


  I will go to a restaurant for pie.


Native speakers didn't correct this sentence. I don't know why. I would say ""I will go to a restaurant to eat a pie"". But maybe that sentence was right. Could you please explain to me what that (first) sentence means?
","In American everyday language it's correct. You can hear people saying: Let's go for pizza/pie/ice-cream/dessert, instead of saying: some/ a piece of pie, etc. Don't forget that all these words are also considered uncountable, therefore don't need the indefinite article a/an.
"
5174,5174,8222,"Magento: Display custom product price in product listing, view page and also set same price after adding product to cart","I need to display custom price for each product where the admin will set different price for each product. and this product price only should be displayed in product listing and product view page, without changing the product actual price. And also the same price should apply to the cart. I tried with catalog_product_get_final_price observer, but It shows the price as special price but it will not change the display of product price. Please give me an idea, how can I do this? Thanks in advance:)
",SKumar,https://stackoverflow.com/users/3484766,"on list page and view page just check whether your custom price is null nor not if it is null show original price and if it not null show custom price.

create a event in config file **checkout_cart_product_add_after** as given below

&lt;events&gt;
    &lt;checkout_cart_product_add_after&gt;
          &lt;observers&gt;
                &lt;unique_event_name&gt;
                  &lt;class&gt;modulename/observer&lt;/class&gt;
                  &lt;method&gt;modifyPrice&lt;/method&gt;
                  &lt;/unique_event_name&gt;
            &lt;/observers&gt;
      &lt;/checkout_cart_product_add_after&gt;
&lt;/events&gt;


create new file **Observer.php**


    class namespace_modulename_Model_Observer

      {

          public function modifyPrice(Varien_Event_Observer $obs)
             {
                 // Get the quote item

                 $item = $obs-&gt;getQuoteItem();

                 // Ensure we have the parent item, if it has one

                 $item = ( $item-&gt;getParentItem() ? $item-&gt;getParentItem() : $item );

                 // Load the custom price

                 $price = $this-&gt;_getPriceByItem($item);

                 // Set the custom price

                 $item-&gt;setCustomPrice($price);

                 $item-&gt;setOriginalCustomPrice($price);

                 // Enable super mode on the product.

                 $item-&gt;getProduct()-&gt;setIsSuperMode(true);

             }


             protected function _getPriceByItem(Mage_Sales_Model_Quote_Item $item)
             {
                 $price;

                 //use $item to determine your custom price.

                 return $price;
             }
                }

",Manoj Chaurasia,https://stackoverflow.com/users/3256230,http://stackoverflow.com/questions/25347405/magento-display-custom-product-price-in-product-listing-view-page-and-also-set,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.5555555555555556,"Magento: display the custom product price in the product list, view the page, and set the same price after adding the product to the shopping cart","I need to display a custom price for each product, and the administrator will set a different price for each product. This product price is only displayed on the product list and product view page, and does not change the actual price of the product. The same price applies to shopping carts. I've tried using catalog products to get the final price observer, but it shows that the price is a special price, but it doesn't change the display of the product price. Please give me an idea. What should I do? Thank you in advance:)","on list page and view page just check whether your custom price is null nor not if it is null show original price and if it not null show custom price.

create a event in config file **checkout_cart_product_add_after** as given below

&lt;events&gt;
    &lt;checkout_cart_product_add_after&gt;
          &lt;observers&gt;
                &lt;unique_event_name&gt;
                  &lt;class&gt;modulename/observer&lt;/class&gt;
                  &lt;method&gt;modifyPrice&lt;/method&gt;
                  &lt;/unique_event_name&gt;
            &lt;/observers&gt;
      &lt;/checkout_cart_product_add_after&gt;
&lt;/events&gt;


create new file **Observer.php**


    class namespace_modulename_Model_Observer

      {

          public function modifyPrice(Varien_Event_Observer $obs)
             {
                 // Get the quote item

                 $item = $obs-&gt;getQuoteItem();

                 // Ensure we have the parent item, if it has one

                 $item = ( $item-&gt;getParentItem() ? $item-&gt;getParentItem() : $item );

                 // Load the custom price

                 $price = $this-&gt;_getPriceByItem($item);

                 // Set the custom price

                 $item-&gt;setCustomPrice($price);

                 $item-&gt;setOriginalCustomPrice($price);

                 // Enable super mode on the product.

                 $item-&gt;getProduct()-&gt;setIsSuperMode(true);

             }


             protected function _getPriceByItem(Mage_Sales_Model_Quote_Item $item)
             {
                 $price;

                 //use $item to determine your custom price.

                 return $price;
             }
                }

"
2322,2322,3704,What filter should I use to avoid overly-whitened daylight  images?,"What filter should I use to avoid whitened images (blown highlights) caused by intense daylight? At the moment I am only using an UV Filter, but it doesn't solve the whole problem.

I am a newbie in photography, and I've recently bought a Nikon DSLR.
",Daniel,https://photo.stackexchange.com/users/6471,"Do you mean over-exposed? If so, use +/- button. That is Exposure-Compensation and lets you make things darker by going negative.

A UV filter does nothing for brightness, usually makes things worst only. Take off and replace with polarizer that darkens the sky (sometimes, if not cloudy).
",Zak,https://photo.stackexchange.com/users/6472,http://photo.stackexchange.com/questions/15334/what-filter-should-i-use-to-avoid-overly-whitened-daylight-images,LIFE_ARTS,photo.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,What filter should I use to avoid over whitening the sun image?,"What kind of filter should I use to avoid the white image caused by strong sunlight? At present, I only use ultraviolet filter, but it can't solve the whole problem.","Do you mean over-exposed? If so, use +/- button. That is Exposure-Compensation and lets you make things darker by going negative.

A UV filter does nothing for brightness, usually makes things worst only. Take off and replace with polarizer that darkens the sky (sometimes, if not cloudy).
"
2451,2451,3913,How valuable is studying cognitive psychology for UX?,"I am starting my second year in grad school and thinking about what to study. One thing that I know is good to have a grasp of is cognitive psychology. But I would like to get someones perspective.

Have you studied cognitive psychology? Either 1 class or more... and what did that give you?
",JeroenEijkhof,https://ux.stackexchange.com/users/793,"Have you studied cognitive psychology? Either 1 class or more...

Yes.

and what did that give you?

That's a difficult question.  

A lot of the academic cognitive psychology probably isn't that relevant to UX to be honest... (for example the language generation / comprehension bit )

Without some good guidance you could spend a lot of time reading psychology stuff, which, while interesting isn't really that relevant to UX.

Which begs the next question...
",PhillipW,https://ux.stackexchange.com/users/4403,http://ux.stackexchange.com/questions/5534/how-valuable-is-studying-cognitive-psychology-for-ux,TECHNOLOGY,ux.stackexchange.com,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.8888888888888888,How valuable is cognitive psychology to user experience?,"In my second year of graduate school, I was thinking about what to learn. One thing I know is that I have a good grasp of cognitive psychology. But I want to know some people's views.","Have you studied cognitive psychology? Either 1 class or more...

Yes.

and what did that give you?

That's a difficult question.  

A lot of the academic cognitive psychology probably isn't that relevant to UX to be honest... (for example the language generation / comprehension bit )

Without some good guidance you could spend a lot of time reading psychology stuff, which, while interesting isn't really that relevant to UX.

Which begs the next question...
"
361,361,571,Do real and reactive energy exist?,"Are there any such things as real and reactive energies just like real and reactive power? if so, how is reactive energy dissipated?
",Sri,https://electronics.stackexchange.com/users/34625,"First of all, remember that in the context of AC (phasor) analysis, real and reactive power, unlike voltage and current, are not phasors, i.e., they do not represent the amplitude and phase of a sinusoid in the time domain.  Thus, we cannot ""tack on"" the time dependence and take the real and imaginary parts to calculate the associated energies in time domain.  

Sometimes it is helpful to ""go back to basics"" to gain insight into a problem.  This is such a case.  Reactive power is a useful concept in AC analysis but what it represents physically is best seen in the time domain.

First, consider a sinusoidal voltage source \$v_s(t) = V\cos\omega t\$ driving a resistor R.  The power delivered to the resistor is:

$$p_R = \dfrac{v^2_s(t)}{R} = \dfrac{V^2\cos^2\omega t}{R} = \dfrac{V^2}{2R}(1 + \cos2\omega t)$$

The key observation here is that the power is never negative, i.e., the flow of energy is from the source to the resistor always.  Thus, the energy supplied by the source increases over time.

The energy supplied by the source over a period \$\dfrac{\pi}{\omega}\$ is:

$$W_R = \dfrac{\pi V^2}{2\omega R}$$

Now, replace the resistor with a capacitor.  The power delivered to the capacitor is:

$$p_C = v_s(t) \cdot i_C =  V\cos\omega t \cdot (-\omega C)V\sin\omega t = -\dfrac{CV^2}{2}\sin2\omega t$$

The energy supplied by the source over a period \$\dfrac{\pi}{\omega}\$ is:

$$W_C = 0 $$

The key observation here is that the power is alternately and equally positive and negative, i.e., the flow of energy is back and forth between the source and the capacitor.  Thus, the energy supplied by the source over a period is zero.

But, as we know, the power associated with a capacitor is reactive power in phasor analysis, and now we can answer your question:


  Are there any such things as real and reactive energies


We have shown that reactive power is associated with an alternating energy flow between the source and load that is zero over a period.  In other words, it is associated with the energy that ""sloshes"" back and forth between the source and load without any dissipation.
",Alfred Centauri,https://electronics.stackexchange.com/users/10475,http://electronics.stackexchange.com/questions/94594/do-real-and-reactive-energy-exist,TECHNOLOGY,electronics.stackexchange.com,0.5555555555555556,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6,0.0,1.0,1.0,1.0,Is there any active and no function?,"Is there real energy and reactive energy, just like real power and reactive power? If so, how to dissipate reactive energy?","First of all, remember that in the context of AC (phasor) analysis, real and reactive power, unlike voltage and current, are not phasors, i.e., they do not represent the amplitude and phase of a sinusoid in the time domain.  Thus, we cannot ""tack on"" the time dependence and take the real and imaginary parts to calculate the associated energies in time domain.  

Sometimes it is helpful to ""go back to basics"" to gain insight into a problem.  This is such a case.  Reactive power is a useful concept in AC analysis but what it represents physically is best seen in the time domain.

First, consider a sinusoidal voltage source \$v_s(t) = V\cos\omega t\$ driving a resistor R.  The power delivered to the resistor is:

$$p_R = \dfrac{v^2_s(t)}{R} = \dfrac{V^2\cos^2\omega t}{R} = \dfrac{V^2}{2R}(1 + \cos2\omega t)$$

The key observation here is that the power is never negative, i.e., the flow of energy is from the source to the resistor always.  Thus, the energy supplied by the source increases over time.

The energy supplied by the source over a period \$\dfrac{\pi}{\omega}\$ is:

$$W_R = \dfrac{\pi V^2}{2\omega R}$$

Now, replace the resistor with a capacitor.  The power delivered to the capacitor is:

$$p_C = v_s(t) \cdot i_C =  V\cos\omega t \cdot (-\omega C)V\sin\omega t = -\dfrac{CV^2}{2}\sin2\omega t$$

The energy supplied by the source over a period \$\dfrac{\pi}{\omega}\$ is:

$$W_C = 0 $$

The key observation here is that the power is alternately and equally positive and negative, i.e., the flow of energy is back and forth between the source and the capacitor.  Thus, the energy supplied by the source over a period is zero.

But, as we know, the power associated with a capacitor is reactive power in phasor analysis, and now we can answer your question:


  Are there any such things as real and reactive energies


We have shown that reactive power is associated with an alternating energy flow between the source and load that is zero over a period.  In other words, it is associated with the energy that ""sloshes"" back and forth between the source and load without any dissipation.
"
4363,4363,6939,In-game rewards for game-related work?,"The other GM in my group and I are both big fans of giving XP rewards for things done out of the game. Ex: We have an artist who will draw and design all sorts of stuff to ""fluff out"" our campaign. 

We noticed participation spiked when we offered rewards like this. Eventually, we even offered XP to our ""scribe"" for recording everything that happened each session. At the most, though, this gives bonus XP for up to two of our players. We do not plan to remove these bonuses, but want to be fair to all our players.

What are some fun things your players can do out of game that you can reward as GM? The goal is to have them be engaged in our game even when we aren't playing.
",pblock,https://rpg.stackexchange.com/users/8116,"The ""Artist"" and ""Scribe"" are quite useful the campaign, and I also agree with lisardggY's suggestions about transportation and centralized documentation to follow the game.  That said, here are my additions:


While the specific game escapes me (I believe it was a White Wolf book), they suggest offering XP to whomever brings snacks for the table.  
As a personal belief, if for some reason I'm not able to run my games in my home, I tend to offer a small bonus to the host of the game session.
Fleshing the Backstory: Most of the players I encounter have their central theme designed more like a video game than actual people until they play for a while and get some momentum.  Thus I have started offering rewards for people who come to game with meaningful data on their character.
Stationary Supplies can be a very eroding stock.  Anyone who consistently has pencils, erasers, especially blank char sheets, quick references, etc.


Side note: Just make sure that the XP bonuses don't ramp up too quickly.  In some games the balance gets upset quite quickly even with the smallest offerings if they happen regularly.
",CatLord,https://rpg.stackexchange.com/users/3273,http://rpg.stackexchange.com/questions/25167/in-game-rewards-for-game-related-work,CULTURE,rpg.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.7,0.3333333333333333,0.0,0.6666666666666666,1.0,Game rewards for game related work?,"The other GM in my group and I are both big fans of giving XP rewards for things done out of the game. Ex: We have an artist who will draw and design all sorts of stuff to ""fluff out"" our campaign. 

We noticed participation spiked when we offered rewards like this. Eventually, we even offered XP to our ""scribe"" for recording everything that happened each session. At the most, though, this gives bonus XP for up to two of our players. We do not plan to remove these bonuses, but want to be fair to all our players.

What are some fun things your players can do out of game that you can reward as GM? The goal is to have them be engaged in our game even when we aren't playing.
","The ""Artist"" and ""Scribe"" are quite useful the campaign, and I also agree with lisardggY's suggestions about transportation and centralized documentation to follow the game.  That said, here are my additions:


While the specific game escapes me (I believe it was a White Wolf book), they suggest offering XP to whomever brings snacks for the table.  
As a personal belief, if for some reason I'm not able to run my games in my home, I tend to offer a small bonus to the host of the game session.
Fleshing the Backstory: Most of the players I encounter have their central theme designed more like a video game than actual people until they play for a while and get some momentum.  Thus I have started offering rewards for people who come to game with meaningful data on their character.
Stationary Supplies can be a very eroding stock.  Anyone who consistently has pencils, erasers, especially blank char sheets, quick references, etc.


Side note: Just make sure that the XP bonuses don't ramp up too quickly.  In some games the balance gets upset quite quickly even with the smallest offerings if they happen regularly.
"
5164,5164,8205,Chaining deferreds,"I have a lot of functions that currently look like this:

function LoadFromURL(url) 
{
    var d = $.Deferred();
    $.get(url).then(function(text)
    {
        LoadFromText(text).then(function(obj)
        {
            d.resolve(obj);
        }, 
        function(err)
        {
            d.reject(err);
        });
    }, 
    function(err)
    {
        d.reject(err);
    });
    return d.promise();
}


This function takes a URL and loads the text within a promise. The text is then passed to the LoadFromText function which returns another promise. If this succeeds, the outer deferred is resolved. If the URL cannot be loaded, or the LoadFromText function fails then the outer deferred is rejected.

Is there a way that I can chain the result of the resolve / reject and end up with something like this:

function LoadFromURL(url) 
{
    return $.get(url).then(function(text)
    {
        return LoadFromText(text);
    }, 
    function(err)
    {
        return $.Deferred().reject(err);
    }).promise();
}


I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used. 

I realise this doesn't work at the moment (the result is the promise, rather than the result of the promise), but hopefully someone can suggest a way to make this work so I can tidy up the sometimes confusing mess of the first example.

I hope this makes sense. Thanks.
",Barguast,https://stackoverflow.com/users/283445,"I'm not sure if I understand you correctly, because your second function LoadFromText is some sort of black box for me. I think, though, that your construct is too bloated for the things executed. Try do do it in more functions that do less. I've done a proposition:

function Load() {
    var myUrl = '//path.to/url';
    LoadFromUrl(myUrl)
        .then(LoadFromText, errorHandler)
        .then(successHandler, errorHandler);
}

function successHandler(returnedData) {
    console.log('Requests were successful: ' + returnedData);
}

function errorHandler(err) {
    console.log('An error occurded: ' + err);
}

function LoadFromURL(url) {
    return $.get(url);
}

function LoadFromText(text) {
    // THIS IS SOME SORT OF BLACK BOX FOR ME...
    // SEEMS TO RETURN A PROMISE, THOUGH

    var $deferred = $.Deferred();

    // DO THE LOGIC TO EITHER REJECT OR RESOLVE THE PROMISE

    return $deferred.promise();
}


You only use the main function Load to start the ajax chain. As soon as the first ajax request is done, the second starts with the data of the first one. After that, the successHandler will do whatever is needed with the data of the second ajax call. This is the important addition to your solution.
Apart from that it's basically the same thing you did, but distributed to smaller functions that are easier maintainable.
",nirazul,https://stackoverflow.com/users/1602864,http://stackoverflow.com/questions/17946391/chaining-deferreds,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,Chain extension,"I have a lot of functions that currently look like this:

function LoadFromURL(url) 
{
    var d = $.Deferred();
    $.get(url).then(function(text)
    {
        LoadFromText(text).then(function(obj)
        {
            d.resolve(obj);
        }, 
        function(err)
        {
            d.reject(err);
        });
    }, 
    function(err)
    {
        d.reject(err);
    });
    return d.promise();
}


This function takes a URL and loads the text within a promise. The text is then passed to the LoadFromText function which returns another promise. If this succeeds, the outer deferred is resolved. If the URL cannot be loaded, or the LoadFromText function fails then the outer deferred is rejected.

Is there a way that I can chain the result of the resolve / reject and end up with something like this:

function LoadFromURL(url) 
{
    return $.get(url).then(function(text)
    {
        return LoadFromText(text);
    }, 
    function(err)
    {
        return $.Deferred().reject(err);
    }).promise();
}


I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used. 

I realise this doesn't work at the moment (the result is the promise, rather than the result of the promise), but hopefully someone can suggest a way to make this work so I can tidy up the sometimes confusing mess of the first example.

I hope this makes sense. Thanks.
","I'm not sure if I understand you correctly, because your second function LoadFromText is some sort of black box for me. I think, though, that your construct is too bloated for the things executed. Try do do it in more functions that do less. I've done a proposition:

function Load() {
    var myUrl = '//path.to/url';
    LoadFromUrl(myUrl)
        .then(LoadFromText, errorHandler)
        .then(successHandler, errorHandler);
}

function successHandler(returnedData) {
    console.log('Requests were successful: ' + returnedData);
}

function errorHandler(err) {
    console.log('An error occurded: ' + err);
}

function LoadFromURL(url) {
    return $.get(url);
}

function LoadFromText(text) {
    // THIS IS SOME SORT OF BLACK BOX FOR ME...
    // SEEMS TO RETURN A PROMISE, THOUGH

    var $deferred = $.Deferred();

    // DO THE LOGIC TO EITHER REJECT OR RESOLVE THE PROMISE

    return $deferred.promise();
}


You only use the main function Load to start the ajax chain. As soon as the first ajax request is done, the second starts with the data of the first one. After that, the successHandler will do whatever is needed with the data of the second ajax call. This is the important addition to your solution.
Apart from that it's basically the same thing you did, but distributed to smaller functions that are easier maintainable.
"
287,287,463,Does this C++ static analysis rule make sense as is?,"I'm implementing some C++ static analysis rules, and one of them prohibits a function from returning a reference or pointer to a reference parameter of the function, i.e. the following are all non-compliant:

int *f(int&amp; x) { return &amp;x; } // #1
const int *g(const int&amp; x) { return &amp;x; } // #2
int&amp; h(int&amp; x) { return x; } // #3
const int&amp; m(const int&amp; x) { return x; } // #4


The justification given for this is that ""It is implementation-defined behaviour whether the reference parameter is a temporary object or a reference to the parameter.""

I'm puzzled by this, however, because stream operators in C++ are written in this way, e.g.

std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const X&amp; x) {
    //...
    return os;
}


I think I'm pretty confident that stream operators in C++ do not in general exhibit implementation-defined behaviour, so what's going on?

According to my understanding as it is at present, I would expect #1 and #3 to be well-defined, on the basis that temporaries cannot be bound to non-const references, so int&amp; x refers to a real object that has lifetime beyond the scope of the function, hence returning a pointer or reference to that object is fine. I would expect #2 to be dodgy, because a temporary could have been bound to const int&amp; x, in which case trying to take its address would seem a bad plan. I'm not sure about #4 - my gut feeling is that that's also potentially dodgy, but I'm not sure. In particular, I'm not clear on what would happen in the following case:

const int&amp; m(const int&amp; x) { return x; }
//...
const int&amp; r = m(23);

",Stuart Golodetz,https://stackoverflow.com/users/499449,"As you say, #1 and #3 are fine (though #1 is arguably bad style).

#4 is dodgy for the same reason #2 is; it allows propagating a const reference to a temporary past its lifetime.

Let's check:

#include &lt;iostream&gt;

struct C {
  C() { std::cout &lt;&lt; ""C()\n""; }
  ~C() { std::cout &lt;&lt; ""~C()\n""; }
  C(const C &amp;) { std::cout &lt;&lt; ""C(const C &amp;)\n""; }
};

const C &amp;foo(const C &amp;c) { return c; }

int main() { 
   const C &amp;c = foo(C());
   std::cout &lt;&lt; ""c in scope\n"";
}


This outputs:

C()
~C()
c in scope

",ecatmur,https://stackoverflow.com/users/567292,http://stackoverflow.com/questions/11538478/does-this-c-static-analysis-rule-make-sense-as-is,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Does this C + + static analysis rule make sense?,"I'm implementing some C++ static analysis rules, and one of them prohibits a function from returning a reference or pointer to a reference parameter of the function, i.e. the following are all non-compliant:

int *f(int&amp; x) { return &amp;x; } // #1
const int *g(const int&amp; x) { return &amp;x; } // #2
int&amp; h(int&amp; x) { return x; } // #3
const int&amp; m(const int&amp; x) { return x; } // #4


The justification given for this is that ""It is implementation-defined behaviour whether the reference parameter is a temporary object or a reference to the parameter.""

I'm puzzled by this, however, because stream operators in C++ are written in this way, e.g.

std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const X&amp; x) {
    //...
    return os;
}


I think I'm pretty confident that stream operators in C++ do not in general exhibit implementation-defined behaviour, so what's going on?

According to my understanding as it is at present, I would expect #1 and #3 to be well-defined, on the basis that temporaries cannot be bound to non-const references, so int&amp; x refers to a real object that has lifetime beyond the scope of the function, hence returning a pointer or reference to that object is fine. I would expect #2 to be dodgy, because a temporary could have been bound to const int&amp; x, in which case trying to take its address would seem a bad plan. I'm not sure about #4 - my gut feeling is that that's also potentially dodgy, but I'm not sure. In particular, I'm not clear on what would happen in the following case:

const int&amp; m(const int&amp; x) { return x; }
//...
const int&amp; r = m(23);

","As you say, #1 and #3 are fine (though #1 is arguably bad style).

#4 is dodgy for the same reason #2 is; it allows propagating a const reference to a temporary past its lifetime.

Let's check:

#include &lt;iostream&gt;

struct C {
  C() { std::cout &lt;&lt; ""C()\n""; }
  ~C() { std::cout &lt;&lt; ""~C()\n""; }
  C(const C &amp;) { std::cout &lt;&lt; ""C(const C &amp;)\n""; }
};

const C &amp;foo(const C &amp;c) { return c; }

int main() { 
   const C &amp;c = foo(C());
   std::cout &lt;&lt; ""c in scope\n"";
}


This outputs:

C()
~C()
c in scope

"
5385,5385,8555,"How can I learn how to lay out an ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
",xenoterracide,https://rpg.stackexchange.com/users/1015,"I can't post this as a comment, but I feel like it's worthy of an answer anyway. it expands on what Bankuei answered about pre-planned scenes. 

Be flexible in your plot

If at all possible, allow the investigators to go at a faster pace than you accounted for. Maybe they figured out where the criminals will strike next before you expected them to, even before the criminals actually strike there. Maybe they decyphered what the big bad is up to at such an early time that they get there before he actually starts a crucial part of his master plan. In that case, avoid the temptation of slowing them down by throwing a couple of not-so-random encounters at them. Players like to think they outsmarted the GM, but don't like it if the GM punishes them for it.

Instead, allow them to halt the big bad before he even gets going. Or let them warn the town watch about the criminals, or even let them go after them themselves. Then, when they're patting themselves on the shoulder, PLOT TWIST! The party gets arrested by the town watch because the watch doesn't know that the esteemed noble is actually a demon. Or the criminals get bailed out and immediately attack the party at their inn.

Or the party is actually completely wrong in their clues. This is a goldmine. Go with the flow. Let the party think they caught a major criminal, while they actually caught a petty thief with no relation to the plot. They think that everything is fixed, but when you then unleash the next part of the plot, they actually realize that there is more to it all.
",Nzall,https://rpg.stackexchange.com/users/11136,http://rpg.stackexchange.com/questions/50671/how-can-i-learn-how-to-lay-out-an-evidence-scene,CULTURE,rpg.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.7777777777777778,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,"How can I learn to set up ""evidence scene""?","I feel like I'm particularly bad at any kind of scene where I want to drop clues. I'm hesitant to use the term ""crime scene"" because it's not always being investigated by ""police"", and some of these times there isn't any kind of typical evidence.

I'm not even 100% sure that my problem is just the scene, but rather creating enough evidence to begin with. Other aspects I struggle with is witnesses - both witnesses with knowledge, and how to reveal it. Having useless witnesses for flavor, etc. I keep feeling that in general I give too little in these scenes, and everything I give is important.

Since I suspect this is a rather broad problem, I'd like to know if there are any Role Playing resources (sections of books, site, etc) that are specifically geared at teaching this portion of RPG storytelling?

I'm currently playing in the ""new"" World of Darkness 2.0, but I want answers on this not tied to the game system's rules.
","I can't post this as a comment, but I feel like it's worthy of an answer anyway. it expands on what Bankuei answered about pre-planned scenes. 

Be flexible in your plot

If at all possible, allow the investigators to go at a faster pace than you accounted for. Maybe they figured out where the criminals will strike next before you expected them to, even before the criminals actually strike there. Maybe they decyphered what the big bad is up to at such an early time that they get there before he actually starts a crucial part of his master plan. In that case, avoid the temptation of slowing them down by throwing a couple of not-so-random encounters at them. Players like to think they outsmarted the GM, but don't like it if the GM punishes them for it.

Instead, allow them to halt the big bad before he even gets going. Or let them warn the town watch about the criminals, or even let them go after them themselves. Then, when they're patting themselves on the shoulder, PLOT TWIST! The party gets arrested by the town watch because the watch doesn't know that the esteemed noble is actually a demon. Or the criminals get bailed out and immediately attack the party at their inn.

Or the party is actually completely wrong in their clues. This is a goldmine. Go with the flow. Let the party think they caught a major criminal, while they actually caught a petty thief with no relation to the plot. They think that everything is fixed, but when you then unleash the next part of the plot, they actually realize that there is more to it all.
"
3896,3896,6206,Would it be a problem if all Amazon links were converted to affiliate links?,"I'm thinking that one way Jeff and the Stack Overflow team could squeeze some extra money out of this site would be to automatically convert all Amazon links posted here into affiliate links, e.g. Stick ""tag=codinghorror-20"" (or more likely a new site-specific tag) onto every Amazon link. This would bring in some additional revenue every time someone purchased a book via a link on this site. 

They could do similar things with other links as well. Amazon's simply the most obvious choice.

So my question is, would anyone have a problem with this?

I know I wouldn't mind, but I don't know how other people would react.

What does everyone think? Is this a horrible idea, a great idea, a waste of time?
",Derek Park,https://meta.stackexchange.com/users/159945,"(Two different respondents said:)


  Amazon affiliate links should be a
  bannable offense. 
  
  I'd post any
  user-generated Amazon referrer link as
  offensive.


Ok, WHY?  

If a person follows the link and buys a book, something is going to happen to the affiliate fee. Either it goes to a SO member, or Amazon keeps it.   

Why is it so vitally important that Amazon keeps it?  Are you stockholders?
",James Curran,https://meta.stackexchange.com/users/143270,http://meta.stackexchange.com/questions/10948/would-it-be-a-problem-if-all-amazon-links-were-converted-to-affiliate-links,TECHNOLOGY,meta.stackexchange.com,1.0,0.7777777777777778,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.5555555555555556,0.4666666666666667,0.0,0.0,0.0,1.0,Would it be a problem if all Amazon links were converted to affiliate links?,"I think one way Jeff and the stack overflow team can squeeze some extra money out of this site is to automatically convert all Amazon links published here into affiliate links, such as ""tag = codinghorror-20"" (or more likely a new site-specific tag) on each Amazon link. This will bring some extra revenue, with one book being purchased each time through a link to the site.","(Two different respondents said:)


  Amazon affiliate links should be a
  bannable offense. 
  
  I'd post any
  user-generated Amazon referrer link as
  offensive.


Ok, WHY?  

If a person follows the link and buys a book, something is going to happen to the affiliate fee. Either it goes to a SO member, or Amazon keeps it.   

Why is it so vitally important that Amazon keeps it?  Are you stockholders?
"
291,291,468,Chaining deferreds,"I have a lot of functions that currently look like this:

function LoadFromURL(url) 
{
    var d = $.Deferred();
    $.get(url).then(function(text)
    {
        LoadFromText(text).then(function(obj)
        {
            d.resolve(obj);
        }, 
        function(err)
        {
            d.reject(err);
        });
    }, 
    function(err)
    {
        d.reject(err);
    });
    return d.promise();
}


This function takes a URL and loads the text within a promise. The text is then passed to the LoadFromText function which returns another promise. If this succeeds, the outer deferred is resolved. If the URL cannot be loaded, or the LoadFromText function fails then the outer deferred is rejected.

Is there a way that I can chain the result of the resolve / reject and end up with something like this:

function LoadFromURL(url) 
{
    return $.get(url).then(function(text)
    {
        return LoadFromText(text);
    }, 
    function(err)
    {
        return $.Deferred().reject(err);
    }).promise();
}


I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used. 

I realise this doesn't work at the moment (the result is the promise, rather than the result of the promise), but hopefully someone can suggest a way to make this work so I can tidy up the sometimes confusing mess of the first example.

I hope this makes sense. Thanks.
",Barguast,https://stackoverflow.com/users/283445,"LoadFromURL will simplify as follows:

function LoadFromURL(url) {
    return $.get(url).then(function(text) {
        return LoadFromText(text);
    });
}


There may be issues you haven't considered ...

Like your original version, the process will tend to recurse indefinitely until the server returns an HTTP error. You would have a slight challenge in writing the server resource appropriately, especially if, as is probable, you need to access the finally delivered text. 

With a little more thought, you could deliver all text in such a way that ""continue"" or ""complete"" is indicated in the text itself, or in an HTTP response code. For example, you could use response code 202 (""Accepted"") to indicate that the process is incomplete. 

I think this will work (with jQuery 1.5+) :

function LoadFromURL(url) {
    return $.get(url).then(function(text, textStatus, jqXHR) {
        if(jqXHR.status === 202) {//continue
            return LoadFromText(text);
        }
        else {//complete
            return text;
        }
    });
}


You just need to arrange for the server to return 202 for ""continue"" or 200 for ""complete"".

Thus, LoadFromURL() could be called as follows :

LoadFromURL('my/resource').then(function(text) {
    console.log(""After a series of $.get requests, the finally delivered text was:\n"" + text);
});

",Beetroot-Beetroot,https://stackoverflow.com/users/1142252,http://stackoverflow.com/questions/17946391/chaining-deferreds,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.0,1.0,0.8888888888888888,Chain extension,"I have a lot of functions that currently look like this:

function LoadFromURL(url) 
{
    var d = $.Deferred();
    $.get(url).then(function(text)
    {
        LoadFromText(text).then(function(obj)
        {
            d.resolve(obj);
        }, 
        function(err)
        {
            d.reject(err);
        });
    }, 
    function(err)
    {
        d.reject(err);
    });
    return d.promise();
}


This function takes a URL and loads the text within a promise. The text is then passed to the LoadFromText function which returns another promise. If this succeeds, the outer deferred is resolved. If the URL cannot be loaded, or the LoadFromText function fails then the outer deferred is rejected.

Is there a way that I can chain the result of the resolve / reject and end up with something like this:

function LoadFromURL(url) 
{
    return $.get(url).then(function(text)
    {
        return LoadFromText(text);
    }, 
    function(err)
    {
        return $.Deferred().reject(err);
    }).promise();
}


I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used. 

I realise this doesn't work at the moment (the result is the promise, rather than the result of the promise), but hopefully someone can suggest a way to make this work so I can tidy up the sometimes confusing mess of the first example.

I hope this makes sense. Thanks.
","LoadFromURL will simplify as follows:

function LoadFromURL(url) {
    return $.get(url).then(function(text) {
        return LoadFromText(text);
    });
}


There may be issues you haven't considered ...

Like your original version, the process will tend to recurse indefinitely until the server returns an HTTP error. You would have a slight challenge in writing the server resource appropriately, especially if, as is probable, you need to access the finally delivered text. 

With a little more thought, you could deliver all text in such a way that ""continue"" or ""complete"" is indicated in the text itself, or in an HTTP response code. For example, you could use response code 202 (""Accepted"") to indicate that the process is incomplete. 

I think this will work (with jQuery 1.5+) :

function LoadFromURL(url) {
    return $.get(url).then(function(text, textStatus, jqXHR) {
        if(jqXHR.status === 202) {//continue
            return LoadFromText(text);
        }
        else {//complete
            return text;
        }
    });
}


You just need to arrange for the server to return 202 for ""continue"" or 200 for ""complete"".

Thus, LoadFromURL() could be called as follows :

LoadFromURL('my/resource').then(function(text) {
    console.log(""After a series of $.get requests, the finally delivered text was:\n"" + text);
});

"
1300,1300,2047,Intersection points of two circles.,"I understand that this is a common question and typically I can solve them, but this one keeps messing me up:

Find the points of intersection (A and B) on the circles $x^2+y^2+4x-10y+20=0$ and $x^2+y^2-4x-2y+12=0$; find the equation of the line $AB$.
",John M,https://math.stackexchange.com/users/96901,"The two given equations, only the first of which is a circle, intersect at infinitely many points, not at just points $A, B$, and those points of intersection lie along a common line. It is never possible that the points of intersection of two circles are all the points on any one line. 

We can see this by solving for the points of intersection of the two equations: Since the left-hand sides of each equation is equal to zero, the left-hand sides are equal to one another. This gives us 

$$\begin{align} x^2+y^2+4x-10y+20 &amp; = x^2+y^2-4x-2y+12\\ \\  \iff 8x-8y+8&amp; =0 \\ \\ \iff y&amp; =x+1.\end{align}$$

So if there were a valid intersection, the ""intersection"" would consist of in this line. Can you see why this can not happen, given the first equation is the equation of a circle? If we had the equations of two circles, they would intersect at nowhere, or at one point (if they were tangent), or at 2 points (overlapping but not concurrent), or else at infinitely many points (if they represented the same circle.) None of those possibilities is met by these two equations. So they cannot define circles. The first does in fact define a circle (graph it to see). The second doesn't (no object has a radius of $\sqrt{-7}$, which occurs with the second equation if you complete the square to obtain the center and radius a circle would have, if it in were a circle.

So I suspect at least the second circle was either mistyped, or is a misprint in the exercises you are working on. 
",amWhy,https://math.stackexchange.com/users/9003,http://math.stackexchange.com/questions/505063/intersection-points-of-two-circles,SCIENCE,math.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,The intersection of two circles.,"I understand that this is a common question and typically I can solve them, but this one keeps messing me up:

Find the points of intersection (A and B) on the circles $x^2+y^2+4x-10y+20=0$ and $x^2+y^2-4x-2y+12=0$; find the equation of the line $AB$.
","The two given equations, only the first of which is a circle, intersect at infinitely many points, not at just points $A, B$, and those points of intersection lie along a common line. It is never possible that the points of intersection of two circles are all the points on any one line. 

We can see this by solving for the points of intersection of the two equations: Since the left-hand sides of each equation is equal to zero, the left-hand sides are equal to one another. This gives us 

$$\begin{align} x^2+y^2+4x-10y+20 &amp; = x^2+y^2-4x-2y+12\\ \\  \iff 8x-8y+8&amp; =0 \\ \\ \iff y&amp; =x+1.\end{align}$$

So if there were a valid intersection, the ""intersection"" would consist of in this line. Can you see why this can not happen, given the first equation is the equation of a circle? If we had the equations of two circles, they would intersect at nowhere, or at one point (if they were tangent), or at 2 points (overlapping but not concurrent), or else at infinitely many points (if they represented the same circle.) None of those possibilities is met by these two equations. So they cannot define circles. The first does in fact define a circle (graph it to see). The second doesn't (no object has a radius of $\sqrt{-7}$, which occurs with the second equation if you complete the square to obtain the center and radius a circle would have, if it in were a circle.

So I suspect at least the second circle was either mistyped, or is a misprint in the exercises you are working on. 
"
2638,2638,4195,The Moon is slowly moving away from the earth. Does this mean that a total solar eclipse wasn't possible at some point in earth's history?,"When the moon was closer to earth, was it still possible to witness a total solar eclipse millions of years ago?  Or was the view-able space so small that it was impractical to even witness it? 
",brant,https://physics.stackexchange.com/users/17270,"The moon is moving away from Earth. So in the past it was closer and its shadow was larger so a wider area experienced a total eclipse.

At some point in the future (in about 0.5 Billion years) a total solar eclipse will no longer be possible because the moon's shadow won't fall on the Earth.
",Martin Beckett,https://physics.stackexchange.com/users/2525,http://physics.stackexchange.com/questions/47829/the-moon-is-slowly-moving-away-from-the-earth-does-this-mean-that-a-total-solar,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.7777777777777778,The moon is slowly leaving the earth. Does this mean that a total solar eclipse is impossible at some point in Earth's history?,Is it still possible to witness a total solar eclipse millions of years ago when the moon is closer to the earth? Or is the viewing space too small to even witness?,"The moon is moving away from Earth. So in the past it was closer and its shadow was larger so a wider area experienced a total eclipse.

At some point in the future (in about 0.5 Billion years) a total solar eclipse will no longer be possible because the moon's shadow won't fall on the Earth.
"
1062,1062,1672,What is output impedance of a pin?,"When a datasheet mentions the output impedance of a pin so and so ohms. What exactly does it mean? Can anybody explain through a diagram how does it look like?
",Durgaprasad,https://electronics.stackexchange.com/users/20352,"Let me start by saying that an output pin (or input pin), by itself, has no impedance. If this was already clear to you, then you know that it has to be between two pins.  It just so happens that the other ""pin"" is ground.  So whenever the impedance of a pin is mentioned, it is commonly known/understood that it is with respect to ground.
What the ""impedance specification"" means, is simply, if you were to take an impedance measurement of the pin to ground, you would obtain the value given.  However, since impedance depends on the frequency used to determine its value, a frequency must also be specified.  If a frequency is not specified, then they are referring only to its resistance and this is the value you obtain if you connect an ohmmeter between the pin and ground.
The diagram provided by Vladimir is the exact model.
",Guill,https://electronics.stackexchange.com/users/46343,http://electronics.stackexchange.com/questions/127046/what-is-output-impedance-of-a-pin,TECHNOLOGY,electronics.stackexchange.com,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,What is the output impedance of the pin?,When the data sheet mentions the output impedance of a pin so ohm. What does that mean? Can anyone use a chart to explain what it looks like?,"Let me start by saying that an output pin (or input pin), by itself, has no impedance. If this was already clear to you, then you know that it has to be between two pins.  It just so happens that the other ""pin"" is ground.  So whenever the impedance of a pin is mentioned, it is commonly known/understood that it is with respect to ground.
What the ""impedance specification"" means, is simply, if you were to take an impedance measurement of the pin to ground, you would obtain the value given.  However, since impedance depends on the frequency used to determine its value, a frequency must also be specified.  If a frequency is not specified, then they are referring only to its resistance and this is the value you obtain if you connect an ohmmeter between the pin and ground.
The diagram provided by Vladimir is the exact model.
"
97,97,158,What does âbupkeâ mean?,"There was the following passage in the New Yorker's (August 27) article titled, âA scandal at the C.I.A. May be.â :


  In January I (David Shafer, novelist) filed a Freedom of Information Act request with the C.I.A., asking for any information relating to my grandfather and Thomas Whittemore and the events of June 1950. They took two months to give me bupkes. But to give me bupkes, they were required to invoke a FOIA exemption, and the exemption that C.I.A. involved were (b)(3), which means the records are protected by another federal statute, and (b)(1) ---


Though I was unable to find the definition of âbupkeâ in OED (10th ed.), OALD (2000), and Collins Cobuild (4th ed.) at hand, I happened to find its definition at bageldrive.com, which says âbupkeâ is;


  A mini-bagel deliciously baked to perfection with fully functional USB 2.0 flash memory and a shmeer. Itâs the worldâs first electronic bagel. The Bagel Drive is ideal for storing files, photos, video, music and all of your digital tchochkes.ãThe site also shows photos of USB attached to plastic bagel models.


What does bupke mean? Is it a flash memory in a bagel shape as described in bagldrive com.? Does it pass as the generic term of flash memory? 

Beside, I wonder why CIA takes bother of using such a funky shape of all flash memories to provide data to the requester.
",Yoichi Oishi,https://english.stackexchange.com/users/3119,"Bupkis/bupki/bupke is slang for ""nothing.""  It's not in much use in the modern vernacular.

http://www.oxforddictionaries.com/us/definition/american_english/bupkis
",Bob Stout,https://english.stackexchange.com/users/71774,http://english.stackexchange.com/questions/193855/what-does-bupke-mean,CULTURE,english.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,"What does ""bupke"" mean?","There was the following passage in the New Yorker's (August 27) article titled, âA scandal at the C.I.A. May be.â :


  In January I (David Shafer, novelist) filed a Freedom of Information Act request with the C.I.A., asking for any information relating to my grandfather and Thomas Whittemore and the events of June 1950. They took two months to give me bupkes. But to give me bupkes, they were required to invoke a FOIA exemption, and the exemption that C.I.A. involved were (b)(3), which means the records are protected by another federal statute, and (b)(1) ---


Though I was unable to find the definition of âbupkeâ in OED (10th ed.), OALD (2000), and Collins Cobuild (4th ed.) at hand, I happened to find its definition at bageldrive.com, which says âbupkeâ is;


  A mini-bagel deliciously baked to perfection with fully functional USB 2.0 flash memory and a shmeer. Itâs the worldâs first electronic bagel. The Bagel Drive is ideal for storing files, photos, video, music and all of your digital tchochkes.ãThe site also shows photos of USB attached to plastic bagel models.


What does bupke mean? Is it a flash memory in a bagel shape as described in bagldrive com.? Does it pass as the generic term of flash memory? 

Beside, I wonder why CIA takes bother of using such a funky shape of all flash memories to provide data to the requester.
","Bupki s / bupki / bupke is slang for ""nothing"", which is not very useful in modern vernacular."
3297,3297,5259,Is the intersection of two star-shaped sets star-shaped?,"Is the intersection of two star-shaped sets star-shaped?

I don't think so but can't think of an example.
",user24883,https://math.stackexchange.com/users/24883,"Yes, it can be. 

No, it does not have to be.


",Henry,https://math.stackexchange.com/users/6460,http://math.stackexchange.com/questions/200152/is-the-intersection-of-two-star-shaped-sets-star-shaped,SCIENCE,math.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.6666666666666667,0.0,0.0,0.0,0.8888888888888888,Is the intersection of two stars star shaped?,"Is the intersection of two star-shaped sets star-shaped?

I don't think so but can't think of an example.
","Yes, it can be. 

No, it does not have to be.


"
1774,1774,2817,Where is the Atiyah-Singer index theorem used in physics?,"I'm trying to get motivated in learning the Atiyah-Singer index theorem.  In most places I read about it, e.g. wikipedia, it is mentioned that the theorem is important in theoretical physics.  So my question is, what are some examples of these applications?
",Eric,https://physics.stackexchange.com/users/37,"In the case of a Dirac operator, the index is the (signed) excess dimension of the space of vacuum modes of one chirality w/r/t the other: i.e., the number of anomalous âghostâ states in a chiral field theory.

Anomalies arise when the classical/quantum symmetry correspondence breaks down under renormalization (a global anomaly could be responsible for quark mass in QCD; resolving the local chiral anomaly in the SM accounts for quarks and leptons; resolving it in superstring theory fixes the gauge group [to either SO(32) or E8 x E8], and the resolution of a conformal anomaly fixes the dimension of spacetime and the fermion content). When trying to turn string theory into actual physics, one asks 


Can it explain three generations of chiral fermions? 
Can it explain the experimental results on proton decay?
Can it explain the smallness of the electron mass? 
Can it explain [things about the cosmological constant]?


and AST helps to answer these questions.
",S Huntsman,https://physics.stackexchange.com/users/711,http://physics.stackexchange.com/questions/1858/where-is-the-atiyah-singer-index-theorem-used-in-physics,SCIENCE,physics.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,Where is the Attica singer index theorem used in physics?,"I'm trying to learn the Atiyah singer index theorem. In most places I read, such as Wikipedia, theorems are important in theoretical physics. So my question is, what are some examples of these applications?","In the case of a Dirac operator, the index is the (signed) excess dimension of the space of vacuum modes of one chirality w/r/t the other: i.e., the number of anomalous âghostâ states in a chiral field theory.

Anomalies arise when the classical/quantum symmetry correspondence breaks down under renormalization (a global anomaly could be responsible for quark mass in QCD; resolving the local chiral anomaly in the SM accounts for quarks and leptons; resolving it in superstring theory fixes the gauge group [to either SO(32) or E8 x E8], and the resolution of a conformal anomaly fixes the dimension of spacetime and the fermion content). When trying to turn string theory into actual physics, one asks 


Can it explain three generations of chiral fermions? 
Can it explain the experimental results on proton decay?
Can it explain the smallness of the electron mass? 
Can it explain [things about the cosmological constant]?


and AST helps to answer these questions.
"
1322,1322,2087,"Origin and meaning of ""The eagle flies at midnight""","
  The eagle flies at midnight.


What's the origin and meaning of this idiom?
",Anderson Silva,https://english.stackexchange.com/users/1446,"It's one of the stereotypical spy code phrases used in bad and/or spoof movies. I've seen it credited to Top Secret, but not having seen that movie, I can't vouch for the assertion.

I've also seen it as ""the rooster crows at midnight"", or ""the eagle flies at noon"". Alas, my Google-fu is not up to finding a definitive source.
",MarthaÂª,https://english.stackexchange.com/users/1547,http://english.stackexchange.com/questions/5305/origin-and-meaning-of-the-eagle-flies-at-midnight,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.5333333333333333,0.0,0.0,1.0,0.8888888888888888,"The origin and significance of ""flying Nighthawk""","
  The eagle flies at midnight.


What's the origin and meaning of this idiom?
","It's one of the stereotypical spy code phrases used in bad and/or spoof movies. I've seen it credited to Top Secret, but not having seen that movie, I can't vouch for the assertion.

I've also seen it as ""the rooster crows at midnight"", or ""the eagle flies at noon"". Alas, my Google-fu is not up to finding a definitive source.
"
5247,5247,8344,Is there a way to fill your tires with nitrogen?,"I know this is a rather controversial issue. I was skeptical as well before doing this on my car, and I have not refilled my car tires for several months. Before that I needed to adjust the pressure every couple of months at least. 

Now I think it is a good idea to try this for our bikes. Especially since, when I see I need to fill up my bike tires, I get too lazy and give up the ride altogether. 

Is there a way to do this at home?

EDIT:
I thought I'd update the question for people who come and read later:  

Thanks for all the comments, I drive a lot (30kmiles/year) and I saw (to my surprise) a significant difference with nitrogen. 

I understand the reasoning with losing oxygen over time and increasing the N2 concentration but in practice that does not happen fast enough.  

I think I'll look into Helium/Argon and I'll update you if I managed to do something interesting. 

And I live in a small place I don't like to have a large pump but that is exactly why pumping is such a chore for me,
",Ali,https://bicycles.stackexchange.com/users/1924,"There is and I have done it with the same setup. I am a diver by trade and I experimented with the same setup. I used a SCUBA bottle and set the regulators with my calibration equipment. I got it to work but it the only value I got from it was knowing that it could be done. The Nâ was expensive, at least compared to air. The SCUBA regulators were expensive and they needed to be precisely set. Calibration is usually not accurate to 1PSI, which you would need. I also didn't want to haul the whole heavy potentially dangerous HP gas setup around with me. 

I dove with He on several occasions. That is even more of a hassle. The whole system would leak no matter what. It was because the Helium molecules are so small they can pass through cracks of pipe fittings no matter how tight the fittings were. 
",Josh Smith,https://bicycles.stackexchange.com/users/6474,http://bicycles.stackexchange.com/questions/16001/is-there-a-way-to-fill-your-tires-with-nitrogen,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,1.0,Is there any way to nitrogen your tires?,"I know this is a rather controversial issue. I was skeptical as well before doing this on my car, and I have not refilled my car tires for several months. Before that I needed to adjust the pressure every couple of months at least. 

Now I think it is a good idea to try this for our bikes. Especially since, when I see I need to fill up my bike tires, I get too lazy and give up the ride altogether. 

Is there a way to do this at home?

EDIT:
I thought I'd update the question for people who come and read later:  

Thanks for all the comments, I drive a lot (30kmiles/year) and I saw (to my surprise) a significant difference with nitrogen. 

I understand the reasoning with losing oxygen over time and increasing the N2 concentration but in practice that does not happen fast enough.  

I think I'll look into Helium/Argon and I'll update you if I managed to do something interesting. 

And I live in a small place I don't like to have a large pump but that is exactly why pumping is such a chore for me,
","Yes, I did it the same way. I am a professional diver, and I have done the same experiment. I used a water lung bottle and set the regulator with my calibration device. I let it work, but the only value I get from it is knowing it can be done. Nitrogen is expensive, at least compared to air. Aqualung regulators are expensive and need to be set accurately. Calibration is usually not accurate to 1psi, which is what you need. I don't want to bring all the high-pressure gases that may be dangerous."
5067,5067,8060,ASP.NET MVC Update part of the model,"I have very complex model. The flow is like this:
- in controller I populate the model from the database
- in view I have several tabs. After I fill in the info on the first tab, the second tab enables (this works just fine) and on click on the second tab button I need to update some properties of the model. How can I do this WITHOUT calling the database again in order to populate the model on the controller? The model is very complex, so I can't store as ""hidden"" all the properties.  

I hope I managed to be clear enough. 
Thanks for any kind of help
",Sandra S.,https://stackoverflow.com/users/1685352,"Use a JSON object that mimics your model and update it when user clicks on different tab or whatever. When Client-side update/manipulation is done, use AJAX to submit your JSON object to the controller. Here is how you can do this on a button click (you can change it to whatever is clicked):

    &lt;script src=""../../Scripts/json2.js"" type=""text/javascript""&gt;&lt;/script&gt;
    &lt;input type=""button"" value=""Partially Update my Model"" onclick=""UpdateYourModel()"" /&gt;
        &lt;input type=""button"" value=""Save to Database"" onclick=""SaveToDataBase""/&gt;
        &lt;script type=""text/javascript""&gt;
            // Create YourModel Json Object including child objects in it.
             var childObject={""ChildId"": """",""ChildDescription"":""""};
//The array name (childObjects) should match the collection name in your actual Model
            var yourModel= { ""ModelId"": """", ""Description"": """",""childObjects[]"":""""  }; 


        function UpdateYourModel() {
        //update the childObject first
          childObject.ChildId=1;//any value from anywhere
          childObject.ChildDescription=""any value"";

        // Update the model
           yourModel.ModelId= $(""#ModelId"").val();
           yourModel.Description=""This property was changed at client side"";
           yourModel.childObjects.push(childObject);//add child object to yourModel

        //Likewise, update other properties of yourModel

        }//function ends here

        function SaveToDataBase()
        {
        $.ajax({
                    url: ""URL to your controller"",
                    data: JSON.stringify(yourModel),
                    type: 'POST',
                    contentType: 'application/json;',
                    dataType: 'json',
                    success: function (result) {
                     alert(""Success"");

                    }
                });
        }
        &lt;/script&gt;

",Bishnu Paudel,https://stackoverflow.com/users/834844,http://stackoverflow.com/questions/14326382/asp-net-mvc-update-part-of-the-model,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Asp.net MVC update part of the model,"I have very complex model. The flow is like this:
- in controller I populate the model from the database
- in view I have several tabs. After I fill in the info on the first tab, the second tab enables (this works just fine) and on click on the second tab button I need to update some properties of the model. How can I do this WITHOUT calling the database again in order to populate the model on the controller? The model is very complex, so I can't store as ""hidden"" all the properties.  

I hope I managed to be clear enough. 
Thanks for any kind of help
","Use a JSON object that mimics your model and update it when user clicks on different tab or whatever. When Client-side update/manipulation is done, use AJAX to submit your JSON object to the controller. Here is how you can do this on a button click (you can change it to whatever is clicked):

    &lt;script src=""../../Scripts/json2.js"" type=""text/javascript""&gt;&lt;/script&gt;
    &lt;input type=""button"" value=""Partially Update my Model"" onclick=""UpdateYourModel()"" /&gt;
        &lt;input type=""button"" value=""Save to Database"" onclick=""SaveToDataBase""/&gt;
        &lt;script type=""text/javascript""&gt;
            // Create YourModel Json Object including child objects in it.
             var childObject={""ChildId"": """",""ChildDescription"":""""};
//The array name (childObjects) should match the collection name in your actual Model
            var yourModel= { ""ModelId"": """", ""Description"": """",""childObjects[]"":""""  }; 


        function UpdateYourModel() {
        //update the childObject first
          childObject.ChildId=1;//any value from anywhere
          childObject.ChildDescription=""any value"";

        // Update the model
           yourModel.ModelId= $(""#ModelId"").val();
           yourModel.Description=""This property was changed at client side"";
           yourModel.childObjects.push(childObject);//add child object to yourModel

        //Likewise, update other properties of yourModel

        }//function ends here

        function SaveToDataBase()
        {
        $.ajax({
                    url: ""URL to your controller"",
                    data: JSON.stringify(yourModel),
                    type: 'POST',
                    contentType: 'application/json;',
                    dataType: 'json',
                    success: function (result) {
                     alert(""Success"");

                    }
                });
        }
        &lt;/script&gt;

"
3175,3175,5058,"Do we say ""shabbat shalom"" on Tisha b'Av that falls on Shabbat?","Yesterday I said ""shabbat shalom"" to someone and he said we don't do that on Tisha b'Av that falls on Shabbat.  I thought that Shabbat trumps the day (and that's why we move the other observances).  Neither of us knew a source, and it hasn't come up yet in 9 be-Av on Shabbos .
",Monica Cellio,https://judaism.stackexchange.com/users/472,"The Shulchan Aruch (i will try to find the exact place) says that on a shabbos thats also tisha b'av you should mour n for the bais hamikdash b'tzinah (privately) verbally not saying good shabbos/shabbat shalom is not exactly private and he was doing it because the day was tisha b'av. Although he might have a special minhag (custom) to not say good shabbos/shabbat shalom, you might want to ask your friend about that.
",MosheY,https://judaism.stackexchange.com/users/1745,http://judaism.stackexchange.com/questions/18128/do-we-say-shabbat-shalom-on-tisha-bav-that-falls-on-shabbat,CULTURE,judaism.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,1.0,0.8333333333333334,"We mean ""Sabah Sharon"" landed on Sabah at Tisha B'Av?","Yesterday I said ""Sabat Salon"" to someone who said we would not do that to Tisha BAFF who fell on Sabat. I think Sabat is better than today (that's why we move other commemorations). Neither of us knows the source, and it hasn't appeared in the 9th episode of the youth party.","The Shulchan Aruch (i will try to find the exact place) says that on a shabbos thats also tisha b'av you should mour n for the bais hamikdash b'tzinah (privately) verbally not saying good shabbos/shabbat shalom is not exactly private and he was doing it because the day was tisha b'av. Although he might have a special minhag (custom) to not say good shabbos/shabbat shalom, you might want to ask your friend about that.
"
1603,1603,2520,Fetching All Posts (200+) in a Category - Performance Issues?,"I want to get the IDs of the 2 previous and 2 next articles in a certain category to show them as a ""related videos"" playlist. I know that there are the functions previous_post_link and next_post_link, which would do the job for me, but I want more than just 1 previous and 1 next link.

Imagine the following scenario:


Post #001
Post #002
Post #003
Post #004
Post #005
Post #006


On Post #001 I want to display #002 and #003.
On Post #003 I want to display #001, #002, #004 and #005.

$post_id = $post-&gt;ID; // current post id

$args = array('category' =&gt; $mycat, 'numberposts' =&gt; 200);
$posts = get_posts($args);
// get ids of posts retrieved from get_posts
$ids = array();
foreach ($posts as $thepost) {
    $ids[] += $thepost-&gt;ID;
}
// get and echo previous and next post in the same category
$thisindex = array_search($post-&gt;ID, $ids);
$prevvid = $ids[$thisindex-2];
$previd = $ids[$thisindex-1];
$nextid = $ids[$thisindex+1];
$nexttid = $ids[$thisindex+2];


I adapted and changed this code from the Wordpress Codex.

And now the part that worries me: If I don't add a large number to numberposts, it will of course only fetch the standard amount of posts and therefore my code won't work the way I want it. I probably will never ever have more than 200 videos in one category. Do you think my solution is a bad idea regarding performance? I didn't find a trick elsewhere to show the adjacent posts.

Thanks in advance for any advice!
",Schilling,https://wordpress.stackexchange.com/users/64986,"If you want to query for a large set of posts, but don't need full information for each you can use 'fields' =&gt; 'ids'm see Return Fields Parameter.

In this case, I concur with comment, it might make more sense to simply retrieve adjacent post several times. You'll have to use setup_postdata() and wp_reset_postdata() since get_adjacent_post() doesn't allow you to set post explicitly. Unfortunately that function isn't too friendly to reuse or make use of SQL it generates.
",Rarst,https://wordpress.stackexchange.com/users/847,http://wordpress.stackexchange.com/questions/172620/fetching-all-posts-200-in-a-category-performance-issues,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Get all posts in a category (200 +) - performance issues?,"I want to get the IDs of the 2 previous and 2 next articles in a certain category to show them as a ""related videos"" playlist. I know that there are the functions previous_post_link and next_post_link, which would do the job for me, but I want more than just 1 previous and 1 next link.

Imagine the following scenario:


Post #001
Post #002
Post #003
Post #004
Post #005
Post #006


On Post #001 I want to display #002 and #003.
On Post #003 I want to display #001, #002, #004 and #005.

$post_id = $post-&gt;ID; // current post id

$args = array('category' =&gt; $mycat, 'numberposts' =&gt; 200);
$posts = get_posts($args);
// get ids of posts retrieved from get_posts
$ids = array();
foreach ($posts as $thepost) {
    $ids[] += $thepost-&gt;ID;
}
// get and echo previous and next post in the same category
$thisindex = array_search($post-&gt;ID, $ids);
$prevvid = $ids[$thisindex-2];
$previd = $ids[$thisindex-1];
$nextid = $ids[$thisindex+1];
$nexttid = $ids[$thisindex+2];


I adapted and changed this code from the Wordpress Codex.

And now the part that worries me: If I don't add a large number to numberposts, it will of course only fetch the standard amount of posts and therefore my code won't work the way I want it. I probably will never ever have more than 200 videos in one category. Do you think my solution is a bad idea regarding performance? I didn't find a trick elsewhere to show the adjacent posts.

Thanks in advance for any advice!
","If you want to query for a large set of posts, but don't need full information for each you can use 'fields' =&gt; 'ids'm see Return Fields Parameter.

In this case, I concur with comment, it might make more sense to simply retrieve adjacent post several times. You'll have to use setup_postdata() and wp_reset_postdata() since get_adjacent_post() doesn't allow you to set post explicitly. Unfortunately that function isn't too friendly to reuse or make use of SQL it generates.
"
4355,4355,6930,How is range measured in League of Legends?,"I know different games use different techniques and units of measurement. In Starcraft II one range for attack is about the width of one zergling. In Guild Wars the range is some fraction of the compass or aggro range (Spears have ~0.7x aggro range, longbows ~1.2x)

Most (or all?) meelee champions in LoL have an attack range of 125. The attack radius for range champions differs quite a bit, e.g. 425 for Urgot, 510 for Twisted Fate and 550 for Heimerdinger. 

I wonder how is range exactly measured in League of Legends?
",fschl,https://gaming.stackexchange.com/users/1400,"I can't tell you exactly how much a unit is on the screen, there are however quite a few ways to get an idea of what different range represent.

A ""distance unit"" is a predefined distance on the field of justice. Range and speed are calculated from this unit.

Movement speed

Movement speed is the amount of ""distance units"" you travel in one second

Spell range

There are many spells with many different ranges. To get an idea of the range it represents, put you mouse over the spell and a circle will show you the range it represents. Here is an example for Kassadin's null sphere with a range of 700 :


Auto-attack range

There isn't anything that can show you directly the range you have. You have to get use to it and compare it with your spells range to get a good idea.

To get an idea of what 125 represents, Nunu's consume has a range of 125 :

",Dalshim,https://gaming.stackexchange.com/users/11339,http://gaming.stackexchange.com/questions/33630/how-is-range-measured-in-league-of-legends,CULTURE,gaming.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.7777777777777778,How to measure the range of legendary League?,"I know that different games use different techniques and units of measurement. In StarCraft II, an attack range is about the width of a Zerg. In guild war, the range is part of the range of a compass or bow (the range of a spear is about 0.7 times, the range of a bow is about 1.2 times)","I can't tell you exactly how much a unit is on the screen, there are however quite a few ways to get an idea of what different range represent.

A ""distance unit"" is a predefined distance on the field of justice. Range and speed are calculated from this unit.

Movement speed

Movement speed is the amount of ""distance units"" you travel in one second

Spell range

There are many spells with many different ranges. To get an idea of the range it represents, put you mouse over the spell and a circle will show you the range it represents. Here is an example for Kassadin's null sphere with a range of 700 :


Auto-attack range

There isn't anything that can show you directly the range you have. You have to get use to it and compare it with your spells range to get a good idea.

To get an idea of what 125 represents, Nunu's consume has a range of 125 :

"
621,621,977,Spring security - Access to a controller method based on an attribute,"I'm configuring Spring Security across all my controllers.
I want some method executions to start only when ""my system is enabled"". This information is accessible from all over the controllers via a specific static method (I can make it non-static).
My point is that I want to avoid making an explicit check in java code at the beginning of every method.
How can I get there via Spring Security?
",Manu,https://stackoverflow.com/users/1490144,"You can use SPEL (Spring Expression Language) in a security annotation. 

See http://static.springsource.org/spring-security/site/docs/3.0.x/reference/el-access.html
",GreyBeardedGeek,https://stackoverflow.com/users/982341,http://stackoverflow.com/questions/15514170/spring-security-access-to-a-controller-method-based-on-an-attribute,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.0,0.0,0.8888888888888888,Spring security - property based access controller method,"I'm configuring Spring Security across all my controllers.
I want some method executions to start only when ""my system is enabled"". This information is accessible from all over the controllers via a specific static method (I can make it non-static).
My point is that I want to avoid making an explicit check in java code at the beginning of every method.
How can I get there via Spring Security?
","You can use SPEL (Spring Expression Language) in a security annotation. 

See http://static.springsource.org/spring-security/site/docs/3.0.x/reference/el-access.html
"
1635,1635,2565,"What is the Goal of ""Hot Network Questions""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
",jmac,https://meta.stackexchange.com/users/209637,"TL;DR: What else are we expected to vote down and close at Workplace and Programmers?

After discovering that one of the answers reflects my own position quite closely I wasn't going to go out on a limb but since a suggestion was made...


  ...Guess what: if your site is full of crappy questions, your site sucks - even if they're not highly-ranked by your own users, folks are finding them via Google, and that's where the vast majority of your readers are coming from. You can work to fix that - as painful as that process is - or you can bury your head in the sand and blame it on all of those stupid people from elsewhere. If you think ""hot"" questions are a serious problem for your site's quality, then you're already ignoring a much bigger problem. Blaming someone else is easy and fun for the whole family - but it doesn't fix anything.


...I would like to address that.

I participate in two sites that suffer from overly hot questions: Programmers and Workplace. In my experience, communities at these sites close inappropriate questions pretty fast, which wipes them from hot list and makes it not an issue.

Questions that really suffer from senseless over-exposure are reasonable ones, those that match site quality requirements and don't deserve closure, nor even downvotes, neither from passers by nor from community regulars.

The only remaining way to ""fix"" these questions, if one takes above suggestion seriously, is to cast unfair down and close votes. However pragmatic it may sound, I believe that this is a fundamentally wrong way, as it suggests bending community morale as a workaround for feature that just poorly implements specification.



Frankly, I feel quite embarrassed to see this suggested by a community manager. It feels like being told by a police officer ""hey it's your fault of being robbed because you did't carry AK-47"".

Oh and please spare me of extending this analogy to mumbling about dangerous districts, abandoned by law, where one would better enter armed. If a particular district of Stack Exchange City turns out broken and abandoned, there are known ways to stop the disorder and add a discipline, without letting the damage spread over and promote itself in the hot news.
",gnat,https://meta.stackexchange.com/users/165773,http://meta.stackexchange.com/questions/219922/what-is-the-goal-of-hot-network-questions,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.6666666666666666,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8333333333333334,0.8333333333333334,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,"What is the goal of ""network hot issues""?","There has been a tug-of-war in the hot-questions list.

Community members like JonW seem to be unhappy with the traffic that it brings to their site:


  'But we want to encourage people to post, that's the whole point of the HQ list!' I hear you cry. I disagree. We want to encourage people to the site not just to that question.


The SE Community Team seems to have a different opinion as Shog9 points out (emphasis mine):


  the results have been... Not great so far: a significantly smaller number of people are clicking through to randomly-selected questions than to the top questions, which hints that the algorithm may've been doing a better job of identifying general-interest questions across topics than some expected.


Disclaimer: This should not be taken as a slight of the community team whatsoever, nor do I think this is some cause for revolt or a boxing match as the below prose may indicate. These are just poorly applied literary tools to emphasize the drastically different approaches to the same list between two groups.

In the Red Corner, the Community Members

The goal of the hot questions should be to drive up interest in the site. The hot questions should be a lure to encourage SE network users to contribute to other content, not just do a drive-by on the hot question.

In the Blue Corner, the Community Team

The goal of the hot questions should be to drive traffic to general-interest questions. After all, the Hot Network Questions used to be more accurately named as ""Popular Questions"".

What is the Goal of Advertising Network Questions?

Before discussing how to calculate hotness, or how the list should be ordered, we need to come to an agreement on what the heck we are actually trying to achieve. Once we know what we are looking to accomplish, we can find the best way to do that.

The list of questions from a variety of sites is in a great location screen-wise, it is readily accessible and does get a lot of eyes on it. But as with any marketing, the goal isn't just to grab eyes, it's to grab the right eyes.*

* I have nothing against left eyes. Most of my friends have left eyes too. And they are awesome. But in the context right eyes are not a geospatial thing, but rather in the 'correct' sense.

So what are the right eyes? What type of people do we want to attract to our site? What would we determine as 'success'? How can we measure that success?

Please do not limit yourself to the very narrowly scoped topic above. Think outside the box if you'd like. On every page across the network we have a nice piece of real estate for showing off the rest of the network. How can that space best be used if not on a list of questions picked by an arbitrary algorithm?
","TL;DR: What else are we expected to vote down and close at Workplace and Programmers?

After discovering that one of the answers reflects my own position quite closely I wasn't going to go out on a limb but since a suggestion was made...


  ...Guess what: if your site is full of crappy questions, your site sucks - even if they're not highly-ranked by your own users, folks are finding them via Google, and that's where the vast majority of your readers are coming from. You can work to fix that - as painful as that process is - or you can bury your head in the sand and blame it on all of those stupid people from elsewhere. If you think ""hot"" questions are a serious problem for your site's quality, then you're already ignoring a much bigger problem. Blaming someone else is easy and fun for the whole family - but it doesn't fix anything.


...I would like to address that.

I participate in two sites that suffer from overly hot questions: Programmers and Workplace. In my experience, communities at these sites close inappropriate questions pretty fast, which wipes them from hot list and makes it not an issue.

Questions that really suffer from senseless over-exposure are reasonable ones, those that match site quality requirements and don't deserve closure, nor even downvotes, neither from passers by nor from community regulars.

The only remaining way to ""fix"" these questions, if one takes above suggestion seriously, is to cast unfair down and close votes. However pragmatic it may sound, I believe that this is a fundamentally wrong way, as it suggests bending community morale as a workaround for feature that just poorly implements specification.



Frankly, I feel quite embarrassed to see this suggested by a community manager. It feels like being told by a police officer ""hey it's your fault of being robbed because you did't carry AK-47"".

Oh and please spare me of extending this analogy to mumbling about dangerous districts, abandoned by law, where one would better enter armed. If a particular district of Stack Exchange City turns out broken and abandoned, there are known ways to stop the disorder and add a discipline, without letting the damage spread over and promote itself in the hot news.
"
218,218,350,Illustrator ctrl-drag to snap to path: how to make it default?,"How do I make ctrl-dragging (to snap to other paths) the default way of dragging in Adobe Illustrator cs6 -- without pressing any key? I recently upgraded from Illustrator cs3 to cs6, and I had this behaviour in cs3. And I'm missing it.
",Vincent,https://graphicdesign.stackexchange.com/users/5498,"Snapping has nothing to do with the Ctrl key, at least not in Illustrator. Items either snap or not based on preferences and view menu settings. The Ctrl (or Command for Mac users) does not alter snap behavior in any way, never has in Illustrator. I sorely wish it did.

You may need to turn on Snap to Point, Snap to Grid, or Smart Guides in the View Menu and ensure the snap distance in the preferences is set how you want it.

My guess would be you simply need to turn on Smart Guides.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/13841/illustrator-ctrl-drag-to-snap-to-path-how-to-make-it-default,LIFE_ARTS,graphicdesign.stackexchange.com,0.6666666666666666,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.3333333333333333,1.0,Illustrator Ctrl drag to snap to path: how do I set it as the default?,"In Adobe Illustrator CS6, how to make Ctrl dragging the default drag method without pressing any key? I recently upgraded from illustrator CS3 to CS6, and I have this behavior in CS3. I missed it.","Capture has nothing to do with the CTRL key, at least not in illustrator. Project snap or not based on preferences and view menu settings. CTRL (or a Mac user's command) does not change the snapshot behavior in any way, never in illustrator. I wish it was."
3380,3380,5390,What is the best way for a user to select an item by unique identifier?,"My team and I are building a mobile app where the user will need to input a human-readable unique identifier (the serial number) of a single unit of inventory. Our system tracks the serial numbers that the user can access. We have considered three possible input modes:

1. We show the user the entire list of serial numbers they can access and allow him to select one from the list (like how a select element would work on an HTML page).

Pros:


The user doesn't have to type anything in.
The user can't enter an invalid serial number.


Cons:


The list is likely to be overwhelmingly large.
The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Data usage for downloading the entire list of serial numbers


2. We allow the user to start entering the serial number in a text input and have an auto-suggest drop-down with a filtered list of serial numbers the user can access.

Pros:


The user doesn't have to type in a complete serial number.
The user is unlikely to enter an invalid serial number.
Smaller list to choose from than Option 1.


Cons:


The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Auto-suggest may have limited value since the unit has a barcode that we could read.
Data usage for downloading a sizable list of serial numbers


3. We require the entire serial number to be entered, and once we recognize the correct number of characters, we validate the serial number against the user's accessible list and show feedback.

Pros:


The unit has a barcode that we could read, so this has the potential to be simpler than an auto-suggest or select-from-list paradigm.
Simpler implementation
Significantly reduced data usage vs. Option 1 and Option 2


Cons:


The unit has multiple barcodes, so it might take a couple of tries for the user to capture the correct one.
Typing manually would be tedious if the camera is unavailable or barcode scanner isn't working for whatever reason (lighting, etc.)


Which of these three is the best approach? Is there a better approach than what we have considered?
",Nick Saunders,https://ux.stackexchange.com/users/50391,"Let's face it, serial numbers weren't meant to be consumed by humans.  Can you imagine going to the grocery store and waiting for someone to manually enter each and every bar code number for all your items?

In your situation I think option 3 is your best bet but I don't see why you couldn't combine option 3 with option 2.  If the bar code scanner is failing for any reason the user can at least get auto-complete help while falling back to entering the string of digits manually.

Don't prevent the user from entering an invalid number but do provide instant feedback when the input string isn't valid.
",DaveAlger,https://ux.stackexchange.com/users/58111,http://ux.stackexchange.com/questions/77187/what-is-the-best-way-for-a-user-to-select-an-item-by-unique-identifier,TECHNOLOGY,ux.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,0.3333333333333333,1.0,What is the best way for users to select items by unique identifier?,"My team and I are building a mobile app where the user will need to input a human-readable unique identifier (the serial number) of a single unit of inventory. Our system tracks the serial numbers that the user can access. We have considered three possible input modes:

1. We show the user the entire list of serial numbers they can access and allow him to select one from the list (like how a select element would work on an HTML page).

Pros:


The user doesn't have to type anything in.
The user can't enter an invalid serial number.


Cons:


The list is likely to be overwhelmingly large.
The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Data usage for downloading the entire list of serial numbers


2. We allow the user to start entering the serial number in a text input and have an auto-suggest drop-down with a filtered list of serial numbers the user can access.

Pros:


The user doesn't have to type in a complete serial number.
The user is unlikely to enter an invalid serial number.
Smaller list to choose from than Option 1.


Cons:


The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Auto-suggest may have limited value since the unit has a barcode that we could read.
Data usage for downloading a sizable list of serial numbers


3. We require the entire serial number to be entered, and once we recognize the correct number of characters, we validate the serial number against the user's accessible list and show feedback.

Pros:


The unit has a barcode that we could read, so this has the potential to be simpler than an auto-suggest or select-from-list paradigm.
Simpler implementation
Significantly reduced data usage vs. Option 1 and Option 2


Cons:


The unit has multiple barcodes, so it might take a couple of tries for the user to capture the correct one.
Typing manually would be tedious if the camera is unavailable or barcode scanner isn't working for whatever reason (lighting, etc.)


Which of these three is the best approach? Is there a better approach than what we have considered?
","Let's face it, serial numbers weren't meant to be consumed by humans.  Can you imagine going to the grocery store and waiting for someone to manually enter each and every bar code number for all your items?

In your situation I think option 3 is your best bet but I don't see why you couldn't combine option 3 with option 2.  If the bar code scanner is failing for any reason the user can at least get auto-complete help while falling back to entering the string of digits manually.

Don't prevent the user from entering an invalid number but do provide instant feedback when the input string isn't valid.
"
972,972,1540,How can I use an SVG image as a map marker in OpenLayers-3?,"I am trying to create map ""pin-drops"" (ie. map markers) in OpenLayers-3 (OL3) using SVG images.

Currently, I am using PNG images as the pindrops that reference the ol.style.Icon source (âsrcâ) property attribute just fine. However, this fails using an SVG image. Is there some other way to use an SVG in the same manner? Maybe by using a reference besides ol.style.Icon even? There is already a lot of built-in SVG in Open Layers so this should be possible, but I haven't found a way to get this working in OL3. Is there some other way to do this in OL3 that I should consider?

Please note: we already tried using an ol.Vector layer, however when the user zooms in/out, the size of the SVG image grows/shrinks which is an inadequate workaround.



OL3 (fails): 

var createMapMarkerImage = function() {
    return function(feature, resolution) {
        var iconStyle = new ol.style.Style({
            image: new ol.style.Icon( ({
                src: 'img/map_pindrop.svg'   // OL3 doesnât like this, but accepts a .PNG just fine
            }))
        });
        return [iconStyle];
    };
};


Very similar functionality, is the below example I found online, is almost perfect if it werenât for the fact that the example uses OpenLayers-2 (OL2) functionality which calls openlayers.js library (instead of OL3âs ol.js library). Sadly, swapping these javascript files out fails.



OL2 (works -but is the old OL library):

http://dev.openlayers.org/sandbox/camptocamp/tipi/examples/vector-symbols.html



Searching online for a solution to this seems to produce only other confused people searching for a solution.

Please help,

FreeBeer
",FreeBeer,https://stackoverflow.com/users/4691155,"SVG icons work fine as long as the content-type of your SVG image file is image/svg+xml. Also note that no external references are supported inside the SVG. OpenLayers 3 simply uses the drawImage function of the 2d context. You can find more details on the requirements of SVG content here: https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Drawing_DOM_objects_into_a_canvas.
",ahocevar,https://stackoverflow.com/users/2389327,http://stackoverflow.com/questions/29152405/how-can-i-use-an-svg-image-as-a-map-marker-in-openlayers-3,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.6666666666666666,0.8888888888888888,How to use SVG image as map marker in openlayers-3?,"I am trying to create map ""pin-drops"" (ie. map markers) in OpenLayers-3 (OL3) using SVG images.

Currently, I am using PNG images as the pindrops that reference the ol.style.Icon source (âsrcâ) property attribute just fine. However, this fails using an SVG image. Is there some other way to use an SVG in the same manner? Maybe by using a reference besides ol.style.Icon even? There is already a lot of built-in SVG in Open Layers so this should be possible, but I haven't found a way to get this working in OL3. Is there some other way to do this in OL3 that I should consider?

Please note: we already tried using an ol.Vector layer, however when the user zooms in/out, the size of the SVG image grows/shrinks which is an inadequate workaround.



OL3 (fails): 

var createMapMarkerImage = function() {
    return function(feature, resolution) {
        var iconStyle = new ol.style.Style({
            image: new ol.style.Icon( ({
                src: 'img/map_pindrop.svg'   // OL3 doesnât like this, but accepts a .PNG just fine
            }))
        });
        return [iconStyle];
    };
};


Very similar functionality, is the below example I found online, is almost perfect if it werenât for the fact that the example uses OpenLayers-2 (OL2) functionality which calls openlayers.js library (instead of OL3âs ol.js library). Sadly, swapping these javascript files out fails.



OL2 (works -but is the old OL library):

http://dev.openlayers.org/sandbox/camptocamp/tipi/examples/vector-symbols.html



Searching online for a solution to this seems to produce only other confused people searching for a solution.

Please help,

FreeBeer
","SVG icons work fine as long as the content-type of your SVG image file is image/svg+xml. Also note that no external references are supported inside the SVG. OpenLayers 3 simply uses the drawImage function of the 2d context. You can find more details on the requirements of SVG content here: https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Drawing_DOM_objects_into_a_canvas.
"
4329,4329,6894,I with my friends vs my friends and I,"I'm pretty sure it's not correct to say I with my friends go to the cinema every weekend. However I sometimes hear it from other Russians. 

I have to use ""and"" instead of ""with"" and put this like this My friends and I go to the cinema every weekend. I'm still wondering what if...

Am I right or wrong?
",Dunno,https://english.stackexchange.com/users/48978,"I would probably say either ""I go to the cinema with my friends every weekend"" or ""I go to the cinema every weekend with my friends.""
",zombiebeethoven,https://english.stackexchange.com/users/59610,http://english.stackexchange.com/questions/161959/i-with-my-friends-vs-my-friends-and-i,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,I with my friends vs my friends and I,"I'm pretty sure it's not correct to say I with my friends go to the cinema every weekend. However I sometimes hear it from other Russians. 

I have to use ""and"" instead of ""with"" and put this like this My friends and I go to the cinema every weekend. I'm still wondering what if...

Am I right or wrong?
","I might say ""I go to the cinema with my friends every weekend"" or ""I go to the cinema with my friends every weekend"""
348,348,554,What is the point of the super secret settings option in the video settings in minecraft 1.7?,"I was messing around with my settings in single creative mode, and I came across these really weird video settings, and I immediately thought what the heck!  They made the game hard, and it was almost impossible to tell between certain blocks.  It made no sense.
",bob at bob dot bob,https://gaming.stackexchange.com/users/69154,"Like many easter eggs, the Super Secret Settings are just a hidden feature of the game that plays a random sound or applies a random shader to the game. It wasn't made for any particular purpose, it's just there for fun and for what is colloquially referred to as ""teh lulz.""

If you want to turn them off, just restart your game.
",oldmud0,https://gaming.stackexchange.com/users/61812,http://gaming.stackexchange.com/questions/157597/what-is-the-point-of-the-super-secret-settings-option-in-the-video-settings-in-m,CULTURE,gaming.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,What is the meaning of the super secret setting option in the video settings of minecraft 1.7?,"I messed up my settings in a creative mode. I met these very strange video settings, and I immediately thought of what the hell! They make the game so difficult that it's almost impossible to distinguish certain blocks. It makes no sense.","Like many Easter eggs, super secret settings are just a hidden feature of the game, allowing you to play random sounds or apply random shaders to the game. It's not made for any specific purpose, it's just for fun and the popular ""teh lulz"""
3096,3096,4933,Should users be forced to go through a walkthrough?,"We've found that our users have almost universally benefited from actually going through our walkthrough. Obviously, we have some more ux work to do on our service. But, based on this information, we decided to force users through the short walkthrough in the interim. Somewhat unsurprisingly, people have protested a bit :) So, what do you think, is it ok to force users through a brief walkthrough when you know it will benefit them in the end?

Edit
We are going to add some mixpanel hooks to find out if users are leaving when presented with a walkthrough they can't exit out of.
",jscheel,https://ux.stackexchange.com/users/22949,"A question I would ask: ""Why do your users protest going through the walk through""? 


Do they not find it useful?
Is it boring?
Do they already know the information? 
Is it unexpected? 
Are you asking for more than you are giving? 
They feel a loss of control?
Is the language hard to read?
Did they have a bad morning? 


You get the idea. As others have said, forcing your user to do something is not generally recommended. Getting the answer to the question above will help. For example if users say ""I do not find it useful"" a potential solution would be to tell them the benefit of the training and encourage/lead (but don't force) them through the training.  
",James D,https://ux.stackexchange.com/users/10696,http://ux.stackexchange.com/questions/33126/should-users-be-forced-to-go-through-a-walkthrough,TECHNOLOGY,ux.stackexchange.com,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.7777777777777778,0.7777777777777778,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.8888888888888888,0.8888888888888888,1.0,1.0,0.0,0.0,0.3333333333333333,1.0,Should users be forced to drill?,"We found that almost all of our users benefited from our walkthroughs. Obviously, we have more user experience work to do. However, based on this information, we decided to force the user to complete a short walkthrough during the transition. It's not surprising that people are protesting:) so, do you think it's OK to force users to have a short drill when you know that it will ultimately benefit them?","A question I would ask: ""Why do your users protest going through the walk through""? 


Do they not find it useful?
Is it boring?
Do they already know the information? 
Is it unexpected? 
Are you asking for more than you are giving? 
They feel a loss of control?
Is the language hard to read?
Did they have a bad morning? 


You get the idea. As others have said, forcing your user to do something is not generally recommended. Getting the answer to the question above will help. For example if users say ""I do not find it useful"" a potential solution would be to tell them the benefit of the training and encourage/lead (but don't force) them through the training.  
"
1465,1465,2308,"What to call ""Cancel"" when ""Cancel"" is already the default action?","When attempting to cancel a service or setting, ""cancel"" is the default action. What should the normal ""cancel"" button be called?

Redbox uses a playful ""just kidding"", which may not be appropriate in all circumstances.


",Luke Charde,https://ux.stackexchange.com/users/5022,"I think that the shown image had a good idea of emulating the user's thoughts, some other good ideas would be:


Nevermind
Abort
Undo
Done
Get me out of here!
Call off
Zap


IMO: Nevermind and Done are the best.
",David,https://ux.stackexchange.com/users/27886,http://ux.stackexchange.com/questions/35753/what-to-call-cancel-when-cancel-is-already-the-default-action,TECHNOLOGY,ux.stackexchange.com,1.0,1.0,0.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,"When cancel is already the default operation, what is the name of cancel?","Cancel is the default action when attempting to cancel a service or setting. What should a normal ""Cancel"" button be called?","I think that the shown image had a good idea of emulating the user's thoughts, some other good ideas would be:


Nevermind
Abort
Undo
Done
Get me out of here!
Call off
Zap


IMO: Nevermind and Done are the best.
"
4632,4632,7347,Reliable way of detecting whether an Android app is running in 'BlueStacks',"I would like to ascertain at run-time inside an Android app whether it is running within the BlueStacks Android emulator. This is so I can modify the way the app runs when running inside BlueStacks.

BlueStacks does not support multi-touch so I want to implement an alternative to the standard pinch-to-zoom functionality my current app has.

E.g.

If (appIsRunningInBlueStacks){
    mySurfaceView.enableMultiTouchAlternatives();
} else{
    mySurfaceView.enableMultiTouchFeatures();
}


What is a reliable way of ascertaining the value of appIsRunningInBlueStacks?

EDIT Summary of answers to comments on question:

Ben, Taras, thanks for the suggestions. The Build.MODEL etc. values for BlueStacks are:


Model: ""GT-I9100""
Manufacturer: ""samsung""
Device: ""GT-I9100""
Product: ""GT-I9100""


This is the same model number as the Samsung Galaxy SII so it would not be ideal to use this for fear of treating all users with SIIs the same as those on BlueStacks.

CommonsWare, the app continues to run in BlueStacks even with the &lt; uses-feature> for multitouch in the manifest. In fact (also answering iagreen's question)...

packageManager.hasSystemFeature(PackageManager.FEATURE_TOUCHSCREEN_MULTITOUCH_DISTINCT);


... returns true! This is to be expected I suppose as the emulator is convinced it is a Samsung Galaxy SII!

Therefore we are still without a way of reliably detecting whether an app is running on BlueStacks without also throwing all Samsung Galaxy SII users in the same bucket. Any other ideas?
",Twice Circled,https://stackoverflow.com/users/1804325,"My version of BlueStacks is reporting my Build.Model as GT-N7100.

Using: android.opengl.GLES20.glGetString(android.opengl.GLES20.GL_RENDERER) I get Bluestacks.
",jacobk,https://stackoverflow.com/users/2577516,http://stackoverflow.com/questions/14143896/reliable-way-of-detecting-whether-an-android-app-is-running-in-bluestacks,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,1.0,0.8333333333333334,0.7,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,"A reliable way to detect whether Android applications are running in ""bluestack""","I would like to ascertain at run-time inside an Android app whether it is running within the BlueStacks Android emulator. This is so I can modify the way the app runs when running inside BlueStacks.

BlueStacks does not support multi-touch so I want to implement an alternative to the standard pinch-to-zoom functionality my current app has.

E.g.

If (appIsRunningInBlueStacks){
    mySurfaceView.enableMultiTouchAlternatives();
} else{
    mySurfaceView.enableMultiTouchFeatures();
}


What is a reliable way of ascertaining the value of appIsRunningInBlueStacks?

EDIT Summary of answers to comments on question:

Ben, Taras, thanks for the suggestions. The Build.MODEL etc. values for BlueStacks are:


Model: ""GT-I9100""
Manufacturer: ""samsung""
Device: ""GT-I9100""
Product: ""GT-I9100""


This is the same model number as the Samsung Galaxy SII so it would not be ideal to use this for fear of treating all users with SIIs the same as those on BlueStacks.

CommonsWare, the app continues to run in BlueStacks even with the &lt; uses-feature> for multitouch in the manifest. In fact (also answering iagreen's question)...

packageManager.hasSystemFeature(PackageManager.FEATURE_TOUCHSCREEN_MULTITOUCH_DISTINCT);


... returns true! This is to be expected I suppose as the emulator is convinced it is a Samsung Galaxy SII!

Therefore we are still without a way of reliably detecting whether an app is running on BlueStacks without also throwing all Samsung Galaxy SII users in the same bucket. Any other ideas?
","My version of BlueStacks is reporting my Build.Model as GT-N7100.

Using: android.opengl.GLES20.glGetString(android.opengl.GLES20.GL_RENDERER) I get Bluestacks.
"
2089,2089,3327,Access/Pass variable between windows form and DataSet TableAdapter SQL where clause,"In Visual Studio 2010, I have a windows forms application frmMain.cs with a ComboBox. From the form itself I can access its value with cmbxYear.SelectedValue. I also have a DataSet.xsd file to bind to an rdlc report to a TableAdapter to present view data. The TableAdapter has a SelectCommand that takes SQL code.  I need to get the value of cmbxYear.SelectedValue into the WHERE clause of the TableAdapter.
Does anyone know how I can access/pass the variable value from the form into the DataSet TableAdapter SelectCommand WHERE clause?  
",Baxter,https://stackoverflow.com/users/1144118,"I am using the OleDb provider for Oracle. 
The bind variable should be a question mark ? not :DEPTCODE

The bind variable :DEPTCODE would be valid for System.Data.OracleClient

See full walk through here: http://www.fullstackbusinessdesign.com/forums/ORA-01008.html

Many thanks to Prashant Kumar for this solution.
http://forums.asp.net/members/Prashant%20Kumar.aspx
",Baxter,https://stackoverflow.com/users/1144118,http://stackoverflow.com/questions/9433761/access-pass-variable-between-windows-form-and-dataset-tableadapter-sql-where-cla,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,0.5,1.0,0.5,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Access / pass variables between Windows Forms and dataset tableadapter SQL where clause,"In Visual Studio 2010, I have a Windows Forms application frmmain.cs with combo boxes. From the form itself, I can access its value using cmbxyyear.selectedvalue. I also have a dataset.xsd file to bind to the RDLC report and tableadapter to display the view data. The tableadapter has a selectcommand that accepts SQL code. I need to get the value of cmbxyyear.selectedvalue into the where clause of the tableadapter.","I am using the OleDb provider for Oracle. 
The bind variable should be a question mark ? not :DEPTCODE

The bind variable :DEPTCODE would be valid for System.Data.OracleClient

See full walk through here: http://www.fullstackbusinessdesign.com/forums/ORA-01008.html

Many thanks to Prashant Kumar for this solution.
http://forums.asp.net/members/Prashant%20Kumar.aspx
"
3148,3148,5013,What is the maximum character limit for a multi-select picklist?,"What is the maximum length of the string of values that a multi-select picklist can return? If the picklist items can be up to 40 characters and users can select 100 of them, that implies that you could get 4100 character returned if the semi-colons are the only extra characters added. I'd love to find the actual documentation that provides the spec.
",AlwaysThinkin,https://salesforce.stackexchange.com/users/761,"The actual byte length of the field remains at 4099 because they don't need a semicolon to delimit the last value.

Interestingly the picklist values are enumerated and those keys are used for comparisons internally. Eg Sunday;Monday;Tuesday get written away under the covers as something like 0AAK0AAL0AAM, so I wouldn't read too much into the field length ;)
",bigassforce,https://salesforce.stackexchange.com/users/320,http://salesforce.stackexchange.com/questions/27315/what-is-the-maximum-character-limit-for-a-multi-select-picklist,TECHNOLOGY,salesforce.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,What is the maximum character limit for the multi option list?,"What is the maximum length of the string that can be returned from the multi select picking list? If the picklist entry can contain up to 40 characters, and the user can select 100 of them, this means that if only semicolons are added, 4100 characters can be returned. I would love to find the actual documentation that provides the specification.","The actual byte length of the field remains at 4099 because they don't need a semicolon to delimit the last value.

Interestingly the picklist values are enumerated and those keys are used for comparisons internally. Eg Sunday;Monday;Tuesday get written away under the covers as something like 0AAK0AAL0AAM, so I wouldn't read too much into the field length ;)
"
5355,5355,8502,saving new category programmatically with setPath,"Now this is the sort of problem I would help others with but I am flummoxed. 
I am creating new categories in an import routine, e.g.

$this-&gt;magObject = Mage::getModel(""catalog/category"");
$this-&gt;magObject-&gt;setName($item[""name""]);
$this-&gt;magObject-&gt;setData(""agilityId"",$item[""id""]);
$this-&gt;magObject-&gt;setIsActive($this-&gt;isActive);
$this-&gt;magObject-&gt;setIsAnchor($this-&gt;isAnchor);
$this-&gt;magObject-&gt;setPageLayout($this-&gt;pageLayout);
$this-&gt;magObject-&gt;setStoreId(Mage::app()-&gt;setCurrentStore(Mage_Core_Model_App::ADMIN_STORE_ID)); 
//$this-&gt;magObject-&gt;setPath (""1/2/6"") ); //actually got by getting path of specific required parent
$this-&gt;magObject-&gt;save();


Without the setPath it saves fine, but with the wrong path (obviously).  When the setPath is included, nothing happens.  I know that there are devious magento elements at work that prevent writing to _entity tables unless certain circumstances are met but I thought I was meeting them .   I am already performing the usual

define(""ADMIN_STORE_ID"",1);
//...
Mage::app();
Mage::setIsDeveloperMode(true);
Mage::app()-&gt;setCurrentStore(Mage::getModel('core/store')-&gt;load(Mage_Core_Model_App::ADMIN_STORE_ID));


at the start but in this instance it just is not working.  I have similar scripts on other sites that do work.  Only difference with this site is that there are multiple store fronts

3 UK
7 Spanish
5 German
6 French
1 Default Store View


Anyone spot something obvious that I am missing, whilst I still have some hair left?

Oh this is using Magento 1.9.1.1.
",Jon Holland,https://magento.stackexchange.com/users/16833,"You are not supposed to set the path. This is calculated based on the parent.  Same goes for the level.
Instead you should set the parent id.

So you can do this:

$this-&gt;magObject = Mage::getModel(""catalog/category"");
$this-&gt;magObject-&gt;setName($item[""name""]);
$this-&gt;magObject-&gt;setData(""agilityId"",$item[""id""]);
$this-&gt;magObject-&gt;setIsActive($this-&gt;isActive);
$this-&gt;magObject-&gt;setIsAnchor($this-&gt;isAnchor);
$this-&gt;magObject-&gt;setPageLayout($this-&gt;pageLayout);
$this-&gt;magObject-&gt;setStoreId(Mage::app()-&gt;setCurrentStore(Mage_Core_Model_App::ADMIN_STORE_ID)); 
$this-&gt;magObject-&gt;setParentId(2);
$this-&gt;magObject-&gt;save();

",Marius,https://magento.stackexchange.com/users/146,http://magento.stackexchange.com/questions/76245/saving-new-category-programmatically-with-setpath,TECHNOLOGY,magento.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.5,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.5,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,1.0,1.0,1.0,0.5,0.5,0.5,1.0,Programmatically save new categories using setpath,"Now this is the sort of problem I would help others with but I am flummoxed. 
I am creating new categories in an import routine, e.g.

$this-&gt;magObject = Mage::getModel(""catalog/category"");
$this-&gt;magObject-&gt;setName($item[""name""]);
$this-&gt;magObject-&gt;setData(""agilityId"",$item[""id""]);
$this-&gt;magObject-&gt;setIsActive($this-&gt;isActive);
$this-&gt;magObject-&gt;setIsAnchor($this-&gt;isAnchor);
$this-&gt;magObject-&gt;setPageLayout($this-&gt;pageLayout);
$this-&gt;magObject-&gt;setStoreId(Mage::app()-&gt;setCurrentStore(Mage_Core_Model_App::ADMIN_STORE_ID)); 
//$this-&gt;magObject-&gt;setPath (""1/2/6"") ); //actually got by getting path of specific required parent
$this-&gt;magObject-&gt;save();


Without the setPath it saves fine, but with the wrong path (obviously).  When the setPath is included, nothing happens.  I know that there are devious magento elements at work that prevent writing to _entity tables unless certain circumstances are met but I thought I was meeting them .   I am already performing the usual

define(""ADMIN_STORE_ID"",1);
//...
Mage::app();
Mage::setIsDeveloperMode(true);
Mage::app()-&gt;setCurrentStore(Mage::getModel('core/store')-&gt;load(Mage_Core_Model_App::ADMIN_STORE_ID));


at the start but in this instance it just is not working.  I have similar scripts on other sites that do work.  Only difference with this site is that there are multiple store fronts

3 UK
7 Spanish
5 German
6 French
1 Default Store View


Anyone spot something obvious that I am missing, whilst I still have some hair left?

Oh this is using Magento 1.9.1.1.
","You are not supposed to set the path. This is calculated based on the parent.  Same goes for the level.
Instead you should set the parent id.

So you can do this:

$this-&gt;magObject = Mage::getModel(""catalog/category"");
$this-&gt;magObject-&gt;setName($item[""name""]);
$this-&gt;magObject-&gt;setData(""agilityId"",$item[""id""]);
$this-&gt;magObject-&gt;setIsActive($this-&gt;isActive);
$this-&gt;magObject-&gt;setIsAnchor($this-&gt;isAnchor);
$this-&gt;magObject-&gt;setPageLayout($this-&gt;pageLayout);
$this-&gt;magObject-&gt;setStoreId(Mage::app()-&gt;setCurrentStore(Mage_Core_Model_App::ADMIN_STORE_ID)); 
$this-&gt;magObject-&gt;setParentId(2);
$this-&gt;magObject-&gt;save();

"
3508,3508,5597,Who counters Jayce top lane besides Yorick?,"I'm aware that Yorick and Cho'Gath are both good counters for Jayce (in Top Lane) but who else might be a good matchup and why?
",Eddie,https://gaming.stackexchange.com/users/29370,"My personal opinion, and this is from playing both champs in question, is dont pick Jax vs Jayce. Most Jax players Leap strike in, only to get knocked away immediately, and then a quick switch into ranged mode from Jayce takes down their health. If Jax uses a Counter Strike + Leap Strike combo for an instant stun, then he is open for +/- 20 seconds, and Jayce can just combo chain abilities to nuke him. Short of a Jax combo including Flash/Exhaust, Jayce should win the lane phase. Try Malphite/Lee instead.
",Phr33k101,https://gaming.stackexchange.com/users/33586,http://gaming.stackexchange.com/questions/77029/who-counters-jayce-top-lane-besides-yorick,CULTURE,gaming.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"Who's dealing with Jess in the top floor lane, except York?","I know that both joric and jogat are good rivals for Joyce, but who else are good rivals and why?","My personal opinion, and this is from playing both champs in question, is dont pick Jax vs Jayce. Most Jax players Leap strike in, only to get knocked away immediately, and then a quick switch into ranged mode from Jayce takes down their health. If Jax uses a Counter Strike + Leap Strike combo for an instant stun, then he is open for +/- 20 seconds, and Jayce can just combo chain abilities to nuke him. Short of a Jax combo including Flash/Exhaust, Jayce should win the lane phase. Try Malphite/Lee instead.
"
1969,1969,3137,Is there a name for the number of values a variable can take?,"For example, a bit or a boolean can be either 0 or 1 so the number 2 is associated with it. Similarly, for a byte which is 8 bits, the maximum number of different assignments would be 2^8.

Is there a name for this number?

When we pass everything through our system that has ECMAScript, Java and MySQL, then a boolean does not have only two possible assignments. For instance, a false boolean gets saved as a 0 and the boxed value could be null so a boolean suddenly can get true, false, 0, 1, null or even undefined or &lt;missing&gt;.

I think it could get problematic in tests to guarantee that the values are not inconsistent. For instance, a value boolean locked could become null and then when a script or a layout template evaluates it then it will evaluate to false somewhere if the real value was null and similar problems.

So why don't we always assert that a boolean has the same number of possible values (2 values) and similarly for other types?

There is a mathematical term named ""arity"" that is something similar but not exactly, and statistics and probability theory also has the concept of ""event space"" that would be almost exactly what I mean. For instance, the event space for a boolean would be the set {0,1} which has cardinality 2 and that cardinality doesn't get preserved throughout the system, especially when data is passed as polyglots and/or serialized (json, jsonp, xml, yaml).
",Niklas Rosencrantz,https://programmers.stackexchange.com/users/12893,"If you subscribe to the ""types as a set of values"" interpretation of type theory, then cardinality is in fact a good name.

So, the cardinality of bool would be 2, the cardinality of byte would be 256, and the cardinality of String would be &aleph;0.
",JÃ¶rg W Mittag,https://programmers.stackexchange.com/users/1352,http://programmers.stackexchange.com/questions/233316/is-there-a-name-for-the-number-of-values-a-variable-can-take,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Is there a name for the number of values a variable can accept?,"For example, a bit or a boolean can be either 0 or 1 so the number 2 is associated with it. Similarly, for a byte which is 8 bits, the maximum number of different assignments would be 2^8.

Is there a name for this number?

When we pass everything through our system that has ECMAScript, Java and MySQL, then a boolean does not have only two possible assignments. For instance, a false boolean gets saved as a 0 and the boxed value could be null so a boolean suddenly can get true, false, 0, 1, null or even undefined or &lt;missing&gt;.

I think it could get problematic in tests to guarantee that the values are not inconsistent. For instance, a value boolean locked could become null and then when a script or a layout template evaluates it then it will evaluate to false somewhere if the real value was null and similar problems.

So why don't we always assert that a boolean has the same number of possible values (2 values) and similarly for other types?

There is a mathematical term named ""arity"" that is something similar but not exactly, and statistics and probability theory also has the concept of ""event space"" that would be almost exactly what I mean. For instance, the event space for a boolean would be the set {0,1} which has cardinality 2 and that cardinality doesn't get preserved throughout the system, especially when data is passed as polyglots and/or serialized (json, jsonp, xml, yaml).
","If you subscribe to the ""types as a set of values"" interpretation of type theory, then cardinality is in fact a good name.

So, the cardinality of bool would be 2, the cardinality of byte would be 256, and the cardinality of String would be &aleph;0.
"
2289,2289,3647,Change created order number,"I lost a few orders at Magento and I am recreating it manually, but I need to keep the old id. 
I do not have enough information to create all the lost orders, because this some orders id need to be skipped, because this I want to manually put the id of them. 

I tried the mysql with the command:

update sales_flat_order set increment_id=100000180, entity_id=180 where entity_id=168;


Thanks in advance
",Eduardo,https://magento.stackexchange.com/users/4489,"THIS IS NO GOOD IDEA. PLAYING IN THE DATABASE IS ALWAYS A BAD IDEA

I'm not sure, whether I understand your question, there is no question mark in it, but I'll try.

The next increment id for an order can be found here: eav_entity_store so change the value to the one you want to have for the next order/invoice/whatever - 1.

Then your way is correct, sort our what IDs your orders need and then change the increment_ids and the entity_ids.
",Fabian Blechschmidt,https://magento.stackexchange.com/users/217,http://magento.stackexchange.com/questions/17683/change-created-order-number,TECHNOLOGY,magento.stackexchange.com,0.5555555555555556,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7,1.0,0.3333333333333333,1.0,0.6666666666666666,Change order number created,"I lost a few orders at Magento and I am recreating it manually, but I need to keep the old id. 
I do not have enough information to create all the lost orders, because this some orders id need to be skipped, because this I want to manually put the id of them. 

I tried the mysql with the command:

update sales_flat_order set increment_id=100000180, entity_id=180 where entity_id=168;


Thanks in advance
","THIS IS NO GOOD IDEA. PLAYING IN THE DATABASE IS ALWAYS A BAD IDEA

I'm not sure, whether I understand your question, there is no question mark in it, but I'll try.

The next increment id for an order can be found here: eav_entity_store so change the value to the one you want to have for the next order/invoice/whatever - 1.

Then your way is correct, sort our what IDs your orders need and then change the increment_ids and the entity_ids.
"
3377,3377,5385,Weird jquery 302 error in Firebug,"I am posting data to servlet using jquery .post() method. The data is being posted and servlet is able to catch the data. But in my firebug I see 302 once the post request is done.

Also I am redirecting the user to success page in my servlet. But the redirect is not happening!!

Should'nt I be getting 200 on the post request?

And why is a simple response.sendRedirect(""success.jsp"") not happening?



When I click on the response tab I can see the success.jsp html tags.

Please throw light on what is happening? How do I correct it?
",enthusiastic,https://stackoverflow.com/users/584003,"Your servlet is sending the redirect message, which gives you the 302 response header. It'd be better to send back an url, and redirect the user to it on success itself.

Like so:

$.post(""scripturl"", { data: data }, function(result) { 
    if (result.success) {
        window.location.href = result.url;
    }
})

",Andreas Eriksson,https://stackoverflow.com/users/181002,http://stackoverflow.com/questions/8613350/weird-jquery-302-error-in-firebug,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,0.8888888888888888,Strange jQuery 302 error in firebug,"I am posting data to servlet using jquery .post() method. The data is being posted and servlet is able to catch the data. But in my firebug I see 302 once the post request is done.

Also I am redirecting the user to success page in my servlet. But the redirect is not happening!!

Should'nt I be getting 200 on the post request?

And why is a simple response.sendRedirect(""success.jsp"") not happening?



When I click on the response tab I can see the success.jsp html tags.

Please throw light on what is happening? How do I correct it?
","Your servlet is sending the redirect message, which gives you the 302 response header. It'd be better to send back an url, and redirect the user to it on success itself.

Like so:

$.post(""scripturl"", { data: data }, function(result) { 
    if (result.success) {
        window.location.href = result.url;
    }
})

"
4586,4586,7268,"display error message under payment method if ""COD "" is not available","i am using this following code to restrict the ""cash on delivery"" payment method based on pin code.

/app/code/core/Mage/Payment/Model/Method/Cashondelivery.php 


Please check code here  

now if cash on delivery payment method is not visible means i want to display ""cod is not available"" under 

payment method. 

please help me to find solution.
",Baby in Magento,https://magento.stackexchange.com/users/12982,"You referral link can only remove the code from payment list at check payment step.If you set error message at session (Mage::getSingleton('core/session')-&gt;addError(Mage::helper('payment')-&gt;__('Code is not avaliable.')))  on function isAvaliable  it can be shown on next step.

According my concept it will be good idea to do something at methods.phtml where all payment method has been listing during the checkout.

&lt;?php
$isCodeAvalibale=0;
    foreach ($this-&gt;getMethods() as $_method):
        $_code = $_method-&gt;getCode();
    if($_code =='cashondelivery'):
    $isCodeAvalibale=1;
    endif;
    endforeach;
if($isCodeAvalibale==0):
echo Mage::helper('payment')-&gt;__('Code is not avaliable.'));
endif;
?&gt;

",Amit Bera,https://magento.stackexchange.com/users/4564,http://magento.stackexchange.com/questions/62420/display-error-message-under-payment-method-if-cod-is-not-available,TECHNOLOGY,magento.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,0.7777777777777778,"If cod is not available, an error message is displayed under payment method","i am using this following code to restrict the ""cash on delivery"" payment method based on pin code.

/app/code/core/Mage/Payment/Model/Method/Cashondelivery.php 


Please check code here  

now if cash on delivery payment method is not visible means i want to display ""cod is not available"" under 

payment method. 

please help me to find solution.
","You referral link can only remove the code from payment list at check payment step.If you set error message at session (Mage::getSingleton('core/session')-&gt;addError(Mage::helper('payment')-&gt;__('Code is not avaliable.')))  on function isAvaliable  it can be shown on next step.

According my concept it will be good idea to do something at methods.phtml where all payment method has been listing during the checkout.

&lt;?php
$isCodeAvalibale=0;
    foreach ($this-&gt;getMethods() as $_method):
        $_code = $_method-&gt;getCode();
    if($_code =='cashondelivery'):
    $isCodeAvalibale=1;
    endif;
    endforeach;
if($isCodeAvalibale==0):
echo Mage::helper('payment')-&gt;__('Code is not avaliable.'));
endif;
?&gt;

"
4052,4052,6467,Real norms on vector spaces over finite fields,"I am interested in functions of the form $\psi: F^n \to \mathbb{R}^+$, where $F$ is a finite field, that have norm-like properties, e.g., $\psi(x+y) \le \psi(x) + \psi(y)$. Does anybody know if there is any literature on this area?
",Manos,https://math.stackexchange.com/users/11921,"If you are truly only interested in the triangle inequality, then there is the Hamming weight
$w(x_1,x_2,\ldots,x_n)=m$ where $m$ is simply the number of non-zero components. This gives you a metric. Mind you, the space $F^n$ is finite, so any metric on it is going to give you the discrete topology. Adding any kind of norm-like requirements (on top of the triangle inequality) is problematic for several reason, as others have pointed out.

The Hamming weight obviously depends on the choice of basis, which may restrict its usefulness (depending on what you wanted to do with this 'norm').

I'm sad to say there isn't an awful lot of analysis happening in this space.
",Jyrki Lahtonen,https://math.stackexchange.com/users/11619,http://math.stackexchange.com/questions/60015/real-norms-on-vector-spaces-over-finite-fields,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,Real norm of vector space over finite field,"I'm interested in functions in the form $\ psi: f ^ n \ to \ mathbb {r} ^ + $, where $f $is a finite field with properties similar to the norm, such as $\ psi (x + y) / Le \ psi (x) + \ psi (y) $. Does anyone know if there is any literature on this?","If you are truly only interested in the triangle inequality, then there is the Hamming weight
$w(x_1,x_2,\ldots,x_n)=m$ where $m$ is simply the number of non-zero components. This gives you a metric. Mind you, the space $F^n$ is finite, so any metric on it is going to give you the discrete topology. Adding any kind of norm-like requirements (on top of the triangle inequality) is problematic for several reason, as others have pointed out.

The Hamming weight obviously depends on the choice of basis, which may restrict its usefulness (depending on what you wanted to do with this 'norm').

I'm sad to say there isn't an awful lot of analysis happening in this space.
"
712,712,1129,Flask-SQLAlchemy many-to-many ordered relationship in hybrid_property,"I am trying to get the first object out of an ordered many-to-many relationship using Flask-SQLAlchemy.

I would like to accomplish this using hybrid properties, so I can reuse my code in a clean way.

Here is the code, with some comment:

class PrimaryModel2Comparator(Comparator):
  def __eq__(self, other):
    return self.__clause_element__().model2s.is_first(other)

class model2s_comparator_factory(RelationshipProperty.Comparator):
  def is_first(self, other, **kwargs):
    return isinstance(other, Model2) &amp; \
           (db.session.execute(select([self.prop.table])).first().id == other.id)

model1_model2_association_table = db.Table('model1_model2_association',
                                           db.Column('model1_id', db.Integer, db.ForeignKey('model1s.id')),
                                           db.Column('model2_id', db.Integer, db.ForeignKey('model2s.id')),
                                           )
class Model1(db.Model):
  __tablename__ = 'model1s'

  id = db.Column(db.Integer, primary_key=True, autoincrement=True)
  model2s = db.relationship('Model2',
                           order_by=desc('Model2.weight'),
                           comparator_factory=model2s_comparator_factory,
                           secondary=model1_model2_association_table,
                           backref=db.backref('model1s', lazy='dynamic'),
                           lazy='dynamic'
  )

  @hybrid_property
  def primary_model2(self):
    return self.model2s.order_by('weight desc').limit(1).one()

  @primary_model2.comparator
  def primary_model2(cls):
    return PrimaryModel2Comparator(cls)


class Model2(db.Model):
  __tablename__ = 'model2s'

  id = db.Column(db.Integer, primary_key=True, autoincrement=True)
  weight = db.Column(db.Integer, nullable=False, default=0)


And the usage:

Model1.query.filter(Model1.primary_model2 == Model2.query.get(1))


The problems are:  


In my comparator factory is_first method I can't get the actual instance, so I don't know which are the Model2s associated
In the same method I want to order my select against the weight attribute of Model2, and then take the first


Something is not clear in my head, maybe there's a simpler solution?
",Michele Gargiulo,https://stackoverflow.com/users/619373,"Perhaps looking at a working many-to-many example might help.  Flask-Security is a great one.

https://pythonhosted.org/Flask-Security/quickstart.html#sqlalchemy-application
",jwogrady,https://stackoverflow.com/users/1569010,http://stackoverflow.com/questions/24147353/flask-sqlalchemy-many-to-many-ordered-relationship-in-hybrid-property,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6,0.0,0.5,0.0,0.8333333333333334,The flask Sqlalchemy many to many order relation in the mixing property,"I am trying to get the first object out of an ordered many-to-many relationship using Flask-SQLAlchemy.

I would like to accomplish this using hybrid properties, so I can reuse my code in a clean way.

Here is the code, with some comment:

class PrimaryModel2Comparator(Comparator):
  def __eq__(self, other):
    return self.__clause_element__().model2s.is_first(other)

class model2s_comparator_factory(RelationshipProperty.Comparator):
  def is_first(self, other, **kwargs):
    return isinstance(other, Model2) &amp; \
           (db.session.execute(select([self.prop.table])).first().id == other.id)

model1_model2_association_table = db.Table('model1_model2_association',
                                           db.Column('model1_id', db.Integer, db.ForeignKey('model1s.id')),
                                           db.Column('model2_id', db.Integer, db.ForeignKey('model2s.id')),
                                           )
class Model1(db.Model):
  __tablename__ = 'model1s'

  id = db.Column(db.Integer, primary_key=True, autoincrement=True)
  model2s = db.relationship('Model2',
                           order_by=desc('Model2.weight'),
                           comparator_factory=model2s_comparator_factory,
                           secondary=model1_model2_association_table,
                           backref=db.backref('model1s', lazy='dynamic'),
                           lazy='dynamic'
  )

  @hybrid_property
  def primary_model2(self):
    return self.model2s.order_by('weight desc').limit(1).one()

  @primary_model2.comparator
  def primary_model2(cls):
    return PrimaryModel2Comparator(cls)


class Model2(db.Model):
  __tablename__ = 'model2s'

  id = db.Column(db.Integer, primary_key=True, autoincrement=True)
  weight = db.Column(db.Integer, nullable=False, default=0)


And the usage:

Model1.query.filter(Model1.primary_model2 == Model2.query.get(1))


The problems are:  


In my comparator factory is_first method I can't get the actual instance, so I don't know which are the Model2s associated
In the same method I want to order my select against the weight attribute of Model2, and then take the first


Something is not clear in my head, maybe there's a simpler solution?
","Perhaps looking at a working many-to-many example might help.  Flask-Security is a great one.

https://pythonhosted.org/Flask-Security/quickstart.html#sqlalchemy-application
"
746,746,1181,How to determine directions of vectors of an electromagnetic wave,"I did an exercise which probably is quite popular,
in which you draw an electromagnetic wave and prove that it should
propagate at the speed of light $1 \over \sqrt {\mu_0\epsilon_0}$ using Farday's law and Ampere's law.

Basically if this is the wave: 




Let's say the E-field (red) is in the X direction, the B-Field (blue) is in the Y direction,
and the velocity of the wave is in the Z direction.

You take for example for ampere's law a surface in the ZY plane with a length L
equal to the amplitude of the wave,
and a width equal to $\lambda\over 4$
You do a similar thing with Faraday's law and you get the speed of light,
assuming you know that the E-field and B-field propagate in this manner.

I got the right answer but I wondered about this:
Let's say I only had the E-field and I know the wave propagates at the speed of light, I assume this is enough information to draw the B-field at each point.

But how will I know the direction? Both Faraday's law and Ampere's law say you need a closed loop integral and the rules I've been taught say
you go over the loop in a clockwise direction for example and take the 
normal to the surface according to the right hand rule etc.

But clockwise and counter-clockwise direction don't really give me much information in this case, so how can I determine the direction of the B-field
if I only have the E-field?
",fiftyeight,https://physics.stackexchange.com/users/6743,"If you're careful about how you define the surface, then you will get the correct direction out of Maxwell's equations. In vector calculus (and generally in math and physics), a surface has an orientation, which also specifies the orientation of the loop that forms its boundary. So you can't just pick a direction to go around the loop at random. The direction in which you go around the loop is related to the orientation of the normal vector to the surface.

Of course, you don't actually need to do a surface integral to figure this out. The electric and magnetic fields in an EM wave (at any given position and moment in time) are related by the equation

$$\mathbf{B} = \frac{1}{c}\hat{\mathbf{k}}\times\mathbf{E}$$

where $\hat{\mathbf{k}}$ is a unit vector that points in the direction of propagation of the wave. If you don't know which direction the wave is moving, you can't tell which way the magnetic field points.
",David Z,https://physics.stackexchange.com/users/124,http://physics.stackexchange.com/questions/20970/how-to-determine-directions-of-vectors-of-an-electromagnetic-wave,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,How to determine the direction of electromagnetic wave vector,"I did an exercise which probably is quite popular,
in which you draw an electromagnetic wave and prove that it should
propagate at the speed of light $1 \over \sqrt {\mu_0\epsilon_0}$ using Farday's law and Ampere's law.

Basically if this is the wave: 




Let's say the E-field (red) is in the X direction, the B-Field (blue) is in the Y direction,
and the velocity of the wave is in the Z direction.

You take for example for ampere's law a surface in the ZY plane with a length L
equal to the amplitude of the wave,
and a width equal to $\lambda\over 4$
You do a similar thing with Faraday's law and you get the speed of light,
assuming you know that the E-field and B-field propagate in this manner.

I got the right answer but I wondered about this:
Let's say I only had the E-field and I know the wave propagates at the speed of light, I assume this is enough information to draw the B-field at each point.

But how will I know the direction? Both Faraday's law and Ampere's law say you need a closed loop integral and the rules I've been taught say
you go over the loop in a clockwise direction for example and take the 
normal to the surface according to the right hand rule etc.

But clockwise and counter-clockwise direction don't really give me much information in this case, so how can I determine the direction of the B-field
if I only have the E-field?
","If you're careful about how you define the surface, then you will get the correct direction out of Maxwell's equations. In vector calculus (and generally in math and physics), a surface has an orientation, which also specifies the orientation of the loop that forms its boundary. So you can't just pick a direction to go around the loop at random. The direction in which you go around the loop is related to the orientation of the normal vector to the surface.

Of course, you don't actually need to do a surface integral to figure this out. The electric and magnetic fields in an EM wave (at any given position and moment in time) are related by the equation

$$\mathbf{B} = \frac{1}{c}\hat{\mathbf{k}}\times\mathbf{E}$$

where $\hat{\mathbf{k}}$ is a unit vector that points in the direction of propagation of the wave. If you don't know which direction the wave is moving, you can't tell which way the magnetic field points.
"
4814,4814,7650,"What does ""pie"" mean in the following sentence?","I once saw a sentence: 


  I will go to a restaurant for pie.


Native speakers didn't correct this sentence. I don't know why. I would say ""I will go to a restaurant to eat a pie"". But maybe that sentence was right. Could you please explain to me what that (first) sentence means?
",user5369,https://ell.stackexchange.com/users/5369,"The preposition for is probably used to show the purpose. 


  for (#8) -used to show purpose or function


Maybe, a similar sentence would be - I'll go to a garden for a jog.

If you go a to restaurant for something, the most common word that could be used  there is some dish, isn't it? to eat pie surely makes better sense but this one could be an informal  or formal way of speech. Let natives write their views. 
",Maulik V,https://ell.stackexchange.com/users/3187,http://ell.stackexchange.com/questions/20276/what-does-pie-mean-in-the-following-sentence,CULTURE,ell.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,1.0,1.0,0.9,0.0,0.0,1.0,0.7777777777777778,"What does ""Pai"" mean in the following sentence?","I once saw a sentence: 


  I will go to a restaurant for pie.


Native speakers didn't correct this sentence. I don't know why. I would say ""I will go to a restaurant to eat a pie"". But maybe that sentence was right. Could you please explain to me what that (first) sentence means?
","The preposition for is probably used to show the purpose. 


  for (#8) -used to show purpose or function


Maybe, a similar sentence would be - I'll go to a garden for a jog.

If you go a to restaurant for something, the most common word that could be used  there is some dish, isn't it? to eat pie surely makes better sense but this one could be an informal  or formal way of speech. Let natives write their views. 
"
1298,1298,2045,Examples of RESTful Web Services for Browser Games,"Can anyone point me towards examples of Browser Games / Browser Game Sites that use RESTful web services?

I have been convinced time and again that building web sites using RESTful principles is a good idea. And I agree.  But I just can't wrap my head around what RESTful means when the service you're providing is just a single (or a few) games.

Any ideas or thoughts would be nice, but I'd also love to see some solid examples.
",theJollySin,https://gamedev.stackexchange.com/users/15684,"I think the network protocol is really irrelevant, each game uses its own protocol, REST or any other standard is only important if you need to interoperate with third party software - which game servers mostly do not.

For example, if you published the API, using REST might be a good idea. But otherwise, I don't see any reason to do so.
",MarkR,https://gamedev.stackexchange.com/users/4484,http://gamedev.stackexchange.com/questions/28058/examples-of-restful-web-services-for-browser-games,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.5,1.0,0.5,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.7777777777777778,0.6,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Example of restful web services for browser games,"Can anyone point me towards examples of Browser Games / Browser Game Sites that use RESTful web services?

I have been convinced time and again that building web sites using RESTful principles is a good idea. And I agree.  But I just can't wrap my head around what RESTful means when the service you're providing is just a single (or a few) games.

Any ideas or thoughts would be nice, but I'd also love to see some solid examples.
","I think the network protocol is really irrelevant, each game uses its own protocol, REST or any other standard is only important if you need to interoperate with third party software - which game servers mostly do not.

For example, if you published the API, using REST might be a good idea. But otherwise, I don't see any reason to do so.
"
1037,1037,1632,What is happening when I convert from a source color space AdobeRGB to a Canon photo paper profile?,"I'm converting my photos in photoshop from the source space of Adobe RGB to the destination space of Canon PRO-100 LU 1/2 Photo Paper Pro Luster and when I do this my colors change very drastically, the become darker and desaturated. 

The photo is changing a lot but I thought this was the correct way to print, to do  a proper conversion to the paper's profile?

What is happening when I convert from a source color space Adobe RGB to a Canon photo paper profile? How do I print and get the proper colors (fairly accurate)?

For instance with these blue colors look like different shades of blue when in Adobe RGB/sRGB as below, but when I print the 3 squares end up looking very similar, and in the print the last square which is really saturated actually looks like the top dark square on my monitor. Print viewed under tungsten lighting and compared a macbook pro at 3 bars brightness. Also when you see the print preview, it actually looks fairly accurate and is completely different from what I see in photoshop. Is there an issue with certain colors? For instance when I printed a desaturated yellow building it looked noticeably warmer than on my display in Adobe RGB


",DavyCrockett,https://photo.stackexchange.com/users/19616,"Short Answer

You should not actually convert your images directly into the printer space, as you then actually lose the ability to properly color manage your results.

For color management to work, each device involved in the process needs to be assigned a color profile. The image should be assigned an appropriate color space itself, and that is usually sRGB, AdobeRGB, or ProPhotoRGB. The color space, when assigned to an image, is the images color profile. The computer screen should be assigned its own separate color profile, usually by using a color profiling tool with a matched software package. Finally, if printing, the printer should also have a color profile, which is selected when printing actually takes place.



Color Spaces

Color spaces define how the colors of an image fit within the available known range of color, officially called L*a*b*, or just Lab for short. The Lab space models the entire range of known color as far as the human eye can perceive it, according to studies done by the IE in the 1930s. Standard color spaces such as sRGB, AdobeRGB, and ProPhotoRGB simply define how each color as it can be described by a computer map to specific color ""coordinates"" in Lab space. It is best to only assign one of these to your images. Which one you assign does not actually matter for the most part, however the smaller the space you assign, the more difficult it will be to preserve maximum original information (i.e. sRGB is a fairly small gamut vs. ProPhotoRGB, and downconverting my require multiple colors to reference the same colors in the end.)

Screen Profiles

In order to properly observe your photographs with accurate color on a computer screen, you should calibrate it. Screen calibration is usually done with some kind of device, a colorimiter or a spectrophotometer, which measures the color output of your screen and produces a custom ICC profile specifically for it, and the environment within which it resides. 

A custom ICC profile will ensure that your screen is reproducing color as accurately as possible, and your photography should not only look more realistic (which may mean less saturated!), but it should display finer levels of contrast between pixels better, so what you see on screen should be crisper and sharper. Having a calibrated screen is not a necessity, however it is highly recommended, as comparing prints to an oversaturated screen can make you wonder why things don't seem to match up.

Print Profiles

To print accurately, you need a print profile. Note that is ""print"" profile, not ""printer"" profile. A print profile actually takes into account the printer, its inks, as well as the paper being printed on. Print is probably the most complex thing to calibrate, as so many potential factors come into play, so it is not generally recommended to create your own print profiles.

Most paper manufacturers offer ICC profiles for all of their papers and a variety of printers. At the very least, the top Epson and Canon printers will have ICC profiles from most paper manufacturers like Hahnemuhle, Illford, Red River, etc. If you do not yet have the necessary print profile, I highly recommend finding them and installing them into your system.



Image Color Management

It should be noted that the print profile calibrates the printer, ink, and paper....NOT the image. The image is calibrated by its color space. For the whole entire color space conversion process to work, Image Color Management, or ICM...a component of most computer systems these days, will handle conversion for you. So long as each component involved is properly calibrated, the image viewed on screen and the image printed should look very similar. There will always be some slight differences due to the nature of print (i.e. printing on a warm paper while your screen is calibrated to a D65 whitepoint will result in a white balance shift between the two.) 

If you assign a profile for a different component to the wrong thing, such as a print profile to an image, not only will the image look wrong on screen, but it will likely look doubly wrong in print. Keep each component assigned its proper profile from the proper pool of valid profiles, and everything should remain consistent.
",jrista,https://photo.stackexchange.com/users/124,http://photo.stackexchange.com/questions/41238/what-is-happening-when-i-convert-from-a-source-color-space-adobergb-to-a-canon-p,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,What happens when I convert the source color space Adobe RGB to Canon Photo Paper configuration file?,"I'm converting my photos in photoshop from the source space of Adobe RGB to the destination space of Canon PRO-100 LU 1/2 Photo Paper Pro Luster and when I do this my colors change very drastically, the become darker and desaturated. 

The photo is changing a lot but I thought this was the correct way to print, to do  a proper conversion to the paper's profile?

What is happening when I convert from a source color space Adobe RGB to a Canon photo paper profile? How do I print and get the proper colors (fairly accurate)?

For instance with these blue colors look like different shades of blue when in Adobe RGB/sRGB as below, but when I print the 3 squares end up looking very similar, and in the print the last square which is really saturated actually looks like the top dark square on my monitor. Print viewed under tungsten lighting and compared a macbook pro at 3 bars brightness. Also when you see the print preview, it actually looks fairly accurate and is completely different from what I see in photoshop. Is there an issue with certain colors? For instance when I printed a desaturated yellow building it looked noticeably warmer than on my display in Adobe RGB


","Short Answer

You should not actually convert your images directly into the printer space, as you then actually lose the ability to properly color manage your results.

For color management to work, each device involved in the process needs to be assigned a color profile. The image should be assigned an appropriate color space itself, and that is usually sRGB, AdobeRGB, or ProPhotoRGB. The color space, when assigned to an image, is the images color profile. The computer screen should be assigned its own separate color profile, usually by using a color profiling tool with a matched software package. Finally, if printing, the printer should also have a color profile, which is selected when printing actually takes place.



Color Spaces

Color spaces define how the colors of an image fit within the available known range of color, officially called L*a*b*, or just Lab for short. The Lab space models the entire range of known color as far as the human eye can perceive it, according to studies done by the IE in the 1930s. Standard color spaces such as sRGB, AdobeRGB, and ProPhotoRGB simply define how each color as it can be described by a computer map to specific color ""coordinates"" in Lab space. It is best to only assign one of these to your images. Which one you assign does not actually matter for the most part, however the smaller the space you assign, the more difficult it will be to preserve maximum original information (i.e. sRGB is a fairly small gamut vs. ProPhotoRGB, and downconverting my require multiple colors to reference the same colors in the end.)

Screen Profiles

In order to properly observe your photographs with accurate color on a computer screen, you should calibrate it. Screen calibration is usually done with some kind of device, a colorimiter or a spectrophotometer, which measures the color output of your screen and produces a custom ICC profile specifically for it, and the environment within which it resides. 

A custom ICC profile will ensure that your screen is reproducing color as accurately as possible, and your photography should not only look more realistic (which may mean less saturated!), but it should display finer levels of contrast between pixels better, so what you see on screen should be crisper and sharper. Having a calibrated screen is not a necessity, however it is highly recommended, as comparing prints to an oversaturated screen can make you wonder why things don't seem to match up.

Print Profiles

To print accurately, you need a print profile. Note that is ""print"" profile, not ""printer"" profile. A print profile actually takes into account the printer, its inks, as well as the paper being printed on. Print is probably the most complex thing to calibrate, as so many potential factors come into play, so it is not generally recommended to create your own print profiles.

Most paper manufacturers offer ICC profiles for all of their papers and a variety of printers. At the very least, the top Epson and Canon printers will have ICC profiles from most paper manufacturers like Hahnemuhle, Illford, Red River, etc. If you do not yet have the necessary print profile, I highly recommend finding them and installing them into your system.



Image Color Management

It should be noted that the print profile calibrates the printer, ink, and paper....NOT the image. The image is calibrated by its color space. For the whole entire color space conversion process to work, Image Color Management, or ICM...a component of most computer systems these days, will handle conversion for you. So long as each component involved is properly calibrated, the image viewed on screen and the image printed should look very similar. There will always be some slight differences due to the nature of print (i.e. printing on a warm paper while your screen is calibrated to a D65 whitepoint will result in a white balance shift between the two.) 

If you assign a profile for a different component to the wrong thing, such as a print profile to an image, not only will the image look wrong on screen, but it will likely look doubly wrong in print. Keep each component assigned its proper profile from the proper pool of valid profiles, and everything should remain consistent.
"
3447,3447,5484,Is it possible to have a convergent subsequence of a divergent sequence?,"Is it possible to have a convergent subsequence of a divergent sequence? Thanks!
",eChung00,https://math.stackexchange.com/users/92974,"Sure. Consider $0, 1, 0, 1, 0, 1, \dots$

Furthermore, the Bolzano-Weierstrass Theorem says that every bounded sequence has a convergent subsequence.
",Michael Albanese,https://math.stackexchange.com/users/39599,http://math.stackexchange.com/questions/494623/is-it-possible-to-have-a-convergent-subsequence-of-a-divergent-sequence,SCIENCE,math.stackexchange.com,0.7777777777777778,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Is it possible for convergent subsequences of divergent sequences?,Is it possible for convergent subsequences of divergent sequences? Thank you!,"Sure. Consider $0, 1, 0, 1, 0, 1, \dots$

Furthermore, the Bolzano-Weierstrass Theorem says that every bounded sequence has a convergent subsequence.
"
2618,2618,4163,Twisted Fate: Do Wildcards (Q) apply the effects of Pick A Card (W)?,"Wildcards (Q):


  Twisted Fate throws 3 cards forward in an arc, dealing magic damage 60 / 110 / 160 / 210 / 260 (+ 65% AP) to enemies they pass through. 


Pick a Card (W):


  When first activated, cards flash over Twisted Fate's head in the following order: blue, then red, then gold (this cycle repeats itself). When he uses the ability again, he picks the current card over his head; the card picked converts his next basic attack within 6 seconds to deal magic damage and add a special effect. Twisted Fate has 6 seconds to select a card.


Do the Wildcard cards apply the same effect as the cards in Pick a Card?
",DropDeadSander - EUW,https://gaming.stackexchange.com/users/61976,"His Q ability is simply an AoE spell that deals damage. Although the cards do occasionally change their color, there is no additional effect to it. It's just cosmetic.
",Jutschge,https://gaming.stackexchange.com/users/64410,http://gaming.stackexchange.com/questions/184880/twisted-fate-do-wildcards-q-apply-the-effects-of-pick-a-card-w,CULTURE,gaming.stackexchange.com,0.6666666666666666,0.5,0.5,1.0,0.5,0.5,0.6666666666666666,0.5,0.5,0.0,0.5,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.5,0.8333333333333334,0.8,0.0,0.0,1.0,0.8333333333333334,Twisted fate: does wildcard (q) apply the effect of selection card (W)?,"Wildcards (Q):


  Twisted Fate throws 3 cards forward in an arc, dealing magic damage 60 / 110 / 160 / 210 / 260 (+ 65% AP) to enemies they pass through. 


Pick a Card (W):


  When first activated, cards flash over Twisted Fate's head in the following order: blue, then red, then gold (this cycle repeats itself). When he uses the ability again, he picks the current card over his head; the card picked converts his next basic attack within 6 seconds to deal magic damage and add a special effect. Twisted Fate has 6 seconds to select a card.


Do the Wildcard cards apply the same effect as the cards in Pick a Card?
","His Q ability is simply an AoE spell that deals damage. Although the cards do occasionally change their color, there is no additional effect to it. It's just cosmetic.
"
5940,5940,9412,Ad layout for programs - Illustrator or InDesign,"today I'm looking for some advice from folks who have laid out event programs. 

In this case, the client (a local nonprofit) has a famous keynote speaker at their event, and have solicited donations from local businesses. Each donation over a certain level = a full page ad in the program for the event. Most of them are ""Congratulations to  on your anniversary"", etc. with a company logo sitting somewhere (the businesses that send in their own camera-ready artwork will just have them dropped into place). 

I'm going to be laying each ad out in a template so they look consistent; my question to the GD crowd is, ""Should I lay the template out in Illustrator and bring each ad individually in to InDesign or should I create a template page for an ad in InDesign and lay each ad out in InDesign?""

Based on your experience, what are the pros and cons of each approach? Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for) but I lose a certain amount of flexibility once I hit InDesign (the program will ultimately be laid out in InDesign).
",lawndartcatcher,https://graphicdesign.stackexchange.com/users/575,"Either one.


  Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for)


Actually, that's not really it's specific purpose. But it does just fine. If you'll be doing any kind of vector work in your ads it may be easier to have such a simple thing all in one doc.

On the other hand, InD does have the better type tools. And templated layout is very straightforward. If you wanted to share styles or colors across the ads (it works in some programs) you could even set them up as a book to make syncing painless.

It all comes down to where you're most comfortable. They are both capable layout environments for simple 1-page pieces. You'll be faster where you know the tool best.

I would avoid saving out the ads as PDF. Since you're controlling the whole scope (program and ads), link directly to the source files and if you have to make updates you can open them directly from the program and updating won't require another PDF export.
",plainclothes,https://graphicdesign.stackexchange.com/users/4216,http://graphicdesign.stackexchange.com/questions/20355/ad-layout-for-programs-illustrator-or-indesign,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.5555555555555556,1.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,Program advertising layout - illustration or illustration,"today I'm looking for some advice from folks who have laid out event programs. 

In this case, the client (a local nonprofit) has a famous keynote speaker at their event, and have solicited donations from local businesses. Each donation over a certain level = a full page ad in the program for the event. Most of them are ""Congratulations to  on your anniversary"", etc. with a company logo sitting somewhere (the businesses that send in their own camera-ready artwork will just have them dropped into place). 

I'm going to be laying each ad out in a template so they look consistent; my question to the GD crowd is, ""Should I lay the template out in Illustrator and bring each ad individually in to InDesign or should I create a template page for an ad in InDesign and lay each ad out in InDesign?""

Based on your experience, what are the pros and cons of each approach? Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for) but I lose a certain amount of flexibility once I hit InDesign (the program will ultimately be laid out in InDesign).
","Either one.


  Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for)


Actually, that's not really it's specific purpose. But it does just fine. If you'll be doing any kind of vector work in your ads it may be easier to have such a simple thing all in one doc.

On the other hand, InD does have the better type tools. And templated layout is very straightforward. If you wanted to share styles or colors across the ads (it works in some programs) you could even set them up as a book to make syncing painless.

It all comes down to where you're most comfortable. They are both capable layout environments for simple 1-page pieces. You'll be faster where you know the tool best.

I would avoid saving out the ads as PDF. Since you're controlling the whole scope (program and ads), link directly to the source files and if you have to make updates you can open them directly from the program and updating won't require another PDF export.
"
5810,5810,9203,How to fix a dpkg broken by the Brother MFC-7340 deb driver,"I'm getting an apt-get error that says

E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.

The brmfc7340lpr is a printer driver -- it's a local deb file. Doing a dpkg or apt-get purge doesn't work, neither does apt-get install -f .

How do I reinstall a package from a local deb file?

Output:

box-name% sudo apt-get upgrade
[sudo] password for username: 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo apt-get purge brmfc7340lpr
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo dpkg --purge brmfc7340lpr 
dpkg: error processing brmfc7340lpr (--purge):
 Package is in a very bad inconsistent state - you should
 reinstall it before attempting a removal.
Errors were encountered while processing:
 brmfc7340lpr
box-name% sudo dpkg --install brmfc7340lpr-2.0.2-1.i386.deb
Selecting previously deselected package brmfc7340lpr.
(Reading database ... 725204 files and directories currently installed.)
Preparing to replace brmfc7340lpr 2.0.2-1 (using .../brmfc7340lpr-2.0.2-1.i386.deb) ...
Unpacking replacement brmfc7340lpr ...
start: Unknown job: lpd
dpkg: warning: subprocess old post-removal script returned error exit status 1
dpkg - trying script from the new package instead ...
start: Unknown job: lpd
dpkg: error processing brmfc7340lpr-2.0.2-1.i386.deb (--install):
 subprocess new post-removal script returned error exit status 1
start: Unknown job: lpd
dpkg: error while cleaning up:
 subprocess new post-removal script returned error exit status 1
Errors were encountered while processing:
brmfc7340lpr-2.0.2-1.i386.deb
box-name% sudo apt-get install -f                                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% 

",Roman A. Taycher,https://askubuntu.com/users/669,"Actually, I ran into the same problem. Turns out I followed some irrelevant information and created a /etc/init.d/lpd file as a softlink to /etc/init.d/cups
The .postrm script checks for lpd and if it exists, tries to start the service.
After I deleted the softlinked lpd file in the init.d directory, the package installation and removal went back to normal.
",Matt,https://askubuntu.com/users/29138,http://askubuntu.com/questions/5058/how-to-fix-a-dpkg-broken-by-the-brother-mfc-7340-deb-driver,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.8888888888888888,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.0,1.0,1.0,How to fix the dpkg damaged by brother mfc-7340 DEB driver,"I'm getting an apt-get error that says

E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.

The brmfc7340lpr is a printer driver -- it's a local deb file. Doing a dpkg or apt-get purge doesn't work, neither does apt-get install -f .

How do I reinstall a package from a local deb file?

Output:

box-name% sudo apt-get upgrade
[sudo] password for username: 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo apt-get purge brmfc7340lpr
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% sudo dpkg --purge brmfc7340lpr 
dpkg: error processing brmfc7340lpr (--purge):
 Package is in a very bad inconsistent state - you should
 reinstall it before attempting a removal.
Errors were encountered while processing:
 brmfc7340lpr
box-name% sudo dpkg --install brmfc7340lpr-2.0.2-1.i386.deb
Selecting previously deselected package brmfc7340lpr.
(Reading database ... 725204 files and directories currently installed.)
Preparing to replace brmfc7340lpr 2.0.2-1 (using .../brmfc7340lpr-2.0.2-1.i386.deb) ...
Unpacking replacement brmfc7340lpr ...
start: Unknown job: lpd
dpkg: warning: subprocess old post-removal script returned error exit status 1
dpkg - trying script from the new package instead ...
start: Unknown job: lpd
dpkg: error processing brmfc7340lpr-2.0.2-1.i386.deb (--install):
 subprocess new post-removal script returned error exit status 1
start: Unknown job: lpd
dpkg: error while cleaning up:
 subprocess new post-removal script returned error exit status 1
Errors were encountered while processing:
brmfc7340lpr-2.0.2-1.i386.deb
box-name% sudo apt-get install -f                                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: The package brmfc7340lpr needs to be reinstalled, but I can't find an archive for it.
box-name% 

","Actually, I ran into the same problem. Turns out I followed some irrelevant information and created a /etc/init.d/lpd file as a softlink to /etc/init.d/cups
The .postrm script checks for lpd and if it exists, tries to start the service.
After I deleted the softlinked lpd file in the init.d directory, the package installation and removal went back to normal.
"
5311,5311,8435,When are we first informed about Gerry Lane's profession?,"In World War Z, Brad Pitt plays the role of a former UN investigator named Gerry Lane. When are we first informed of this fact?

When I watched the film, I spent half the movie wondering who he was that he could get a helicopter to specially ferry him and his family out of the city. It was only when he spoke to the naval honcho that I found out that he was a former UN man. Is this the first instance of this information being revealed to the audience?

I can remember a conversation about his job when the Lanes are having breakfast. But I don't recall the UN being mentioned.
",coleopterist,https://movies.stackexchange.com/users/3650,"While the opening chatter does mention the UN and the WHO, and Gerry explains martial law to his daughter, we do not find out exactly what his profession is/was until he and his family are extracted and arrive on the warship (and, as in my question, speak to the naval man). This is also the first time that the UN is mentioned after the aforementioned opening chatter.


  The Under-Secretary here says you were his best investigator when you were at the U.N.





  You were on the ground during the Liberian Civil War. Investigated Chechen war crimes. Sri Lanka in '07. Places you and I both know Dr. Fassbach wouldn't last a night in.


This conversation occurs at around the 32 minute mark. Until then, we have no idea who he really is.
",coleopterist,https://movies.stackexchange.com/users/3650,http://movies.stackexchange.com/questions/13714/when-are-we-first-informed-about-gerry-lanes-profession,LIFE_ARTS,movies.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,When did we first know about grey Lane's career?,"In World War Z, Brad Pitt plays the role of a former UN investigator named Gerry Lane. When are we first informed of this fact?

When I watched the film, I spent half the movie wondering who he was that he could get a helicopter to specially ferry him and his family out of the city. It was only when he spoke to the naval honcho that I found out that he was a former UN man. Is this the first instance of this information being revealed to the audience?

I can remember a conversation about his job when the Lanes are having breakfast. But I don't recall the UN being mentioned.
","Although the opening remarks did mention the United Nations and the World Health Organization, and grey explained the martial law to his daughter, we couldn't know exactly what his career was until he and his family were rescued and boarded the warship (as I asked, talking to the Navy). It is also the first time that the United Nations has been mentioned since the opening remarks."
1834,1834,2911,"What does ""to become controversial"" mean?","As a non-native speaker, I do not fully understand the meaning of the term ""to become controversial"" in the following text, which I have to translate into German:


  Where translators have made their presence felt they have become controversial, with those who characteristically intervene, seeking to domesticate texts, contrasted with those who foreignise, supposedly allowing other languages to alter our own.

",Patrick Oscity,https://english.stackexchange.com/users/12804,"It means that they have caused controversy by adding their opinions to the text they are translating rather than sticking to the literal meaning.

For example some biblical scholars changed the phrasing of parts of the Bible to suit their political agenda, the King James Bible for example is supposed to play down how bad it is to be a tyrant (I've not read it so I can't confirm this).

Wikipedia defines Controversy as:


  Controversy is a state of prolonged public dispute or debate, usually
  concerning a matter of opinion. The word was coined from the Latin
  controversia, as a composite of controversus â ""turned in an opposite
  direction,"" from contra â ""against"" â and vertere â to turn, or versus
  (see verse), hence, ""to turn against.""

",Omar Kooheji,https://english.stackexchange.com/users/963,http://english.stackexchange.com/questions/50804/what-does-to-become-controversial-mean,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.3333333333333333,1.0,1.0,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.8888888888888888,"What does ""becoming controversial"" mean?","As a non-native speaker, I do not fully understand the meaning of the term ""to become controversial"" in the following text, which I have to translate into German:


  Where translators have made their presence felt they have become controversial, with those who characteristically intervene, seeking to domesticate texts, contrasted with those who foreignise, supposedly allowing other languages to alter our own.

","It means that they have caused controversy by adding their opinions to the text they are translating rather than sticking to the literal meaning.

For example some biblical scholars changed the phrasing of parts of the Bible to suit their political agenda, the King James Bible for example is supposed to play down how bad it is to be a tyrant (I've not read it so I can't confirm this).

Wikipedia defines Controversy as:


  Controversy is a state of prolonged public dispute or debate, usually
  concerning a matter of opinion. The word was coined from the Latin
  controversia, as a composite of controversus â ""turned in an opposite
  direction,"" from contra â ""against"" â and vertere â to turn, or versus
  (see verse), hence, ""to turn against.""

"
4206,4206,6706,check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
",Oneb,https://stackoverflow.com/users/1012518,"There is no way to solve this using regexes apart from the ""overkill"" solution of listing each of the possible sequences you want to match.  Regexes are not expressive enough to offer a better solution.
",Stephen C,https://stackoverflow.com/users/139985,http://stackoverflow.com/questions/12493931/check-if-a-string-has-four-consecutive-letters-in-ascending-or-descending-order,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,1.0,"Check if the string has four consecutive letters, in ascending or descending order","Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
","There's no way to use regular expressions to solve this problem other than to list ""kill"" solutions for each possible sequence to match. Regular expressions are not enough to provide a better solution."
4750,4750,7536,Listview doesn't display data when I run on real device(API 8) but displays when i run on emulater(API 16),"Can anyone please tel me what can be the problem?

This is my code

public void onCreate(Bundle icicle) {
        super.onCreate(icicle);
        setContentView(R.layout.book_list);
        lst = (ListView) findViewById(R.id.listView1);
    new Thread(new Runnable() {
            public void run() {
                data = fetchData();                                 
                runOnUiThread(new Runnable() {                       
                    @Override
                    public void run() {
                        ArrayList&lt;String&gt; users = parseJSON(data);                                                
                    }
                });   
            }
        }).start();

final SimpleAdapter adapter =
            new SimpleAdapter(this, mylistData, R.layout.rowlayout,
                    row , new int[] {R.id.label,R.id.label1});
            lst.setAdapter(adapter);


ERROR LOG

05-24 11:08:32.218: E/AndroidRuntime(19121): FATAL EXCEPTION: Thread-12
05-24 11:08:32.218: E/AndroidRuntime(19121): android.view.ViewRoot$CalledFromWrongThreadException: Only the original thread that created a view hierarchy can touch its views.
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewRoot.checkThread(ViewRoot.java:3041)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewRoot.invalidateChild(ViewRoot.java:647)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewRoot.invalidateChildInParent(ViewRoot.java:673)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewGroup.invalidateChild(ViewGroup.java:2511)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.View.invalidate(View.java:5255)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.invalidateCursor(TextView.java:3774)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.spanChange(TextView.java:6680)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView$ChangeWatcher.onSpanAdded(TextView.java:6805)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.SpannableStringBuilder.sendSpanAdded(SpannableStringBuilder.java:906)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.SpannableStringBuilder.setSpan(SpannableStringBuilder.java:611)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.SpannableStringBuilder.setSpan(SpannableStringBuilder.java:514)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.Selection.setSelection(Selection.java:74)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.Selection.setSelection(Selection.java:85)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.method.ArrowKeyMovementMethod.initialize(ArrowKeyMovementMethod.java:280)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.setText(TextView.java:2798)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.setText(TextView.java:2671)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.EditText.setText(EditText.java:178)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.setText(TextView.java:2646)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at com.example.book.ManageAuthor.parseJSON(ManageAuthor.java:198)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at com.example.book.ManageAuthor$1.run(ManageAuthor.java:77)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at java.lang.Thread.run(Thread.java:1019)
",Programmer,https://stackoverflow.com/users/1884804,"Try to use http://developer.android.com/reference/android/view/View.html#post(java.lang.Runnable).

For example:

public void onCreate(Bundle icicle) {
    super.onCreate(icicle);
    setContentView(R.layout.book_list);
    lst = (ListView) findViewById(R.id.listView1);

    new Thread(new Runnable() {
        public void run() {
            data = fetchData();                                 
            lst.post(new Runnable() {                       
                @Override
                public void run() {
                    ArrayList&lt;String&gt; users = parseJSON(data);               
                    SimpleAdapter adapter = new SimpleAdapter(this, mylistData, R.layout.rowlayout, row , new int[] {R.id.label,R.id.label1});   
                    lst.setAdapter(adapter);                              
                }
            });   
        }
    }).start();


In that way you can parse the JSON data asynchronously and modify the data of the listview in a thread safe manner. 
",s.froehlich,https://stackoverflow.com/users/575693,http://stackoverflow.com/questions/16728456/listview-doesnt-display-data-when-i-run-on-real-deviceapi-8-but-displays-when,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.3333333333333333,0.8888888888888888,"Listview does not display data when running on the actual device (API 8), but displays data when running on the simulator (API 16)","Can anyone please tel me what can be the problem?

This is my code

public void onCreate(Bundle icicle) {
        super.onCreate(icicle);
        setContentView(R.layout.book_list);
        lst = (ListView) findViewById(R.id.listView1);
    new Thread(new Runnable() {
            public void run() {
                data = fetchData();                                 
                runOnUiThread(new Runnable() {                       
                    @Override
                    public void run() {
                        ArrayList&lt;String&gt; users = parseJSON(data);                                                
                    }
                });   
            }
        }).start();

final SimpleAdapter adapter =
            new SimpleAdapter(this, mylistData, R.layout.rowlayout,
                    row , new int[] {R.id.label,R.id.label1});
            lst.setAdapter(adapter);


ERROR LOG

05-24 11:08:32.218: E/AndroidRuntime(19121): FATAL EXCEPTION: Thread-12
05-24 11:08:32.218: E/AndroidRuntime(19121): android.view.ViewRoot$CalledFromWrongThreadException: Only the original thread that created a view hierarchy can touch its views.
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewRoot.checkThread(ViewRoot.java:3041)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewRoot.invalidateChild(ViewRoot.java:647)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewRoot.invalidateChildInParent(ViewRoot.java:673)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.ViewGroup.invalidateChild(ViewGroup.java:2511)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.view.View.invalidate(View.java:5255)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.invalidateCursor(TextView.java:3774)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.spanChange(TextView.java:6680)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView$ChangeWatcher.onSpanAdded(TextView.java:6805)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.SpannableStringBuilder.sendSpanAdded(SpannableStringBuilder.java:906)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.SpannableStringBuilder.setSpan(SpannableStringBuilder.java:611)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.SpannableStringBuilder.setSpan(SpannableStringBuilder.java:514)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.Selection.setSelection(Selection.java:74)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.Selection.setSelection(Selection.java:85)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.text.method.ArrowKeyMovementMethod.initialize(ArrowKeyMovementMethod.java:280)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.setText(TextView.java:2798)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.setText(TextView.java:2671)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.EditText.setText(EditText.java:178)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at android.widget.TextView.setText(TextView.java:2646)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at com.example.book.ManageAuthor.parseJSON(ManageAuthor.java:198)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at com.example.book.ManageAuthor$1.run(ManageAuthor.java:77)
05-24 11:08:32.218: E/AndroidRuntime(19121):    at java.lang.Thread.run(Thread.java:1019)
","Try to use http://developer.android.com/reference/android/view/View.html#post(java.lang.Runnable).

For example:

public void onCreate(Bundle icicle) {
    super.onCreate(icicle);
    setContentView(R.layout.book_list);
    lst = (ListView) findViewById(R.id.listView1);

    new Thread(new Runnable() {
        public void run() {
            data = fetchData();                                 
            lst.post(new Runnable() {                       
                @Override
                public void run() {
                    ArrayList&lt;String&gt; users = parseJSON(data);               
                    SimpleAdapter adapter = new SimpleAdapter(this, mylistData, R.layout.rowlayout, row , new int[] {R.id.label,R.id.label1});   
                    lst.setAdapter(adapter);                              
                }
            });   
        }
    }).start();


In that way you can parse the JSON data asynchronously and modify the data of the listview in a thread safe manner. 
"
4956,4956,7892,Chaining deferreds,"I have a lot of functions that currently look like this:

function LoadFromURL(url) 
{
    var d = $.Deferred();
    $.get(url).then(function(text)
    {
        LoadFromText(text).then(function(obj)
        {
            d.resolve(obj);
        }, 
        function(err)
        {
            d.reject(err);
        });
    }, 
    function(err)
    {
        d.reject(err);
    });
    return d.promise();
}


This function takes a URL and loads the text within a promise. The text is then passed to the LoadFromText function which returns another promise. If this succeeds, the outer deferred is resolved. If the URL cannot be loaded, or the LoadFromText function fails then the outer deferred is rejected.

Is there a way that I can chain the result of the resolve / reject and end up with something like this:

function LoadFromURL(url) 
{
    return $.get(url).then(function(text)
    {
        return LoadFromText(text);
    }, 
    function(err)
    {
        return $.Deferred().reject(err);
    }).promise();
}


I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used. 

I realise this doesn't work at the moment (the result is the promise, rather than the result of the promise), but hopefully someone can suggest a way to make this work so I can tidy up the sometimes confusing mess of the first example.

I hope this makes sense. Thanks.
",Barguast,https://stackoverflow.com/users/283445,"
  Is there a way that I can chain the result


Yes, that is the default behaviour of then!

function LoadFromURL(url) {
    return $.get(url).then(LoadFromText);
}



  I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used.


jQuery does support this behaviour since version 1.8. For 1.5 to 1.7 you could use .pipe.
",Bergi,https://stackoverflow.com/users/1048572,http://stackoverflow.com/questions/17946391/chaining-deferreds,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.7777777777777778,Chain extension,"I have a lot of functions that currently look like this:

function LoadFromURL(url) 
{
    var d = $.Deferred();
    $.get(url).then(function(text)
    {
        LoadFromText(text).then(function(obj)
        {
            d.resolve(obj);
        }, 
        function(err)
        {
            d.reject(err);
        });
    }, 
    function(err)
    {
        d.reject(err);
    });
    return d.promise();
}


This function takes a URL and loads the text within a promise. The text is then passed to the LoadFromText function which returns another promise. If this succeeds, the outer deferred is resolved. If the URL cannot be loaded, or the LoadFromText function fails then the outer deferred is rejected.

Is there a way that I can chain the result of the resolve / reject and end up with something like this:

function LoadFromURL(url) 
{
    return $.get(url).then(function(text)
    {
        return LoadFromText(text);
    }, 
    function(err)
    {
        return $.Deferred().reject(err);
    }).promise();
}


I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used. 

I realise this doesn't work at the moment (the result is the promise, rather than the result of the promise), but hopefully someone can suggest a way to make this work so I can tidy up the sometimes confusing mess of the first example.

I hope this makes sense. Thanks.
","
  Is there a way that I can chain the result


Yes, that is the default behaviour of then!

function LoadFromURL(url) {
    return $.get(url).then(LoadFromText);
}



  I've seen some implementations of promises that allow this - returning a promise within 'then', means that the eventual result of the promise is used.


jQuery does support this behaviour since version 1.8. For 1.5 to 1.7 you could use .pipe.
"
4832,4832,7680,Mathematics of Ritardando,"Beyond feel &amp; experience, is there a rule conductors use for ritardando in terms of  (a) its rate, (b) its change in rate, and/or (c) the relationship between the final tempo and the tempo of the piece?

(In getting my software to execute a ritardando, I employed over four measures a measure-by-measure decrease in tempo, and what sounded ""right"" to me ultimately was decreasing the tempo by 4 bpm, then a further 9, then a further 16 (pleasing pattern) to arrive at 127/156 (close to 3/4) the original tempo.)


",commonhare,https://music.stackexchange.com/users/16938,"""Beyond feel and experience""? Using a mathematical formula to create a ritard in music would not be beyond using instinct, but vice versa. It's nearly impossible to create an authentic ritard in computerized music because composers don't create ritards to slow down the music, but to create an emotional reaction in the audience. The rates of ritards depend on countless criteriae such as harmony, melody, timbre, and rhythm, and what the musician has had for lunch.

Computers are thus extremely impractical music makers. It is up to you to decide what is pleasing and program the computer to follow your wishes, if possible. Whatever you decide is pleasing, it is extremely probably that someone out there will disagree with you. The best you can do is make an intelligent decision about the music.

In terms of following ritadando markings in the score:

At the end of a piece

Ritardando markings at the end of a piece should generally be greater than other ritardandos throughout the piece, unless otherwise specified. If the music was slow to begin with, musicians should be careful not to slow too dramatically.

When there is a dashed line (- - -) indicating the length of the ritard

Musicians should gradually slow the music down until the dashed line ends in the score. There may or may not be a tempo indicated to arrive at. Obey any ""a tempo"" markings.

When there is a ritard marking alone

Obey the ritard marking intelligently.
",Richard,https://music.stackexchange.com/users/7103,http://music.stackexchange.com/questions/27009/mathematics-of-ritardando,LIFE_ARTS,music.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,Ritadando mathematics,"Beyond feel &amp; experience, is there a rule conductors use for ritardando in terms of  (a) its rate, (b) its change in rate, and/or (c) the relationship between the final tempo and the tempo of the piece?

(In getting my software to execute a ritardando, I employed over four measures a measure-by-measure decrease in tempo, and what sounded ""right"" to me ultimately was decreasing the tempo by 4 bpm, then a further 9, then a further 16 (pleasing pattern) to arrive at 127/156 (close to 3/4) the original tempo.)


","""Beyond feel and experience""? Using a mathematical formula to create a ritard in music would not be beyond using instinct, but vice versa. It's nearly impossible to create an authentic ritard in computerized music because composers don't create ritards to slow down the music, but to create an emotional reaction in the audience. The rates of ritards depend on countless criteriae such as harmony, melody, timbre, and rhythm, and what the musician has had for lunch.

Computers are thus extremely impractical music makers. It is up to you to decide what is pleasing and program the computer to follow your wishes, if possible. Whatever you decide is pleasing, it is extremely probably that someone out there will disagree with you. The best you can do is make an intelligent decision about the music.

In terms of following ritadando markings in the score:

At the end of a piece

Ritardando markings at the end of a piece should generally be greater than other ritardandos throughout the piece, unless otherwise specified. If the music was slow to begin with, musicians should be careful not to slow too dramatically.

When there is a dashed line (- - -) indicating the length of the ritard

Musicians should gradually slow the music down until the dashed line ends in the score. There may or may not be a tempo indicated to arrive at. Obey any ""a tempo"" markings.

When there is a ritard marking alone

Obey the ritard marking intelligently.
"
3900,3900,6216,HP EVA4400 Vraid5 Virtual Disks Failure,"I have a eva4400 with 8 disks six of them in a raid6 group

I have 2 vraid5 in this group.

I have lost 3 disks.

Since I get the administrator post after the disaster happened I have no clue on how where the disks distributed on eva but, I notice that I have 2 disks failed in the disk group, 1 disk failed on Ungrouped disks, and 1 good drive also in Ungrouped disks.

I dont now if the 2 disks (the good and the bad) where in the ungrouped disks from the start

I bought 3 new disks from HP and place them in so now I have 4 good disks on ungrouped disks and 1 bad disk and also still 2 bad disks on disk group

Since I have no support from HP is there anything I can do to save the data from failed vraid5 diks?
Any help is much appriciated.
",Steaven Wolf,https://serverfault.com/users/188241,"
  is there anything I can do to save the data from failed vraid5 disks?


No, you'll have to restore from backup sorry.

That said I did just want to clarify that you meant you have 8 disks, 1 disk group with two spares and two virtual disks using VRAID5 - is that right? I just wanted to get the terminology right as your question wasn't as clear as it could be.

Can I suggest that when you get this back up and running you configure the disk group to only have a single spare, not double - not for such a small array. Then use either VRAID 6 or 10 (0+1 actually), they're much more resilient than VRAID 5.

Oh and on one final note - these aren't the 1TB FATA disks are they? a few years ago we saw a ridiculous number of these fail, many at the same time - due to miscommunicated duty-cycle requirements - we abandoned using those disks. I'm just keen to help you avoid a repeat of this issue.
",Chopper3,https://serverfault.com/users/1435,http://serverfault.com/questions/535712,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.0,0.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,HP eva4400 vraid5 virtual disk failure,"I have a eva4400 with 8 disks six of them in a raid6 group

I have 2 vraid5 in this group.

I have lost 3 disks.

Since I get the administrator post after the disaster happened I have no clue on how where the disks distributed on eva but, I notice that I have 2 disks failed in the disk group, 1 disk failed on Ungrouped disks, and 1 good drive also in Ungrouped disks.

I dont now if the 2 disks (the good and the bad) where in the ungrouped disks from the start

I bought 3 new disks from HP and place them in so now I have 4 good disks on ungrouped disks and 1 bad disk and also still 2 bad disks on disk group

Since I have no support from HP is there anything I can do to save the data from failed vraid5 diks?
Any help is much appriciated.
","
  is there anything I can do to save the data from failed vraid5 disks?


No, you'll have to restore from backup sorry.

That said I did just want to clarify that you meant you have 8 disks, 1 disk group with two spares and two virtual disks using VRAID5 - is that right? I just wanted to get the terminology right as your question wasn't as clear as it could be.

Can I suggest that when you get this back up and running you configure the disk group to only have a single spare, not double - not for such a small array. Then use either VRAID 6 or 10 (0+1 actually), they're much more resilient than VRAID 5.

Oh and on one final note - these aren't the 1TB FATA disks are they? a few years ago we saw a ridiculous number of these fail, many at the same time - due to miscommunicated duty-cycle requirements - we abandoned using those disks. I'm just keen to help you avoid a repeat of this issue.
"
2714,2714,4327,Where do I stand from a legal perspective using Helvetica Neue in my logo?,"What is the legal perspective of using specific fonts for your company logo?

Which fonts CAN you use in your logo? 
",Tom,https://graphicdesign.stackexchange.com/users/19236,"Every font should come with a EULA (End User License Agreement) that will outline what you can and can not do with the font.

In most every case, you having purchased a license for a font grants you the right to use the font for typesetting any work you are creating. In some cases, there may be some exceptions. Some common exceptions:


some fonts don't allow you to embed them in electronic files (software or PDFs)
some fonts don't let you use them for commercial work (typically an exclusion in freeware fonts)
some fonts require an additional license for usage as a logo for large corporations (this is restriction for some of House Industry's faces)
most fonts don't let you use the font as a primary element of a retail item (for instance, using the font to create big wooden letters and then selling the letters) without an additional license. Another example is some fonts require additional licenses for using it in clothing. 
some fonts have moral clauses (for instance, not being allowed to use it to promote tobacco products)


In general, though, most fonts that you have paid a license for allow you to legally use them in logos. Just check to see if there are any exceptions in the license. If you're not sure, email the foundry and they'll be glad to answer the question for you. 
",DA01,https://graphicdesign.stackexchange.com/users/306,http://graphicdesign.stackexchange.com/questions/26599/where-do-i-stand-from-a-legal-perspective-using-helvetica-neue-in-my-logo,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.7777777777777778,0.0,0.5,1.0,1.0,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,1.0,"From a legal point of view, where should I stand when using Helvetica Neue in my logo?",What is your legal opinion on the use of specific fonts in your company's trademarks?,"Every font should come with a EULA (End User License Agreement) that will outline what you can and can not do with the font.

In most every case, you having purchased a license for a font grants you the right to use the font for typesetting any work you are creating. In some cases, there may be some exceptions. Some common exceptions:


some fonts don't allow you to embed them in electronic files (software or PDFs)
some fonts don't let you use them for commercial work (typically an exclusion in freeware fonts)
some fonts require an additional license for usage as a logo for large corporations (this is restriction for some of House Industry's faces)
most fonts don't let you use the font as a primary element of a retail item (for instance, using the font to create big wooden letters and then selling the letters) without an additional license. Another example is some fonts require additional licenses for using it in clothing. 
some fonts have moral clauses (for instance, not being allowed to use it to promote tobacco products)


In general, though, most fonts that you have paid a license for allow you to legally use them in logos. Just check to see if there are any exceptions in the license. If you're not sure, email the foundry and they'll be glad to answer the question for you. 
"
2409,2409,3845,How to configure ssh tunneling with Putty between two RHEL servers?,"I'm trying to allow ssh access from a remote RHEL server to a local RHEL box via Win/Putty gateway. Basically, I'd like to be able to do 'ssh localhost -p 512' on a remote server so that it would connect to the RHEL server in the local network. The local network is beyond a firewall so I can connect from my Win PC to the remote server with Putty/ssh but not vice verse.

LclSrv----WinXP/Putty-----||-----RmtSrv

So, I've added the following tunneling settings to the current RmtSrv session in Putty (actually I use Kitty but doesn't matter):

R512 LclSrv:22

I expect that this would create a process on the remote server that listens port 512 and transfers the connections to a local network/LclSrv port 22.

After pressing start button, Putty opens a regular ssh terminal session successfully but nothing happens. (options show active port forwarding). I've checked with netstat -l that port 512 is not listening on RmtSrv. ssh on this port returns 'connection refused'. What am I doing wrong? May be there is something in the sshd_config that needs to be changed in order to allow the tunneling? Could it be user privileges on RmtSrv that prevents me from creating tunnels? I have sudo btw.

Cheers, Vlad.
",spoonboy,https://serverfault.com/users/201265,"Local port forwarding scenario (rmtsrv has access to WinXP):

What you want to do in ssh terms is forward a local port to another machine and allow other hosts (rmtsrv) to connect to it.

So you set up local WinXP:512 to forward to lclsrv:22.

So in Putty's Tunnel settings be sure to check Local ports accept connections from other hosts and add source port 512 with the destination lclsrv:22 to the forwarded ports.

Edit to accommodate comment:
Remote port forwarding scenario (WinXP has access to both srvs):

The configuration you suggest should work.

r512 LclSrv:22


Is correct.
I'd guess the issue is with the sshd security settings on rmtsrv. Check if this is enabled:

AllowTcpForwarding yes


If you want to enable access to the forwarded port for others on rmtsrvs network:

GatewayPorts yes


The config usually resides in '/etc/ssh/sshd_config
",AndreasT,https://serverfault.com/users/24526,http://serverfault.com/questions/558831,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,How to use putty to configure SSH tunnel between two RHEL servers?,"I'm trying to allow ssh access from a remote RHEL server to a local RHEL box via Win/Putty gateway. Basically, I'd like to be able to do 'ssh localhost -p 512' on a remote server so that it would connect to the RHEL server in the local network. The local network is beyond a firewall so I can connect from my Win PC to the remote server with Putty/ssh but not vice verse.

LclSrv----WinXP/Putty-----||-----RmtSrv

So, I've added the following tunneling settings to the current RmtSrv session in Putty (actually I use Kitty but doesn't matter):

R512 LclSrv:22

I expect that this would create a process on the remote server that listens port 512 and transfers the connections to a local network/LclSrv port 22.

After pressing start button, Putty opens a regular ssh terminal session successfully but nothing happens. (options show active port forwarding). I've checked with netstat -l that port 512 is not listening on RmtSrv. ssh on this port returns 'connection refused'. What am I doing wrong? May be there is something in the sshd_config that needs to be changed in order to allow the tunneling? Could it be user privileges on RmtSrv that prevents me from creating tunnels? I have sudo btw.

Cheers, Vlad.
","Local port forwarding scenario (rmtsrv has access to WinXP):

What you want to do in ssh terms is forward a local port to another machine and allow other hosts (rmtsrv) to connect to it.

So you set up local WinXP:512 to forward to lclsrv:22.

So in Putty's Tunnel settings be sure to check Local ports accept connections from other hosts and add source port 512 with the destination lclsrv:22 to the forwarded ports.

Edit to accommodate comment:
Remote port forwarding scenario (WinXP has access to both srvs):

The configuration you suggest should work.

r512 LclSrv:22


Is correct.
I'd guess the issue is with the sshd security settings on rmtsrv. Check if this is enabled:

AllowTcpForwarding yes


If you want to enable access to the forwarded port for others on rmtsrvs network:

GatewayPorts yes


The config usually resides in '/etc/ssh/sshd_config
"
4804,4804,7633,OpenLayers and TInyOWS WFS won't load - 'InvalidParameterValue',"I've got a tinyows on localhost that works fine (both through browser GetFeature and QGIS). But my OpenLayers code fails. I've checked here:
Display a WFS layer with OpenLayers and here : How to add a simple WFS layer from GeoServer to OpenLayers map?
and other similar questions to no avail. Can anyone help?

Here is the code:

    wfs = new OpenLayers.Layer.Vector(""Editable Features"", {
    strategies : [new OpenLayers.Strategy.Fixed(), saveStrategy],
    projection: new OpenLayers.Projection(""EPSG:4326""),
    protocol: new OpenLayers.Protocol.WFS({
        version: ""1.1.0"",
        srsName: ""EPSG:4326"",
        url: ""http://localhost/cgi-bin/tinyows"",
        featurePrefix: ""tows"",
        featureNS :  ""http://www.tinyows.org/"",
        featureType: ""trad"",
        geometryName: ""wkb_geometry"",
        schema: ""http://127.0.0.1/cgi-bin/tinyows?service=WFS&amp;version=1.1.0&amp;request=DescribeFeatureType&amp;Typename=tows:trad""
    })
}); 

map.addLayers([gphy, wfs]);


Here is the xml according to Firebug:

&lt;wfs:GetFeature xmlns:wfs=""http://www.opengis.net/wfs"" service=""WFS"" version=""1.1.0"" xsi:schemaLocation=""http://www.opengis.net/wfs http://schemas.opengis.net/wfs/1.1.0/wfs.xsd"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;





Here is the post response according to firebug:

&lt;?xml version='1.0' encoding='UTF-8'?&gt;
&lt;ows:ExceptionReport
  xmlns='http://www.opengis.net/ows'
  xmlns:ows='http://www.opengis.net/ows'
  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
  xsi:schemaLocation='http://www.opengis.net/ows http://schemas.opengis.net/ows/1.0.0/owsExceptionReport.xsd'
  version='1.1.0' language='en'&gt;
&lt;ows:Exception exceptionCode='InvalidParameterValue' locator='request'&gt;
&lt;ows:ExceptionText&gt;XML request isn't valid&lt;/ows:ExceptionText&gt;
&lt;/ows:Exception&gt;
&lt;/ows:ExceptionReport&gt;


Here is the tinyows config file:

&lt;tinyows online_resource=""http://127.0.0.1/cgi-bin/tinyows""
     schema_dir=""/usr/local/tinyows/schema/""&gt;
&lt;pg host=""127.0.0.1"" user=""postgres"" password=""****"" dbname=""****"" port=""5432""/&gt;
&lt;metadata name=""TinyOWS Server""
       title=""TinyOWS Server - Demo Service"" /&gt;
&lt;layer retrievable=""1""
    writable=""1""
    ns_prefix=""tows""
    ns_uri=""http://www.tinyows.org/""
    name=""trad""
    title=""TrÃ¤d"" /&gt;
&lt;/tinyows&gt;


Can anyone help?

Thanks in advance
",user10895,https://gis.stackexchange.com/users/10895,"In your TinyOWS config you write online_resource=""http://127.0.0.1/cgi-bin/tinyows"" but in OpenLayers you use another host name - http://localhost/cgi-bin/tinyows. This mismatch causes an error.
",drnextgis,https://gis.stackexchange.com/users/3420,http://gis.stackexchange.com/questions/54038/openlayers-and-tinyows-wfs-wont-load-invalidparametervalue,TECHNOLOGY,gis.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,"Openlayers and tinyows WFS will not load - ""invalidparametervalue""","I've got a tinyows on localhost that works fine (both through browser GetFeature and QGIS). But my OpenLayers code fails. I've checked here:
Display a WFS layer with OpenLayers and here : How to add a simple WFS layer from GeoServer to OpenLayers map?
and other similar questions to no avail. Can anyone help?

Here is the code:

    wfs = new OpenLayers.Layer.Vector(""Editable Features"", {
    strategies : [new OpenLayers.Strategy.Fixed(), saveStrategy],
    projection: new OpenLayers.Projection(""EPSG:4326""),
    protocol: new OpenLayers.Protocol.WFS({
        version: ""1.1.0"",
        srsName: ""EPSG:4326"",
        url: ""http://localhost/cgi-bin/tinyows"",
        featurePrefix: ""tows"",
        featureNS :  ""http://www.tinyows.org/"",
        featureType: ""trad"",
        geometryName: ""wkb_geometry"",
        schema: ""http://127.0.0.1/cgi-bin/tinyows?service=WFS&amp;version=1.1.0&amp;request=DescribeFeatureType&amp;Typename=tows:trad""
    })
}); 

map.addLayers([gphy, wfs]);


Here is the xml according to Firebug:

&lt;wfs:GetFeature xmlns:wfs=""http://www.opengis.net/wfs"" service=""WFS"" version=""1.1.0"" xsi:schemaLocation=""http://www.opengis.net/wfs http://schemas.opengis.net/wfs/1.1.0/wfs.xsd"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;





Here is the post response according to firebug:

&lt;?xml version='1.0' encoding='UTF-8'?&gt;
&lt;ows:ExceptionReport
  xmlns='http://www.opengis.net/ows'
  xmlns:ows='http://www.opengis.net/ows'
  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
  xsi:schemaLocation='http://www.opengis.net/ows http://schemas.opengis.net/ows/1.0.0/owsExceptionReport.xsd'
  version='1.1.0' language='en'&gt;
&lt;ows:Exception exceptionCode='InvalidParameterValue' locator='request'&gt;
&lt;ows:ExceptionText&gt;XML request isn't valid&lt;/ows:ExceptionText&gt;
&lt;/ows:Exception&gt;
&lt;/ows:ExceptionReport&gt;


Here is the tinyows config file:

&lt;tinyows online_resource=""http://127.0.0.1/cgi-bin/tinyows""
     schema_dir=""/usr/local/tinyows/schema/""&gt;
&lt;pg host=""127.0.0.1"" user=""postgres"" password=""****"" dbname=""****"" port=""5432""/&gt;
&lt;metadata name=""TinyOWS Server""
       title=""TinyOWS Server - Demo Service"" /&gt;
&lt;layer retrievable=""1""
    writable=""1""
    ns_prefix=""tows""
    ns_uri=""http://www.tinyows.org/""
    name=""trad""
    title=""TrÃ¤d"" /&gt;
&lt;/tinyows&gt;


Can anyone help?

Thanks in advance
","In tinyows configuration, you can write ""http://127.0.0.1/cgi-bin/tinyows"" online, but in openlayers, you can use another host name - http://localhost/cgi-bin/tinyows. This mismatch can lead to errors."
1025,1025,1616,"Flying from NYC via Philadelphia to Halifax, I clear Immigration and Customs in Canada?","Because I am trying to process an immigration work permit for Canada, (I am an American citizen), I need to fly directly into Halifax from the States.  I am trying to make sure that I don't clear Canadian immigration and customs in the Philadelphia airport.  (For instance, when I fly from Toronto to the USA, I clear American immigration and customs there.)  Any ideas?
",Paul,https://travel.stackexchange.com/users/27254,"No, American airports don't offer preclearance the way Canadian ones do. (The reason is the relative number of airports in each country: the preclearance in a small handful of Canadian cities enables flights into hundreds of American cities. To do it the other way around would be crazy.)

You will clear customs and immigration when you land in Halifax.
",Kate Gregory,https://travel.stackexchange.com/users/46,http://travel.stackexchange.com/questions/43898/flying-from-nyc-via-philadelphia-to-halifax-i-clear-immigration-and-customs-in,CULTURE,travel.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,1.0,"Fly from New York City to Halifax, and I'll go through immigration and customs procedures in Canada?","I need to fly directly from the United States to Halifax because I am applying for an immigrant work permit in Canada (I am an American citizen). I tried to make sure I didn't go through Canadian immigration and customs at Philadelphia Airport. (for example, when I fly from Toronto to the United States, I go through American Immigration and customs procedures there.) Do you have any ideas?","No, American airports don't offer preclearance the way Canadian ones do. (The reason is the relative number of airports in each country: the preclearance in a small handful of Canadian cities enables flights into hundreds of American cities. To do it the other way around would be crazy.)

You will clear customs and immigration when you land in Halifax.
"
4071,4071,6498,Number-to-word converter,"My code works, but the aesthetic of the code seems to need some real work. The logic is simple enough: 


Create three lists of words that will be used throughout the conversion
Create three functions: 

One for sub-1000 conversion
Another for 1000-and-up conversion
Another function for splitting and storing into a list of numbers above 1000.



First the code:

# Create the lists of word-equivalents from 1-19, then one for the tens group.
# Finally, a list of the (for lack of a better word) ""zero-groups"".

ByOne = [
""zero"",
""one"",
""two"",
""three"",
""four"",
""five"",
""six"",
""seven"",
""eight"",
""nine"",
""ten"",
""eleven"",
""twelve"",
""thirteen"",
""fourteen"",
""fifteen"",
""sixteen"",
""seventeen"",
""eighteen"",
""nineteen""
]

ByTen = [
""zero"",
""ten"",
""twenty"",
""thirty"",
""forty"",
""fifty"",
""sixty"",
""seventy"",
""eighty"",
""ninety""
]

zGroup = [
"""",
""thousand"",
""million"",
""billion"",
""trillion"",
""quadrillion"",
""quintillion"",
""sextillion"",
""septillion"",
""octillion"",
""nonillion"",
""decillion"",
""undecillion"",
""duodecillion"",
""tredecillion"",
""quattuordecillion"",
""sexdecillion"",
""septendecillion"",
""octodecillion"",
""novemdecillion"",
""vigintillion""
]

strNum = raw_input(""Please enter an integer:\n&gt;&gt; "")

# A recursive function to get the word equivalent for numbers under 1000.

def subThousand(inputNum):
    num = int(inputNum)
    if 0 &lt;= num &lt;= 19:
        return ByOne[num]
    elif 20 &lt;= num &lt;= 99:
        if inputNum[-1] == ""0"":
            return ByTen[int(inputNum[0])]
        else:
            return ByTen[int(inputNum[0])] + ""-"" + ByOne[int(inputNum[1])]
    elif 100 &lt;= num &lt;= 999:
        rem = num % 100
        dig = num / 100
        if rem == 0:
            return ByOne[dig] + "" hundred""
        else:
            return ByOne[dig] + "" hundred and "" + subThousand(str(rem))

# A looping function to get the word equivalent for numbers above 1000
# by splitting a number by the thousands, storing them in a list, and 
# calling subThousand on each of them, while appending the correct
# ""zero-group"".

def thousandUp(inputNum):
    num = int(inputNum)
    arrZero = splitByThousands(num)
    lenArr = len(arrZero) - 1
    resArr = []
    for z in arrZero[::-1]:
        wrd = subThousand(str(z)) + "" ""
        zap = zGroup[lenArr] + "", ""
        if wrd == "" "":
            break
        elif wrd == ""zero "":
            wrd, zap = """", """"
        resArr.append(wrd + zap)
        lenArr -= 1
    res = """".join(resArr).strip()
    if res[-1] == "","": res = res[:-1]
    return res

# Function to return a list created from splitting a number above 1000.

def splitByThousands(inputNum):
    num = int(inputNum)
    arrThousands = []
    while num != 0:
        arrThousands.append(num % 1000)
        num /= 1000
    return arrThousands

### Last part is pretty much just the output.

intNum = int(strNum)

if intNum &lt; 0:
    print ""Minus"",
    intNum *= -1
    strNum = strNum[1:]

if intNum &lt; 1000:
    print subThousand(strNum)
else:
    print thousandUp(strNum)


Sample run:

&gt;&gt;&gt; 
Please enter an integer:
&gt;&gt; 95505896639631893
ninety-five quadrillion, five hundred and five trillion, eight hundred and ninety-six billion, six hundred and thirty-nine million, six hundred and thirty-one thousand, eight hundred and ninety-three 
&gt;&gt;&gt;


Issues:

Basically, the peeves I'm having are as follows:


My first two functions seems to be taking up too many lines. The first one, subThousand, seems to be this way because of the check made against the last digit of a number from 20 to 99. The logic I applied was, if it ends in 0, use the ByTen list. If it doesn't combined ByTen and ByOne. While effective, I feel like it could use some real work since I think it qualifies as a DRY-violation. Even the final part checking for numbers from 100 to 999 seems to follow the same pattern. Alas, I've tried paring it down but I've honestly hit a roadblock on this one insofar as trying to come up with a creative and clean solution.
My second function, thousandUp is quite the disaster. I tried coming up with a looping function that creates a list of one to three-digit numbers, so that I can call subThousand on each of them from the front to the back (hence the arrZero[::-1]. At the same time, after converting each element in the list to a word, I concatenate it with the appropriate equivalent in the zGroup list, or the list of the ""zero-groups"". However, I personally can't find a safer and more precise way of landing on the ""correct"" spot in the zGroup list to start concatenating.

To get around this, I took the length of the splitByThousands array, adjusted for 0-index, and used it to get the appropriate ""zero-append"" (zap). Before the loop ends, I subtract one from its current value so that it's adjusted accordingly.
In addition, as I'm attempting to make the output as clean as possible, I add a "" "" to the wrd variable so it doesn't concatenate poorly with the zero-append, as well as add a "", "" to the zero-append to separate it from the next zero-group. However, there will be instances that there are no values for some zero-groups. To avoid showing stuff like zero million, I added a check inside. This is the part that makes me die a little inside:

for z in arrZero[::-1]:
    wrd = subThousand(str(z)) + "" ""
    zap = zGroup[lenArr] + "", ""
    if wrd == "" "":
        break
    elif wrd == ""zero "":
         wrd, zap = """", """"
    resArr.append(wrd + zap)
    lenArr -= 1



It works, but it just doesn't look good. Is it possible to do this in list-comprehension form or a better for-loop without turning it into more confusing mush?

I must admit as well that the last part of the code sucks a little. I've done a lot of str--&gt;int conversions inside the functions, then I did one more outside of them. On top of that, my approach to negative numbers is hackish at best (print ""Minus"").
",Manhattan,https://codereview.stackexchange.com/users/38300,"A couple of thoughts:


You only want to output zero in the special case when the number is 0. It would be easiest to handle that special case at the outermost level.
Use "" and "".join and "", "".join to construct strings from parts. The delimiter will be automatically left out when there are less than two parts.


Here's how I would rewrite subThousand as two functions:

def subThousand(inputNum):
    """"""Convert a number &lt; 1000 to words, and 0 to the empty string
    """"""
    num = int(inputNum)  #this should be done at higher level
    hundreds, ones = divmod(num, 100)

    parts = []
    if hundreds:
        parts.append(ByOne[hundreds] + "" hundred"")
    if ones:
        parts.append(subHundred(ones))

    return "" and "".join(parts)

def subHundred(num):
    """"""Convert a number &lt; 100 to words, and 0 to the empty string
    """"""
    if num &gt;= 20:
        tens, ones = divmod(num, 10)
    else:
        tens, ones = 0, num

    parts = []
    if tens:
        parts.append(ByTen[tens])
    if ones:
        parts.append(ByOne[ones])

    return ""-"".join(parts)

",Janne Karila,https://codereview.stackexchange.com/users/10916,http://codereview.stackexchange.com/questions/43744/number-to-word-converter,TECHNOLOGY,codereview.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Digital converter,"My code works, but the aesthetic of the code seems to need some real work. The logic is simple enough: 


Create three lists of words that will be used throughout the conversion
Create three functions: 

One for sub-1000 conversion
Another for 1000-and-up conversion
Another function for splitting and storing into a list of numbers above 1000.



First the code:

# Create the lists of word-equivalents from 1-19, then one for the tens group.
# Finally, a list of the (for lack of a better word) ""zero-groups"".

ByOne = [
""zero"",
""one"",
""two"",
""three"",
""four"",
""five"",
""six"",
""seven"",
""eight"",
""nine"",
""ten"",
""eleven"",
""twelve"",
""thirteen"",
""fourteen"",
""fifteen"",
""sixteen"",
""seventeen"",
""eighteen"",
""nineteen""
]

ByTen = [
""zero"",
""ten"",
""twenty"",
""thirty"",
""forty"",
""fifty"",
""sixty"",
""seventy"",
""eighty"",
""ninety""
]

zGroup = [
"""",
""thousand"",
""million"",
""billion"",
""trillion"",
""quadrillion"",
""quintillion"",
""sextillion"",
""septillion"",
""octillion"",
""nonillion"",
""decillion"",
""undecillion"",
""duodecillion"",
""tredecillion"",
""quattuordecillion"",
""sexdecillion"",
""septendecillion"",
""octodecillion"",
""novemdecillion"",
""vigintillion""
]

strNum = raw_input(""Please enter an integer:\n&gt;&gt; "")

# A recursive function to get the word equivalent for numbers under 1000.

def subThousand(inputNum):
    num = int(inputNum)
    if 0 &lt;= num &lt;= 19:
        return ByOne[num]
    elif 20 &lt;= num &lt;= 99:
        if inputNum[-1] == ""0"":
            return ByTen[int(inputNum[0])]
        else:
            return ByTen[int(inputNum[0])] + ""-"" + ByOne[int(inputNum[1])]
    elif 100 &lt;= num &lt;= 999:
        rem = num % 100
        dig = num / 100
        if rem == 0:
            return ByOne[dig] + "" hundred""
        else:
            return ByOne[dig] + "" hundred and "" + subThousand(str(rem))

# A looping function to get the word equivalent for numbers above 1000
# by splitting a number by the thousands, storing them in a list, and 
# calling subThousand on each of them, while appending the correct
# ""zero-group"".

def thousandUp(inputNum):
    num = int(inputNum)
    arrZero = splitByThousands(num)
    lenArr = len(arrZero) - 1
    resArr = []
    for z in arrZero[::-1]:
        wrd = subThousand(str(z)) + "" ""
        zap = zGroup[lenArr] + "", ""
        if wrd == "" "":
            break
        elif wrd == ""zero "":
            wrd, zap = """", """"
        resArr.append(wrd + zap)
        lenArr -= 1
    res = """".join(resArr).strip()
    if res[-1] == "","": res = res[:-1]
    return res

# Function to return a list created from splitting a number above 1000.

def splitByThousands(inputNum):
    num = int(inputNum)
    arrThousands = []
    while num != 0:
        arrThousands.append(num % 1000)
        num /= 1000
    return arrThousands

### Last part is pretty much just the output.

intNum = int(strNum)

if intNum &lt; 0:
    print ""Minus"",
    intNum *= -1
    strNum = strNum[1:]

if intNum &lt; 1000:
    print subThousand(strNum)
else:
    print thousandUp(strNum)


Sample run:

&gt;&gt;&gt; 
Please enter an integer:
&gt;&gt; 95505896639631893
ninety-five quadrillion, five hundred and five trillion, eight hundred and ninety-six billion, six hundred and thirty-nine million, six hundred and thirty-one thousand, eight hundred and ninety-three 
&gt;&gt;&gt;


Issues:

Basically, the peeves I'm having are as follows:


My first two functions seems to be taking up too many lines. The first one, subThousand, seems to be this way because of the check made against the last digit of a number from 20 to 99. The logic I applied was, if it ends in 0, use the ByTen list. If it doesn't combined ByTen and ByOne. While effective, I feel like it could use some real work since I think it qualifies as a DRY-violation. Even the final part checking for numbers from 100 to 999 seems to follow the same pattern. Alas, I've tried paring it down but I've honestly hit a roadblock on this one insofar as trying to come up with a creative and clean solution.
My second function, thousandUp is quite the disaster. I tried coming up with a looping function that creates a list of one to three-digit numbers, so that I can call subThousand on each of them from the front to the back (hence the arrZero[::-1]. At the same time, after converting each element in the list to a word, I concatenate it with the appropriate equivalent in the zGroup list, or the list of the ""zero-groups"". However, I personally can't find a safer and more precise way of landing on the ""correct"" spot in the zGroup list to start concatenating.

To get around this, I took the length of the splitByThousands array, adjusted for 0-index, and used it to get the appropriate ""zero-append"" (zap). Before the loop ends, I subtract one from its current value so that it's adjusted accordingly.
In addition, as I'm attempting to make the output as clean as possible, I add a "" "" to the wrd variable so it doesn't concatenate poorly with the zero-append, as well as add a "", "" to the zero-append to separate it from the next zero-group. However, there will be instances that there are no values for some zero-groups. To avoid showing stuff like zero million, I added a check inside. This is the part that makes me die a little inside:

for z in arrZero[::-1]:
    wrd = subThousand(str(z)) + "" ""
    zap = zGroup[lenArr] + "", ""
    if wrd == "" "":
        break
    elif wrd == ""zero "":
         wrd, zap = """", """"
    resArr.append(wrd + zap)
    lenArr -= 1



It works, but it just doesn't look good. Is it possible to do this in list-comprehension form or a better for-loop without turning it into more confusing mush?

I must admit as well that the last part of the code sucks a little. I've done a lot of str--&gt;int conversions inside the functions, then I did one more outside of them. On top of that, my approach to negative numbers is hackish at best (print ""Minus"").
","A couple of thoughts:


You only want to output zero in the special case when the number is 0. It would be easiest to handle that special case at the outermost level.
Use "" and "".join and "", "".join to construct strings from parts. The delimiter will be automatically left out when there are less than two parts.


Here's how I would rewrite subThousand as two functions:

def subThousand(inputNum):
    """"""Convert a number &lt; 1000 to words, and 0 to the empty string
    """"""
    num = int(inputNum)  #this should be done at higher level
    hundreds, ones = divmod(num, 100)

    parts = []
    if hundreds:
        parts.append(ByOne[hundreds] + "" hundred"")
    if ones:
        parts.append(subHundred(ones))

    return "" and "".join(parts)

def subHundred(num):
    """"""Convert a number &lt; 100 to words, and 0 to the empty string
    """"""
    if num &gt;= 20:
        tens, ones = divmod(num, 10)
    else:
        tens, ones = 0, num

    parts = []
    if tens:
        parts.append(ByTen[tens])
    if ones:
        parts.append(ByOne[ones])

    return ""-"".join(parts)

"
4438,4438,7046,Mathematics of a leading signal for a sine wave,"Taken from elsewhere on the web : -

""The derivative of a sine function is

d SIN(Ï*t) / dt = Ï * COS(Ï t)
where Ï = angular frequency = 2 Ï *frequency

and this derivative leads the original function by 90
degrees (a quarter period) because a cosine wave leads a sine wave by
90 degrees. This derivative is also different in amplitude from
the original sine wave because the cosine wave is multiplied by the
angular frequency. If we take the simple difference of equally spaced successive points of the sine wave (i.e. 20 points in a 20 period sine wave, 21 points in a 21 period sine wave etc.) we can cause that difference to have the same amplitude as the sine wave if we ânormalizeâ the difference. Normalization is done by multiplying the difference by (1/Ï). In the case the sine wave the angular frequency is 2*Pi divided by the period of the sine wave therefore the amplitude normalization factor is

Normalizer = Period / (2*Ï)

Using the normalizer, this difference function of sine wave now has the same amplitude as the sine wave and leads it by 90 degrees in phase (a quarter cycle). The amount of phase lead can be reduced with a little vector arithmetic. Vector addition of the sine wave and difference function results in a vector that leads the sine wave by only 45 degrees. Since this vector forms the hypotenuse of a right angled triangle, it is also larger than the sine wave by a factor of 1.414. We simply divide the sum by 1.414 to achieve the
correct amplitude for our leading signal.

In summary, we create a leading signal by taking the
difference of equally spaced successive samples of a sine wave; multiply that difference by Period/(2*Ï); add that product to the sine wave; and divide the sum by 1.414.""

I would like to use this approach to create a leading signal for a sine wave which always has a set constant lead e.g. the above approach gives a 2.5 point lead for a 20 period sine wave but will give a 5 point lead for a 40 period sine wave. Since I will always know the period and the difference between successive points of the sine wave, how can I adjust the vector arithmetic so that the lead will always be a constant 2.5 points (or constant 3.5 points, whatever?) irrespective of the sine wave period?
",babelproofreader,https://math.stackexchange.com/users/6882,"As $\sin(\omega t + \phi)=\sin(\omega t) \cos(\phi)+\sin(\phi)\cos(\omega t)$.  $\phi$ is the lead angle.  As you say, $\cos(\omega t)=\frac{1}{\omega}\frac{d\sin(\omega t)}{dt}$.  So $\sin(\omega t + \phi)=\sin(\omega t) \cos(\phi)+\frac{\sin(\phi)}{\omega}\frac{d\sin(\omega t)}{dt}$.  Is this what you were looking for?
",Ross Millikan,https://math.stackexchange.com/users/1827,http://math.stackexchange.com/questions/21453/mathematics-of-a-leading-signal-for-a-sine-wave,SCIENCE,math.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.8,1.0,0.0,0.0,0.8888888888888888,Mathematics of leading signal of sine wave,"Taken from elsewhere on the web : -

""The derivative of a sine function is

d SIN(Ï*t) / dt = Ï * COS(Ï t)
where Ï = angular frequency = 2 Ï *frequency

and this derivative leads the original function by 90
degrees (a quarter period) because a cosine wave leads a sine wave by
90 degrees. This derivative is also different in amplitude from
the original sine wave because the cosine wave is multiplied by the
angular frequency. If we take the simple difference of equally spaced successive points of the sine wave (i.e. 20 points in a 20 period sine wave, 21 points in a 21 period sine wave etc.) we can cause that difference to have the same amplitude as the sine wave if we ânormalizeâ the difference. Normalization is done by multiplying the difference by (1/Ï). In the case the sine wave the angular frequency is 2*Pi divided by the period of the sine wave therefore the amplitude normalization factor is

Normalizer = Period / (2*Ï)

Using the normalizer, this difference function of sine wave now has the same amplitude as the sine wave and leads it by 90 degrees in phase (a quarter cycle). The amount of phase lead can be reduced with a little vector arithmetic. Vector addition of the sine wave and difference function results in a vector that leads the sine wave by only 45 degrees. Since this vector forms the hypotenuse of a right angled triangle, it is also larger than the sine wave by a factor of 1.414. We simply divide the sum by 1.414 to achieve the
correct amplitude for our leading signal.

In summary, we create a leading signal by taking the
difference of equally spaced successive samples of a sine wave; multiply that difference by Period/(2*Ï); add that product to the sine wave; and divide the sum by 1.414.""

I would like to use this approach to create a leading signal for a sine wave which always has a set constant lead e.g. the above approach gives a 2.5 point lead for a 20 period sine wave but will give a 5 point lead for a 40 period sine wave. Since I will always know the period and the difference between successive points of the sine wave, how can I adjust the vector arithmetic so that the lead will always be a constant 2.5 points (or constant 3.5 points, whatever?) irrespective of the sine wave period?
","As $\ sin (\ Omega T + \ phi) = \ sin (\ Omega t \ cos (\ phi) + \ sin (\ phi \ cos (\ Omega T) $. $\ Phi $is the leading angle. As you said, $\ cos (\ Omega T) = \ frac {1} {\ Omega} \ frac {D \ sin (\ Omega T)} {DT} $. So $\ sin (\ Omega T + \ phi) = \ sin (\ Omega t \ cos (\ phi) + \ frac {\ sin (\ phi)} {\ Omega} \ frac {D \ sin (\ Omega T)} {DT} $. Is that what you're looking for?"
5840,5840,9253,In-game rewards for game-related work?,"The other GM in my group and I are both big fans of giving XP rewards for things done out of the game. Ex: We have an artist who will draw and design all sorts of stuff to ""fluff out"" our campaign. 

We noticed participation spiked when we offered rewards like this. Eventually, we even offered XP to our ""scribe"" for recording everything that happened each session. At the most, though, this gives bonus XP for up to two of our players. We do not plan to remove these bonuses, but want to be fair to all our players.

What are some fun things your players can do out of game that you can reward as GM? The goal is to have them be engaged in our game even when we aren't playing.
",pblock,https://rpg.stackexchange.com/users/8116,"I was first introduced to this idea in the Amber Diceless Roleplaying Game, which encouraged player involvement by awarding Good Stuff (a mix of character-building points and general karma) for out-of-character actions.

The main ones used there were more fitting for the Amber setting - drawing character cards (Trumps) of the characters, or writing in-character diaries for the character, which worked fantastically for our game, since in addition to having us think of the characters between session, created a running documentary of the campaign. Additionally, this scales up to however many players want in, though it's not necessarily as useful for a dungeon-crawling sort of game.

Other options for us involved the rather prosaic driving duties - a player who regularly picked up transportationally-challenged players and drove them to and from the sessions was rewarded, as were the players who build the campaign website (now sadly offline, I really need to put it back up).

I don't have the Amber Diceless book any more, but if you can get your hands on it (there's a PDF version being sold at DrivethruRPG) you can look up their suggestions for player rewards.
",lisardggY,https://rpg.stackexchange.com/users/3043,http://rpg.stackexchange.com/questions/25167/in-game-rewards-for-game-related-work,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.4444444444444444,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,0.8888888888888888,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Game rewards for game related work?,"The other GM in my group and I are both big fans of giving XP rewards for things done out of the game. Ex: We have an artist who will draw and design all sorts of stuff to ""fluff out"" our campaign. 

We noticed participation spiked when we offered rewards like this. Eventually, we even offered XP to our ""scribe"" for recording everything that happened each session. At the most, though, this gives bonus XP for up to two of our players. We do not plan to remove these bonuses, but want to be fair to all our players.

What are some fun things your players can do out of game that you can reward as GM? The goal is to have them be engaged in our game even when we aren't playing.
","I was first introduced to this idea in the Amber Diceless Roleplaying Game, which encouraged player involvement by awarding Good Stuff (a mix of character-building points and general karma) for out-of-character actions.

The main ones used there were more fitting for the Amber setting - drawing character cards (Trumps) of the characters, or writing in-character diaries for the character, which worked fantastically for our game, since in addition to having us think of the characters between session, created a running documentary of the campaign. Additionally, this scales up to however many players want in, though it's not necessarily as useful for a dungeon-crawling sort of game.

Other options for us involved the rather prosaic driving duties - a player who regularly picked up transportationally-challenged players and drove them to and from the sessions was rewarded, as were the players who build the campaign website (now sadly offline, I really need to put it back up).

I don't have the Amber Diceless book any more, but if you can get your hands on it (there's a PDF version being sold at DrivethruRPG) you can look up their suggestions for player rewards.
"
2058,2058,3280,False positive Apache version in scanner results on Centos,"Recently I need to care a lot of false positive vulnerabilities in scanner results on Apache version.
Example of false positive vulnerability:

Apache 2.2 &lt; 2.2.16 Multiple Vulnerabilities


Our customers run scanners and they check Apache version related to the official Apache version numbering.

We use Centos, and the Apache version numbering is different from the official Apache version numbering.

For example now we install httpd-2.2.15-26.el6.centos.x86_64 and it includes all security patches released by Apache in recent versions.

The Centos Apache version numbering relies on the RedHat Apache version numbering and they do not change the base number (httpd-2.2.15) each update.
But scanners do not âunderstandâ this and check that 2.2.15 &lt; 2.2.16.

Can you point me to the good document that explains the RedHat Apache version numbering?

Do you know if exist scanner that âunderstandâ the RedHat Apache version numbering?
",Michael,https://security.stackexchange.com/users/24842,"All security tools produce false positives, and this should not be treated any differently.  If you are having trouble with this report,  I suggest seeking a different approach to testing,  perhaps one that isn't  dependent on a broken tool.

That being said httpd-2.2.15-26.el6.centos.x86_64 was released on March 2nd 2013, and there have been a couple of vulnerabilities found in Apache since March 2nd.  It would be best to manually verify that you are not affected by these exposures.
",rook,https://security.stackexchange.com/users/975,http://security.stackexchange.com/questions/47711/false-positive-apache-version-in-scanner-results-on-centos,TECHNOLOGY,security.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.5333333333333333,1.0,0.3333333333333333,0.6666666666666666,1.0,Wrong positive Apache version in scanner results on CentOS,"Recently I need to care a lot of false positive vulnerabilities in scanner results on Apache version.
Example of false positive vulnerability:

Apache 2.2 &lt; 2.2.16 Multiple Vulnerabilities


Our customers run scanners and they check Apache version related to the official Apache version numbering.

We use Centos, and the Apache version numbering is different from the official Apache version numbering.

For example now we install httpd-2.2.15-26.el6.centos.x86_64 and it includes all security patches released by Apache in recent versions.

The Centos Apache version numbering relies on the RedHat Apache version numbering and they do not change the base number (httpd-2.2.15) each update.
But scanners do not âunderstandâ this and check that 2.2.15 &lt; 2.2.16.

Can you point me to the good document that explains the RedHat Apache version numbering?

Do you know if exist scanner that âunderstandâ the RedHat Apache version numbering?
","All security tools produce false positives, and this should not be treated any differently.  If you are having trouble with this report,  I suggest seeking a different approach to testing,  perhaps one that isn't  dependent on a broken tool.

That being said httpd-2.2.15-26.el6.centos.x86_64 was released on March 2nd 2013, and there have been a couple of vulnerabilities found in Apache since March 2nd.  It would be best to manually verify that you are not affected by these exposures.
"
5225,5225,8307,STFT - DFT size of the bins,"Having some trouble understanding this concept, really could do with some advice.

I want my STFT to have the following parameters: NFFT = 256 overlap/hop = 128

Now essentially, the algorithm will work as follows:

1) Split the signal into blocks of 256 


This will result in around 72*265:

2) For each of these blocks, calculate against the Hanning Window 

3) Create a ""slider"" that does an overlap of 128.. So, in theory it would 
   therefore be: `size = 256 + 128` 


Therefore, when I'm computing the DFT for each of the overlapped blocks, will my FFT remain at size 256 or will the size be 256 + 128 If this is the case, does each block in the resulting vector still have to be of size 256?

Thanks  

EDIT: 

This is now my result:



But, compare this to a spectrogram in matplotlib



Where am I actually going wrong? I cannot make any sense of this. 

I've looked bat through all the data, the blocks are correctly overlapping, Hanning window is being applied correctly.

Could it be to do with the fact I'm using a 1D DFT? I.e. 

std::vector&lt;complex&gt; FFT-&gt;transform(complex_vector[0...n], 256);

",Phorce,https://dsp.stackexchange.com/users/5182,"The overlap is the way that you walk on your signal to be analyzed, lets go to an simple example, imagine that your signal X has a length = 14, NFFT = 4 and overlap/hop = 2

X = 1 2 3 4 5 6 7 8 9 10 11 12 13 14


To know the number of blocks of analysis you will:

int(n_samples/Overlap) - 1 


Then for this example:

(14/2)-1 = 6


lets get 4 points from X to pass to your FFT

At the first time you get from X

X2 = 1 2 3 4


from now you need overlap by 2

X2 = 3 4 5 6


Third time

X2 = 5 6 7 8


fourth time

X2 = 7 8 9 10


fifth time

X2 = 9 10 11 12


sixth time

X2 = 11 12 13 14

",ederwander,https://dsp.stackexchange.com/users/1081,http://dsp.stackexchange.com/questions/13774/stft-dft-size-of-the-bins,TECHNOLOGY,dsp.stackexchange.com,1.0,0.3333333333333333,0.0,0.5,0.3333333333333333,0.5,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,0.3333333333333333,1.0,Dry film thickness of STFT box,"Having some trouble understanding this concept, really could do with some advice.

I want my STFT to have the following parameters: NFFT = 256 overlap/hop = 128

Now essentially, the algorithm will work as follows:

1) Split the signal into blocks of 256 


This will result in around 72*265:

2) For each of these blocks, calculate against the Hanning Window 

3) Create a ""slider"" that does an overlap of 128.. So, in theory it would 
   therefore be: `size = 256 + 128` 


Therefore, when I'm computing the DFT for each of the overlapped blocks, will my FFT remain at size 256 or will the size be 256 + 128 If this is the case, does each block in the resulting vector still have to be of size 256?

Thanks  

EDIT: 

This is now my result:



But, compare this to a spectrogram in matplotlib



Where am I actually going wrong? I cannot make any sense of this. 

I've looked bat through all the data, the blocks are correctly overlapping, Hanning window is being applied correctly.

Could it be to do with the fact I'm using a 1D DFT? I.e. 

std::vector&lt;complex&gt; FFT-&gt;transform(complex_vector[0...n], 256);

","The overlap is the way that you walk on your signal to be analyzed, lets go to an simple example, imagine that your signal X has a length = 14, NFFT = 4 and overlap/hop = 2

X = 1 2 3 4 5 6 7 8 9 10 11 12 13 14


To know the number of blocks of analysis you will:

int(n_samples/Overlap) - 1 


Then for this example:

(14/2)-1 = 6


lets get 4 points from X to pass to your FFT

At the first time you get from X

X2 = 1 2 3 4


from now you need overlap by 2

X2 = 3 4 5 6


Third time

X2 = 5 6 7 8


fourth time

X2 = 7 8 9 10


fifth time

X2 = 9 10 11 12


sixth time

X2 = 11 12 13 14

"
5473,5473,8691,How to make a figure span on two columns in a scientific paper?,"If I just try to set the figure's size to 0.9\textwidth my figure will just end up on the right column, sized to be two-columns wide.

Has anyone done this before?
",levesque,https://tex.stackexchange.com/users/10,"What about using the code below?

\documentclass[11pt,a4paper,twocolumn,english]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[font=small,labelfont=bf,tableposition=top]{caption}
\usepackage{blindtext}
\usepackage{cuted}

\title{Two column document with figure underneath title}
\author{abhijit8}

\begin{document}
\maketitle

\begin{strip}
    \centering\noindent
    \rule{0.75\linewidth}{0.5\linewidth}
    \captionof{figure}{\blindtext}
\end{strip}

\blindtext[2]

\begin{strip}
    \centering\noindent
    \rule{0.75\linewidth}{0.5\linewidth}
    \captionof{figure}{\blindtext}
\end{strip}

\medskip
\noindent
\begin{minipage}{\linewidth}
    \centering
    \rule{0.75\linewidth}{0.5\linewidth}
    \captionof{figure}{The quick brown fox jumps over the lazy dog}
\end{minipage}

\medskip
\blindtext[4]
\end{document}


It is from http://www.latex-community.org/forum/viewtopic.php?f=45&amp;t=10661#p41194 and works like a charm for me.
",Marco Lorenco,https://tex.stackexchange.com/users/60889,http://tex.stackexchange.com/questions/3173/how-to-make-a-figure-span-on-two-columns-in-a-scientific-paper,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.8333333333333334,"In scientific papers, how to build a digital span on two columns?","If I just try to set the size of my graph to 0.9 \ textwidth, my graph will end up in the right column, which is two columns wide.","What about using the code below?

\documentclass[11pt,a4paper,twocolumn,english]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[font=small,labelfont=bf,tableposition=top]{caption}
\usepackage{blindtext}
\usepackage{cuted}

\title{Two column document with figure underneath title}
\author{abhijit8}

\begin{document}
\maketitle

\begin{strip}
    \centering\noindent
    \rule{0.75\linewidth}{0.5\linewidth}
    \captionof{figure}{\blindtext}
\end{strip}

\blindtext[2]

\begin{strip}
    \centering\noindent
    \rule{0.75\linewidth}{0.5\linewidth}
    \captionof{figure}{\blindtext}
\end{strip}

\medskip
\noindent
\begin{minipage}{\linewidth}
    \centering
    \rule{0.75\linewidth}{0.5\linewidth}
    \captionof{figure}{The quick brown fox jumps over the lazy dog}
\end{minipage}

\medskip
\blindtext[4]
\end{document}


It is from http://www.latex-community.org/forum/viewtopic.php?f=45&amp;t=10661#p41194 and works like a charm for me.
"
3703,3703,5903,"Flying from NYC via Philadelphia to Halifax, I clear Immigration and Customs in Canada?","Because I am trying to process an immigration work permit for Canada, (I am an American citizen), I need to fly directly into Halifax from the States.  I am trying to make sure that I don't clear Canadian immigration and customs in the Philadelphia airport.  (For instance, when I fly from Toronto to the USA, I clear American immigration and customs there.)  Any ideas?
",Paul,https://travel.stackexchange.com/users/27254,"Unlike US Canada doesn't have immigration preclearance so the immigration control you will be passing in Canada.
",Karlson,https://travel.stackexchange.com/users/1372,http://travel.stackexchange.com/questions/43898/flying-from-nyc-via-philadelphia-to-halifax-i-clear-immigration-and-customs-in,CULTURE,travel.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,"Fly from New York City to Halifax, and I'll go through immigration and customs procedures in Canada?","I need to fly directly from the United States to Halifax because I am applying for an immigrant work permit in Canada (I am an American citizen). I tried to make sure I didn't go through Canadian immigration and customs at Philadelphia Airport. (for example, when I fly from Toronto to the United States, I go through American Immigration and customs procedures there.) Do you have any ideas?","Unlike US Canada doesn't have immigration preclearance so the immigration control you will be passing in Canada.
"
2505,2505,3995,"Excel VBA App stops spontaneously with message ""Code execution has been halted""","From what I can see on the web, this is a fairly common complaint, but answers seem to be rarer. The problem is this:

We have a number of Excel VBA apps which work perfectly on a number of users' machines. However on one machine they stop on certain lines of code. It is always the same lines, but those lines seem to have nothing in common with one another.

If you press F5 (run) after the halt, the app continues, so it's almost like a break point has been added. We've tried selecting 'remove all breaks' from the menu and even adding a break and removing it again.

We've had this issue with single apps before and we've 'bodged' it by cutting code out of modules, compiling and then pasting it back in etc.

The problem now seems to relate to Excel itself rather than a single .xls, so we're a little unsure how to manage this.

Any help would be gratefully received :)

Thanks,

Philip Whittington
",Phil Whittington,https://stackoverflow.com/users/223126,"One solution is here:


  The solution for this problem is to add the line of code
  âApplication.EnableCancelKey = xlDisabledâ  in the first line of your
  macro.. This will fix the problem and you will be able to execute the macro
  successfully without getting the error message âCode execution has been interruptedâ.


But, after I inserted this line of code, I was not able to use Ctrl+Break any more. So it works but not greatly.
",Stan,https://stackoverflow.com/users/435476,http://stackoverflow.com/questions/2154699/excel-vba-app-stops-spontaneously-with-message-code-execution-has-been-halted,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.5,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.6,1.0,0.0,0.6666666666666666,0.8888888888888888,"Excel VBA Application stops automatically with the message ""code execution stopped""","From what I can see on the web, this is a fairly common complaint, but answers seem to be rarer. The problem is this:

We have a number of Excel VBA apps which work perfectly on a number of users' machines. However on one machine they stop on certain lines of code. It is always the same lines, but those lines seem to have nothing in common with one another.

If you press F5 (run) after the halt, the app continues, so it's almost like a break point has been added. We've tried selecting 'remove all breaks' from the menu and even adding a break and removing it again.

We've had this issue with single apps before and we've 'bodged' it by cutting code out of modules, compiling and then pasting it back in etc.

The problem now seems to relate to Excel itself rather than a single .xls, so we're a little unsure how to manage this.

Any help would be gratefully received :)

Thanks,

Philip Whittington
","One solution is here:


  The solution for this problem is to add the line of code
  âApplication.EnableCancelKey = xlDisabledâ  in the first line of your
  macro.. This will fix the problem and you will be able to execute the macro
  successfully without getting the error message âCode execution has been interruptedâ.


But, after I inserted this line of code, I was not able to use Ctrl+Break any more. So it works but not greatly.
"
5567,5567,8841,Are comments considered a form of documentation?,"When I am writing small scripts for myself, I stack my code high with comments (sometimes I comment more than I code). A lot of people I talk to say that I should be documenting these scripts, even though they are personal, so that if I ever do sell them, I would be ready. But aren't comments a form of documentation?

Wouldn't this:

$foo = ""bar""; # this is a comment
print $foo; # this prints ""bar""


be considered documentation, especially if a developer is using my code? Or is documentation considered to be outside of the code itself?
",Dynamic,https://programmers.stackexchange.com/users/34364,"Comments are definitely documentation. For most projects, comments are (unfortunately) the primary (if not only) form of project documentation. For this reason, it's very important to get it right. You need to make sure that this documentation stays accurate despite code changes. This is a common problem with comments. Developers often ""tune"" them out when they're working in familiar code, so they forget to update comments to reflect code. This can create out-of-date, and misleading comments.

A lot of people suggest making the code self-documenting. This means that instead of comments, you restructure your code to remove the need for them. This can get rid of most of the ""what"" and ""how"" comments, but doesn't really help with the ""why"" comments. While this might work effectively to get rid of most comments, there are still plenty of times where writing a comment is the simplest and most efficient way to document a piece of code.
",Oleksi,https://programmers.stackexchange.com/users/47555,http://programmers.stackexchange.com/questions/148471/are-comments-considered-a-form-of-documentation,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Is the comment considered a document form?,"When I write small scripts for myself, I use comments (sometimes I have more than my code) to pile up the code very high. A lot of people I talked to said that I should record these scripts, even if they are personal, so if I really sell them, I'll be ready. But isn't comment a form of documentation?","Comments are absolutely documents. For most projects, annotations (unfortunately) are the main (if not the only) form of project documentation. For this reason, it is very important to do a good job. You need to make sure that this document is accurate when the code changes. This is a FAQ for comments. When developers work in familiar code, they often ""tune"" them, so they forget to update comments to reflect the code. This can lead to outdated and misleading comments."
5173,5173,8220,How can I enable HttpOnly cookies in EE,"Update:
Thanks to Dom Stubbs, I have an extension to accomplish this now.  It is up on devot-ee and also up on GitHub.  Thanks Dom!

The Original Question

I am nearly through a security review of a new EE2 version of an existing EE1 site that I hope to launch soon.  One of the final issues remaining is to make the cookies HttpOnly.  I've tried doing that through this line in the apache config:

Header edit Set-Cookie ""(?i)^((?:(?!;\s?HttpOnly).)+)$"" ""$1; HttpOnly""


Using the dev tools in my browser I can see that it does indeed append HttpOnly to the Set-Cookie headers, but the issue then becomes that I cannot log in.  When I asked Ellislab they tell me that the cookies should not be being dealt with in javascript, which was what I expected the issue might be.

ExpressionEngine does not seem to use the session libraries from codeignitor, if it did I could set a config variable to turn httponly on, but it looks like the session handling code is in the expressionengine side of things.

The real question that I need answered is how can I make HttpOnly cookies work, but I guess that breaks down into some potential subquestions:


Am I missing an addon that would allow me to do this without a lot more heartache?Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Failing these, can anybody give me a hint as to where cookies are being set in expressionengine so I can dig in there and try to fix this?

",UltraBob,https://expressionengine.stackexchange.com/users/268,"I've not attempted to implement HttpOnly cookies with EE, but doing so should be relatively straightforward. If you go to line 805 of Functions.php you'll see the setcookie() call EE uses. Directly above that is the set_cookie_end hook. As that receives the $data array of cookie params it would be trivial to create an extension with a custom setcookie() call. The following is untested but I think it should work:

function set_cookie_end($data)
{
    // Block EE's native setcookie() call
    $this-&gt;EE-&gt;extensions-&gt;end_script = TRUE; 

    // Set a HttpOnly cookie
    setcookie($data['prefix'].$data['name'], $data['value'], $data['expire'], 
        $data['path'], $data['domain'], $data['secure_cookie'], TRUE);
}


You can use Pkg.io to eliminate some of the hassle of creating the extension.
",Dom Stubbs,https://expressionengine.stackexchange.com/users/77,http://expressionengine.stackexchange.com/questions/112/how-can-i-enable-httponly-cookies-in-ee,TECHNOLOGY,expressionengine.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.5,1.0,1.0,0.6666666666666666,0.4444444444444444,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.7,1.0,0.3333333333333333,0.0,1.0,How to enable httponly cookies in EE,"Update:
Thanks to Dom Stubbs, I have an extension to accomplish this now.  It is up on devot-ee and also up on GitHub.  Thanks Dom!

The Original Question

I am nearly through a security review of a new EE2 version of an existing EE1 site that I hope to launch soon.  One of the final issues remaining is to make the cookies HttpOnly.  I've tried doing that through this line in the apache config:

Header edit Set-Cookie ""(?i)^((?:(?!;\s?HttpOnly).)+)$"" ""$1; HttpOnly""


Using the dev tools in my browser I can see that it does indeed append HttpOnly to the Set-Cookie headers, but the issue then becomes that I cannot log in.  When I asked Ellislab they tell me that the cookies should not be being dealt with in javascript, which was what I expected the issue might be.

ExpressionEngine does not seem to use the session libraries from codeignitor, if it did I could set a config variable to turn httponly on, but it looks like the session handling code is in the expressionengine side of things.

The real question that I need answered is how can I make HttpOnly cookies work, but I guess that breaks down into some potential subquestions:


Am I missing an addon that would allow me to do this without a lot more heartache?Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Is there something wrong with my apache approach?  Are you able to log in if you enable that in Apache, log out and try to log back in?
Failing these, can anybody give me a hint as to where cookies are being set in expressionengine so I can dig in there and try to fix this?

","I've not attempted to implement HttpOnly cookies with EE, but doing so should be relatively straightforward. If you go to line 805 of Functions.php you'll see the setcookie() call EE uses. Directly above that is the set_cookie_end hook. As that receives the $data array of cookie params it would be trivial to create an extension with a custom setcookie() call. The following is untested but I think it should work:

function set_cookie_end($data)
{
    // Block EE's native setcookie() call
    $this-&gt;EE-&gt;extensions-&gt;end_script = TRUE; 

    // Set a HttpOnly cookie
    setcookie($data['prefix'].$data['name'], $data['value'], $data['expire'], 
        $data['path'], $data['domain'], $data['secure_cookie'], TRUE);
}


You can use Pkg.io to eliminate some of the hassle of creating the extension.
"
5334,5334,8473,Story about Big-Brother-like society where everybody wears a controlling wristwatch,"A future Big-Brother society where people wore wristwatches which both monitored their movements and kept them informed about their role in society. 

I don't remember whether the story was located on Earth or a fictional planet.
The book was read late 60's or early 70's. I only read a small number of authors (max 10) so I would immediately recognise the author's name if the storyline was identified.

Possibilities:
Brian Aldiss,
Piers Anthony,
Isaac Asimov,
Ray Bradbury,
Arthur C. Clarke,
Robert Heinlein,
Frank Herbert,
Ursula K. Le Guin,
Theodore Sturgeon,
Kurt Vonnegut Jr.

What I'm thinking now is how uncannily like the Apple Watch and similar products this was. This is the only story I remember that foresaw the wireless/digital age.
",Mike Wilson,https://scifi.stackexchange.com/users/38791,"''The Creature from Cleveland Depths'' was a short story by Fritz Leiber written in 1962. As noted in my comment above, an engineer devises a little clockwork/tape-based thing where a man can make notes and reminders, and the device would give the wearer a slight shock, a ""tickle"" when the time hit, reminding him to check his appointments. His friend, a marketer, stole the idea (which he was noted as doing often, something the protagonist cheerfully grumbled about) and released it, claiming his company had been working on it all the time. As time went on, the tickler was improved to also automatically remind a person to do routine chores, and to even inject drugs to help make them happier. By the end of the story, the engineer, who has refused the tickler, realizes that the ticklers have taken over.

One of the other odd details that stuck in my mind was that the marketing friend drops off a case of lifelike masks for the engineer, prior products of the company, and he and his wife have a brief bout of fun while she's wearing the face of a prominent actress.
",FuzzyBoots,https://scifi.stackexchange.com/users/23243,http://scifi.stackexchange.com/questions/76811/story-about-big-brother-like-society-where-everybody-wears-a-controlling-wristwa,LIFE_ARTS,scifi.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,The story of everyone wearing watch in big brother Society,"A future Big-Brother society where people wore wristwatches which both monitored their movements and kept them informed about their role in society. 

I don't remember whether the story was located on Earth or a fictional planet.
The book was read late 60's or early 70's. I only read a small number of authors (max 10) so I would immediately recognise the author's name if the storyline was identified.

Possibilities:
Brian Aldiss,
Piers Anthony,
Isaac Asimov,
Ray Bradbury,
Arthur C. Clarke,
Robert Heinlein,
Frank Herbert,
Ursula K. Le Guin,
Theodore Sturgeon,
Kurt Vonnegut Jr.

What I'm thinking now is how uncannily like the Apple Watch and similar products this was. This is the only story I remember that foresaw the wireless/digital age.
","""The creatures of Cleveland"" is a short story written by Fritz Leiber in 1962. As I mentioned in the comments above, an engineer designed a small device based on clock / tape, where a person can make notes and reminders, the device will give the wearer a slight vibration, when the time is up, it will emit a ""tick"" to remind him to check his appointment. His friend, a marketer, stole the idea (it was noted that he often did so, which was the subject of the hero's exuberant complaints) and released it, claiming that his company had been studying it. Over time, tickling has also improved, automatically reminding people to do their daily chores and even injecting drugs to help them be happier. At the end of the story, the engineer who refused to tickle realized that the tickler had the upper hand."
3704,3704,5906,lion: assign buttons on a Microsoft mouse,"I have an old 5 button Microsoft mouse (Laser Mouse 6000) and forever I've assigned the thumb button to ""back"" in the browser and the middle mouse button to ""next app"" on the desktop. Since I've installed Lion, this doesn't seem to work. The settings in the ""Microsoft Mouse"" panel in System Preferences don't seem have any effect. 

Is there another way to map mouse buttons? I've noticed that Mission Control seems to detect my 5 buttons and let me assign them, but only to Mission Control functions. I don't see anywhere else where I can do this. Do I just need to wait for new MS drivers? Thanks.
",asciitaxi,https://apple.stackexchange.com/users/8223,"BetterTouchTool's ""Normal Mouse"" area allows you to assign functions to all kinds of mouse buttons and should work for you. It's free, too, so it won't hurt to try.

The author has issued a couple of recent updates to make it more compatible with Lion. There are still a couple of small things but I'm using it every day (previously with my mouse, now with my trackpad) and it's tremendously useful.
",Matthew Frederick,https://apple.stackexchange.com/users/1807,http://apple.stackexchange.com/questions/18361/lion-assign-buttons-on-a-microsoft-mouse,TECHNOLOGY,apple.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,0.3333333333333333,1.0,Lion: specify button on Microsoft Mouse,"I have an old five button Microsoft mouse (Laser Mouse 6000), always I assign a thumb button ""back"" in the browser and middle mouse button ""next app"" on the desktop. Now that I have lion installed, it doesn't seem to work. The settings in the Microsoft mouse panel in system preferences do not appear to have any effect.","BetterTouchTool's ""Normal Mouse"" area allows you to assign functions to all kinds of mouse buttons and should work for you. It's free, too, so it won't hurt to try.

The author has issued a couple of recent updates to make it more compatible with Lion. There are still a couple of small things but I'm using it every day (previously with my mouse, now with my trackpad) and it's tremendously useful.
"
3516,3516,5607,Is there a word for something loved by the masses but whose true value is lacking?,"Is there a general word for someone or something popular or loved by the masses but that has not been proven to be effectual (like how some would use the term ""pop psychology"" pejoratively)? Examples would be how things like popular psychology or holistic medicine are accepted excitedly by numerous people while not being proven to be useful to the majority.

UPDATE: Thanks for you responses. I think the word ""fad"" (or ""hype"") would come closest to what I was looking for (thank you for that).

But is there a more general or appropriate term? I'm not American so apologies in advance (this is strictly for the sake of discussion): the only example I can think of is certain voters who were initially excited about Obama, but came to be disappointed after he failed to meet their expectations. Is there a word that could be used to describe Obama in this context? Something well-loved which turns out to be a disappointment.
",Mia T,https://english.stackexchange.com/users/106861,"The word ""fad"" is not always pejorative, but if you use it to describe something that others take seriously, then it comes off as insulting.
",Oldbag,https://english.stackexchange.com/users/99368,http://english.stackexchange.com/questions/222672/is-there-a-word-for-something-loved-by-the-masses-but-whose-true-value-is-lackin,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.7777777777777778,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,Is there a word to describe what the masses love but lack real value?,"Is there a general word for someone or something popular or loved by the masses but that has not been proven to be effectual (like how some would use the term ""pop psychology"" pejoratively)? Examples would be how things like popular psychology or holistic medicine are accepted excitedly by numerous people while not being proven to be useful to the majority.

UPDATE: Thanks for you responses. I think the word ""fad"" (or ""hype"") would come closest to what I was looking for (thank you for that).

But is there a more general or appropriate term? I'm not American so apologies in advance (this is strictly for the sake of discussion): the only example I can think of is certain voters who were initially excited about Obama, but came to be disappointed after he failed to meet their expectations. Is there a word that could be used to describe Obama in this context? Something well-loved which turns out to be a disappointment.
","The word ""fad"" is not always pejorative, but if you use it to describe something that others take seriously, then it comes off as insulting.
"
492,492,767,"SQL agent job, why is the job history showing that a step is still running even though the job has completed","I have a sql agent job that runs Powershell as its first step (there are 3 steps in total).

I have set this step to have 2 retries, with a 3 minute retry interval.
When I look into the job history, the step_1 states that it is still running, and also that it has completed. It has done this for every time that it has run (at least the last year).
Am I missing something from my powershell? Or is this something to do with sql agent itself?

Details of querying the sysjobhistory table (Pipe seperated):

Step_name|step_id|run_date|run_time|run_duration|run_status

(Job outcome)|0|2014/02/12|01:20:00|5|Succeded

Record volume space to file|1|2014/02/12|01:20:00|2|In Progress

Record volume space to file|1|2014/02/12|01:20:00|2|Succeded

Load Volume Space|2|2014/02/12|01:20:02|1|Succeded

Record database data file space|3|2014/02/12|01:20:03|2|Succeded


Step 1 runs the following Powershell:

gwmi win32_volume | select name, capacity, freespace | Export-Csv c:\temp.tmp

",Jake,https://dba.stackexchange.com/users/36309,"Try simply restarting the SQL Server Agent and testing again. Your results from sysjobhistory lead me to believe that isn't because of a PowerShell error. You have a success record but you also have an in progress record. I've seen the SQL Agent act very odd sometimes and restarting it was the only thing I've figured out to fix it. For example, I've had jobs miss a schedule execution and then never run on a schedule again because of the next run time being in the past. In addition, I've definitely seen completion records not recorded even though I've never seen them doubled up like you have.
",SQL Hammer,https://dba.stackexchange.com/users/48295,http://dba.stackexchange.com/questions/65089/sql-agent-job-why-is-the-job-history-showing-that-a-step-is-still-running-even,TECHNOLOGY,dba.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.4444444444444444,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,"SQL agent job, why the job history shows that the step is still running even if the job has completed","I have a sql agent job that runs Powershell as its first step (there are 3 steps in total).

I have set this step to have 2 retries, with a 3 minute retry interval.
When I look into the job history, the step_1 states that it is still running, and also that it has completed. It has done this for every time that it has run (at least the last year).
Am I missing something from my powershell? Or is this something to do with sql agent itself?

Details of querying the sysjobhistory table (Pipe seperated):

Step_name|step_id|run_date|run_time|run_duration|run_status

(Job outcome)|0|2014/02/12|01:20:00|5|Succeded

Record volume space to file|1|2014/02/12|01:20:00|2|In Progress

Record volume space to file|1|2014/02/12|01:20:00|2|Succeded

Load Volume Space|2|2014/02/12|01:20:02|1|Succeded

Record database data file space|3|2014/02/12|01:20:03|2|Succeded


Step 1 runs the following Powershell:

gwmi win32_volume | select name, capacity, freespace | Export-Csv c:\temp.tmp

","Try simply restarting the SQL Server Agent and testing again. Your results from sysjobhistory lead me to believe that isn't because of a PowerShell error. You have a success record but you also have an in progress record. I've seen the SQL Agent act very odd sometimes and restarting it was the only thing I've figured out to fix it. For example, I've had jobs miss a schedule execution and then never run on a schedule again because of the next run time being in the past. In addition, I've definitely seen completion records not recorded even though I've never seen them doubled up like you have.
"
941,941,1491,How do I install mupen64plus?,"I'm new to Ubuntu and Linux and I just downloaded mupen64plus 1.99.5 and it came as a *.tar.gz file. I found some guides about how to install a .tar.gz file with the terminal but it doesn't work. How can I install it?
",N00b,https://askubuntu.com/users/83163,"You can install it from the Ubuntu Software Center by clicking the button below:



You can then open a terminal via Ctrl-Alt-T and run it by typing mupen64plus and then the name of the ROM you want to run. See the manpage for the instructions.
",Jorge Castro,https://askubuntu.com/users/235,http://askubuntu.com/questions/175466/how-do-i-install-mupen64plus,TECHNOLOGY,askubuntu.com,0.8333333333333334,0.8333333333333334,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,How to install mupen64plus?,"I'm new to Ubuntu and Linux. I just downloaded mupen64plus 1.99.5, which is a *. Tar.gz file. I found some guidance on how to install the. Tar.gz file on the terminal, but it didn't work. How to install?","You can install it from the Ubuntu Software Center by clicking the button below:



You can then open a terminal via Ctrl-Alt-T and run it by typing mupen64plus and then the name of the ROM you want to run. See the manpage for the instructions.
"
4742,4742,7523,Please help me in changing layout of all products page,"

can anyone tell me where can I change layout of this page i think this page is now having 3columns.phtml layout but I need 2columns-left.phtml layout please help me.
",Abdul,https://magento.stackexchange.com/users/16312,"To change the product page layout:

From the Admin menu, select Catalog > Manage Products.

Find the product in the list, and click to open the record.

In the Product Information panel on the left, select Design. Then in the Design section, set Page Layout to a different column configuration.

When complete, click the Save button.

To change the category page layout:

From the Admin menu, select Catalog > Manage Categories.

In the Categories tree, select the category level you want to change.

On the Custom Design tab, set Page Layout to â2 columns with right bar.â

Click the Save Category button.
",JACK,https://magento.stackexchange.com/users/16443,http://magento.stackexchange.com/questions/44475/how-to-change-the-layout-of-the-all-products-page,TECHNOLOGY,magento.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Please help me change the layout of all product pages,"Who can tell me where I can change the layout of this page? I think this page now has three columns.phtml layouts, but I need two columns-left.phtml layouts. Please help me.","To change the product page layout:

From the Admin menu, select Catalog > Manage Products.

Find the product in the list, and click to open the record.

In the Product Information panel on the left, select Design. Then in the Design section, set Page Layout to a different column configuration.

When complete, click the Save button.

To change the category page layout:

From the Admin menu, select Catalog > Manage Categories.

In the Categories tree, select the category level you want to change.

On the Custom Design tab, set Page Layout to â2 columns with right bar.â

Click the Save Category button.
"
6027,6027,9563,Timer writes in log twice,"Everything works fine except for one thing.  My program prints ""player hit"" 2 times then ""mob hit"" 2 times and then ""player hit"" 2 times again and so forth.  I want it to type ""player Hit"" ""mob Hit"" ""player Hit"" ""mob Hit"" and so on.  I can't see why it types it 2 times.  

My code looks like this:

public partial class Form1 : Form
{
    public Form1()
    {
        int Rase1 = 0;

        InitializeComponent();

        timer1.Tick += new EventHandler(timer1_Tick);
        timer1.Interval = (1000);
        timer1.Enabled = false;

        timer2.Tick += new EventHandler(timer2_Tick);
        timer2.Interval = (1000);
        timer2.Enabled = false;
    }

    private void buttonChoseRase_Click(object sender, EventArgs e)
    {
        if (Rase1 == 0)
        {
            Rase1 = 1;
            Rase Rase = new Race(this);
            Rase.Show();
        }
        else if (Race1 &gt;= 1)
        {
            buttonChoseRase.Enabled = false;

            Rebirth Reb = new Rebirth(this);
            Reb.Show();
        }
    }

    private void buttonStart_Click(object sender, EventArgs e)
    {
        textBoxCombatLog.Text = """";

        buttonStart.Enabled = false;
        buttonStop.Enabled = true;

        timer1.Start();

        timer2.Stop();
    }

    private void buttonStop_Click(object sender, EventArgs e)
    {
        buttonStart.Enabled = true;
        buttonStop.Enabled = false;

        timer1.Stop();
        timer2.Stop();
    }

    private void LogWrite(string txt)
    {
        textBoxCombatLog.AppendText(txt + Environment.NewLine);
        textBoxCombatLog.SelectionStart = textBoxCombatLog.Text.Length;
    }

    private void timer1_Tick(object sender, EventArgs e)
    {
        LogWrite(TimeDate + ""Player Hit \n"");

        timer1.Stop();

        timer2.Start();
    }

    private void timer2_Tick(object sender, EventArgs e)
    {
        LogWrite(TimeDate + ""Mob Hit \n"");

        timer2.Stop();

        timer1.Start();
    }

    private string TimeDate
    {
        get { return ""["" + DateTime.Now.ToString(""HH:mm:ss"") + ""]"" + "": ""; }
    }
}




Here is what is looks like running, and no matter what I do, everything shows up twice:


",Johannes BjÃ¤rehall,https://stackoverflow.com/users/2414858,"You've attached the event handler to the Tick event of the timer through designer in addition to through the code file itself.  You need to remove one of the two.  Either attach the event handler in code or attach it through the designer.
",Servy,https://stackoverflow.com/users/1159478,http://stackoverflow.com/questions/16741646/timer-writes-in-log-twice,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Timer writes to log twice,"Everything works fine except for one thing.  My program prints ""player hit"" 2 times then ""mob hit"" 2 times and then ""player hit"" 2 times again and so forth.  I want it to type ""player Hit"" ""mob Hit"" ""player Hit"" ""mob Hit"" and so on.  I can't see why it types it 2 times.  

My code looks like this:

public partial class Form1 : Form
{
    public Form1()
    {
        int Rase1 = 0;

        InitializeComponent();

        timer1.Tick += new EventHandler(timer1_Tick);
        timer1.Interval = (1000);
        timer1.Enabled = false;

        timer2.Tick += new EventHandler(timer2_Tick);
        timer2.Interval = (1000);
        timer2.Enabled = false;
    }

    private void buttonChoseRase_Click(object sender, EventArgs e)
    {
        if (Rase1 == 0)
        {
            Rase1 = 1;
            Rase Rase = new Race(this);
            Rase.Show();
        }
        else if (Race1 &gt;= 1)
        {
            buttonChoseRase.Enabled = false;

            Rebirth Reb = new Rebirth(this);
            Reb.Show();
        }
    }

    private void buttonStart_Click(object sender, EventArgs e)
    {
        textBoxCombatLog.Text = """";

        buttonStart.Enabled = false;
        buttonStop.Enabled = true;

        timer1.Start();

        timer2.Stop();
    }

    private void buttonStop_Click(object sender, EventArgs e)
    {
        buttonStart.Enabled = true;
        buttonStop.Enabled = false;

        timer1.Stop();
        timer2.Stop();
    }

    private void LogWrite(string txt)
    {
        textBoxCombatLog.AppendText(txt + Environment.NewLine);
        textBoxCombatLog.SelectionStart = textBoxCombatLog.Text.Length;
    }

    private void timer1_Tick(object sender, EventArgs e)
    {
        LogWrite(TimeDate + ""Player Hit \n"");

        timer1.Stop();

        timer2.Start();
    }

    private void timer2_Tick(object sender, EventArgs e)
    {
        LogWrite(TimeDate + ""Mob Hit \n"");

        timer2.Stop();

        timer1.Start();
    }

    private string TimeDate
    {
        get { return ""["" + DateTime.Now.ToString(""HH:mm:ss"") + ""]"" + "": ""; }
    }
}




Here is what is looks like running, and no matter what I do, everything shows up twice:


","In addition to the code file itself, the event handler is attached to the timer's tick event through the designer. You need to remove one of them. Attach the event handler in your code or through the designer."
3074,3074,4895,In what order are taxes applied,"Lets say we have a product that costs 100$ (net price). This product has 3 taxes that must be applied to it: 2 percentage taxes (e.g. 17% and 20%) and one fixed amount tax (e.g. +10$).

My question is - what math is done in this case?

Are the percentage taxes applied on the net price and summed or the first one is calculated and then the second one is done with the price we get after applying the first? When is the fixed amount tax applied? After the other two or the other two are done with net+fixed tax?
",karka91,https://money.stackexchange.com/users/6846,"In the US and indeed around the world, there are very few ""tax on taxes"" situations. These situations are generally called out where they exist and politicians are pressured to change them; it is generally considered onerous for a government to include an amount of taxes in calculating another tax, because the government is then taxing the money you're already paying them. This is why most U.S. State and local taxes (sales taxes, property taxes, etc) are deductible from your income when itemizing deductions (the alternate ""standard deduction"" is an ""average"" amount that a person/household would be able to deduct if they itemized all lower-level taxes they had paid).

So, most taxes, especially sales taxes/duties/tariffs, are all levied on a ""pre-tax"" or ""subtotal"" amount. In your example, all three of those taxes would be calculated on the $100 ""subtotal"" amount, before any other tax is added, and then those amounts are added to the subtotal to produce the grand total (of $147 as Alex shows).
",KeithS,https://money.stackexchange.com/users/4637,http://money.stackexchange.com/questions/16200/in-what-order-are-taxes-applied,LIFE_ARTS,money.stackexchange.com,0.8333333333333334,0.8333333333333334,0.0,0.0,1.0,0.5,0.6666666666666666,0.5,0.5,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.5,1.0,1.0,In what order are taxes applied,"Lets say we have a product that costs 100$ (net price). This product has 3 taxes that must be applied to it: 2 percentage taxes (e.g. 17% and 20%) and one fixed amount tax (e.g. +10$).

My question is - what math is done in this case?

Are the percentage taxes applied on the net price and summed or the first one is calculated and then the second one is done with the price we get after applying the first? When is the fixed amount tax applied? After the other two or the other two are done with net+fixed tax?
","In the US and indeed around the world, there are very few ""tax on taxes"" situations. These situations are generally called out where they exist and politicians are pressured to change them; it is generally considered onerous for a government to include an amount of taxes in calculating another tax, because the government is then taxing the money you're already paying them. This is why most U.S. State and local taxes (sales taxes, property taxes, etc) are deductible from your income when itemizing deductions (the alternate ""standard deduction"" is an ""average"" amount that a person/household would be able to deduct if they itemized all lower-level taxes they had paid).

So, most taxes, especially sales taxes/duties/tariffs, are all levied on a ""pre-tax"" or ""subtotal"" amount. In your example, all three of those taxes would be calculated on the $100 ""subtotal"" amount, before any other tax is added, and then those amounts are added to the subtotal to produce the grand total (of $147 as Alex shows).
"
2023,2023,3226,"Learning the musical concepts in the book ""GÃ¶del, Escher, Bach""","I am reading the book ""GÃ¶del, Escher, Bach"", in which the author tries to present concepts in mathematics, drawings and music as instances of a certain ""pattern"", that he calls ""strange loops"". He makes several comments about Bach's music, in particular, as the title suggests. So, he talks about the fugues, sonatas and partitas, modulation, themes played against themselves, how Bach manages to get two or more musical lines going simultaneously and so on.

But I don't understand a thing about these musical concepts. I have tried to listen on YouTube to some of the compositions he mentions in the book, but my stupid brain only hears a stream of notes flowing. I can't recognize the patterns he talks about, nor can I grasp, for example, the fact the the ""Canon per Tonos"" rises successively until it reaches the key C again. 

So how can I learn more about these musical concepts, so as to better follow the book's main ideas? To make this question narrower, I'm not asking for general references to learn about music, but something very specific to the content of the book, so that I don't miss important information (and fun) from his exposition.
",Otavio Macedo,https://music.stackexchange.com/users/12666,"A key to following the polyphonic music of Bach is to be able to single out the individual voices. You will be very much helped by having a score at hand. In a fugue, the theme is presented in one voice, then repeated on the dominant with slightly modified intervals (but same rhythm and pitch profile) in another voice, then introduced in the tonic in a third voice and so on. A good pianist will bring out these entries, but seeing them in the score will most likely aid your understanding of what goes on.

Keeping track of modulations throughout a piece can be quite challenging even for experienced musicians, but in the score these different tonal regions can be easily identified.

By the way, I think the ideas about self reference and GÃ¶del's incompleteness theorem are much harder to grasp for most readers of GEB, but still the book is just as enjoyable.
",oberdada,https://music.stackexchange.com/users/6424,http://music.stackexchange.com/questions/22216/learning-the-musical-concepts-in-the-book-g%C3%B6del-escher-bach,LIFE_ARTS,music.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.5,0.8888888888888888,0.8888888888888888,0.7,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,"Learning the concept of music in Godel, Escher and Bach","I am reading the book ""GÃ¶del, Escher, Bach"", in which the author tries to present concepts in mathematics, drawings and music as instances of a certain ""pattern"", that he calls ""strange loops"". He makes several comments about Bach's music, in particular, as the title suggests. So, he talks about the fugues, sonatas and partitas, modulation, themes played against themselves, how Bach manages to get two or more musical lines going simultaneously and so on.

But I don't understand a thing about these musical concepts. I have tried to listen on YouTube to some of the compositions he mentions in the book, but my stupid brain only hears a stream of notes flowing. I can't recognize the patterns he talks about, nor can I grasp, for example, the fact the the ""Canon per Tonos"" rises successively until it reaches the key C again. 

So how can I learn more about these musical concepts, so as to better follow the book's main ideas? To make this question narrower, I'm not asking for general references to learn about music, but something very specific to the content of the book, so that I don't miss important information (and fun) from his exposition.
","A key to following the polyphonic music of Bach is to be able to single out the individual voices. You will be very much helped by having a score at hand. In a fugue, the theme is presented in one voice, then repeated on the dominant with slightly modified intervals (but same rhythm and pitch profile) in another voice, then introduced in the tonic in a third voice and so on. A good pianist will bring out these entries, but seeing them in the score will most likely aid your understanding of what goes on.

Keeping track of modulations throughout a piece can be quite challenging even for experienced musicians, but in the score these different tonal regions can be easily identified.

By the way, I think the ideas about self reference and GÃ¶del's incompleteness theorem are much harder to grasp for most readers of GEB, but still the book is just as enjoyable.
"
4028,4028,6430,Why did they choose Barabbas?,"John 19:38 - 40 (NLT)


  38 âWhat is truth?â Pilate asked. Then he went out again to the people
  and told them, âHe is not guilty of any crime. 39 But you have a
  custom of asking me to release one prisoner each year at Passover.
  Would you like me to release this âKing of the Jewsâ?â
  
  40 But they shouted back, âNo! Not this man. We want Barabbas!â
  (Barabbas was a revolutionary.)


Why were they so messed up that they would choose the rebellious, murderous Barabbas over the innocent Son of God?
",Andrew,https://christianity.stackexchange.com/users/65,"
  John 12:12-13 (KJV)
  12On the next day much people that were come to the feast, when they heard that Jesus was coming to Jerusalem, 13Took branches of palm trees, and went forth to meet him, and cried, Hosanna: Blessed is the King of Israel that cometh in the name of the Lord.


When Jesus came into Jerusalem on Palm Sunday, the people welcomed Him as a deliverer from the oppression of Rome. They cried, ""Hosanna!"" which means ""Save us!"" They threw down palm branches, which since the time of the Maccabean revolt had been a Jewish symbol of victory (see section ""3. Palm Branches"" from Bible Encyclopedia and 1 Maccabees 13:51).


  John 12:14-15 (KJV)
  14And Jesus, when he had found a young ass, sat thereon; as it is written, 15Fear not, daughter of Sion: behold, thy King cometh, sitting on an ass's colt.


This prophecy is from Zechariah 9:9, and if you read the entire passage, you can see again what the Jews expected: a Messiah that would drive out their oppressors and be a physical savior.

Why did the Jews choose Barabbas instead of Jesus mere days after they welcomed Him so strongly? The other answers correctly point out that the chief priests and elders stirred the crowd against Jesus. However, the people were able to be swayed because their expectations were disappointed. Jesus didn't ride into Jerusalem on a battle charger, accepting a crown and forming an army to defeat Rome. Instead He came humbly, on a donkey, and He came not to conquer Rome, but to conquer death and sin through His sacrificial death.
",Brian Koser,https://christianity.stackexchange.com/users/491,http://christianity.stackexchange.com/questions/7043/why-did-they-choose-barabbas,CULTURE,christianity.stackexchange.com,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Why did they choose Barabbas?,"John 19:38 - 40 (NLT)


  38 âWhat is truth?â Pilate asked. Then he went out again to the people
  and told them, âHe is not guilty of any crime. 39 But you have a
  custom of asking me to release one prisoner each year at Passover.
  Would you like me to release this âKing of the Jewsâ?â
  
  40 But they shouted back, âNo! Not this man. We want Barabbas!â
  (Barabbas was a revolutionary.)


Why were they so messed up that they would choose the rebellious, murderous Barabbas over the innocent Son of God?
","
  John 12:12-13 (KJV)
  12On the next day much people that were come to the feast, when they heard that Jesus was coming to Jerusalem, 13Took branches of palm trees, and went forth to meet him, and cried, Hosanna: Blessed is the King of Israel that cometh in the name of the Lord.


When Jesus came into Jerusalem on Palm Sunday, the people welcomed Him as a deliverer from the oppression of Rome. They cried, ""Hosanna!"" which means ""Save us!"" They threw down palm branches, which since the time of the Maccabean revolt had been a Jewish symbol of victory (see section ""3. Palm Branches"" from Bible Encyclopedia and 1 Maccabees 13:51).


  John 12:14-15 (KJV)
  14And Jesus, when he had found a young ass, sat thereon; as it is written, 15Fear not, daughter of Sion: behold, thy King cometh, sitting on an ass's colt.


This prophecy is from Zechariah 9:9, and if you read the entire passage, you can see again what the Jews expected: a Messiah that would drive out their oppressors and be a physical savior.

Why did the Jews choose Barabbas instead of Jesus mere days after they welcomed Him so strongly? The other answers correctly point out that the chief priests and elders stirred the crowd against Jesus. However, the people were able to be swayed because their expectations were disappointed. Jesus didn't ride into Jerusalem on a battle charger, accepting a crown and forming an army to defeat Rome. Instead He came humbly, on a donkey, and He came not to conquer Rome, but to conquer death and sin through His sacrificial death.
"
1864,1864,2962,Order of footnotes with packages afterpage and footnote,"I need to have footnotes in captions of figures and therefore use the afterpage package to keep the footnotes and the figure on the same page (also using package footnote for footnotes in figures). I need to write my PhD thesis in a style that was defined in Word, but I wanted to write in Latex. Word always puts footnotes at the bottom of the page. So basically, I'm forced to put footnotes at the bottom. Others seem to have the same problem (other question, accepted answer puts footnote on bottom of page, but is manual; also for tables that might float and floats in general, where I found the idea with afterpage; also in other places on the web), so I though I might share my progress made so far and get input from others on the issue.

When using floats in an afterpage environment, the ordering of the footnotes at the bottom gets mangled up in some parts of the document. I managed to fix the ordering of the footnotes at the bottom with a dirty hack (see below), but the footnote number of the figure is not always the first footnote number appearing on the page. So I now have basically two questions:


What does my dirty hack do? I just tried some things and somehow it worked, now I'd like to understand why and whether it might have effects on other parts of the document.
How can I get the correct footnote number, i.e. the lowest footnote number on that page, for the footnote of the caption?


My dirty hack (using \patchcmd from etoolbox): 

\usepackage{etoolbox}

\makeatletter
\tracingpatches
\patchcmd{\AP@savetop}{\global\setbox\AP@footins\box\footins}{}{}{}
\patchcmd{\AP@@}{\insert\footins{\unvbox\AP@footins}\fi}{\setbox\footins\vbox{\unvbox\AP@footins}\fi}{}{}
\makeatother


What I get without my dirty hack:


  
  Footnotes on same page as figure
  Footnotes order not correct
  Footnote number of caption not first number on page
  




What I get with my dirty hack


  
  Footnotes on same page as figure
  Footnotes order correct
  Footnote number of caption not first number on page
  




What I want


  
  Footnotes on same page as figure
  Footnotes order correct
  Footnote number of caption first number on page
  


MWE:

\documentclass[12pt,a4paper,twoside,openany,fleqn]{book}

\usepackage{afterpage}
\usepackage[ngerman]{babel}
\usepackage{lipsum}
\usepackage{footnote}
\makesavenoteenv{figure}

\begin{document}
\chapter{First Chapter}

\lipsum[1]\footnote{Footnote}
\afterpage{
    \begin{figure}[htp]
        \fbox{Hello World}
        \caption[test]{test\protect\footnote{Test}}
    \end{figure}
}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}
\afterpage{
    \begin{figure}[htp]
        \fbox{Hello World}
        \caption[test]{test\protect\footnote{Test}}
    \end{figure}
}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}

\end{document}


Edit1:
Second MWE without afterpage, where footnote is kept on different page. Adding afterpage around the figures moves the footnote to the correct page:

\documentclass[12pt,a4paper,twoside,openany,fleqn]{book}

\usepackage[ngerman]{babel}
\usepackage{lipsum}
\usepackage{footnote}
\makesavenoteenv{figure}

\begin{document}
\chapter{First Chapter}

\lipsum[1]\footnote{Footnote}

    \begin{figure}[tp]
        \begin{minipage}[t][0.4\textheight][t]{0.6\textwidth}
                \end{minipage}
        \caption[test]{test\protect\footnote{Test}}
    \end{figure}

\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}

    \begin{figure}[tp]
        \begin{minipage}[t][0.4\textheight][t]{0.6\textwidth}
    \end{minipage}
    \caption[test]{test\protect\footnote{Test}}
    \end{figure}

\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}

\end{document}




",ThomasD,https://tex.stackexchange.com/users/59897,"There is no way to do this with floating figures without rewriting half of latex: the caption (including any footnote marks) is set at the point of the figure environment and a floating figure can float past footnotes, thus getting the footnote numbers out of order.

If you really want this output style (I can see no good reason for it, a float is by design a distinct object not in the main flow of text on the page, and so having its footnotes in the page just seems wrong) then you need to use non floating figures.

You can use float package \begin{figure}[H] or or caption or capt-of package \captionof{figure}{...} then the figure is not a floating object but fixed in the page, and you can then use \footnotemark in the caption and \footnotetext immediately after the \end{figure} and they will come on the same page.
",David Carlisle,https://tex.stackexchange.com/users/1090,http://tex.stackexchange.com/questions/193895/order-of-footnotes-with-packages-afterpage-and-footnote,TECHNOLOGY,tex.stackexchange.com,0.8333333333333334,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.5555555555555556,0.5,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.3333333333333333,0.8888888888888888,"Order with package footnotes, attachment and footnotes","I need to have footnotes in captions of figures and therefore use the afterpage package to keep the footnotes and the figure on the same page (also using package footnote for footnotes in figures). I need to write my PhD thesis in a style that was defined in Word, but I wanted to write in Latex. Word always puts footnotes at the bottom of the page. So basically, I'm forced to put footnotes at the bottom. Others seem to have the same problem (other question, accepted answer puts footnote on bottom of page, but is manual; also for tables that might float and floats in general, where I found the idea with afterpage; also in other places on the web), so I though I might share my progress made so far and get input from others on the issue.

When using floats in an afterpage environment, the ordering of the footnotes at the bottom gets mangled up in some parts of the document. I managed to fix the ordering of the footnotes at the bottom with a dirty hack (see below), but the footnote number of the figure is not always the first footnote number appearing on the page. So I now have basically two questions:


What does my dirty hack do? I just tried some things and somehow it worked, now I'd like to understand why and whether it might have effects on other parts of the document.
How can I get the correct footnote number, i.e. the lowest footnote number on that page, for the footnote of the caption?


My dirty hack (using \patchcmd from etoolbox): 

\usepackage{etoolbox}

\makeatletter
\tracingpatches
\patchcmd{\AP@savetop}{\global\setbox\AP@footins\box\footins}{}{}{}
\patchcmd{\AP@@}{\insert\footins{\unvbox\AP@footins}\fi}{\setbox\footins\vbox{\unvbox\AP@footins}\fi}{}{}
\makeatother


What I get without my dirty hack:


  
  Footnotes on same page as figure
  Footnotes order not correct
  Footnote number of caption not first number on page
  




What I get with my dirty hack


  
  Footnotes on same page as figure
  Footnotes order correct
  Footnote number of caption not first number on page
  




What I want


  
  Footnotes on same page as figure
  Footnotes order correct
  Footnote number of caption first number on page
  


MWE:

\documentclass[12pt,a4paper,twoside,openany,fleqn]{book}

\usepackage{afterpage}
\usepackage[ngerman]{babel}
\usepackage{lipsum}
\usepackage{footnote}
\makesavenoteenv{figure}

\begin{document}
\chapter{First Chapter}

\lipsum[1]\footnote{Footnote}
\afterpage{
    \begin{figure}[htp]
        \fbox{Hello World}
        \caption[test]{test\protect\footnote{Test}}
    \end{figure}
}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}
\afterpage{
    \begin{figure}[htp]
        \fbox{Hello World}
        \caption[test]{test\protect\footnote{Test}}
    \end{figure}
}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}

\end{document}


Edit1:
Second MWE without afterpage, where footnote is kept on different page. Adding afterpage around the figures moves the footnote to the correct page:

\documentclass[12pt,a4paper,twoside,openany,fleqn]{book}

\usepackage[ngerman]{babel}
\usepackage{lipsum}
\usepackage{footnote}
\makesavenoteenv{figure}

\begin{document}
\chapter{First Chapter}

\lipsum[1]\footnote{Footnote}

    \begin{figure}[tp]
        \begin{minipage}[t][0.4\textheight][t]{0.6\textwidth}
                \end{minipage}
        \caption[test]{test\protect\footnote{Test}}
    \end{figure}

\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}

    \begin{figure}[tp]
        \begin{minipage}[t][0.4\textheight][t]{0.6\textwidth}
    \end{minipage}
    \caption[test]{test\protect\footnote{Test}}
    \end{figure}

\lipsum[1]\footnote{Footnote}
\lipsum[1]\footnote{Footnote}

\end{document}




","There is no way to do this with floating figures without rewriting half of latex: the caption (including any footnote marks) is set at the point of the figure environment and a floating figure can float past footnotes, thus getting the footnote numbers out of order.

If you really want this output style (I can see no good reason for it, a float is by design a distinct object not in the main flow of text on the page, and so having its footnotes in the page just seems wrong) then you need to use non floating figures.

You can use float package \begin{figure}[H] or or caption or capt-of package \captionof{figure}{...} then the figure is not a floating object but fixed in the page, and you can then use \footnotemark in the caption and \footnotetext immediately after the \end{figure} and they will come on the same page.
"
3987,3987,6365,What's the play event on a video html5 element?,"I have a video html5 tag embedded on page. I need to trigger an action when the user clicks the ""Play Button"". But I can't find how to bind that to my action. Is there an event for what I need? I'm using jQuery...

Thanks!
",Andres,https://stackoverflow.com/users/973242,"I used code from the following page and stripped it:

&lt;script language=""javascript""&gt;
    document.addEventListener(""DOMContentLoaded"", init, false);

    function init() {
        var _video = document.getElementById(""video"");
        _video.addEventListener(""playing"", play_clicked, false);
    }

    function play_clicked() {
        alert(""play was clicked"");
    }
&lt;/script&gt;

&lt;video id='video'
  controls preload='none' 
  poster=""http://media.w3.org/2010/05/sintel/poster.png""&gt;
  &lt;source id='mp4'
    src=""http://media.w3.org/2010/05/sintel/trailer.mp4""
    type='video/mp4'&gt;
  &lt;p&gt;Your user agent does not support the HTML5 Video element.&lt;/p&gt;
&lt;/video&gt;


Hoped I could help.
",Uri May,https://stackoverflow.com/users/485574,http://stackoverflow.com/questions/12680432/whats-the-play-event-on-a-video-html5-element,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,1.0,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,What are the playback events for video HTML5 elements?,"I embedded a video HTML 5 tag on the page. When the user clicks the play button, I need to trigger an action. But I couldn't find a way to relate it to my behavior. Is there any activity I need? I'm using jQuery...","I used code from the following page and stripped it:

&lt;script language=""javascript""&gt;
    document.addEventListener(""DOMContentLoaded"", init, false);

    function init() {
        var _video = document.getElementById(""video"");
        _video.addEventListener(""playing"", play_clicked, false);
    }

    function play_clicked() {
        alert(""play was clicked"");
    }
&lt;/script&gt;

&lt;video id='video'
  controls preload='none' 
  poster=""http://media.w3.org/2010/05/sintel/poster.png""&gt;
  &lt;source id='mp4'
    src=""http://media.w3.org/2010/05/sintel/trailer.mp4""
    type='video/mp4'&gt;
  &lt;p&gt;Your user agent does not support the HTML5 Video element.&lt;/p&gt;
&lt;/video&gt;


Hoped I could help.
"
5636,5636,8936,Electric current of inductor,"I have a homework problem that was solved by our instructor: 

""Calculate the electric current of the inductor at \$t=0^+\$.""



He calculated \$1/30\$ but the answer sheet was says \$-1/30\$.

Which of them is correct? 

Our instructor's work:






",Michle Jordan,https://electronics.stackexchange.com/users/53796,"I would say that both answers are wrong. Imagine if the inductor were omitted from the circuit and any source of voltage or current were applied (via the 3 ohm series resistor) to what is basically a balanced bridge.

What would be the voltage at the junction of the two 1 ohm resistors - it would be the same voltage as at the junction of the two 3 ohm resistors - net voltage across the two points (where the inductor was connected) is always zero.

So, now replace the inductor and ask yourself what the net voltage across the inductor will be - it'll still be zero and never, ever will any current flow thru it.
",Andy aka,https://electronics.stackexchange.com/users/20218,http://electronics.stackexchange.com/questions/140212/electric-current-of-inductor,TECHNOLOGY,electronics.stackexchange.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.6,0.0,0.0,0.0,1.0,Inductor current,"I have a homework problem that was solved by our instructor: 

""Calculate the electric current of the inductor at \$t=0^+\$.""



He calculated \$1/30\$ but the answer sheet was says \$-1/30\$.

Which of them is correct? 

Our instructor's work:






","I would say that both answers are wrong. Imagine if the inductor were omitted from the circuit and any source of voltage or current were applied (via the 3 ohm series resistor) to what is basically a balanced bridge.

What would be the voltage at the junction of the two 1 ohm resistors - it would be the same voltage as at the junction of the two 3 ohm resistors - net voltage across the two points (where the inductor was connected) is always zero.

So, now replace the inductor and ask yourself what the net voltage across the inductor will be - it'll still be zero and never, ever will any current flow thru it.
"
5479,5479,8698,What do you call a group of people that move a lot?,"I can't think of the word to describe it. Something similar to ""wanderer"" or ""roamer"". 

It's often used to describe people that don't stay in one place... not ""migratory""...
",Marty,https://english.stackexchange.com/users/9704,"Some more possibilities:

transients
vagrants
drifters
fugitives
migrants
errants
floaters
wanderers
Bedouins
itinerants (from @Kit)
",Callithumpian,https://english.stackexchange.com/users/5822,http://english.stackexchange.com/questions/29078/what-do-you-call-a-group-of-people-that-move-a-lot,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,0.7777777777777778,What do you call people who move a lot?,"I can't think of the word to describe it. Something similar to ""wanderer"" or ""roamer"". 

It's often used to describe people that don't stay in one place... not ""migratory""...
","Some more possibilities:

transients
vagrants
drifters
fugitives
migrants
errants
floaters
wanderers
Bedouins
itinerants (from @Kit)
"
189,189,303,Show UILabel with complete text or hide it,"I have a UI label say ""ABCDEFGH"". In iPhone 6 etc wider devices I can show the complete text. In small screen devices like iPhone 5, I see text as ""ABCD..."". I want the following:

if(complete text can be shown) 
{
    // show UILabel with text
} else // if text can not fit in, ""ABCD..."" case 
{    
    // hide the UILabel
}


How can I do this?
",Vinuta,https://stackoverflow.com/users/1155552,"call the sizeToFit function on the UILabel. If it's size is longer that the maximum, hide it...
",Yedidya,https://stackoverflow.com/users/1284137,http://stackoverflow.com/questions/31168215/show-uilabel-with-complete-text-or-hide-it,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,1.0,0.0,0.0,0.7777777777777778,Show or hide uilabel with full text,"I have a user interface label that says ""abcdefgh."". On a wider range of devices, such as the iPhone 6, I can display full text. In a small screen device like the iPhone 5, I think of text as ""ABCD..."". I want to:","Call sizetofit function on uilabel. If it's the largest, hide it"
2569,2569,4090,What to do about students who ask for help too often?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
",Village,https://academia.stackexchange.com/users/600,"If you see something definitely plagiarized, you could try to get them to claim it as theirs when they consult you and fail them on the spot for making the claim whether it's in class or not.

I do agree with @DaveClarke that on this or the other issue, announcing a policy at the start of the term (no more than N consults per assignment/per term, and plagiarism is an automatic F and will also be referred to the school's academic conduct team) would help set expectations, cut down on abuse, and give you grounds to say ""No, it wouldn't be fair to others if I helped you again before you turn it in.""
",keshlam,https://academia.stackexchange.com/users/10225,http://academia.stackexchange.com/questions/28504/what-to-do-about-students-who-ask-for-help-too-often,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.0,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.6666666666666667,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,What to do with students who often ask for help?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
","If you see something definitely plagiarized, you could try to get them to claim it as theirs when they consult you and fail them on the spot for making the claim whether it's in class or not.

I do agree with @DaveClarke that on this or the other issue, announcing a policy at the start of the term (no more than N consults per assignment/per term, and plagiarism is an automatic F and will also be referred to the school's academic conduct team) would help set expectations, cut down on abuse, and give you grounds to say ""No, it wouldn't be fair to others if I helped you again before you turn it in.""
"
2727,2727,4348,Unable to make Zsh not to suggest a fix for an alias,"I have an alias for

alias tdA='todo -a'


I get the following in Zsh

tdA          
zsh: correct 'tdA' to 'tda' [nyae]?


How can you make Zsh not to suggest a fix for an alias?
",LÃ©o LÃ©opold Hertz ì¤ì,https://serverfault.com/users/1944,"try


  % unsetopt correct 


I have the spelling correction off by default.

If it works, add it to your .zshrc file.
",Jindrich,https://serverfault.com/users/4694,http://serverfault.com/questions/21521,TECHNOLOGY,serverfault.com,0.7777777777777778,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,1.0,0.0,0.3333333333333333,0.7777777777777778,Unable to make Zsh not recommend repairing aliases,"I have an alias for

alias tdA='todo -a'


I get the following in Zsh

tdA          
zsh: correct 'tdA' to 'tda' [nyae]?


How can you make Zsh not to suggest a fix for an alias?
","try


  % unsetopt correct 


I have the spelling correction off by default.

If it works, add it to your .zshrc file.
"
4890,4890,7783,Ticketing/Project Management/Collaborative Software for Graphic Design,"I manage our company's in-house graphic design.  We have a lot of requests that are very simple (ie, ad-resizing, simple web banners, logo-adjustments, etc) and a number of requests that are complex and require a lot of back and forth (ie, brochures and magazines ranging from 3 to 200 pages, concept design for new ad campaigns, etc...)

Currently, we employ a very simple issue tracking system (which is technically for software development) for all requests. For the most part it does the job.  Users can write a description of the materials they need, upload attachments, leave comments, but because our company is growing in size and the amount of requests are steadily growing, I was looking for a more robust solution.

After doing a lot of research, I've found a number of new systems I could potentially upgrade to, however, everything I have found explains how their system is best suited for an IT/software development team.

So before upgrading to a newer, more robust project management system that is specifically geared toward software development/IT desktop support, I was wondering if anyone of knew of any ticketing/collaborative systems specifically geared toward graphic design?

Thanks
",kdub,https://graphicdesign.stackexchange.com/users/2193,"As mentioned before, a dedicated project management software such as Jira may be overkill and too clumsy for your application. At the same time, a plain helpdesk may just solve one end of your problem (tackle your tickets) but it won't necessarily help out with collaboration or feedback tracking that you'll receive from your clients.

Something that may work for you is Helprace. 

Helprace is not only a ticket system for client requests, but also a collaboration and idea tracking tool. Customers or staff can collaborate and share questions/ideas/problem/praise publicly. You can also open as many portals as you like (for different projects) or make them private, so only staff can see them (in other words, staff can collaborate in private).

To be honest, I don't know of other simple project collaboration + helpdesk combos, but most helpdesk providers want to do one thing and do it well, so rather than committing to developing the whole system from scratch, they will offer integrations which is not for everyone.
",VitaliyVerbenko,https://graphicdesign.stackexchange.com/users/45781,http://graphicdesign.stackexchange.com/questions/17324/ticketing-project-management-collaborative-software-for-graphic-design,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.7777777777777778,0.3333333333333333,1.0,0.6666666666666666,0.5,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,0.6666666666666666,1.0,Ticketing / Project Management / graphic design collaboration software,"I manage our company's in-house graphic design.  We have a lot of requests that are very simple (ie, ad-resizing, simple web banners, logo-adjustments, etc) and a number of requests that are complex and require a lot of back and forth (ie, brochures and magazines ranging from 3 to 200 pages, concept design for new ad campaigns, etc...)

Currently, we employ a very simple issue tracking system (which is technically for software development) for all requests. For the most part it does the job.  Users can write a description of the materials they need, upload attachments, leave comments, but because our company is growing in size and the amount of requests are steadily growing, I was looking for a more robust solution.

After doing a lot of research, I've found a number of new systems I could potentially upgrade to, however, everything I have found explains how their system is best suited for an IT/software development team.

So before upgrading to a newer, more robust project management system that is specifically geared toward software development/IT desktop support, I was wondering if anyone of knew of any ticketing/collaborative systems specifically geared toward graphic design?

Thanks
","As mentioned before, a dedicated project management software such as Jira may be overkill and too clumsy for your application. At the same time, a plain helpdesk may just solve one end of your problem (tackle your tickets) but it won't necessarily help out with collaboration or feedback tracking that you'll receive from your clients.

Something that may work for you is Helprace. 

Helprace is not only a ticket system for client requests, but also a collaboration and idea tracking tool. Customers or staff can collaborate and share questions/ideas/problem/praise publicly. You can also open as many portals as you like (for different projects) or make them private, so only staff can see them (in other words, staff can collaborate in private).

To be honest, I don't know of other simple project collaboration + helpdesk combos, but most helpdesk providers want to do one thing and do it well, so rather than committing to developing the whole system from scratch, they will offer integrations which is not for everyone.
"
1128,1128,1769,Possible to remove p tags from a table cell in Wygwam,"I have a problem that occasionally a &lt;p&gt; tag is being added to a table cell, usually when someone pastes something into it. 

Is there a way to remove that &lt;p&gt; and just have the cell be an empty &lt;td&gt; or &lt;th&gt;, ideally without editing the source? 

Is there an option that could be added through the advanced settings?
",since1976,https://expressionengine.stackexchange.com/users/53,"If the reason is appearance, you can remove any margin/padding formatting with css, like:
table p {padding:0; margin:0}
Or you can add specific classes to the styling menu of wygwam for tables, for a more fine grained control over styling tables.
",GDmac,https://expressionengine.stackexchange.com/users/155,http://expressionengine.stackexchange.com/questions/4852/possible-to-remove-p-tags-from-a-table-cell-in-wygwam,TECHNOLOGY,expressionengine.stackexchange.com,0.5,0.5,0.5,0.0,0.5,0.5,0.6666666666666666,0.5,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8333333333333334,0.8,0.0,0.5,0.5,0.8333333333333334,You can remove the P tag from a table cell in wygwam,"I have a problem that occasionally a &lt;p&gt; tag is being added to a table cell, usually when someone pastes something into it. 

Is there a way to remove that &lt;p&gt; and just have the cell be an empty &lt;td&gt; or &lt;th&gt;, ideally without editing the source? 

Is there an option that could be added through the advanced settings?
","If the reason is appearance, you can remove any margin/padding formatting with css, like:
table p {padding:0; margin:0}
Or you can add specific classes to the styling menu of wygwam for tables, for a more fine grained control over styling tables.
"
994,994,1571,php mysql return wrong boolean result,"I have the following query :

'SELECT Active FROM tbUsers WHERE Id=55'


The Id is unique and I need just to know the status of the user if he's active yes or no. The Column Active is set as boolean in Mysql

When I tried to return the result like the following (using another php function) :

$result = $this-&gt;selectRow($db,""tbClass"",""Active"",""Id='$Id'"");
if($result) { return ""ok"" ; } else { return ""nok"" ;)


it returns 'ok' on both cases.
Any idea what's wrong with it ?

Here is the other function :

public function selectRow($db,$tableName,$field,$where) {
        if($where == """") {
            $query = ""SELECT $field FROM $tableName"";
        }
        else
        { $query = ""SELECT $field FROM $tableName WHERE $where""; }

        $result=$db-&gt;Qry($query);


        if ($result) {
            $no_of_rows =  $db-&gt;TotRows($result);
            if($no_of_rows == 1) {
                return $result;
            }
            if($no_of_rows == 0) {
                return '';
            }
            if($no_of_rows &lt; 0) {
                die('Invalid query: ' . $sender .""("".$query  .""): "".mysql_errno()."": "". mysql_error());
                return '';
            }
        } 
        else {
            die('Invalid query: ' . $sender ."": "" .$query."": "". mysql_errno()."": "". mysql_error());
            return '';
        }
    }


Qry Function is the following :

function Qry($sql) {
    if($result = mysqli_query($this-&gt;con,$sql) ) {
        return $result;
    }
    else 
    {
        $err = ""Error: "".$sql. "" :: "". mysqli_error;
        die(""$err"");
    }
}

",koul,https://stackoverflow.com/users/4297309,"Alright, so $result is a mysqli_result object.
You might want to fetch the first row of that result and return the desired column.

Replace

return $result;


with 

return $result-&gt;fetch_assoc()[$field];

",Siguza,https://stackoverflow.com/users/2302862,http://stackoverflow.com/questions/30592415/php-mysql-return-wrong-boolean-result,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,PHP MySQL returns wrong Boolean results,"I have the following query :

'SELECT Active FROM tbUsers WHERE Id=55'


The Id is unique and I need just to know the status of the user if he's active yes or no. The Column Active is set as boolean in Mysql

When I tried to return the result like the following (using another php function) :

$result = $this-&gt;selectRow($db,""tbClass"",""Active"",""Id='$Id'"");
if($result) { return ""ok"" ; } else { return ""nok"" ;)


it returns 'ok' on both cases.
Any idea what's wrong with it ?

Here is the other function :

public function selectRow($db,$tableName,$field,$where) {
        if($where == """") {
            $query = ""SELECT $field FROM $tableName"";
        }
        else
        { $query = ""SELECT $field FROM $tableName WHERE $where""; }

        $result=$db-&gt;Qry($query);


        if ($result) {
            $no_of_rows =  $db-&gt;TotRows($result);
            if($no_of_rows == 1) {
                return $result;
            }
            if($no_of_rows == 0) {
                return '';
            }
            if($no_of_rows &lt; 0) {
                die('Invalid query: ' . $sender .""("".$query  .""): "".mysql_errno()."": "". mysql_error());
                return '';
            }
        } 
        else {
            die('Invalid query: ' . $sender ."": "" .$query."": "". mysql_errno()."": "". mysql_error());
            return '';
        }
    }


Qry Function is the following :

function Qry($sql) {
    if($result = mysqli_query($this-&gt;con,$sql) ) {
        return $result;
    }
    else 
    {
        $err = ""Error: "".$sql. "" :: "". mysqli_error;
        die(""$err"");
    }
}

","Alright, so $result is a mysqli_result object.
You might want to fetch the first row of that result and return the desired column.

Replace

return $result;


with 

return $result-&gt;fetch_assoc()[$field];

"
314,314,503,Is there a word for something loved by the masses but whose true value is lacking?,"Is there a general word for someone or something popular or loved by the masses but that has not been proven to be effectual (like how some would use the term ""pop psychology"" pejoratively)? Examples would be how things like popular psychology or holistic medicine are accepted excitedly by numerous people while not being proven to be useful to the majority.

UPDATE: Thanks for you responses. I think the word ""fad"" (or ""hype"") would come closest to what I was looking for (thank you for that).

But is there a more general or appropriate term? I'm not American so apologies in advance (this is strictly for the sake of discussion): the only example I can think of is certain voters who were initially excited about Obama, but came to be disappointed after he failed to meet their expectations. Is there a word that could be used to describe Obama in this context? Something well-loved which turns out to be a disappointment.
",Mia T,https://english.stackexchange.com/users/106861,"Not sure why nobody said this. Is ""overrated"" the word you are looking for?
",guru,https://english.stackexchange.com/users/106949,http://english.stackexchange.com/questions/222672/is-there-a-word-for-something-loved-by-the-masses-but-whose-true-value-is-lackin,CULTURE,english.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,Is there a word to describe what the masses love but lack real value?,"Is there a general word for someone or something popular or loved by the masses but that has not been proven to be effectual (like how some would use the term ""pop psychology"" pejoratively)? Examples would be how things like popular psychology or holistic medicine are accepted excitedly by numerous people while not being proven to be useful to the majority.

UPDATE: Thanks for you responses. I think the word ""fad"" (or ""hype"") would come closest to what I was looking for (thank you for that).

But is there a more general or appropriate term? I'm not American so apologies in advance (this is strictly for the sake of discussion): the only example I can think of is certain voters who were initially excited about Obama, but came to be disappointed after he failed to meet their expectations. Is there a word that could be used to describe Obama in this context? Something well-loved which turns out to be a disappointment.
","I don't know why no one said that. Is the word you are looking for ""overestimate""?"
6046,6046,9594,How to know which edition a DotNetNuke site is,"This may be a silly question, but I recently inherited a DotNetNuke site.  Looking in the settings, I can see it's running version 4.09.00 of DNN. Looking at current DNN 5.0 information, there appears to be several editions available (Community, Professional, Enterprise, etc).

So my question is:


Were these editions also available in the 4.0 version of DNN?
If so, is there a way to tell which edition the site is running?  I didn't see any immediately obvious designation in the admin areas.


Thanks!
",mrdrbob,https://webmasters.stackexchange.com/users/1436,"
Log into the site with the Host account
Mouseover Host from the navigation menu - select Host Settings from the dropdown
Version should be the second row, Edition first row


Mine says
DotNetNuke Product: DotNetNuke Community Edition 
DotNetNuke Version: 04.09.05 
",Wil,https://webmasters.stackexchange.com/users/795,http://webmasters.stackexchange.com/questions/2139/how-to-know-which-edition-a-dotnetnuke-site-is,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,How to know which version of DotNetNuke site is,"This may be a silly question, but I recently inherited a DotNetNuke website. In the setup, I can see that it is running version 4.09.00 of DNN. Looking at the current DNN 5.0 information, it appears that several versions are available (community, professional, enterprise, etc.).","
Log into the site with the Host account
Mouseover Host from the navigation menu - select Host Settings from the dropdown
Version should be the second row, Edition first row


Mine says
DotNetNuke Product: DotNetNuke Community Edition 
DotNetNuke Version: 04.09.05 
"
2605,2605,4146,Ticketing/Project Management/Collaborative Software for Graphic Design,"I manage our company's in-house graphic design.  We have a lot of requests that are very simple (ie, ad-resizing, simple web banners, logo-adjustments, etc) and a number of requests that are complex and require a lot of back and forth (ie, brochures and magazines ranging from 3 to 200 pages, concept design for new ad campaigns, etc...)

Currently, we employ a very simple issue tracking system (which is technically for software development) for all requests. For the most part it does the job.  Users can write a description of the materials they need, upload attachments, leave comments, but because our company is growing in size and the amount of requests are steadily growing, I was looking for a more robust solution.

After doing a lot of research, I've found a number of new systems I could potentially upgrade to, however, everything I have found explains how their system is best suited for an IT/software development team.

So before upgrading to a newer, more robust project management system that is specifically geared toward software development/IT desktop support, I was wondering if anyone of knew of any ticketing/collaborative systems specifically geared toward graphic design?

Thanks
",kdub,https://graphicdesign.stackexchange.com/users/2193,"If you're after something that is very generic, you could do worse than Trello: it's designed for tracking lists of lists, and then moving individual cards/requests between the lists. You have some pretty fine-grained controls for sharing within an organisation as well.
",Iain Hallam,https://graphicdesign.stackexchange.com/users/187,http://graphicdesign.stackexchange.com/questions/17324/ticketing-project-management-collaborative-software-for-graphic-design,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.4444444444444444,0.7777777777777778,1.0,0.4,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Ticketing / Project Management / graphic design collaboration software,"I manage our company's in-house graphic design.  We have a lot of requests that are very simple (ie, ad-resizing, simple web banners, logo-adjustments, etc) and a number of requests that are complex and require a lot of back and forth (ie, brochures and magazines ranging from 3 to 200 pages, concept design for new ad campaigns, etc...)

Currently, we employ a very simple issue tracking system (which is technically for software development) for all requests. For the most part it does the job.  Users can write a description of the materials they need, upload attachments, leave comments, but because our company is growing in size and the amount of requests are steadily growing, I was looking for a more robust solution.

After doing a lot of research, I've found a number of new systems I could potentially upgrade to, however, everything I have found explains how their system is best suited for an IT/software development team.

So before upgrading to a newer, more robust project management system that is specifically geared toward software development/IT desktop support, I was wondering if anyone of knew of any ticketing/collaborative systems specifically geared toward graphic design?

Thanks
","If you're after something that is very generic, you could do worse than Trello: it's designed for tracking lists of lists, and then moving individual cards/requests between the lists. You have some pretty fine-grained controls for sharing within an organisation as well.
"
1613,1613,2531,What is the torque and sequence for a '99 Jetta Oil Pan?,"I have a '99 Jetta TDI (diesel) with a cracked oil pan.  I'm looking for the sequence of tightening the bolts and the torque needed for each bolt.  I've been doing to google-fu but can't seem to find it. Does anyone specifically know these details, or where I can maybe find this?

Note: Can someone with priv please put 'oil-pan' and 'bolt-sequence' as tags :)
",KronoS,https://mechanics.stackexchange.com/users/578,"Do you have a workshop manual for the car? The torque figures should be listed in there. In the UK Haynes manuals they are at the beginning of the relevant chapter. 

I'm not aware of a specific order for oil sump bolts, but if there is one it should be listed in the approprate section of said manual. Normally it is only head bolts that need to be tightened in a certain sequence, but I don't know about modern VW engines.
",Nick C,https://mechanics.stackexchange.com/users/373,http://mechanics.stackexchange.com/questions/1013/what-is-the-torque-and-sequence-for-a-99-jetta-oil-pan,CULTURE,mechanics.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,0.8333333333333334,0.3333333333333333,0.8333333333333334,0.8333333333333334,0.5,0.0,0.0,1.0,0.8333333333333334,99 what is the torque and sequence for the Jetta sump?,"I have a 99 year old Jetta TDI with a cracked oil pan. I am looking for the sequence of tightening bolts and the torque required for each bolt. I've been looking up Fu on Google, but I can't seem to find it. Is anyone particularly aware of these details, or where can I find them?","Do you have a workshop manual for the car? The torque figures should be listed in there. In the UK Haynes manuals they are at the beginning of the relevant chapter. 

I'm not aware of a specific order for oil sump bolts, but if there is one it should be listed in the approprate section of said manual. Normally it is only head bolts that need to be tightened in a certain sequence, but I don't know about modern VW engines.
"
4475,4475,7098,"ListBox is selecting many items even in SelectionMode=""Single""","I have encountered something very strange, simple WPF application

&lt;Window x:Class=""ListBoxSelection.MainWindow""
        xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
        xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
        Title=""MainWindow"" Height=""350"" Width=""525""&gt;
    &lt;Grid&gt;
        &lt;ListBox ItemsSource=""{Binding Path=Strings}"" SelectionMode=""Single""/&gt;
    &lt;/Grid&gt;
&lt;/Window&gt;


with code behind

public class ViewModel
{
    public List&lt;string&gt; Strings { get; set; }

    public ViewModel ()
    {
        Strings = new List&lt;string&gt; ();
        Strings.Add (""A"");
        // add many items ...
        Strings.Add (""A"");
    }
}

/// &lt;summary&gt;
/// Interaction logic for MainWindow.xaml
/// &lt;/summary&gt;
public partial class MainWindow : Window
{
    public MainWindow ()
    {
        InitializeComponent ();

        DataContext = new ViewModel ();
    }
}


and when I click on a single item,



if I continue clicking items, they just aggregate. Clicking an already selected item does nothing. Scratching my head, I have databound lists to ListBoxes before, and have never seen this before. Running Win7 (64), VS2010, behaviour presents with .Net 3.5, .Net 3.5 Client Profile, .Net 4, and .Net 4 Client Profile.

Arg, I should mention I am expecting normal, default, single-select behaviour.
",johnny g,https://stackoverflow.com/users/189183,"Dan Bryant got most of the answer in his comment.

What's going on here is string interning.  When you create a bunch of strings with the same value, .Net saves on memory usage by having all references to the same string value actually refer to the same string object.  (See this, for instance, for details.)

I don't really know why the ListBox behaves exactly the way it does, which is that the first time you select any item in the list, it selects both that item and the first item in the list.  But it doesn't unselect when you click on a new item because checks to see if the SelectedItem is different from the item you just clicked on, and it isn't.  

I got exactly the same behavior by binding a ListBox to a collection of test objects:

public class TestObject
{
    public override string ToString()
    {
        return GetHashCode().ToString();
    }
}


In MainWindow.xaml:

&lt;ListBox x:Name=""MyListBox"" ItemsSource={Binding}""/&gt;


In MainWindow.xaml.cs:

ObservableCollection&lt;TestObject&gt; test = new ObservableCollection&lt;TestObject&gt;();
TestObject t = new TestObject();
test.Add(t);
test.Add(t);
test.Add(t);
test.Add(t);
test.Add(t);
test.Add(t);
MyListBox.DataContext = test;

",Robert Rossney,https://stackoverflow.com/users/19403,http://stackoverflow.com/questions/3843784/listbox-is-selecting-many-items-even-in-selectionmode-single,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,1.0,"ListBox is selecting many items, even in SelectionMode= ""Single""","I have encountered something very strange, simple WPF application

&lt;Window x:Class=""ListBoxSelection.MainWindow""
        xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
        xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
        Title=""MainWindow"" Height=""350"" Width=""525""&gt;
    &lt;Grid&gt;
        &lt;ListBox ItemsSource=""{Binding Path=Strings}"" SelectionMode=""Single""/&gt;
    &lt;/Grid&gt;
&lt;/Window&gt;


with code behind

public class ViewModel
{
    public List&lt;string&gt; Strings { get; set; }

    public ViewModel ()
    {
        Strings = new List&lt;string&gt; ();
        Strings.Add (""A"");
        // add many items ...
        Strings.Add (""A"");
    }
}

/// &lt;summary&gt;
/// Interaction logic for MainWindow.xaml
/// &lt;/summary&gt;
public partial class MainWindow : Window
{
    public MainWindow ()
    {
        InitializeComponent ();

        DataContext = new ViewModel ();
    }
}


and when I click on a single item,



if I continue clicking items, they just aggregate. Clicking an already selected item does nothing. Scratching my head, I have databound lists to ListBoxes before, and have never seen this before. Running Win7 (64), VS2010, behaviour presents with .Net 3.5, .Net 3.5 Client Profile, .Net 4, and .Net 4 Client Profile.

Arg, I should mention I am expecting normal, default, single-select behaviour.
","Dan Bryant got most of the answer in his comment.

What's going on here is string interning.  When you create a bunch of strings with the same value, .Net saves on memory usage by having all references to the same string value actually refer to the same string object.  (See this, for instance, for details.)

I don't really know why the ListBox behaves exactly the way it does, which is that the first time you select any item in the list, it selects both that item and the first item in the list.  But it doesn't unselect when you click on a new item because checks to see if the SelectedItem is different from the item you just clicked on, and it isn't.  

I got exactly the same behavior by binding a ListBox to a collection of test objects:

public class TestObject
{
    public override string ToString()
    {
        return GetHashCode().ToString();
    }
}


In MainWindow.xaml:

&lt;ListBox x:Name=""MyListBox"" ItemsSource={Binding}""/&gt;


In MainWindow.xaml.cs:

ObservableCollection&lt;TestObject&gt; test = new ObservableCollection&lt;TestObject&gt;();
TestObject t = new TestObject();
test.Add(t);
test.Add(t);
test.Add(t);
test.Add(t);
test.Add(t);
test.Add(t);
MyListBox.DataContext = test;

"
3932,3932,6273,PHP and MySQL calendar issue,"I'm writing trying to build a calendar right from scratch. I'm using the function written by David Walsh (see link) and it's great. 
He does a query for each day's cell.
But, I'm afraid that when the script's gonna have to run 30 queries in each render, it's gonna be sloooow. 

So, I was trying to think in another logic, for example, make a big query from X date to Y date at the begining of the script and then, at each day, check if that particular day has an event in the previous query. But I have no idea of how to do this...
So, if anyone can help, please shout!

Thanks.
",fedeisas,https://stackoverflow.com/users/227927,"Yes, I would go with your...uh...bold suggestion. As posted above, it makes no sense to run the query in a loop. What exactly do you need help with, then?
",Franz,https://stackoverflow.com/users/192741,http://stackoverflow.com/questions/1873340/php-and-mysql-calendar-issue,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.7333333333333333,0.3333333333333333,0.0,0.0,1.0,PHP and MySQL calendar problems,"I'm writing trying to build a calendar right from scratch. I'm using the function written by David Walsh (see link) and it's great. 
He does a query for each day's cell.
But, I'm afraid that when the script's gonna have to run 30 queries in each render, it's gonna be sloooow. 

So, I was trying to think in another logic, for example, make a big query from X date to Y date at the begining of the script and then, at each day, check if that particular day has an event in the previous query. But I have no idea of how to do this...
So, if anyone can help, please shout!

Thanks.
","Yes, I would go with your...uh...bold suggestion. As posted above, it makes no sense to run the query in a loop. What exactly do you need help with, then?
"
5060,5060,8047,How to ask a question according to the specific sections?,"
  ï¼1ï¼I get up early in order to catch a bus. 
  
  ï¼2ï¼I get up early because I can catch a bus.


How to ask a question according to âin order to catch a bus â and ""because I can catch  a bus""?
",user48070,https://ell.stackexchange.com/users/2065,"What do you want to achieve by getting up early?  I get up early in order to catch the morning bus. 

What is your reason for wanting to get up early? I get up early because if I don't, I will miss the morning bus.

Note that the question can really the same: why?  The difference is how the answer is worded:


Why do you X? I do X in order to .
Why do you X? I do X because of .


I think your intended answers are based on the fact that you must catch the morning bus to arrive to work on time. 
 - I get up early in order to catch the morning bus. 
 - I get up early because if I don't, I'll miss the morning buss. 
 - I get up early so I can make it to work on time. 
 - I get up early because I want to make it to work on time.

Following is a bunch of examples. I'm not sure if it's just me, but it seems that often the ""because"" answer is kind of worded in the opposite sense of the ""in order to answer"".  It seems like ""because"" is the driving force or reason, and ""in order to"" is a goal state.  Also, the ""in order to"" answer seems more cold/clinical/unemotional/to-the-point while the ""because"" has more emotion and  a broader set of reasons.  I don't know if this is just me though:


Why do you eat hamburgers? I eat hamburgers because I like hamburgers.  
Why do you eat hamburgers? I eat hamburgers because [I'm trying | I want | I need] to gain weight.  
Why do you eat hamburgers? I eat hamburgers in order to gain weight. 
Why are you eating hamburgers right now? Because their only $1 each.
Why are you eating hamburgers right now? In order to save money; they're only $1 each.
Why are you eating hamburgers right now? Because [I want | I need] to save money, and their only $1 each.
Why do you eat food? I eat food in order to live. Note how well ""in order to"" answers an abstract question.
Why do you eat food? I eat food because I need to eat food in order to live. Not a great answer. 
Why do you eat food? I eat food because if I don't, I will starve to death. Because is using the opposite sense to mean the same thing.
Why do you eat food? I eat food in order to avoid starving to death.  In order to sounds more awkward this way than the first line.   
Why do you eat food? I eat food because I get hungry.  Because is more simple here, based on base emotion or desire.
Why do you eat food? I eat food in order to satisfy my hunger.  In order to has to carefully consider the goal state.
Why do you watch James Bond movies? I watch James Bond movies because I like James Bond. 
Why do you watch movies? I watch movies in order to gain enjoyment.  In order to is more cold/passive way of describing things.  
Why do you watch movies? I watch movies because it's fun.
Why do you smoke? I smoke because I'm addicted to nicotine.
Why do you smoke? I smoke in order to satisfy my nicotine cravings.
Why are you trying to quit smoking?  I'm trying to quit smoking because smoking is bad for me.
What are you trying to quit smoking? I'm trying to quit smoking in order to get more healthy.

",CoolHandLouis,https://ell.stackexchange.com/users/3796,http://ell.stackexchange.com/questions/22934/how-to-ask-a-question-according-to-the-specific-sections,CULTURE,ell.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.5,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8333333333333334,1.0,1.0,1.0,1.0,0.9,1.0,0.0,1.0,1.0,How to ask questions according to specific chapters?,"
  ï¼1ï¼I get up early in order to catch a bus. 
  
  ï¼2ï¼I get up early because I can catch a bus.


How to ask a question according to âin order to catch a bus â and ""because I can catch  a bus""?
","What do you want to achieve by getting up early?  I get up early in order to catch the morning bus. 

What is your reason for wanting to get up early? I get up early because if I don't, I will miss the morning bus.

Note that the question can really the same: why?  The difference is how the answer is worded:


Why do you X? I do X in order to .
Why do you X? I do X because of .


I think your intended answers are based on the fact that you must catch the morning bus to arrive to work on time. 
 - I get up early in order to catch the morning bus. 
 - I get up early because if I don't, I'll miss the morning buss. 
 - I get up early so I can make it to work on time. 
 - I get up early because I want to make it to work on time.

Following is a bunch of examples. I'm not sure if it's just me, but it seems that often the ""because"" answer is kind of worded in the opposite sense of the ""in order to answer"".  It seems like ""because"" is the driving force or reason, and ""in order to"" is a goal state.  Also, the ""in order to"" answer seems more cold/clinical/unemotional/to-the-point while the ""because"" has more emotion and  a broader set of reasons.  I don't know if this is just me though:


Why do you eat hamburgers? I eat hamburgers because I like hamburgers.  
Why do you eat hamburgers? I eat hamburgers because [I'm trying | I want | I need] to gain weight.  
Why do you eat hamburgers? I eat hamburgers in order to gain weight. 
Why are you eating hamburgers right now? Because their only $1 each.
Why are you eating hamburgers right now? In order to save money; they're only $1 each.
Why are you eating hamburgers right now? Because [I want | I need] to save money, and their only $1 each.
Why do you eat food? I eat food in order to live. Note how well ""in order to"" answers an abstract question.
Why do you eat food? I eat food because I need to eat food in order to live. Not a great answer. 
Why do you eat food? I eat food because if I don't, I will starve to death. Because is using the opposite sense to mean the same thing.
Why do you eat food? I eat food in order to avoid starving to death.  In order to sounds more awkward this way than the first line.   
Why do you eat food? I eat food because I get hungry.  Because is more simple here, based on base emotion or desire.
Why do you eat food? I eat food in order to satisfy my hunger.  In order to has to carefully consider the goal state.
Why do you watch James Bond movies? I watch James Bond movies because I like James Bond. 
Why do you watch movies? I watch movies in order to gain enjoyment.  In order to is more cold/passive way of describing things.  
Why do you watch movies? I watch movies because it's fun.
Why do you smoke? I smoke because I'm addicted to nicotine.
Why do you smoke? I smoke in order to satisfy my nicotine cravings.
Why are you trying to quit smoking?  I'm trying to quit smoking because smoking is bad for me.
What are you trying to quit smoking? I'm trying to quit smoking in order to get more healthy.

"
2044,2044,3258,What's the play event on a video html5 element?,"I have a video html5 tag embedded on page. I need to trigger an action when the user clicks the ""Play Button"". But I can't find how to bind that to my action. Is there an event for what I need? I'm using jQuery...

Thanks!
",Andres,https://stackoverflow.com/users/973242,"Does this W3C demo page help? http://www.w3.org/2010/05/video/mediaevents.html It appears the play event is simply 'play'.

For example:

$('video').bind('play', function (e) {
    // do something
});


or

$('video').on('play', function (e) {
    // do something
});

",Stephen Booher,https://stackoverflow.com/users/25295,http://stackoverflow.com/questions/12680432/whats-the-play-event-on-a-video-html5-element,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.0,1.0,What are the playback events for video HTML5 elements?,"I embedded a video HTML 5 tag on the page. When the user clicks the play button, I need to trigger an action. But I couldn't find a way to relate it to my behavior. Is there any activity I need? I'm using jQuery...","Does this W3C demo page help? http://www.w3.org/2010/05/video/mediaevents.html It appears the play event is simply 'play'.

For example:

$('video').bind('play', function (e) {
    // do something
});


or

$('video').on('play', function (e) {
    // do something
});

"
4208,4208,6708,Unable to Import Data,"I am following this tutorial,

but i am not able to get the right username and password to import data. How do I know what the username password is? By default I see tomcat6 as database and username and no password in the textbox. As i am following the tutorial I changed it to username: postgis and password: postgres.

How do I know what my username and password is?

EDIT

Import the data in PostGIS, which requires PostGIS connection.

UPDATE

Ok so i got the user and passwd but when I am trying to add the shapefile using the Shape File to PostGIS Importer Plugin and having made connection successfully, I am getting this error when I am adding the shapefile.

Connecting: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Connection succeeded.
Connection: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Destination: public.AllQuebecSpecies
Source File: /home/smaranh/development/Biodiversity/biodiversity/shapefile/AllQuebecSpecies
Shapefile type: Point
Postgis type: POINT[2]
Failed SQL begins: ""SET CLIENT_ENCODING TO UTF8;
SET STANDARD_CONFORMING_STRINGS TO ON;
BEGIN;
CREATE TABLE ""public"".""AllQuebecSpecies"" (gid serial PRIMARY KEY,
""family"" varchar(50),
""species"" varchar(50));
SELECT AddGeometryColumn('public','AllQuebecSpecies','the_geom','-1""
Failed in pgui_exec(): ERROR:  function addgeometrycolumn(unknown, unknown, unknown, unknown, unknown, integer) does not exist
LINE 7: SELECT AddGeometryColumn('public','AllQuebecSpecies','the_ge...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

Shapefile import failed.


Can somebody tell me where am I going wrong?
",Sam007,https://gis.stackexchange.com/users/4333,"Maybe you created a database without PostGIS extension. 
You should choose the PostGIS template on the 'Definition' tag when creating a new database.
",Ben,https://gis.stackexchange.com/users/21813,http://gis.stackexchange.com/questions/25437/unable-to-import-data,TECHNOLOGY,gis.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,1.0,1.0,Unable to import data,"I am following this tutorial,

but i am not able to get the right username and password to import data. How do I know what the username password is? By default I see tomcat6 as database and username and no password in the textbox. As i am following the tutorial I changed it to username: postgis and password: postgres.

How do I know what my username and password is?

EDIT

Import the data in PostGIS, which requires PostGIS connection.

UPDATE

Ok so i got the user and passwd but when I am trying to add the shapefile using the Shape File to PostGIS Importer Plugin and having made connection successfully, I am getting this error when I am adding the shapefile.

Connecting: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Connection succeeded.
Connection: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Destination: public.AllQuebecSpecies
Source File: /home/smaranh/development/Biodiversity/biodiversity/shapefile/AllQuebecSpecies
Shapefile type: Point
Postgis type: POINT[2]
Failed SQL begins: ""SET CLIENT_ENCODING TO UTF8;
SET STANDARD_CONFORMING_STRINGS TO ON;
BEGIN;
CREATE TABLE ""public"".""AllQuebecSpecies"" (gid serial PRIMARY KEY,
""family"" varchar(50),
""species"" varchar(50));
SELECT AddGeometryColumn('public','AllQuebecSpecies','the_geom','-1""
Failed in pgui_exec(): ERROR:  function addgeometrycolumn(unknown, unknown, unknown, unknown, unknown, integer) does not exist
LINE 7: SELECT AddGeometryColumn('public','AllQuebecSpecies','the_ge...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

Shapefile import failed.


Can somebody tell me where am I going wrong?
","Maybe you created a database without PostGIS extension. 
You should choose the PostGIS template on the 'Definition' tag when creating a new database.
"
263,263,426,Shalom alecha rebbi (u'mori),"What is the significance of the time it takes to say Shalom Alecha Rebbi (U'mori)?
",shlomo,https://judaism.stackexchange.com/users/107,"I once heard from my rabbi in high school that it was about 3 seconds. Not sure the source,  but it always made sense to me. Witnesses also must recite their identical testimony within that same timeframe. 
",Seth J,https://judaism.stackexchange.com/users/5,http://judaism.stackexchange.com/questions/955/shalom-alecha-rebbi-umori,CULTURE,judaism.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Shalom alecha rebbi,What's the point of saying the time of Shalom alecha rebbi (u'mori)?,"When I was in high school, I heard from my rabbi that it was about three seconds. Not sure about the source, but it always makes sense to me. Witnesses must also recite the same testimony at the same time."
133,133,213,"Huffy Cranbrook 26"" Ladies' Cruiser crank / pedal / chain ""pop"" sound...?","Before you say it's a cheap bike, what more do you want... I get that! :D
But it's brand new, and as you pedal it... no matter the speed, you get a pop sound at a specific point on each rotation...

What could / should I do to help silence this sound and make the ride more enjoyable.

Please advise if you can!

VIDEO UPDATE:
I uploaded this video of the happenings ;)


                
            
",Joshua F. Rountree,https://bicycles.stackexchange.com/users/4032,"My guess is that the chain is too tight. You say it is only at a specific spot in the rotation which leads me to believe your chainring being slightly off center (I have not found one 100% perfect) is causing the popping. 

Flip the bike on it's back and spin the cranks slowly. If it is a freewheel pedal, it backwards since this will not engage the sprocket. If it is a coaster, you will have to pedal it forwards. If you notice the chain get really tight then loose as you do this, adjust your chain. Find the same spot the pedals are at where it gets the tightest and loosen then tighten the rear wheel with the cranks in the same spot so that the tightest it will get is where you just set it.

If the chain tension was not the problem, you might need to check the bearings. Huffys almost never have sealed bearings and they can be over under tightened, either being a problem.
",BillyNair,https://bicycles.stackexchange.com/users/3949,http://bicycles.stackexchange.com/questions/9307/huffy-cranbrook-26-ladies-cruiser-crank-pedal-chain-pop-sound,CULTURE,bicycles.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,"Hafi Cranbrook 26 ""women's cruiser crank / pedal / chain"" Bang...?","Before you say it's a cheap bike, what more do you want... I get that! :D
But it's brand new, and as you pedal it... no matter the speed, you get a pop sound at a specific point on each rotation...

What could / should I do to help silence this sound and make the ride more enjoyable.

Please advise if you can!

VIDEO UPDATE:
I uploaded this video of the happenings ;)


                
            
","My guess is that the chain is too tight. You say it is only at a specific spot in the rotation which leads me to believe your chainring being slightly off center (I have not found one 100% perfect) is causing the popping. 

Flip the bike on it's back and spin the cranks slowly. If it is a freewheel pedal, it backwards since this will not engage the sprocket. If it is a coaster, you will have to pedal it forwards. If you notice the chain get really tight then loose as you do this, adjust your chain. Find the same spot the pedals are at where it gets the tightest and loosen then tighten the rear wheel with the cranks in the same spot so that the tightest it will get is where you just set it.

If the chain tension was not the problem, you might need to check the bearings. Huffys almost never have sealed bearings and they can be over under tightened, either being a problem.
"
5229,5229,8311,"Meaning of 'on' in ""We feasted that evening as 'on' nectar and ambrosia""","
  âI meant to give each of you some of this to take with you,â said she,
  âbut as there is so little toast, you must have it now,â and she
  proceeded to cut slices with a generous hand. We feasted that evening
  as on nectar and ambrosia; and not the least delight of the
  entertainment was the smile of gratification with which our hostess
  regarded us, as we satisfied our famished appetites on the delicate
  fare she liberally supplied. (Jane Eyre)


Whatâs the meaning of âonâ?
",Listenever,https://ell.stackexchange.com/users/504,"I think the key word here is as, actually.  The word as lets you know that it's a simile; the word on is just the preposition in the phrase ""feast on [something]"".

It means the same thing as if these words were inserted:


  We feasted [on the food we had] that evening as [we would] on nectar and ambrosia [...]

",snailplane,https://ell.stackexchange.com/users/230,http://ell.stackexchange.com/questions/3393/meaning-of-on-in-we-feasted-that-evening-as-on-nectar-and-ambrosia,CULTURE,ell.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,"""We took 'on' as' on 'nectar and Ambrosia that night""","
  âI meant to give each of you some of this to take with you,â said she,
  âbut as there is so little toast, you must have it now,â and she
  proceeded to cut slices with a generous hand. We feasted that evening
  as on nectar and ambrosia; and not the least delight of the
  entertainment was the smile of gratification with which our hostess
  regarded us, as we satisfied our famished appetites on the delicate
  fare she liberally supplied. (Jane Eyre)


Whatâs the meaning of âonâ?
","I think the key word here is as, actually.  The word as lets you know that it's a simile; the word on is just the preposition in the phrase ""feast on [something]"".

It means the same thing as if these words were inserted:


  We feasted [on the food we had] that evening as [we would] on nectar and ambrosia [...]

"
2740,2740,4369,Remove all files in directory except last 20,"I have question why is my cmd for ""removing all files in directory except last 20"" not working within cron but in command prompt yes.

* * * * *  ls -1tr /home/testusr/test | head -n -20 | xargs -d '\n' rm -f  &gt; /var/opt/check.log 2&gt;&amp;1


Directory contains let say 100x files which are named DATA-20140605xxxx generated minute by minute.

Thank advance for any answer.
",George_223907,https://serverfault.com/users/223907,"The problem you are having is caused because the output of your ls command doesn't contain the path to the file it only contains the filename. When a cron job runs, it runs in the users home directory so when your rm is run, it is looking for files in /home/testuser not /home/testuser/test.

You could fix this with a simple cd command

cd /home/testuser/test &amp;&amp; ls -1tr /home/testusr/test ...


This however isn't great as you are parsing the output of ls which is a Bad IdeaTM see the link for extensive discussion.
",Iain,https://serverfault.com/users/9517,http://serverfault.com/questions/601986,TECHNOLOGY,serverfault.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,Delete all but the last 20 files in the directory,"I have question why is my cmd for ""removing all files in directory except last 20"" not working within cron but in command prompt yes.

* * * * *  ls -1tr /home/testusr/test | head -n -20 | xargs -d '\n' rm -f  &gt; /var/opt/check.log 2&gt;&amp;1


Directory contains let say 100x files which are named DATA-20140605xxxx generated minute by minute.

Thank advance for any answer.
","The problem you are having is caused because the output of your ls command doesn't contain the path to the file it only contains the filename. When a cron job runs, it runs in the users home directory so when your rm is run, it is looking for files in /home/testuser not /home/testuser/test.

You could fix this with a simple cd command

cd /home/testuser/test &amp;&amp; ls -1tr /home/testusr/test ...


This however isn't great as you are parsing the output of ls which is a Bad IdeaTM see the link for extensive discussion.
"
5991,5991,9498,Is my interval training routine effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
",DigiKev,https://bicycles.stackexchange.com/users/3323,"I think there are several issues with your approach for improving power on bike:


doing the same workout stresses the same aerobic pathway, since there are several ways your body can burn fuel it is worth exercising all of them. This means doing intervals of different length with different rest periods. Example: 3x(12+6) min on and off. The on part is similar to what you can do for 1 hour and the off part is half of that. Another example: 3x(3+3) min on and off where the on part is what you can do for 5 minutes, off part is half of that.
the intervals do not seem to be anaerobic, because of the short recovery period( anaerobic intervals need longer recovery periods ). They are either Vo2Max intervals or Threshold. If they are Vo2Max I think the workout is too hard, usually accumulating 6 to 9 minutes at Vo2Max in a training session is too much, if they are threshold I don't think the approach is very good, better go with a longer interval period since threshold power can be usually sustained by riders for 30 to 60 minutes.
if you want to endure in long events/rides you need to do longer sessions to have the endurance
heart rate on an indoor trainer seems to be artificially high for me, I think it is because of the poor ventilation. Also power on the trainer is much lower then going outside, so pacing with heart rate on an indoor trainer seems to be a bad idea at least this is my experience. Suppose your 170bpm is upper tempo power, on an  indoor trainer that might be actually upper endurance because of the artificial high heart rate.
for effective mountain biking you also need riding skills, these are not developed on a trainer.


I would try to look at the requirements of your specific events and target those, also try to do longer sessions on the trail to build the endurance needed to complete this events.

An alternate way is to get a generic mountain biking endurance plan and build on that, it won't be perfect but I think is much superior over what you have now.

Also, try to ride outside if possible, the workouts are better and you will enjoy the training much more.
",Bogdan Petrica,https://bicycles.stackexchange.com/users/7327,http://bicycles.stackexchange.com/questions/7801/is-my-interval-training-routine-effective-for-mountain-bike-training,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,Is my interval training effective for mountain bike training?,"During these winter months I am currently attending the gym 3 times a week. On each of the days I start my training on an exercise bike with the following:


5 minute warm up
30 minutes, 1 minute hard, 1 minute recovery
5 minute warm down


I am using a specific interval training setting on the bike. I preset the training to level 15, which is a high resistance and as much as I can take.

Hard is a cadence of between 80-90rpm high resistance. Recovery is a cadence of 60prm and the resistance backs off considerably, I imagine to approximately level 7.

My heart rate towards the end of the session reaches 170â190bpm, and I am working flat-out. I turn 30 in March, am 5' 8"" and weigh approx 168lbs.

Does this training routine seem sensible for building strength and speed on the mountain? Should I be changing up the training with other types of bike training?

It is also worth noting that after the interval training I perform free weight strength training too.
","I think there are several issues with your approach for improving power on bike:


doing the same workout stresses the same aerobic pathway, since there are several ways your body can burn fuel it is worth exercising all of them. This means doing intervals of different length with different rest periods. Example: 3x(12+6) min on and off. The on part is similar to what you can do for 1 hour and the off part is half of that. Another example: 3x(3+3) min on and off where the on part is what you can do for 5 minutes, off part is half of that.
the intervals do not seem to be anaerobic, because of the short recovery period( anaerobic intervals need longer recovery periods ). They are either Vo2Max intervals or Threshold. If they are Vo2Max I think the workout is too hard, usually accumulating 6 to 9 minutes at Vo2Max in a training session is too much, if they are threshold I don't think the approach is very good, better go with a longer interval period since threshold power can be usually sustained by riders for 30 to 60 minutes.
if you want to endure in long events/rides you need to do longer sessions to have the endurance
heart rate on an indoor trainer seems to be artificially high for me, I think it is because of the poor ventilation. Also power on the trainer is much lower then going outside, so pacing with heart rate on an indoor trainer seems to be a bad idea at least this is my experience. Suppose your 170bpm is upper tempo power, on an  indoor trainer that might be actually upper endurance because of the artificial high heart rate.
for effective mountain biking you also need riding skills, these are not developed on a trainer.


I would try to look at the requirements of your specific events and target those, also try to do longer sessions on the trail to build the endurance needed to complete this events.

An alternate way is to get a generic mountain biking endurance plan and build on that, it won't be perfect but I think is much superior over what you have now.

Also, try to ride outside if possible, the workouts are better and you will enjoy the training much more.
"
2490,2490,3971,Water : Aquatic :: Sand : xxx?,"Just as aquatic is to water and aerial is to air, what is an equivalent word for sand (or earth, I suppose)?

For context, Iâm trying to describe the locomotion of worms within desert sand (as opposed to its surface). Ergo, terrestrial isnât particularly suitable and neither is earthy.
",coleopterist,https://english.stackexchange.com/users/23608,"Well, fancy words for âsandyâ are arenarious and arenaceous, with the second apparently preferred.   Perhaps one of those two will do.

You can also use arenaceo- as a combining form.  Darwin did, when he wrote of arenaceo-calcareous loam.



Edit

Oh wait, there is one for just what you want here.  From the OED:


  arenicolous /-ÉlÉs/, a. 
  
  Etymology: f. as prec. + -ous.
  
  Inhabiting sand. 
  
  
  1851-9 Owen in Man. Sc. Enq. 381 â Arenicolous mollusks.
  


The preceding entry referenced above is:


  arenicolite /Ã¦rÉªËnÉªkÉlaÉªt/. 
  
  Etymology: f. mod.L. arÄnicol-a sand-worm, lob-worm (f. arÄna sand + âcola inhabiting) + âite.
  
  A worm-hole made originally in sand, and preserved in a sandstone rock. 
  
  1864 in Webster.


Once you remember that Latin had arena for sand (as do Spanish, Italian, Catalan, Portuguese, and various others), the rest is easy: just look for words that start with arena- or areni-, of which we have a fair number.  As another example, arenosity is sandiness.

I also looked for things related to Latin sabulum for gravel, modern French sable for sand, but it was not productive, as all our English uses of sable are related to the furry critter, to black,  or to heraldry.   We have no sabl- words related to sand.
",tchrist,https://english.stackexchange.com/users/2085,http://english.stackexchange.com/questions/93891/water-aquatic-sand-xxx,CULTURE,english.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,1.0,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Water: water: Sand: XXX?,"Just as aquatic is to water and aerial is to air, what is an equivalent word for sand (or earth, I suppose)?

For context, Iâm trying to describe the locomotion of worms within desert sand (as opposed to its surface). Ergo, terrestrial isnât particularly suitable and neither is earthy.
","Well, fancy words for âsandyâ are arenarious and arenaceous, with the second apparently preferred.   Perhaps one of those two will do.

You can also use arenaceo- as a combining form.  Darwin did, when he wrote of arenaceo-calcareous loam.



Edit

Oh wait, there is one for just what you want here.  From the OED:


  arenicolous /-ÉlÉs/, a. 
  
  Etymology: f. as prec. + -ous.
  
  Inhabiting sand. 
  
  
  1851-9 Owen in Man. Sc. Enq. 381 â Arenicolous mollusks.
  


The preceding entry referenced above is:


  arenicolite /Ã¦rÉªËnÉªkÉlaÉªt/. 
  
  Etymology: f. mod.L. arÄnicol-a sand-worm, lob-worm (f. arÄna sand + âcola inhabiting) + âite.
  
  A worm-hole made originally in sand, and preserved in a sandstone rock. 
  
  1864 in Webster.


Once you remember that Latin had arena for sand (as do Spanish, Italian, Catalan, Portuguese, and various others), the rest is easy: just look for words that start with arena- or areni-, of which we have a fair number.  As another example, arenosity is sandiness.

I also looked for things related to Latin sabulum for gravel, modern French sable for sand, but it was not productive, as all our English uses of sable are related to the furry critter, to black,  or to heraldry.   We have no sabl- words related to sand.
"
200,200,321,Are there any disadvantages to encrypting the password hash?,"Is encrypting the password hash in database more secure than storing only the hash?

Suppose we store encrypted SHA-256 result with AES instead of hash directly. Is this a good protection from a situation in the future when someone will break one of the algorithms?
",Piotr MÃ¼ller,https://security.stackexchange.com/users/61366,"First of all, every stored password should be hashed with a different pseudo-random salt.  Second, SHA-256 is not appropriate for storing passwords; instead, you want to use a key stretching algorithm, as has already been mentioned.  There is a lot more detail at Crackstation.

An encrypted hash is also called a keyed hash, and the key is sometimes called a ""pepper.""  There need not be a separate encryption step.  Instead, the secret key is part of the input to the hash function.  That can improve security somewhat.  There are two ways attackers can get a copy of your password hashes.  One is to compromise the storage mechanism, as with SQL injection.  In that case, a keyed hash can make it effectively impossible to retrieve plaintext passwords from the hashes because the key can be compiled in to a program or otherwise kept outside the password storage mechanism.  The other way is to compromise the OS itself.  In that case, the key is compromised, and is no longer an impediment against attempts to attack the passwords.

So, the short answer is yes, but you have to do the underlying work right, first.
",Bob Brown,https://security.stackexchange.com/users/52741,http://security.stackexchange.com/questions/73586/are-there-any-disadvantages-to-encrypting-the-password-hash,TECHNOLOGY,security.stackexchange.com,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.6666666666666666,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,1.0,What are the disadvantages of encrypted password hash?,"Is encrypting the password hash in database more secure than storing only the hash?

Suppose we store encrypted SHA-256 result with AES instead of hash directly. Is this a good protection from a situation in the future when someone will break one of the algorithms?
","First of all, every stored password should be hashed with a different pseudo-random salt.  Second, SHA-256 is not appropriate for storing passwords; instead, you want to use a key stretching algorithm, as has already been mentioned.  There is a lot more detail at Crackstation.

An encrypted hash is also called a keyed hash, and the key is sometimes called a ""pepper.""  There need not be a separate encryption step.  Instead, the secret key is part of the input to the hash function.  That can improve security somewhat.  There are two ways attackers can get a copy of your password hashes.  One is to compromise the storage mechanism, as with SQL injection.  In that case, a keyed hash can make it effectively impossible to retrieve plaintext passwords from the hashes because the key can be compiled in to a program or otherwise kept outside the password storage mechanism.  The other way is to compromise the OS itself.  In that case, the key is compromised, and is no longer an impediment against attempts to attack the passwords.

So, the short answer is yes, but you have to do the underlying work right, first.
"
705,705,1115,Tooltip pointer in ParametricPlots,"ParametricPlot[{ Cos[u]^v , u}, {v, 0, 1}, {u, 0, Pi/2 }, Mesh -&gt; {5, 5}]

ParametricPlot[Tootip[{ Cos[u]^v , u}, {v, 0, 1}], {u, 0, Pi/2 }]


How to introduce Tooltip pointers?

( ParametricPlot3D Tooltip may not be available yet? ).

EDIT1:

Updating my question. Please ignore everything above the EDIT1: 

ParametricPlot[ { u Cos[v], u Sin[v]}, {u, 1, 2}, {v, 0, Pi/2}, 
 Mesh -&gt; {3, 5}]


It is a two parameter plot. So I like to see either of $ u,v $ parameter lines being pointed at with the value of the set constant only.

To make clear with an example, when I mouse over circles, like to see Tooltips in the above ParametricPlot pointing with SINGLE values {$ 1,1.25,1.5,1.75,2 $} and also when mousing over radial lines  SINGLE {$ 0, \pi/12, 2 \pi/12,...5 \pi/12, \pi/2 $ }  for the radial lines.

It is a very simple requirement that I believe could cater to a common requirement of a majority of users. I am not looking at high frequency sophisticated dynamic motion picture display. Not even looking at double parameter display at intersection/junction  of parameter lines. Just like the way height is displayed for ContourPlots. Here it is required for both parameters, with or without Shading. 

Asked this because it is not (yet) a standard feature.

EDIT2:

Based on Michael E2's lines, tried to depict eccentric circles.In the space  between parameter lines it may need to be somewhat changed.

{umin, umax, ustep, vmin, vmax, vstep} = {0, 2 Pi, Pi/8, 0.25, 1.25, .25};
ParametricPlot[{Sqrt[2 + v^2] + v Cos[u], v Sin[u]}, {u, umin,  umax}, {v, vmin, vmax}, Mesh -&gt; {Table[{u, Tooltip[Null, u]}, {u, umin, umax, ustep}], 
    Table[{v, Tooltip[Null, v]}, {v, vmin, vmax, vstep}]}] /. {g___, 
   Tooltip[_, label_], l_Line} :&gt; {g, Tooltip[l, label]}

",Narasimham,https://mathematica.stackexchange.com/users/19067,"Add a dummy graphic to each mesh line with the appropriate tooltip label and combine them via post-processing:

ParametricPlot[{u Cos[v], u Sin[v]}, {u, 1, 2}, {v, 0, Pi/2},
  Mesh -&gt; {
    Table[{u, Tooltip[Null, u]}, {u, 1, 2, 0.25}],
    Table[{v, Tooltip[Null, v]}, {v, 0, Pi/2, Pi/12}]}
  ] /. {g___, Tooltip[_, label_], l__Line} :&gt; {g, Tooltip[{l}, label]}


Update notice: The pattern was changed from l_Line to l__Line to handle multiple instances of Line in a mesh line, as pointed out by Mr.Wizard in a comment, along with a change in the Tooltip code to handle the sequence l.
",Michael E2,https://mathematica.stackexchange.com/users/4999,http://mathematica.stackexchange.com/questions/79095/tooltip-pointer-in-parametricplots,TECHNOLOGY,mathematica.stackexchange.com,0.5555555555555556,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,Tooltip pointer in parameter diagram,"ParametricPlot[{ Cos[u]^v , u}, {v, 0, 1}, {u, 0, Pi/2 }, Mesh -&gt; {5, 5}]

ParametricPlot[Tootip[{ Cos[u]^v , u}, {v, 0, 1}], {u, 0, Pi/2 }]


How to introduce Tooltip pointers?

( ParametricPlot3D Tooltip may not be available yet? ).

EDIT1:

Updating my question. Please ignore everything above the EDIT1: 

ParametricPlot[ { u Cos[v], u Sin[v]}, {u, 1, 2}, {v, 0, Pi/2}, 
 Mesh -&gt; {3, 5}]


It is a two parameter plot. So I like to see either of $ u,v $ parameter lines being pointed at with the value of the set constant only.

To make clear with an example, when I mouse over circles, like to see Tooltips in the above ParametricPlot pointing with SINGLE values {$ 1,1.25,1.5,1.75,2 $} and also when mousing over radial lines  SINGLE {$ 0, \pi/12, 2 \pi/12,...5 \pi/12, \pi/2 $ }  for the radial lines.

It is a very simple requirement that I believe could cater to a common requirement of a majority of users. I am not looking at high frequency sophisticated dynamic motion picture display. Not even looking at double parameter display at intersection/junction  of parameter lines. Just like the way height is displayed for ContourPlots. Here it is required for both parameters, with or without Shading. 

Asked this because it is not (yet) a standard feature.

EDIT2:

Based on Michael E2's lines, tried to depict eccentric circles.In the space  between parameter lines it may need to be somewhat changed.

{umin, umax, ustep, vmin, vmax, vstep} = {0, 2 Pi, Pi/8, 0.25, 1.25, .25};
ParametricPlot[{Sqrt[2 + v^2] + v Cos[u], v Sin[u]}, {u, umin,  umax}, {v, vmin, vmax}, Mesh -&gt; {Table[{u, Tooltip[Null, u]}, {u, umin, umax, ustep}], 
    Table[{v, Tooltip[Null, v]}, {v, vmin, vmax, vstep}]}] /. {g___, 
   Tooltip[_, label_], l_Line} :&gt; {g, Tooltip[l, label]}

","Add a dummy graphic to each mesh line with the appropriate tooltip label and combine them via post-processing:

ParametricPlot[{u Cos[v], u Sin[v]}, {u, 1, 2}, {v, 0, Pi/2},
  Mesh -&gt; {
    Table[{u, Tooltip[Null, u]}, {u, 1, 2, 0.25}],
    Table[{v, Tooltip[Null, v]}, {v, 0, Pi/2, Pi/12}]}
  ] /. {g___, Tooltip[_, label_], l__Line} :&gt; {g, Tooltip[{l}, label]}


Update notice: The pattern was changed from l_Line to l__Line to handle multiple instances of Line in a mesh line, as pointed out by Mr.Wizard in a comment, along with a change in the Tooltip code to handle the sequence l.
"
1477,1477,2323,"What to call ""Cancel"" when ""Cancel"" is already the default action?","When attempting to cancel a service or setting, ""cancel"" is the default action. What should the normal ""cancel"" button be called?

Redbox uses a playful ""just kidding"", which may not be appropriate in all circumstances.


",Luke Charde,https://ux.stackexchange.com/users/5022,"My suggestion: never use the word ""Cancel"" in the default action.

To cancel a subscription, you can, for example, say ""Remove Subscription"" or ""Unsubscribe.""

To cancel a download, you can, for example, say ""Stop Downloading"".

To cancel a setting, you can, for example, say ""Revert Settings"".
",Heng-Cheong Leong,https://ux.stackexchange.com/users/630,http://ux.stackexchange.com/questions/35753/what-to-call-cancel-when-cancel-is-already-the-default-action,TECHNOLOGY,ux.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,"When cancel is already the default operation, what is the name of cancel?","Cancel is the default action when attempting to cancel a service or setting. What should a normal ""Cancel"" button be called?","My suggestion: never use the word ""Cancel"" in the default action.

To cancel a subscription, you can, for example, say ""Remove Subscription"" or ""Unsubscribe.""

To cancel a download, you can, for example, say ""Stop Downloading"".

To cancel a setting, you can, for example, say ""Revert Settings"".
"
2448,2448,3907,Two different analytic curves cannot intersect in infinitely many points,"A curve in Euclidean space $\mathbb{R}^n$, $n \geq 2$ is $analytic$ if the coordinates of its points $x= x_{1},...,x_{n}$ can be expressed as analytic functions of a real parameter $x_{i}=x_{i}(t)$, $i=1,...,n$ and $\alpha \leq t \leq \beta$ and the derivatives $x'(t_{0})$ do not simultaneously vanish for any $t_{0} \in [\alpha, \beta]$.
I search for a proof of the following fact:

If the set of intersection points of two analytic curves is infinite, then these curves coincide.

Can we prove the same as above if we relax the condition that the coordinates are analytic to the condition that the coordinates belong to the class $C^{\infty}$?

Edit: Thanks to below remark by Ramiro, to obtain the above implication, we have to assume that any two curves $K_{1}, K_{2}$ as in the question are such that $K_{1} \cap K_{2}$ is not another analytic curve.

2nd edit: As suggested Peter, we can reformulate our question as follows:
   Consider two immersed curves which are parameterized real analytically on compact intervals. If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
",Grzegorz Tomkowicz,https://mathoverflow.net/users/31376,"Wrong: $t\mapsto \binom{t}{\sin(t)}$ and $t\mapsto\binom{t}{\cos(t)}$.

Edit: Grzegorz pointed out that $t$ is in a compact interval $[\alpha,\beta]$.
Under this assumption the statement is correct.

Proof: Let $f,g:[\alpha,\beta]\to \mathbb R^n$ be the two real analytically parameterized curves which intersect in $f(t_i)=g(t_i), i=1,2,\dots$ different points. Then the $t_i$ have accumulation points in $[\alpha,\beta]$, thus $f$ and $g$ coincide on $[\alpha,\beta]$.

In the $C^\infty$ case the statement is wrong: Let $[\alpha,\beta]=[0,1]$ and consider
$$f(t) = \binom{t}{e^{-1/t^2}\sin(1/t)},\qquad g(t)=\binom{t}{0}.$$

2nd edit: Noam pointed out that my proof above was not conclusive. 
So let me try again: Suppose that $f(t_i)=g(u_i)$ for sequences of distinct points.
The $t_i$ have accumulation an point $t$ and the $u_i$ have an accumulation point $u$.
By continuity, $x=f(t)=g(u)$. Now we change both parameterizations as follows:
Choose a line $r\mapsto x + r.v$ for a vector $v$ such that both curves are transversal to the hyperplane $v^\bot$. Since both curves are immersions (if I understood the question right),
such $v$ exists. Now consider the orthogonal projection of both curves onto this line. In a neighborhood of $r=0$ these are real analytic diffeomorphisms, so their inverses gives us new parameterizations of both curves in the parameter $r$. There are still infinitely many intersection points of the two curves near $x$, but these intersections happen now at the same 
parameter values $r_i$ with $r_i\to 0$ without loss. Now my proof from above applies. 

I hope that I did not overlook something else this time. Many thanks for pointing out my mistakes. 

3rd edit: I overlooked again something (Thanks SJR and Ramiro). So what I proved is:
The intersection of the two curves contains an open interval in each curve. Note that each curve, as an immersion, is locally a real analytic submanifold.  

4th edit: Grzegorz, to the new question you posed in the comment, the following comes to my mind:
By a theorem of Whitney, any closed set in $\mathbb R^n$ is the zero locus of a smooth function. So take a set in $\mathbb R$ like the Cantor set which in uncountable, and a smooth function on $\mathbb R$ vanishing exactly on this set. The graph of this function and the $x$-axis are two $C^\infty$-curves which intersect in this set.

What do mean by: $K_1\cap K_2$ is not $C^\infty$?

5th edit: Grzegorz, instead of excluding Ramiro's example in your edit of the question,
you could reformulate as follows:

Consider two  immersed curves which are parameterized real analytically on compact intervals.
If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
",Peter Michor,https://mathoverflow.net/users/26935,http://mathoverflow.net/questions/121602,SCIENCE,mathoverflow.net,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,1.0,0.5,0.8888888888888888,1.0,0.6,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,Two different analytic curves cannot intersect at infinity,"A curve in Euclidean space $\mathbb{R}^n$, $n \geq 2$ is $analytic$ if the coordinates of its points $x= x_{1},...,x_{n}$ can be expressed as analytic functions of a real parameter $x_{i}=x_{i}(t)$, $i=1,...,n$ and $\alpha \leq t \leq \beta$ and the derivatives $x'(t_{0})$ do not simultaneously vanish for any $t_{0} \in [\alpha, \beta]$.
I search for a proof of the following fact:

If the set of intersection points of two analytic curves is infinite, then these curves coincide.

Can we prove the same as above if we relax the condition that the coordinates are analytic to the condition that the coordinates belong to the class $C^{\infty}$?

Edit: Thanks to below remark by Ramiro, to obtain the above implication, we have to assume that any two curves $K_{1}, K_{2}$ as in the question are such that $K_{1} \cap K_{2}$ is not another analytic curve.

2nd edit: As suggested Peter, we can reformulate our question as follows:
   Consider two immersed curves which are parameterized real analytically on compact intervals. If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
","Wrong: $t\mapsto \binom{t}{\sin(t)}$ and $t\mapsto\binom{t}{\cos(t)}$.

Edit: Grzegorz pointed out that $t$ is in a compact interval $[\alpha,\beta]$.
Under this assumption the statement is correct.

Proof: Let $f,g:[\alpha,\beta]\to \mathbb R^n$ be the two real analytically parameterized curves which intersect in $f(t_i)=g(t_i), i=1,2,\dots$ different points. Then the $t_i$ have accumulation points in $[\alpha,\beta]$, thus $f$ and $g$ coincide on $[\alpha,\beta]$.

In the $C^\infty$ case the statement is wrong: Let $[\alpha,\beta]=[0,1]$ and consider
$$f(t) = \binom{t}{e^{-1/t^2}\sin(1/t)},\qquad g(t)=\binom{t}{0}.$$

2nd edit: Noam pointed out that my proof above was not conclusive. 
So let me try again: Suppose that $f(t_i)=g(u_i)$ for sequences of distinct points.
The $t_i$ have accumulation an point $t$ and the $u_i$ have an accumulation point $u$.
By continuity, $x=f(t)=g(u)$. Now we change both parameterizations as follows:
Choose a line $r\mapsto x + r.v$ for a vector $v$ such that both curves are transversal to the hyperplane $v^\bot$. Since both curves are immersions (if I understood the question right),
such $v$ exists. Now consider the orthogonal projection of both curves onto this line. In a neighborhood of $r=0$ these are real analytic diffeomorphisms, so their inverses gives us new parameterizations of both curves in the parameter $r$. There are still infinitely many intersection points of the two curves near $x$, but these intersections happen now at the same 
parameter values $r_i$ with $r_i\to 0$ without loss. Now my proof from above applies. 

I hope that I did not overlook something else this time. Many thanks for pointing out my mistakes. 

3rd edit: I overlooked again something (Thanks SJR and Ramiro). So what I proved is:
The intersection of the two curves contains an open interval in each curve. Note that each curve, as an immersion, is locally a real analytic submanifold.  

4th edit: Grzegorz, to the new question you posed in the comment, the following comes to my mind:
By a theorem of Whitney, any closed set in $\mathbb R^n$ is the zero locus of a smooth function. So take a set in $\mathbb R$ like the Cantor set which in uncountable, and a smooth function on $\mathbb R$ vanishing exactly on this set. The graph of this function and the $x$-axis are two $C^\infty$-curves which intersect in this set.

What do mean by: $K_1\cap K_2$ is not $C^\infty$?

5th edit: Grzegorz, instead of excluding Ramiro's example in your edit of the question,
you could reformulate as follows:

Consider two  immersed curves which are parameterized real analytically on compact intervals.
If they have an infinite number of different intersection points, then their union is again a real analytic immersed curve. 
"
1106,1106,1741,Drywall - final joint compound coat,"While remodeling an older house (where nothing is quite straight) we used fiber glass mesh joint tape and 3 coats of joint compound. The first coat was applied with a 4 inch knife, the second with an 8 inch and ending the third on a 12 inch knife. I can still see the texture from the mesh tape I used on some of the joints.

I hoped that a coat of primer would level it off, but after using Kilz 2 primer I can still see the tape in some spots. :(

Sanding through the primer now proves difficult (doesn't work) with a medium grit sanding block.

Should I add another coat? I could never quite get the joint compound to adhere over the mesh tape. I've always been taught to go as thin as I can on the joint compound to reduce the sanding part. Did I go too thin? 

I'm hoping a second coat of primer and 2 coats of the final latex paint hides it, but I know this isn't the right answer. How can I fix this?



following what doresoom and shirlock said; i just applied a coat with the 12 inch knife practically against the wall (accidentally touching the wall with the handle once or twice) - more or less dragging the compound across the surface

this produced the result explained - about 1/32nd ? thickness of mud, covering the tape that i'll need to feather round the edges

i miss spoke earlier - i was using a sponge sanding block (not strait paper sand paper)

now that the primer has dried (did it saturday) its not as bad as i thought it was, but this is the right way to do it (not covering it with paint)

just as a side, we've used sherwin williams paint throughout the house and although its great paint (IMO) the plaster and lath walls that remain, even those repairs show through - and if those do, than this new work will... may as well do finish it right...

thanks for the help guys - i'll check this coat tomorrow and give a last one with the soap and water if it needs it.
",lsiunsuex,https://diy.stackexchange.com/users/1154,"Mistake #1. Never use mesh tape with pre mixed joint compound. Mesh tape is for setting type (powder mix) compound. Also never use paper tape with setting type compound.

Mistake #2. Bubble problem. Always make sure that you have a BLEED OUT when you set the paper tape. Bleed out = when you're pushing the tape into the compound make sure you see excess compound squeezing out on sides of the 4"" knife. If you don't, then you don't have enough compound on the wall. Pull the tape and do it again.
",Mark Steele,https://diy.stackexchange.com/users/31586,http://diy.stackexchange.com/questions/6985/drywall-final-joint-compound-coat,LIFE_ARTS,diy.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.7777777777777778,Dry wall - final joint composite coating,"While remodeling an older house (where nothing is quite straight) we used fiber glass mesh joint tape and 3 coats of joint compound. The first coat was applied with a 4 inch knife, the second with an 8 inch and ending the third on a 12 inch knife. I can still see the texture from the mesh tape I used on some of the joints.

I hoped that a coat of primer would level it off, but after using Kilz 2 primer I can still see the tape in some spots. :(

Sanding through the primer now proves difficult (doesn't work) with a medium grit sanding block.

Should I add another coat? I could never quite get the joint compound to adhere over the mesh tape. I've always been taught to go as thin as I can on the joint compound to reduce the sanding part. Did I go too thin? 

I'm hoping a second coat of primer and 2 coats of the final latex paint hides it, but I know this isn't the right answer. How can I fix this?



following what doresoom and shirlock said; i just applied a coat with the 12 inch knife practically against the wall (accidentally touching the wall with the handle once or twice) - more or less dragging the compound across the surface

this produced the result explained - about 1/32nd ? thickness of mud, covering the tape that i'll need to feather round the edges

i miss spoke earlier - i was using a sponge sanding block (not strait paper sand paper)

now that the primer has dried (did it saturday) its not as bad as i thought it was, but this is the right way to do it (not covering it with paint)

just as a side, we've used sherwin williams paint throughout the house and although its great paint (IMO) the plaster and lath walls that remain, even those repairs show through - and if those do, than this new work will... may as well do finish it right...

thanks for the help guys - i'll check this coat tomorrow and give a last one with the soap and water if it needs it.
","Mistake #1. Never use mesh tape with pre mixed joint compound. Mesh tape is for setting type (powder mix) compound. Also never use paper tape with setting type compound.

Mistake #2. Bubble problem. Always make sure that you have a BLEED OUT when you set the paper tape. Bleed out = when you're pushing the tape into the compound make sure you see excess compound squeezing out on sides of the 4"" knife. If you don't, then you don't have enough compound on the wall. Pull the tape and do it again.
"
2848,2848,4531,Is my session-less authentication system secure?,"So, I've created an authentication system. Poured over it for any kind of security flaws and tested the crap out of it. I think it's fairly secure, but there is one ""different"" by-design aspect of it that's not usual of a web authentication system. 

Basically, I wanted to make it so that authentication could be done without keeping track of each user's session. This means less load on the database, and trivial to scale and cache. Here are the ""secrets"" kept by the server:


A private-key is kept in the source code of the application
A randomly generated salt is kept for each user


To make it sessionless, but making forging cookies not easy, this is the format of my cookies

expires=expiretimestamp
secret=hash(privatekey + otherinfo + username + hashedpassword + expires)
username=username


(with otherinfo being things like IP address, browser info, etc and with hashedpassword=hash(username + salt + password + privatekey) 

My understanding is that forging login cookies (not cracking the passwords) requires:


Source code access to the application, or a way to trick it to spit out the private key
Read-only access to the database to get the salt and hashedpassword


Whereas the traditional session method requires:


Write and read access to the database (to inject the session, or trick the web app into doing it for you)
Possibly source code access depending on how it works


Anyway, does this seem overly insecure to anyone? Are there any ways for me to improve on it and make it more secure(while keeping with the stateless/sessionless model)? Are there any existing authentication systems which use this stateless model? 

Also, the hashing method can be basically anything, ranging from SHA256 to Blowfish
",Earlz,https://security.stackexchange.com/users/1398,"This proposed system is a session handler used to maintain an authenticated state and your method of building session tokens is insecure.

For example,  using SQL Injection you can read most of the secret data from the database.  If you are using MySQL SQL Injection can be used to read files using the load_file() function which could be used to read the secret from a config file.

In general you should not reinvent the wheel when building a system.  I am sure your platform comes with a secure session handler because just about every web application will need one.

Session ID's should be purely random values and an entropy pool like /dev/urandom is an excellent choice.  Just because you are using the platform's session handler doesn't mean its configured properly.  I recommend reading the OWASP Session Management Cheat Sheet.
",rook,https://security.stackexchange.com/users/975,http://security.stackexchange.com/questions/24730/is-my-session-less-authentication-system-secure,TECHNOLOGY,security.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,1.0,Is my session free authentication system secure?,"So, I've created an authentication system. Poured over it for any kind of security flaws and tested the crap out of it. I think it's fairly secure, but there is one ""different"" by-design aspect of it that's not usual of a web authentication system. 

Basically, I wanted to make it so that authentication could be done without keeping track of each user's session. This means less load on the database, and trivial to scale and cache. Here are the ""secrets"" kept by the server:


A private-key is kept in the source code of the application
A randomly generated salt is kept for each user


To make it sessionless, but making forging cookies not easy, this is the format of my cookies

expires=expiretimestamp
secret=hash(privatekey + otherinfo + username + hashedpassword + expires)
username=username


(with otherinfo being things like IP address, browser info, etc and with hashedpassword=hash(username + salt + password + privatekey) 

My understanding is that forging login cookies (not cracking the passwords) requires:


Source code access to the application, or a way to trick it to spit out the private key
Read-only access to the database to get the salt and hashedpassword


Whereas the traditional session method requires:


Write and read access to the database (to inject the session, or trick the web app into doing it for you)
Possibly source code access depending on how it works


Anyway, does this seem overly insecure to anyone? Are there any ways for me to improve on it and make it more secure(while keeping with the stateless/sessionless model)? Are there any existing authentication systems which use this stateless model? 

Also, the hashing method can be basically anything, ranging from SHA256 to Blowfish
","This proposed system is a session handler used to maintain an authenticated state and your method of building session tokens is insecure.

For example,  using SQL Injection you can read most of the secret data from the database.  If you are using MySQL SQL Injection can be used to read files using the load_file() function which could be used to read the secret from a config file.

In general you should not reinvent the wheel when building a system.  I am sure your platform comes with a secure session handler because just about every web application will need one.

Session ID's should be purely random values and an entropy pool like /dev/urandom is an excellent choice.  Just because you are using the platform's session handler doesn't mean its configured properly.  I recommend reading the OWASP Session Management Cheat Sheet.
"
4909,4909,7813,"Relationship field - {count} of type, and {total_results} of type","I have a relationship field which contains a number of different pieces of content.

Each piece of content has a type property.

Is there anyway I can count the number of each of the types that is included in the relationship.

For example.  3 Product related items, and 2 Showcase related items.

I need to be able to get the {total_results} of each type. 

This is what I'm trying to do...

 {if ""{related:panel_type}"" == ""products""}

      {if ""{related:count}"" == ""1""}
        &lt;ul class=""p""&gt;
      {/if}
        // do stuff 
      {if ""{related:count}"" == ""{related:total_results}""}
        &lt;/ul&gt;
      {/if}

    {/if}

  {if ""{related:panel_type}"" == ""showcase""}

      {if ""{related:count}"" == ""1""}
        &lt;ul class=""s""&gt;
      {/if}
        // do stuff 
      {if ""{related:count}"" == ""{related:total_results}""}
        &lt;/ul&gt;
      {/if}

    {/if}


So at the moment {total_results} is equal to 5 so my ul is not getting closed properly.

Does anyone have any ideas how I can get around this problem.

I would like to keep my markup inside the exp:channel:entries loop, and ideally use only one loop.

Any help, greatly appreciated 
",magicspon,https://expressionengine.stackexchange.com/users/730,"Faffing about with loop counters is quite unpleasant and inelegant... these are the kind of problems you run into when your data-fetching is tightly coupled to your data-output. Instead put Stash to work. Here's how:

{!--  ============================================
STORE THE DATA into dynamic stash lists using context.
Avoid the temptation to put any markup here.
================================================== --}

{exp:channel:entries ...}   
    {related}
        {exp:stash:append_list name=""related-items"" context=""{related:panel_type}""}
            {stash:the-title}{related:title}{/stash:the-title}
            {stash:a-custom-field}{related:a-custom-field}{/stash:a-custom-field}
        {/exp:stash:append_list}
    {/related}
{/exp:channel:entries}


{!--  ============================================
ASSEMBLE THE MARKUP and OUTPUT THE DATA
================================================== --}

{exp:stash:parse process=""end""}     

    {if {exp:stash:not_empty name=""related-items"" context=""products""}}
        &lt;h2&gt;Related Products&lt;/h2&gt;
        &lt;ul class=""p""&gt;
           {exp:stash:get_list name=""related-items"" context=""products""}
             &lt;li&gt;{the-title} | {a-custom-field}&lt;/li&gt;
           {/exp:stash:get_list}
        &lt;/ul&gt;
    {/if}

    {if {exp:stash:not_empty name=""related-items"" context=""showcase""}}
        &lt;h2&gt;Related Showcase&lt;/h2&gt;
        &lt;ul class=""s""&gt;
           {exp:stash:get_list name=""related-items"" context=""showcase""}
             &lt;li&gt;{the-title} | {a-custom-field}&lt;/li&gt;
           {/exp:stash:get_list}
        &lt;/ul&gt;
    {/if}

{/exp:stash:parse}


If you were using a separate view template for your layout you wouldn't need the final stash:parse tag, but if you're setting and getting in the same template it helps to avoid parse order issues. (Full explanation and tutorials here: http://www.jamessmith.co.uk/articles/expressionengine-stash-tutorials)
",James Smith,https://expressionengine.stackexchange.com/users/182,http://expressionengine.stackexchange.com/questions/17252/relationship-field-count-of-type-and-total-results-of-type,TECHNOLOGY,expressionengine.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,1.0,0.8888888888888888,0.9,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,"Relation field - {count} type, and {total} type","I have a relationship field which contains a number of different pieces of content.

Each piece of content has a type property.

Is there anyway I can count the number of each of the types that is included in the relationship.

For example.  3 Product related items, and 2 Showcase related items.

I need to be able to get the {total_results} of each type. 

This is what I'm trying to do...

 {if ""{related:panel_type}"" == ""products""}

      {if ""{related:count}"" == ""1""}
        &lt;ul class=""p""&gt;
      {/if}
        // do stuff 
      {if ""{related:count}"" == ""{related:total_results}""}
        &lt;/ul&gt;
      {/if}

    {/if}

  {if ""{related:panel_type}"" == ""showcase""}

      {if ""{related:count}"" == ""1""}
        &lt;ul class=""s""&gt;
      {/if}
        // do stuff 
      {if ""{related:count}"" == ""{related:total_results}""}
        &lt;/ul&gt;
      {/if}

    {/if}


So at the moment {total_results} is equal to 5 so my ul is not getting closed properly.

Does anyone have any ideas how I can get around this problem.

I would like to keep my markup inside the exp:channel:entries loop, and ideally use only one loop.

Any help, greatly appreciated 
","Faffing about with loop counters is quite unpleasant and inelegant... these are the kind of problems you run into when your data-fetching is tightly coupled to your data-output. Instead put Stash to work. Here's how:

{!--  ============================================
STORE THE DATA into dynamic stash lists using context.
Avoid the temptation to put any markup here.
================================================== --}

{exp:channel:entries ...}   
    {related}
        {exp:stash:append_list name=""related-items"" context=""{related:panel_type}""}
            {stash:the-title}{related:title}{/stash:the-title}
            {stash:a-custom-field}{related:a-custom-field}{/stash:a-custom-field}
        {/exp:stash:append_list}
    {/related}
{/exp:channel:entries}


{!--  ============================================
ASSEMBLE THE MARKUP and OUTPUT THE DATA
================================================== --}

{exp:stash:parse process=""end""}     

    {if {exp:stash:not_empty name=""related-items"" context=""products""}}
        &lt;h2&gt;Related Products&lt;/h2&gt;
        &lt;ul class=""p""&gt;
           {exp:stash:get_list name=""related-items"" context=""products""}
             &lt;li&gt;{the-title} | {a-custom-field}&lt;/li&gt;
           {/exp:stash:get_list}
        &lt;/ul&gt;
    {/if}

    {if {exp:stash:not_empty name=""related-items"" context=""showcase""}}
        &lt;h2&gt;Related Showcase&lt;/h2&gt;
        &lt;ul class=""s""&gt;
           {exp:stash:get_list name=""related-items"" context=""showcase""}
             &lt;li&gt;{the-title} | {a-custom-field}&lt;/li&gt;
           {/exp:stash:get_list}
        &lt;/ul&gt;
    {/if}

{/exp:stash:parse}


If you were using a separate view template for your layout you wouldn't need the final stash:parse tag, but if you're setting and getting in the same template it helps to avoid parse order issues. (Full explanation and tutorials here: http://www.jamessmith.co.uk/articles/expressionengine-stash-tutorials)
"
5076,5076,8074,CName for static images - will Google crawl?,"I am planning to serve images on a CDN using a CNAME: images.mysite.com. I am doing this because CDNname.mysite.com makes ugly URL's and MAY be bad for SEO (debatable).

Will Google crawl the subdomain (only storing images and nothing on the main domain will link to it).

If so, would a simple robots.txt be suitable? Is this even possible seeing that the subdomain is ONLY serving images, JS, CSS i.e. not HTML?

Thanks
",Jason,https://webmasters.stackexchange.com/users/28557,"Since the images on the subdomains would be linked from the main domain, Google will certainly be aware of the subdomain and will certainly grab the linked images.  I don't believe you will get the subdomain actively crawled as a separate entity, though.  The algorithm is smart enough to detect that you are just serving resources off the subdomain instead of actively hosting real content and index accordingly.
",JCL1178,https://webmasters.stackexchange.com/users/5757,http://webmasters.stackexchange.com/questions/49232/cname-for-static-images-will-google-crawl,TECHNOLOGY,webmasters.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,CNAME for still pictures - will Google crawl?,"I am planning to serve images on a CDN using a CNAME: images.mysite.com. I am doing this because CDNname.mysite.com makes ugly URL's and MAY be bad for SEO (debatable).

Will Google crawl the subdomain (only storing images and nothing on the main domain will link to it).

If so, would a simple robots.txt be suitable? Is this even possible seeing that the subdomain is ONLY serving images, JS, CSS i.e. not HTML?

Thanks
","Because the image on the subdomain will be linked from the primary domain, Google will definitely notice the subdomain and will definitely get the linked image. However, I do not believe that you will actively crawl subdomains as separate entities. The algorithm is smart enough to detect that you are only serving resources outside the subdomain, rather than actively hosting the real content and corresponding indexes."
3996,3996,6381,Wiki-like tool for writing specifications and documentation,"I am looking for a wiki or wiki-like system for writing and managing specification and documentation for a software project. 

I know there are lots of wiki-implementations available, but are there some that are especially well-suited for this kind of task?

Actually it doesn't have to be a wiki, just a system that makes it easy to write and navigate specs and documentation, and which support change tracing.
",user35746,https://programmers.stackexchange.com/users/35746,"For the personal project (existing only in my PC) I use Wiki in a Jar. In the past I worked with Redmine (it has furthermore a system of bug tracking and SCM  )
",alepuzio,https://programmers.stackexchange.com/users/6330,http://programmers.stackexchange.com/questions/105179/wiki-like-tool-for-writing-specifications-and-documentation,TECHNOLOGY,programmers.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.4444444444444444,1.0,1.0,0.6666666666666667,0.0,0.0,0.0,0.5555555555555556,Wiki like tools for writing specifications and documents,"I am looking for a wiki or wiki-like system for writing and managing specification and documentation for a software project. 

I know there are lots of wiki-implementations available, but are there some that are especially well-suited for this kind of task?

Actually it doesn't have to be a wiki, just a system that makes it easy to write and navigate specs and documentation, and which support change tracing.
","For the personal project (existing only in my PC) I use Wiki in a Jar. In the past I worked with Redmine (it has furthermore a system of bug tracking and SCM  )
"
2201,2201,3508,Why didn't they change the intro in House MD from season 4 to reflect the new doctors?,"From Season 4, House has three new doctors as part of his team and the previous three just appear off an on. Why didn't the show's creators update the intro to show the new team? It always shows Cameron, Chase and Foreman.
",bobbyalex,https://movies.stackexchange.com/users/1111,"Season 4 takes place after House fires his entire team and must start playing his game to find a new one.

During this season however, the production crew knew that the old team members would still be a part of the show in some capacity.  Foreman eventually rejoined the team, Chase became the head of Surgery, and Cameron became the head of the ER.  

With that spoiler out of the way, the crew themselves did not know who was going to be voted off House's Game of Jobs.  This combined with the Writer's Strike at the time made the series as chaotic as possible.  This is what adds to the fact that the opening sequence did not change to reflect the new cast members, merely putting them in the credits at the start of the actual episode.

In fact, if memory serves this continues until at least season 7 where the intro completely changed to reflect Jennifer Morrison's departure from the series and features brand new sequences in the intro including spots for Peter Jacobson and Olivia Wilde in the intro who were upgraded to full cast members.
",user1238523,https://movies.stackexchange.com/users/130,http://movies.stackexchange.com/questions/12318/why-didnt-they-change-the-intro-in-house-md-from-season-4-to-reflect-the-new-do,LIFE_ARTS,movies.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Why didn't they change the introduction of the internal MD from the fourth quarter to reflect the new doctor?,"Starting in the fourth quarter, house had three new doctors as part of his team, while the first three were only occasional. Why didn't the show's creators update the introduction to show the new team? It always shows Cameron, chase and foreman.","Season 4 takes place after House fires his entire team and must start playing his game to find a new one.

During this season however, the production crew knew that the old team members would still be a part of the show in some capacity.  Foreman eventually rejoined the team, Chase became the head of Surgery, and Cameron became the head of the ER.  

With that spoiler out of the way, the crew themselves did not know who was going to be voted off House's Game of Jobs.  This combined with the Writer's Strike at the time made the series as chaotic as possible.  This is what adds to the fact that the opening sequence did not change to reflect the new cast members, merely putting them in the credits at the start of the actual episode.

In fact, if memory serves this continues until at least season 7 where the intro completely changed to reflect Jennifer Morrison's departure from the series and features brand new sequences in the intro including spots for Peter Jacobson and Olivia Wilde in the intro who were upgraded to full cast members.
"
1335,1335,2104,How do electrical devices suck electricity?,"If the electric potential is 220V and some device needs 1500watts then how does it suck exactly that amount of electrical energy from outlet?
",Ron,https://physics.stackexchange.com/users/7253,"It is not the most straightforward viewpoint to say that a device ""needs 1500 watts"". This is more a consequence than a condition. What happens is that you create an electric circuit by plugging in a device into the outlet. That circuit follows Ohm's law: $$V = I R$$ So for a given voltage and resistance a certain current $I$ will flow. The power is simply $$P = V I = V^{2}/R = I^2 R$$The device does not know anything, it just has a property, it's resistance $R$.
",Alexander,https://physics.stackexchange.com/users/5931,http://physics.stackexchange.com/questions/19838/how-do-electrical-devices-suck-electricity,SCIENCE,physics.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.7777777777777778,1.0,0.4444444444444444,1.0,1.0,0.7333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,How do electrical appliances absorb electricity?,"If the potential is 220 volts and some devices need 1500 watts, how does it accurately absorb so much power from the power outlet?","It is not the most straightforward viewpoint to say that a device ""needs 1500 watts"". This is more a consequence than a condition. What happens is that you create an electric circuit by plugging in a device into the outlet. That circuit follows Ohm's law: $$V = I R$$ So for a given voltage and resistance a certain current $I$ will flow. The power is simply $$P = V I = V^{2}/R = I^2 R$$The device does not know anything, it just has a property, it's resistance $R$.
"
5121,5121,8142,"What is another way to put ""mistaken about what one saw""?","Is there any more slangy/easy way of saying ""mistakenly about what one saw""?
Like in the below example what else can be replaced Maybe I was mistaken.?


  A: I think I heard something in the dark.
  
  B: I didn't hear anything.
  
  A: Maybe I was mistaken.

",user49119,https://ell.stackexchange.com/users/3086,"mistaken is easy and unambiguous so better use this word only. Still, if you want other ways to say that, here are they...


  A: I think I heard something in the dark. 
      B: I didn't hear anything. 
      A: Maybe, I was mislead about that sound. OR Maybe, it could be something else! OR Maybe, I misunderstood it as some sound.


To avoid ambiguity, I'd prefer the second one - Maybe, it could be something else (not sound). 
",Maulik V,https://ell.stackexchange.com/users/3187,http://ell.stackexchange.com/questions/19037/what-is-another-way-to-put-mistaken-about-what-one-saw,CULTURE,ell.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,0.3333333333333333,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,0.0,0.8888888888888888,What else can you do to make a mistake about what a person sees?,"Is there any more slangy/easy way of saying ""mistakenly about what one saw""?
Like in the below example what else can be replaced Maybe I was mistaken.?


  A: I think I heard something in the dark.
  
  B: I didn't hear anything.
  
  A: Maybe I was mistaken.

","mistaken is easy and unambiguous so better use this word only. Still, if you want other ways to say that, here are they...


  A: I think I heard something in the dark. 
      B: I didn't hear anything. 
      A: Maybe, I was mislead about that sound. OR Maybe, it could be something else! OR Maybe, I misunderstood it as some sound.


To avoid ambiguity, I'd prefer the second one - Maybe, it could be something else (not sound). 
"
2136,2136,3402,How do I reduce the size of mlocate database?,"I'm out of space on /var

  25G   25G     0 100% /var


It looks like mlocate.db is the problem:

# find /var -printf '%s %p\n' | sort -nr | head
13140140032 ./lib/mlocate/mlocate.db.cgLMAM
12409839616 ./lib/mlocate/mlocate.db.MqGeqe

# cat /etc/updatedb.conf
PRUNE_BIND_MOUNTS=""yes""
PRUNENAMES="".git .bzr .hg .svn""
PRUNEPATHS=""/tmp /var/spool /media""
PRUNEFS=""NFS nfs nfs4 rpc_pipefs afs binfmt_misc proc smbfs autofs iso9660 ncpfs coda devpts ftpfs devfs mfs shfs sysfs cifs lustre_lite tmpfs usbfs udf""


I don't see anything else to prune. So how can I fix this? Thanks
",MountainX,https://askubuntu.com/users/36661,"The /var/lib/mlocate/mlocate.db.?????? files are leftover temporary files from a (probably) interrupted updatedb run. They don't appear on either of my Ubuntu 11.10 systems, except when updatedb is running. Delete them:

sudo rm -f /var/lib/mlocate/mlocate.db.??????


then, to be sure, run 

sudo /etc/cron.daily/mlocate

",waltinator,https://askubuntu.com/users/25618,http://askubuntu.com/questions/117162/how-do-i-reduce-the-size-of-mlocate-database,TECHNOLOGY,askubuntu.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,How to reduce the size of mlocate database?,"I'm out of space on /var

  25G   25G     0 100% /var


It looks like mlocate.db is the problem:

# find /var -printf '%s %p\n' | sort -nr | head
13140140032 ./lib/mlocate/mlocate.db.cgLMAM
12409839616 ./lib/mlocate/mlocate.db.MqGeqe

# cat /etc/updatedb.conf
PRUNE_BIND_MOUNTS=""yes""
PRUNENAMES="".git .bzr .hg .svn""
PRUNEPATHS=""/tmp /var/spool /media""
PRUNEFS=""NFS nfs nfs4 rpc_pipefs afs binfmt_misc proc smbfs autofs iso9660 ncpfs coda devpts ftpfs devfs mfs shfs sysfs cifs lustre_lite tmpfs usbfs udf""


I don't see anything else to prune. So how can I fix this? Thanks
","The /var/lib/mlocate/mlocate.db.?????? files are leftover temporary files from a (probably) interrupted updatedb run. They don't appear on either of my Ubuntu 11.10 systems, except when updatedb is running. Delete them:

sudo rm -f /var/lib/mlocate/mlocate.db.??????


then, to be sure, run 

sudo /etc/cron.daily/mlocate

"
4845,4845,7712,Complete induction,"I am very confused with complete induction. Because in every task there is something different to do, and I never know what to insert (thats my biggest problem). 
Here's the example:
Proof with complete induction. Please please help me, because I have exams coming up (I am just becoming a primary school teacher..)


  For $n\in\mathbb{N}$:
  
  $$\sum^n_{i=1}\frac{1}{(2i-1)(2i+1)}=\frac{n}{2n+1}$$

",Sophia,https://math.stackexchange.com/users/63169,"There is one more (easier) way to solve this problem without induction: Expand the summand into partial fractions to obtain (denote $S_n$ the actual sum):
$$
S_n = \frac{1}{2} \sum_{k=1}^{n}\bigg(\frac{1}{2k-1}-\frac{1}{2k+1} \bigg)=\frac{1}{2} \bigg(1-\frac{1}{3} +\frac{1}{3} + \cdots - \frac{1}{2n+1} \bigg) = \frac{n}{2n+1}
$$
",Alex,https://math.stackexchange.com/users/38873,http://math.stackexchange.com/questions/309300/complete-induction-sumn-i-1-frac12i-12i1-fracn2n1,SCIENCE,math.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.7777777777777778,0.6666666666666667,1.0,0.0,0.3333333333333333,0.8888888888888888,Complete induction,"I am very confused with complete induction. Because in every task there is something different to do, and I never know what to insert (thats my biggest problem). 
Here's the example:
Proof with complete induction. Please please help me, because I have exams coming up (I am just becoming a primary school teacher..)


  For $n\in\mathbb{N}$:
  
  $$\sum^n_{i=1}\frac{1}{(2i-1)(2i+1)}=\frac{n}{2n+1}$$

","There is one more (easier) way to solve this problem without induction: Expand the summand into partial fractions to obtain (denote $S_n$ the actual sum):
$$
S_n = \frac{1}{2} \sum_{k=1}^{n}\bigg(\frac{1}{2k-1}-\frac{1}{2k+1} \bigg)=\frac{1}{2} \bigg(1-\frac{1}{3} +\frac{1}{3} + \cdots - \frac{1}{2n+1} \bigg) = \frac{n}{2n+1}
$$
"
2254,2254,3593,Exit Google Chrome from terminal,"Is there a way to cause google-chrome to quit, from the terminal, besides using killall google-chrome? 
I would like to be able to close it from a script without killing it.
",slybloty,https://unix.stackexchange.com/users/14775,"This works for me:

killall --quiet --signal 15 -- chrome


Note that I'm using a rather verbose command to keep it readable in the code, of course you could also issue:

killall -q -15 chrome

",Fleshgrinder,https://unix.stackexchange.com/users/60822,http://unix.stackexchange.com/questions/34101/exit-google-chrome-from-terminal,TECHNOLOGY,unix.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Exit Google browser from the terminal,"Besides using killall Google Chrome, is there any way to get Google Chrome out of the terminal?","This works for me:

killall --quiet --signal 15 -- chrome


Note that I'm using a rather verbose command to keep it readable in the code, of course you could also issue:

killall -q -15 chrome

"
654,654,1040,Best way to migrate text field to taxonomy reference field,"I want to migrate a text field to taxonomy reference field( the Tags one).

I've 1200 nodes having a field ""Organization name"". Those creating the content are making mistakes like misspelled company names. I'm using the company name in the views to find all related nodes.

This will help those entering can simply choose the company names or if someone has entered IBM for International Business Machines then I can merge those terms when using taxonomy reference field.

Should I go and create a vocabulary, add all existing values as terms in vocabulary then programmatically assign the text field values to the taxonomy reference field? Then delete the text field and change references in the views etc.
",AgA,https://drupal.stackexchange.com/users/2113,"I would:


Go thorough all values, grouping them by their Levenshtein distance from each other.
For all set of similar names, I would choose canonical one, and put them in taxonomy as a term. 
Using Computed Field or VBO I would choose the Levenshtein closest term for each node.


Details of implementation would need a bit of polishing, but that's my general approach. Apparently you can use Views Bulk Operations both to create taxonomy terms and to set field's value on node.
",MoÅot,https://drupal.stackexchange.com/users/16495,http://drupal.stackexchange.com/questions/76784/best-way-to-migrate-text-field-to-taxonomy-reference-field,TECHNOLOGY,drupal.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,1.0,0.5,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8333333333333334,0.6666666666666666,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8333333333333334,The best way to migrate text fields to classified reference fields,"I want to migrate a text field to taxonomy reference field( the Tags one).

I've 1200 nodes having a field ""Organization name"". Those creating the content are making mistakes like misspelled company names. I'm using the company name in the views to find all related nodes.

This will help those entering can simply choose the company names or if someone has entered IBM for International Business Machines then I can merge those terms when using taxonomy reference field.

Should I go and create a vocabulary, add all existing values as terms in vocabulary then programmatically assign the text field values to the taxonomy reference field? Then delete the text field and change references in the views etc.
","I would:


Go thorough all values, grouping them by their Levenshtein distance from each other.
For all set of similar names, I would choose canonical one, and put them in taxonomy as a term. 
Using Computed Field or VBO I would choose the Levenshtein closest term for each node.


Details of implementation would need a bit of polishing, but that's my general approach. Apparently you can use Views Bulk Operations both to create taxonomy terms and to set field's value on node.
"
5000,5000,7959,Do I need Android SDK to connect my phone in USB debug mode?,"I'm following the steps provided here to root my Samsung Captivate (Galaxy-S).  I install the USB drivers in the link provided.  Whenever I connect my phone, I get the error There was a problem installing this hardware... SAMSUNG Android Composite ADB Interface.  I do have USB Debug mode checked on my phone.

The googling I have done on this issue mention downloading the Android SDK, but I have heard no mention of needing this on the XDA developers forum or in any other conversation about rooting.  So, I wanted to ensure that downloading the Android SDK was necessary, or would even fix my problem before I bother installing it and its dependencies (Java JDK).  I'm running Windows XP.  

Note:  Although I'm running a 64-bit machine, I Installed the x86 Samsung Drivers since Windows XP is a 32-bit OS.  I hope that's right.

  
",Chance,https://android.stackexchange.com/users/3415,"No, you don't need to install the Android SDK.  The SDK's drivers don't work for the Galaxy S, actually, at least not the last time I tried.

You best bet is to download Samsung Kies and update the drivers through it, as per this answer to another question.  You can get Kies most easily from Samsung UK here.
",Matthew Read,https://android.stackexchange.com/users/1465,http://android.stackexchange.com/questions/8913/do-i-need-android-sdk-to-connect-my-phone-in-usb-debug-mode,TECHNOLOGY,android.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,1.0,0.0,0.3333333333333333,0.7777777777777778,Do I need the Android SDK to connect to my phone in USB debugging mode?,"I'm following the steps provided here to root my Samsung Captivate (Galaxy-S).  I install the USB drivers in the link provided.  Whenever I connect my phone, I get the error There was a problem installing this hardware... SAMSUNG Android Composite ADB Interface.  I do have USB Debug mode checked on my phone.

The googling I have done on this issue mention downloading the Android SDK, but I have heard no mention of needing this on the XDA developers forum or in any other conversation about rooting.  So, I wanted to ensure that downloading the Android SDK was necessary, or would even fix my problem before I bother installing it and its dependencies (Java JDK).  I'm running Windows XP.  

Note:  Although I'm running a 64-bit machine, I Installed the x86 Samsung Drivers since Windows XP is a 32-bit OS.  I hope that's right.

  
","No, you don't need to install the Android SDK.  The SDK's drivers don't work for the Galaxy S, actually, at least not the last time I tried.

You best bet is to download Samsung Kies and update the drivers through it, as per this answer to another question.  You can get Kies most easily from Samsung UK here.
"
5982,5982,9484,"SQL server moved, now can't use as linked server","So I have a SQL server database that was controlled by an outside vendor.  It is hosted remotely.  Then he needed to move the server to a new host.  Now, I'm able to connect to the server manually from SSMS and I can add it as a linked server, but I can't USE it as a linked server, or even browse the servers catalogs.

My instance is 2000, and I assume the remote server is 2008 or 2008 R2.

When I try to use the server (try to update a stored proc that points to the linked server) I get the following error: 

Trying to browse the linked server's catalogs from SSMS throws this:


  Failed to retrieve data for this request.
  (Microsoft.SqlServer.Management.Sdk.Sfc)
  
  [DBNETLIB][ConnectionOpen (Connect()).]SQL Server does not exist or
  access denied. (Microsoft SQL Server, Error: 17)


A friend suggested I run Exec sys.sp_change_users_login 'Report', but it turns up no orphaned records, and anyway, I can login using the credentials, so that doesn't look like the problem.

EDIT: Can't connect at all with IP, but hostname connects then gives above error.  HUH?
",MAW74656,https://dba.stackexchange.com/users/1107,"Did the vendor use 2008(r2) prior to the move?

If so, there is a possibility that when they moved they didnt transfer all of the inbound external ports.  You may have been part of a redirect policy for your login and when they moved the policy is still pointing to the old server address.

Although this is not an Authentication issue, i think it is part of your Authentication.  Cause the server moved and now you cant access.  
",GoldBishop,https://dba.stackexchange.com/users/10115,http://dba.stackexchange.com/questions/24188/sql-server-moved-now-cant-use-as-linked-server,TECHNOLOGY,dba.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,SQL server has been moved and cannot be used as a linked server at this time,"So I have a SQL server database that was controlled by an outside vendor.  It is hosted remotely.  Then he needed to move the server to a new host.  Now, I'm able to connect to the server manually from SSMS and I can add it as a linked server, but I can't USE it as a linked server, or even browse the servers catalogs.

My instance is 2000, and I assume the remote server is 2008 or 2008 R2.

When I try to use the server (try to update a stored proc that points to the linked server) I get the following error: 

Trying to browse the linked server's catalogs from SSMS throws this:


  Failed to retrieve data for this request.
  (Microsoft.SqlServer.Management.Sdk.Sfc)
  
  [DBNETLIB][ConnectionOpen (Connect()).]SQL Server does not exist or
  access denied. (Microsoft SQL Server, Error: 17)


A friend suggested I run Exec sys.sp_change_users_login 'Report', but it turns up no orphaned records, and anyway, I can login using the credentials, so that doesn't look like the problem.

EDIT: Can't connect at all with IP, but hostname connects then gives above error.  HUH?
","Did the vendor use 2008(r2) prior to the move?

If so, there is a possibility that when they moved they didnt transfer all of the inbound external ports.  You may have been part of a redirect policy for your login and when they moved the policy is still pointing to the old server address.

Although this is not an Authentication issue, i think it is part of your Authentication.  Cause the server moved and now you cant access.  
"
302,302,488,Is pretending to want to trade before playing a monopoly card objectionable?,"In Settlers of Catan, I sometimes try to ask people if they want to trade a certain resource, tricking them into revealing the approximate amount of that resource in everyone's hand. After this I play the monopoly card. This has on some occasions not been received very well.

Is this fair play?
",Matthijs Wessels,https://boardgames.stackexchange.com/users/117,"This is the most EVIL play in the game.

It is legal though.  Just very very EVIL.  So EVIL that many people get mad when you do it.  

It is very frowned on at my table.  If you do it most players will not even acknowledge your trade attempts in the future.
",Vaccano,https://boardgames.stackexchange.com/users/56,http://boardgames.stackexchange.com/questions/577/is-pretending-to-want-to-trade-before-playing-a-monopoly-card-objectionable,CULTURE,boardgames.stackexchange.com,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Is it offensive to pretend to trade before playing Monopoly?,"Among the settlers in katan, I sometimes try to ask people if they want to exchange certain resources and cheat them to reveal the approximate amount of resources in each person's hands. After that, I played Monopoly. This is not well accepted in some cases.","This is the most EVIL play in the game.

It is legal though.  Just very very EVIL.  So EVIL that many people get mad when you do it.  

It is very frowned on at my table.  If you do it most players will not even acknowledge your trade attempts in the future.
"
2840,2840,4520,Who counters Jayce top lane besides Yorick?,"I'm aware that Yorick and Cho'Gath are both good counters for Jayce (in Top Lane) but who else might be a good matchup and why?
",Eddie,https://gaming.stackexchange.com/users/29370,"Malphite can win this lane consistently.
",SubSalac,https://gaming.stackexchange.com/users/29319,http://gaming.stackexchange.com/questions/77029/who-counters-jayce-top-lane-besides-yorick,CULTURE,gaming.stackexchange.com,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.5,1.0,0.0,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.6,0.0,0.0,0.3333333333333333,0.7777777777777778,"Who's dealing with Jess in the top floor lane, except York?","I know that both joric and jogat are good rivals for Joyce, but who else are good rivals and why?","Malphite can win this lane consistently.
"
1066,1066,1683,How was this photo taken,"My question is how was this picture taken.
And I've got a few assumptions I made regarding the photo, please correct me when I am wrong.


Low aperture value, like 1.4-2.0
Quite high shutter speed, my guess is that it was 400-500
Auto iso speed


That's how I would have taken a picture like this. The other thing is that it has some vignetting - I guess, it's a postprocessing.
What else? It looks to me that some other postprocessing had to be done.

And what kind of lens you think it was?
My guess is that it was some zoom-lens, but that's all I can tell.


",Anders D,https://photo.stackexchange.com/users/21963,"This is mostly guess-work:

To me this looks like a medium length zoom:


(Assuming its on a Full Frame body) of 150mm - 200mm.
Shutter speed would be 1/200th+
ISO 800 (I NEVER use Auto ISO)
Aperture may not be that large, as the lens is long-ish, could be 3.5f ish
The vignette looks fake

",Digital Lightcraft,https://photo.stackexchange.com/users/9999,http://photo.stackexchange.com/questions/65875/which-equipment-and-settings-were-used-for-this-kiteboarding-photo,LIFE_ARTS,photo.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,1.0,0.0,0.7777777777777778,How is this picture taken,"My question is how was this picture taken.
And I've got a few assumptions I made regarding the photo, please correct me when I am wrong.


Low aperture value, like 1.4-2.0
Quite high shutter speed, my guess is that it was 400-500
Auto iso speed


That's how I would have taken a picture like this. The other thing is that it has some vignetting - I guess, it's a postprocessing.
What else? It looks to me that some other postprocessing had to be done.

And what kind of lens you think it was?
My guess is that it was some zoom-lens, but that's all I can tell.


","This is mostly guess-work:

To me this looks like a medium length zoom:


(Assuming its on a Full Frame body) of 150mm - 200mm.
Shutter speed would be 1/200th+
ISO 800 (I NEVER use Auto ISO)
Aperture may not be that large, as the lens is long-ish, could be 3.5f ish
The vignette looks fake

"
3435,3435,5461,Created Custom objects on salesforce not showing up under Leads,"I have custom object 'Subject_c' with 3 fields and I have created those objects by uploading a CSV file. Subject_c has a lookup relationship with Leads (Its general for the same user regardless of what lead he is viewing). I am able to insert a related list and I can see that the objects are created under Data Management/Storage Usage. But it shows blank under related list. 
",sPaz,https://stackoverflow.com/users/1762092,"You're saying that the custom object has lookup to Lead but then you say Subjects are generic and somehow should be displayed on every Lead page? I don't think it'll work.

Stuff appears on related list only when field Subject_c.Lead_c will be populated with ""this"" Lead's Id. (please note I've made best guess at the field name). So you'd need to insert separate data for each Lead which can quickly blow your storage usage and will be a pain in the a$$ to maintain later. Is it only for displaying? Or do you plan to later capture some kind of survey results for each Lead?

If it's just for display I think you'll need to embed a Visualforce page in the Lead page layout to achieve that in a saner way. The subjects are specific to current viewing user? Or it's more like a general list, just 3 subjects for whole organisation?

P.S. ""object"" is like a table in normal database. I think you mixed a bit the difference between table and records / rows of data stored in it.
",eyescream,https://stackoverflow.com/users/313628,http://stackoverflow.com/questions/15562322/created-custom-objects-on-salesforce-not-showing-up-under-leads,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,1.0,Custom objects created on salesforce are not displayed under leads,"I have custom objects ""subject \ u c"" of 3 fields, which I created by uploading CSV file. There is a lookup relationship between the subject and the leads (no matter what lead he is viewing, it is the general relationship of the same user). I can insert a related list, and I can see that these objects are created under data management / storage usage. But it is blank under the related list.","You're saying that the custom object has lookup to Lead but then you say Subjects are generic and somehow should be displayed on every Lead page? I don't think it'll work.

Stuff appears on related list only when field Subject_c.Lead_c will be populated with ""this"" Lead's Id. (please note I've made best guess at the field name). So you'd need to insert separate data for each Lead which can quickly blow your storage usage and will be a pain in the a$$ to maintain later. Is it only for displaying? Or do you plan to later capture some kind of survey results for each Lead?

If it's just for display I think you'll need to embed a Visualforce page in the Lead page layout to achieve that in a saner way. The subjects are specific to current viewing user? Or it's more like a general list, just 3 subjects for whole organisation?

P.S. ""object"" is like a table in normal database. I think you mixed a bit the difference between table and records / rows of data stored in it.
"
1571,1571,2471,Where to create a shared media folder?,"I'd like to place all my family's media in one shared folder for everyone to use from any computer.  Whether it's a PC or home server.

What is more appropriate:


Create it in my home folder (/home/lamcro/media/)
Create a new account called media (/home/media/)
or just Create a new folder  (/media/)


As far as I know, there is no ""Shared Folder"" in Ubuntu, like in Windows.

I'm just looking for the least cumbersome method, in case I ever want to do a full Linux re-install.
",lamcro,https://superuser.com/users/1237,"I do this exact thing with an external drive. Same basic idea as the new partition without repartitioning. I have never looked into the nuts and bolts but the drive is on when you boot up so shows up for everyone and we use it for any data that is appropriate to share between users.
",Dennis,https://superuser.com/users/5144,http://superuser.com/questions/22355,TECHNOLOGY,superuser.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.7777777777777778,0.6,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Where do I create a shared media folder?,"I'd like to place all my family's media in one shared folder for everyone to use from any computer.  Whether it's a PC or home server.

What is more appropriate:


Create it in my home folder (/home/lamcro/media/)
Create a new account called media (/home/media/)
or just Create a new folder  (/media/)


As far as I know, there is no ""Shared Folder"" in Ubuntu, like in Windows.

I'm just looking for the least cumbersome method, in case I ever want to do a full Linux re-install.
","I do this exact thing with an external drive. Same basic idea as the new partition without repartitioning. I have never looked into the nuts and bolts but the drive is on when you boot up so shows up for everyone and we use it for any data that is appropriate to share between users.
"
5911,5911,9366,How can I save messages from a particular sender in a particular folder in Gmail?,"A particular sender (an advertising company) sends a lot of emails daily into my Gmail inbox. Now those mails are important to me, since I am interested in their ads, but every time it is not possible to check them all. So I don't want my inbox to be flooded with their emails. Sometimes I can't work properly with my inbox filled with their emails. So is there a way so that I can mark the sender such a way so that the mail comes as usual, but it goes to a specific folder in lieu of flooding my inbox, so that when I get free time I can check their mails entering a particular folder?
",Mistu4u,https://webapps.stackexchange.com/users/31136,"A strength of Gmail is the use of labels, instead of folders.  You need to create a filter to automatically add a label to the message and automaticlly archive the messages.

To create a filer for a message that frequently is sent to you:


select or open a message you want to filter
Under the More pulldown select the command: Filter messages like these
You will then see the form open up with the FROM box filled in.
Google with then show you the messages that the filter has found.
Click create filter with this search. 
You can now specify if you want to:

Skip the Inbox (Archive it)
Apply the label:
Also apply filter to x matching conversations.

Click create the filter.


Archiving the messages keeps the message, it just removes the inbox label from the message. Labels can be used to search using label:mylabel. Labels are listed on the sidebar menu so that you can quickly jump to a filter that just shows the messages with that label. Plus messages can have multiple labels. 

You can edit/delete/create filters under Settings(gear)->Filter
",mhoran_psprep,https://webapps.stackexchange.com/users/15682,http://webapps.stackexchange.com/questions/40676/how-can-i-save-messages-from-a-particular-sender-in-a-particular-folder-in-gmail,TECHNOLOGY,webapps.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,How do I save messages from specific senders in a specific folder in Gmail?,"A specific sender (an advertising company) sends a lot of emails to my Gmail inbox every day. Now these emails are very important to me, because I am very interested in their advertisements, but I can't find all of them every time. So I don't want my inbox to be full of their mail. Sometimes my inbox is full of their mail and I can't work properly. So, is there a way for me to tag the sender so that the mail is as usual, but it goes to a specific folder instead of flooding my inbox so that when I'm free, I can check their mail into a specific folder?","A strength of Gmail is the use of labels, instead of folders.  You need to create a filter to automatically add a label to the message and automaticlly archive the messages.

To create a filer for a message that frequently is sent to you:


select or open a message you want to filter
Under the More pulldown select the command: Filter messages like these
You will then see the form open up with the FROM box filled in.
Google with then show you the messages that the filter has found.
Click create filter with this search. 
You can now specify if you want to:

Skip the Inbox (Archive it)
Apply the label:
Also apply filter to x matching conversations.

Click create the filter.


Archiving the messages keeps the message, it just removes the inbox label from the message. Labels can be used to search using label:mylabel. Labels are listed on the sidebar menu so that you can quickly jump to a filter that just shows the messages with that label. Plus messages can have multiple labels. 

You can edit/delete/create filters under Settings(gear)->Filter
"
1135,1135,1779,STFT - DFT size of the bins,"Having some trouble understanding this concept, really could do with some advice.

I want my STFT to have the following parameters: NFFT = 256 overlap/hop = 128

Now essentially, the algorithm will work as follows:

1) Split the signal into blocks of 256 


This will result in around 72*265:

2) For each of these blocks, calculate against the Hanning Window 

3) Create a ""slider"" that does an overlap of 128.. So, in theory it would 
   therefore be: `size = 256 + 128` 


Therefore, when I'm computing the DFT for each of the overlapped blocks, will my FFT remain at size 256 or will the size be 256 + 128 If this is the case, does each block in the resulting vector still have to be of size 256?

Thanks  

EDIT: 

This is now my result:



But, compare this to a spectrogram in matplotlib



Where am I actually going wrong? I cannot make any sense of this. 

I've looked bat through all the data, the blocks are correctly overlapping, Hanning window is being applied correctly.

Could it be to do with the fact I'm using a 1D DFT? I.e. 

std::vector&lt;complex&gt; FFT-&gt;transform(complex_vector[0...n], 256);

",Phorce,https://dsp.stackexchange.com/users/5182,"For a non-zero overlap, the size of each FFT will remain exactly the same.  However some of the data points used in each successive FFT will be from the previous FFT window, thus allowing less completely new data points to make up the final length to be fed to that successive FFT.  Thus more overlap will create a larger number of blocks.

For an overlap of 128, the 2nd FFT uses 128 points from the end of the first FFT, and adds 128 new points from the data stream, to make up a total of 256 data points, the same length as the first FFT.  Rinse and repeat.  The number of blocks for 50% overlap will approach double that of the number for zero overlap.
",hotpaw2,https://dsp.stackexchange.com/users/154,http://dsp.stackexchange.com/questions/13774/stft-dft-size-of-the-bins,TECHNOLOGY,dsp.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.6666666666666666,0.0,1.0,1.0,Dry film thickness of STFT box,"Having some trouble understanding this concept, really could do with some advice.

I want my STFT to have the following parameters: NFFT = 256 overlap/hop = 128

Now essentially, the algorithm will work as follows:

1) Split the signal into blocks of 256 


This will result in around 72*265:

2) For each of these blocks, calculate against the Hanning Window 

3) Create a ""slider"" that does an overlap of 128.. So, in theory it would 
   therefore be: `size = 256 + 128` 


Therefore, when I'm computing the DFT for each of the overlapped blocks, will my FFT remain at size 256 or will the size be 256 + 128 If this is the case, does each block in the resulting vector still have to be of size 256?

Thanks  

EDIT: 

This is now my result:



But, compare this to a spectrogram in matplotlib



Where am I actually going wrong? I cannot make any sense of this. 

I've looked bat through all the data, the blocks are correctly overlapping, Hanning window is being applied correctly.

Could it be to do with the fact I'm using a 1D DFT? I.e. 

std::vector&lt;complex&gt; FFT-&gt;transform(complex_vector[0...n], 256);

","For a non-zero overlap, the size of each FFT will remain exactly the same.  However some of the data points used in each successive FFT will be from the previous FFT window, thus allowing less completely new data points to make up the final length to be fed to that successive FFT.  Thus more overlap will create a larger number of blocks.

For an overlap of 128, the 2nd FFT uses 128 points from the end of the first FFT, and adds 128 new points from the data stream, to make up a total of 256 data points, the same length as the first FFT.  Rinse and repeat.  The number of blocks for 50% overlap will approach double that of the number for zero overlap.
"
3724,3724,5935,Setup ntp client with embedded device,"I need to run an NTP client on a very limited embedded device.  

ntpd is available but I do not see anything like rc.conf, or ntp.conf, or xntp.conf?  Can someone advise on how to setup NTP?  

I ran ntpd, but the date and time haven't updated.
",Bob,https://unix.stackexchange.com/users/7295,"It looks like you have the Busybox version of ntpd.  Here's a useful HOWTO:

http://wiki.openwrt.org/doc/howto/ntp.client

For example:

ntpd -q -p ptbtime1.ptb.de

",samiam,https://unix.stackexchange.com/users/58180,http://unix.stackexchange.com/questions/113560/setup-ntp-client-with-embedded-device,TECHNOLOGY,unix.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.3333333333333333,1.0,Installing NTP client with embedded device,"I need to run an NTP client on a very limited embedded device.  

ntpd is available but I do not see anything like rc.conf, or ntp.conf, or xntp.conf?  Can someone advise on how to setup NTP?  

I ran ntpd, but the date and time haven't updated.
","It looks like you have the Busybox version of ntpd.  Here's a useful HOWTO:

http://wiki.openwrt.org/doc/howto/ntp.client

For example:

ntpd -q -p ptbtime1.ptb.de

"
1202,1202,1890,Kohana (or straight PHP) OAuth2 implementation,"Does anyone have a very clear step-by-step guide for implementing OAuth2 (preferably in Kohana 3.2, but I'll take whatever I can get)?

I would like it to include the tables I need to create, etc.  (Hard to implement something without knowing the table structure.)

UPDATE:

I completely forgot to mention that I'm looking for a Provider implementation!  Thanks! (and sorry).
",Mr MikkÃ©l,https://stackoverflow.com/users/388325,"Maybe this helps: https://github.com/kohana-world (look into https://github.com/kohana-world/kw-accounts and https://github.com/kohana-world/kw-auth modules). Unfortunately, currently we have no time for development :(

PS. Also I've wrote an article about OAuth2 in Kohana, you can try to translate it from russian: http://translate.google.com/translate?hl=ru&amp;ie=UTF8&amp;prev=_t&amp;sl=ru&amp;tl=en&amp;u=http://brotkin.ru/2011/05/24/oauth-v2/
",biakaveron,https://stackoverflow.com/users/432669,http://stackoverflow.com/questions/11571010/kohana-or-straight-php-oauth2-implementation,STACKOVERFLOW,stackoverflow.com,0.5,0.5,0.0,0.0,0.5,0.5,0.6666666666666666,0.5,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.8333333333333334,0.6666666666666666,0.5,0.6666666666666666,0.6666666666666666,0.6,0.5,0.0,0.0,0.5,Kohana (or direct PHP) oauth2 implementation,"Does anyone have a very clear step-by-step guide for implementing OAuth2 (preferably in Kohana 3.2, but I'll take whatever I can get)?

I would like it to include the tables I need to create, etc.  (Hard to implement something without knowing the table structure.)

UPDATE:

I completely forgot to mention that I'm looking for a Provider implementation!  Thanks! (and sorry).
","Maybe this helps: https://github.com/kohana-world (look into https://github.com/kohana-world/kw-accounts and https://github.com/kohana-world/kw-auth modules). Unfortunately, currently we have no time for development :(

PS. Also I've wrote an article about OAuth2 in Kohana, you can try to translate it from russian: http://translate.google.com/translate?hl=ru&amp;ie=UTF8&amp;prev=_t&amp;sl=ru&amp;tl=en&amp;u=http://brotkin.ru/2011/05/24/oauth-v2/
"
1356,1356,2136,How soon after baking can you refrigerate freshly made fruit pies?,"How soon after baking a fresh fruit custard pie can I refrigerate it? Must it be at room temperature before it's put in the fridge?
",Deedee,https://cooking.stackexchange.com/users/36628,"EDIT: Although the question title says ""fruit pies,"" the question specifies a ""fruit custard pie.""  The following answer relates to custard pies and other pies containing fillings with eggs and/or milk.  Actual plain ""fruit pies"" generally contain enough sugar to prevent rapid spoilage and therefore often do not require refrigeration.  If you do plan to refrigerate a plain fruit pie, there's no significant advantage to getting it into the fridge quickly.



Pies do not have to come down to room temperature before refrigeration.  In fact, most food safety organizations recommend the same general policy for egg-based and dairy-based pies as they do for other foods: don't leave leftovers out for more than 2 hours after cooking.  See, for example, recommendations here:


  Foods which contain eggs and milk, with high moisture content, must be
  kept refrigerated, as bacteria love to grow in these foods. Failing to
  put that pie back into the refrigerator before it has remained on the
  counter for more than 2 hours can make a very merry celebration for
  the bacteria, but not so good for friends and family.


So, 2 hours should be a maximum before refrigeration.

As for recommendations about the appropriate time to let cool at room temperature, see here, for example, which states:


  Cool cream pies at room temperature for only  30 minutes after you
  take them out  of the oven.
  
  After 30 minutes, put them in the refrigerator  to complete the
  cooling and to keep them  cold.


While it says ""cream pies"" here, the guidelines above in that link imply that such guidelines also relate to custard and pumpkin pies.  (The first link above also says the same thing about pumpkin pies.)

Basically, the only reason to keep a dairy-based or egg-based pie out of the refrigerator after removing from the oven is to allow cooking and setting to continue.  Many custard pies will continue to set a bit while cooling, and putting them in the refrigerator immediately might ""shock"" them and disrupt this process of solidification.  Changes in humidity levels and condensation might also have unpredictable effects on the pie surface while it is very hot.

(As for concerns about putting hot food in the fridge, see links to food safety organizations on the subject in my answer here.  Basically, you shouldn't put a hot or warm pie near anything that's very perishable in the fridge.  Otherwise, you're safer getting it in the fridge as soon as it has stablized after cooking, which shouldn't take more than 30 minutes or so.)
",Athanasius,https://cooking.stackexchange.com/users/15018,http://cooking.stackexchange.com/questions/58802/how-soon-after-baking-can-you-refrigerate-freshly-made-fruit-pies,LIFE_ARTS,cooking.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,How long after baking can you refrigerate the fresh fruit pie?,How long after baking a fresh fruit cream pie can I refrigerate it? Must it be at room temperature before putting it in the refrigerator?,"EDIT: Although the question title says ""fruit pies,"" the question specifies a ""fruit custard pie.""  The following answer relates to custard pies and other pies containing fillings with eggs and/or milk.  Actual plain ""fruit pies"" generally contain enough sugar to prevent rapid spoilage and therefore often do not require refrigeration.  If you do plan to refrigerate a plain fruit pie, there's no significant advantage to getting it into the fridge quickly.



Pies do not have to come down to room temperature before refrigeration.  In fact, most food safety organizations recommend the same general policy for egg-based and dairy-based pies as they do for other foods: don't leave leftovers out for more than 2 hours after cooking.  See, for example, recommendations here:


  Foods which contain eggs and milk, with high moisture content, must be
  kept refrigerated, as bacteria love to grow in these foods. Failing to
  put that pie back into the refrigerator before it has remained on the
  counter for more than 2 hours can make a very merry celebration for
  the bacteria, but not so good for friends and family.


So, 2 hours should be a maximum before refrigeration.

As for recommendations about the appropriate time to let cool at room temperature, see here, for example, which states:


  Cool cream pies at room temperature for only  30 minutes after you
  take them out  of the oven.
  
  After 30 minutes, put them in the refrigerator  to complete the
  cooling and to keep them  cold.


While it says ""cream pies"" here, the guidelines above in that link imply that such guidelines also relate to custard and pumpkin pies.  (The first link above also says the same thing about pumpkin pies.)

Basically, the only reason to keep a dairy-based or egg-based pie out of the refrigerator after removing from the oven is to allow cooking and setting to continue.  Many custard pies will continue to set a bit while cooling, and putting them in the refrigerator immediately might ""shock"" them and disrupt this process of solidification.  Changes in humidity levels and condensation might also have unpredictable effects on the pie surface while it is very hot.

(As for concerns about putting hot food in the fridge, see links to food safety organizations on the subject in my answer here.  Basically, you shouldn't put a hot or warm pie near anything that's very perishable in the fridge.  Otherwise, you're safer getting it in the fridge as soon as it has stablized after cooking, which shouldn't take more than 30 minutes or so.)
"
2344,2344,3735,Ad layout for programs - Illustrator or InDesign,"today I'm looking for some advice from folks who have laid out event programs. 

In this case, the client (a local nonprofit) has a famous keynote speaker at their event, and have solicited donations from local businesses. Each donation over a certain level = a full page ad in the program for the event. Most of them are ""Congratulations to  on your anniversary"", etc. with a company logo sitting somewhere (the businesses that send in their own camera-ready artwork will just have them dropped into place). 

I'm going to be laying each ad out in a template so they look consistent; my question to the GD crowd is, ""Should I lay the template out in Illustrator and bring each ad individually in to InDesign or should I create a template page for an ad in InDesign and lay each ad out in InDesign?""

Based on your experience, what are the pros and cons of each approach? Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for) but I lose a certain amount of flexibility once I hit InDesign (the program will ultimately be laid out in InDesign).
",lawndartcatcher,https://graphicdesign.stackexchange.com/users/575,"Depends entirely upon ad style.

If the ads are more illustrative in nature, I'd use Illustrator for the ad, then place then in a master Indesign document. Ads with text transforms, image interactions (cutouts) or with other non-critical design elements such as spot illustrations or flourishes can often be easier to create in Illustrator.

If the ads are more text-based, I'd use Indesign for the ads as well as a master document.

There is no set rule as to which one is better or should be used - Illustrator or Indesign. It really all comes down to personal preference and features needed.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/20355/ad-layout-for-programs-illustrator-or-indesign,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,0.3333333333333333,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,Program advertising layout - illustration or illustration,"today I'm looking for some advice from folks who have laid out event programs. 

In this case, the client (a local nonprofit) has a famous keynote speaker at their event, and have solicited donations from local businesses. Each donation over a certain level = a full page ad in the program for the event. Most of them are ""Congratulations to  on your anniversary"", etc. with a company logo sitting somewhere (the businesses that send in their own camera-ready artwork will just have them dropped into place). 

I'm going to be laying each ad out in a template so they look consistent; my question to the GD crowd is, ""Should I lay the template out in Illustrator and bring each ad individually in to InDesign or should I create a template page for an ad in InDesign and lay each ad out in InDesign?""

Based on your experience, what are the pros and cons of each approach? Obviously it would be easier to lay each ad out in Illustrator (that's what it's there for) but I lose a certain amount of flexibility once I hit InDesign (the program will ultimately be laid out in InDesign).
","Depends entirely upon ad style.

If the ads are more illustrative in nature, I'd use Illustrator for the ad, then place then in a master Indesign document. Ads with text transforms, image interactions (cutouts) or with other non-critical design elements such as spot illustrations or flourishes can often be easier to create in Illustrator.

If the ads are more text-based, I'd use Indesign for the ads as well as a master document.

There is no set rule as to which one is better or should be used - Illustrator or Indesign. It really all comes down to personal preference and features needed.
"
5205,5205,8272,Is ZIP archive capable of storing permissions?,"I am using Maven Assembly plugin to bundle my application along with configuration/settings files. It allows to specify persmissions to be stored along with files, which is quite convenient.

Still I never found a confirmation, that ZIP archive is capable of storing UNIX permissions. Is it? (please, post some proof if you answer either yes or no).
",user1065145,https://serverfault.com/users/149491,"From the unzip(1) manpage:

   Dates,  times  and  permissions  of stored directories are not restored
   except under Unix. (On Windows NT and successors,  timestamps  are  now
   restored.)


So yes, permissions can be stored.
",MikeyB,https://serverfault.com/users/2101,http://serverfault.com/questions/585817,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Can zip archive store permissions?,"I am using the Maven assembly plug-in to bundle my application with a configuration / settings file. It allows you to specify the people to store with the file, which is very convenient.","From the unzip(1) manpage:

   Dates,  times  and  permissions  of stored directories are not restored
   except under Unix. (On Windows NT and successors,  timestamps  are  now
   restored.)


So yes, permissions can be stored.
"
5459,5459,8668,Where to create a shared media folder?,"I'd like to place all my family's media in one shared folder for everyone to use from any computer.  Whether it's a PC or home server.

What is more appropriate:


Create it in my home folder (/home/lamcro/media/)
Create a new account called media (/home/media/)
or just Create a new folder  (/media/)


As far as I know, there is no ""Shared Folder"" in Ubuntu, like in Windows.

I'm just looking for the least cumbersome method, in case I ever want to do a full Linux re-install.
",lamcro,https://superuser.com/users/1237,"I would recommend creating and using a /srv mount point for ""services provided by your system"".

Personally, I have the following:

/srv

    /srv/mm         (for ""multimedia"")
    /srv/mm/music   (all shared music)
    /srv/mm/photos  (all shared photos)
    ...
    ...


I then mount these directories using NFS on all other family computers on the network. I use the same naming convention on each client to keep things simple.
",Nick Pierpoint,https://superuser.com/users/452,http://superuser.com/questions/22355,TECHNOLOGY,superuser.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Where do I create a shared media folder?,"I'd like to place all my family's media in one shared folder for everyone to use from any computer.  Whether it's a PC or home server.

What is more appropriate:


Create it in my home folder (/home/lamcro/media/)
Create a new account called media (/home/media/)
or just Create a new folder  (/media/)


As far as I know, there is no ""Shared Folder"" in Ubuntu, like in Windows.

I'm just looking for the least cumbersome method, in case I ever want to do a full Linux re-install.
","I would recommend creating and using a /srv mount point for ""services provided by your system"".

Personally, I have the following:

/srv

    /srv/mm         (for ""multimedia"")
    /srv/mm/music   (all shared music)
    /srv/mm/photos  (all shared photos)
    ...
    ...


I then mount these directories using NFS on all other family computers on the network. I use the same naming convention on each client to keep things simple.
"
1659,1659,2622,"Excel VBA App stops spontaneously with message ""Code execution has been halted""","From what I can see on the web, this is a fairly common complaint, but answers seem to be rarer. The problem is this:

We have a number of Excel VBA apps which work perfectly on a number of users' machines. However on one machine they stop on certain lines of code. It is always the same lines, but those lines seem to have nothing in common with one another.

If you press F5 (run) after the halt, the app continues, so it's almost like a break point has been added. We've tried selecting 'remove all breaks' from the menu and even adding a break and removing it again.

We've had this issue with single apps before and we've 'bodged' it by cutting code out of modules, compiling and then pasting it back in etc.

The problem now seems to relate to Excel itself rather than a single .xls, so we're a little unsure how to manage this.

Any help would be gratefully received :)

Thanks,

Philip Whittington
",Phil Whittington,https://stackoverflow.com/users/223126,"I have came across this issue few times during the development of one complex Excel VBA app. Sometimes Excel started to break VBA object quite randomly. And the only remedy was to reboot machine. After reboot, Excel usually started to act normally.

Soon I have found out that possible solution to this issue is to hit CTRL+Break once when macro is NOT running. Maybe this can help to you too.
",bazinac,https://stackoverflow.com/users/1346521,http://stackoverflow.com/questions/2154699/excel-vba-app-stops-spontaneously-with-message-code-execution-has-been-halted,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.5,0.0,1.0,0.5,1.0,0.5,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,"Excel VBA Application stops automatically with the message ""code execution stopped""","From what I can see on the web, this is a fairly common complaint, but answers seem to be rarer. The problem is this:

We have a number of Excel VBA apps which work perfectly on a number of users' machines. However on one machine they stop on certain lines of code. It is always the same lines, but those lines seem to have nothing in common with one another.

If you press F5 (run) after the halt, the app continues, so it's almost like a break point has been added. We've tried selecting 'remove all breaks' from the menu and even adding a break and removing it again.

We've had this issue with single apps before and we've 'bodged' it by cutting code out of modules, compiling and then pasting it back in etc.

The problem now seems to relate to Excel itself rather than a single .xls, so we're a little unsure how to manage this.

Any help would be gratefully received :)

Thanks,

Philip Whittington
","I have came across this issue few times during the development of one complex Excel VBA app. Sometimes Excel started to break VBA object quite randomly. And the only remedy was to reboot machine. After reboot, Excel usually started to act normally.

Soon I have found out that possible solution to this issue is to hit CTRL+Break once when macro is NOT running. Maybe this can help to you too.
"
4007,4007,6398,MonoTouch: How to save a huge PDF downloaded from an URL incrementally?,"I need to download a huge PDF file from an URL in my MonoTouch iPhone/iPad newsstand app.

The PDF is too big to fit in memory, so I need to save it incrementally with NSData.

My idea is the following: instead of appending all the downloaded data in NSData and at the very end of the download, when I got all data, to store it to a file, I want to execute the download asynchronously in a separate thread and append to a file each received chunk and free my memory, but be certain that if the connection is dropped or the app crashes the download would resume automatically from the last chunk without corrupting the file.

What do you suggest? Is there a better method? How can I do it in MonoTouch? I did't find any documentation or code example about iOS incremental download/resume on the Xamarin website.
",Emanuele Sabetta,https://stackoverflow.com/users/959398,"You can use System.Net.WebClient and use the DownloadFile method, which will stream the data from HTTP to disk, without keeping it in memory.
",miguel.de.icaza,https://stackoverflow.com/users/16929,http://stackoverflow.com/questions/8666648/monotouch-how-to-save-a-huge-pdf-downloaded-from-an-url-incrementally,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.7777777777777778,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,Monotouch: how to save a huge PDF file downloaded from a URL incrementally?,"I need to download a huge PDF file from an URL in my MonoTouch iPhone/iPad newsstand app.

The PDF is too big to fit in memory, so I need to save it incrementally with NSData.

My idea is the following: instead of appending all the downloaded data in NSData and at the very end of the download, when I got all data, to store it to a file, I want to execute the download asynchronously in a separate thread and append to a file each received chunk and free my memory, but be certain that if the connection is dropped or the app crashes the download would resume automatically from the last chunk without corrupting the file.

What do you suggest? Is there a better method? How can I do it in MonoTouch? I did't find any documentation or code example about iOS incremental download/resume on the Xamarin website.
","You can use System.Net.WebClient and use the DownloadFile method, which will stream the data from HTTP to disk, without keeping it in memory.
"
1665,1665,2634,How do I deal with a clinic billing mistake that was sent to collections?,"Recently I created a CreditKarma.com account so that I can keep and eye on my credit.  Upon logging in, I noticed I have a pretty low score (not that surprising since I just opened my first credit card recently), but I had a look around anyway just out of curiosity.

What I found out was that I have three medical bills in collections from my local clinic that total around $250!

What's odd is that I have insurance that should have paid those costs, and I've never received bills from them before for that reason.

What can be done to get this removed from my credit report without paying it, since I wasn't supposed to pay it in the first place.  Likely this started out as just an insurance mistake between the clinic and my insurance.
",Soviero,https://money.stackexchange.com/users/15097,"This happened to me when I went to buy my house. I had an ""outstanding"" $48 and $150 in medical bills due. When I paid them, I got checks 8 weeks later for the exact amounts I'd written, stating that it was over-payment. When I called the hospital, they said that collections didn't have updated billing records.

1) Contact the clinic

Ask if you actually owe anything. They'll be able to pull all of the billing records for your account. If you do owe something, let them know that your insurance was supposed to cover that. If they insist that insurance doesn't / didn't, then you're liable for whatever is left. If it has gone to collections, you'll have to pay through the collections company, not directly to the clinic.

2) Contact the collections company

They are notoriously bad at keeping their records up-to-date, and will continue to report ""unpaid medical"" until you pay it or they clear it. If the clinic says you're paid up, let them know that. They will contact the clinic to get the billing records. Once that's cleared up, move on to...

3) Contact the credit bureaus where this is affecting your history

You can dispute an item to have it removed. They will contact the collections company and raise the dispute. If you've contacted collections, and they know you don't owe anything, they'll clear it when the dispute reaches them. 

This process can take a few months to complete (and for the bad mark to be removed from your report). In general, a single $250 medical bill past due doesn't have a huge effect on your credit score, but it's always good to get it cleared up.
",Noah,https://money.stackexchange.com/users/14835,http://money.stackexchange.com/questions/33596/how-do-i-deal-with-a-clinic-billing-mistake-that-was-sent-to-collections,LIFE_ARTS,money.stackexchange.com,1.0,0.4444444444444444,0.0,0.0,1.0,1.0,0.8888888888888888,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,How to deal with the clinic bill error sent to the cashier?,"Recently I created a CreditKarma.com account so that I can keep and eye on my credit.  Upon logging in, I noticed I have a pretty low score (not that surprising since I just opened my first credit card recently), but I had a look around anyway just out of curiosity.

What I found out was that I have three medical bills in collections from my local clinic that total around $250!

What's odd is that I have insurance that should have paid those costs, and I've never received bills from them before for that reason.

What can be done to get this removed from my credit report without paying it, since I wasn't supposed to pay it in the first place.  Likely this started out as just an insurance mistake between the clinic and my insurance.
","This happened to me when I went to buy my house. I had an ""outstanding"" $48 and $150 in medical bills due. When I paid them, I got checks 8 weeks later for the exact amounts I'd written, stating that it was over-payment. When I called the hospital, they said that collections didn't have updated billing records.

1) Contact the clinic

Ask if you actually owe anything. They'll be able to pull all of the billing records for your account. If you do owe something, let them know that your insurance was supposed to cover that. If they insist that insurance doesn't / didn't, then you're liable for whatever is left. If it has gone to collections, you'll have to pay through the collections company, not directly to the clinic.

2) Contact the collections company

They are notoriously bad at keeping their records up-to-date, and will continue to report ""unpaid medical"" until you pay it or they clear it. If the clinic says you're paid up, let them know that. They will contact the clinic to get the billing records. Once that's cleared up, move on to...

3) Contact the credit bureaus where this is affecting your history

You can dispute an item to have it removed. They will contact the collections company and raise the dispute. If you've contacted collections, and they know you don't owe anything, they'll clear it when the dispute reaches them. 

This process can take a few months to complete (and for the bad mark to be removed from your report). In general, a single $250 medical bill past due doesn't have a huge effect on your credit score, but it's always good to get it cleared up.
"
5078,5078,8079,Macro that follows a link and downloads the table into a new sheet,"I am a geologist working for a small oil company in Louisiana. I constitute our tech department, and unfortunately my experience with coding is quite limited. I have used very basic vba coding in the past, but I dont code that much in my daily job, so I have forgotten most of it.

The louisiana dnr keeps amazing records for every single oil well drilled in the state and all of these records are located at www.Sonris.com. Part of these records are the production records for each well. I would like to create a macro that follows a given url and downloads the table found on the URL (aka the production records). After it downloads the file, I would like it to put the table in a new sheet and then to name this sheet based on the well name. 

I have fooled around with the retrieve data from web function, however I cannot make the function dynamic enough. I need the code to copy the hyperlink data found in a cell. Currently, the code just follows the hyperlink that I copy and paste while recording the macro. 

Any help would be appreciated

Sincerely,
Josiah

Below is the code generated;

    Sub Macro2()
'
'     Macro2 Macro
' attempt with multiple well to look at code instead of 1 well
'

'
    Range(""E27"").Select
    ActiveWorkbook.Worksheets.Add
    With ActiveSheet.QueryTables.Add(Connection:= _
        ""URL;http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=159392"" _
        , Destination:=Range(""$A$1""))
        .Name = ""cart_con_wellinfo2?p_WSN=159392""
        .FieldNames = True
        .RowNumbers = False
        .FillAdjacentFormulas = False
        .PreserveFormatting = True
        .RefreshOnFileOpen = False
        .BackgroundQuery = True
        .RefreshStyle = xlInsertDeleteCells
        .SavePassword = False
        .SaveData = True
        .AdjustColumnWidth = True
        .RefreshPeriod = 0
        .WebSelectionType = xlSpecifiedTables
        .WebFormatting = xlWebFormattingNone
        .WebTables = ""1,11""
        .WebPreFormattedTextToColumns = True
        .WebConsecutiveDelimitersAsOne = True
        .WebSingleBlockTextImport = False
        .WebDisableDateRecognition = False
        .WebDisableRedirections = False
        .Refresh BackgroundQuery:=False
    End With
    Sheets(""Sheet1"").Select
End Sub

",Josiah Hulsey,https://stackoverflow.com/users/4390183,"Just to piggy back on @Jeeped awesome solution, I added in the formating to delete and just have the LeaseUnit/Well/Production info left.  This assumes Casing table always follow the Production table

Option Explicit

Public Const csURL As String = ""http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=ÃWSNÃ""

Sub Gather_Well_Data()
    Dim rw As Long, lr As Long, w As Long, wsn As String, wb As Workbook, frow As String, lrow As String
    On Error GoTo FÃ¬n
    Application.ScreenUpdating = False
    Application.DisplayAlerts = False



    With ThisWorkbook.Sheets(""WSNs"")
        lr = .Cells(Rows.Count, 1).End(xlUp).Row
        For rw = 2 To lr
            .Cells(rw, 2) = 0
            For w = 1 To .Parent.Sheets.Count
                If .Parent.Sheets(w).Name = CStr(.Cells(rw, 1).Value) Then
                    .Parent.Sheets(w).Delete
                    Exit For
                End If
            Next w
            wsn = Replace(csURL, ""ÃWSNÃ"", .Cells(rw, 1).Value)
            Set wb = Workbooks.Open(Filename:=wsn, ReadOnly:=True, addtomru:=False)

            frow = Application.WorksheetFunction.Match(""LEASE\UNIT\WELL PRODUCTION"", Range(""A:A""), 0)
            lrow = Application.WorksheetFunction.Match(""Casing"", Range(""A:A""), 0)
            lrow = lrow - 1
            frow = ""A"" &amp; frow
            lrow = ""K"" &amp; lrow
            Range(frow, lrow).Cut Range(""Q1"")
            Columns(""A:P"").Select
            Selection.Delete Shift:=xlToLeft
            Cells.EntireColumn.AutoFit

            wb.Sheets(1).Range(""A1:A3"").Font.Size = 12
            wb.Sheets(1).Copy After:=.Parent.Sheets(.Parent.Sheets.Count)
            .Parent.Sheets(.Parent.Sheets.Count).Name = .Cells(rw, 1).Value
            wb.Close savechanges:=False
            Set wb = Nothing
            .Cells(rw, 2) = 1
            Application.ScreenUpdating = True
            Application.ScreenUpdating = False
            .Parent.Save
        Next rw
        .Activate
    End With
FÃ¬n:
    Application.DisplayAlerts = True
    Application.ScreenUpdating = True
End Sub

",mrbungle,https://stackoverflow.com/users/2967019,http://stackoverflow.com/questions/27690443/macro-that-follows-a-link-and-downloads-the-table-into-a-new-sheet,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Track links and download tables to macros in new worksheets,"I am a geologist working for a small oil company in Louisiana. I constitute our tech department, and unfortunately my experience with coding is quite limited. I have used very basic vba coding in the past, but I dont code that much in my daily job, so I have forgotten most of it.

The louisiana dnr keeps amazing records for every single oil well drilled in the state and all of these records are located at www.Sonris.com. Part of these records are the production records for each well. I would like to create a macro that follows a given url and downloads the table found on the URL (aka the production records). After it downloads the file, I would like it to put the table in a new sheet and then to name this sheet based on the well name. 

I have fooled around with the retrieve data from web function, however I cannot make the function dynamic enough. I need the code to copy the hyperlink data found in a cell. Currently, the code just follows the hyperlink that I copy and paste while recording the macro. 

Any help would be appreciated

Sincerely,
Josiah

Below is the code generated;

    Sub Macro2()
'
'     Macro2 Macro
' attempt with multiple well to look at code instead of 1 well
'

'
    Range(""E27"").Select
    ActiveWorkbook.Worksheets.Add
    With ActiveSheet.QueryTables.Add(Connection:= _
        ""URL;http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=159392"" _
        , Destination:=Range(""$A$1""))
        .Name = ""cart_con_wellinfo2?p_WSN=159392""
        .FieldNames = True
        .RowNumbers = False
        .FillAdjacentFormulas = False
        .PreserveFormatting = True
        .RefreshOnFileOpen = False
        .BackgroundQuery = True
        .RefreshStyle = xlInsertDeleteCells
        .SavePassword = False
        .SaveData = True
        .AdjustColumnWidth = True
        .RefreshPeriod = 0
        .WebSelectionType = xlSpecifiedTables
        .WebFormatting = xlWebFormattingNone
        .WebTables = ""1,11""
        .WebPreFormattedTextToColumns = True
        .WebConsecutiveDelimitersAsOne = True
        .WebSingleBlockTextImport = False
        .WebDisableDateRecognition = False
        .WebDisableRedirections = False
        .Refresh BackgroundQuery:=False
    End With
    Sheets(""Sheet1"").Select
End Sub

","Just to piggy back on @Jeeped awesome solution, I added in the formating to delete and just have the LeaseUnit/Well/Production info left.  This assumes Casing table always follow the Production table

Option Explicit

Public Const csURL As String = ""http://sonlite.dnr.state.la.us/sundown/cart_prod/cart_con_wellinfo2?p_WSN=ÃWSNÃ""

Sub Gather_Well_Data()
    Dim rw As Long, lr As Long, w As Long, wsn As String, wb As Workbook, frow As String, lrow As String
    On Error GoTo FÃ¬n
    Application.ScreenUpdating = False
    Application.DisplayAlerts = False



    With ThisWorkbook.Sheets(""WSNs"")
        lr = .Cells(Rows.Count, 1).End(xlUp).Row
        For rw = 2 To lr
            .Cells(rw, 2) = 0
            For w = 1 To .Parent.Sheets.Count
                If .Parent.Sheets(w).Name = CStr(.Cells(rw, 1).Value) Then
                    .Parent.Sheets(w).Delete
                    Exit For
                End If
            Next w
            wsn = Replace(csURL, ""ÃWSNÃ"", .Cells(rw, 1).Value)
            Set wb = Workbooks.Open(Filename:=wsn, ReadOnly:=True, addtomru:=False)

            frow = Application.WorksheetFunction.Match(""LEASE\UNIT\WELL PRODUCTION"", Range(""A:A""), 0)
            lrow = Application.WorksheetFunction.Match(""Casing"", Range(""A:A""), 0)
            lrow = lrow - 1
            frow = ""A"" &amp; frow
            lrow = ""K"" &amp; lrow
            Range(frow, lrow).Cut Range(""Q1"")
            Columns(""A:P"").Select
            Selection.Delete Shift:=xlToLeft
            Cells.EntireColumn.AutoFit

            wb.Sheets(1).Range(""A1:A3"").Font.Size = 12
            wb.Sheets(1).Copy After:=.Parent.Sheets(.Parent.Sheets.Count)
            .Parent.Sheets(.Parent.Sheets.Count).Name = .Cells(rw, 1).Value
            wb.Close savechanges:=False
            Set wb = Nothing
            .Cells(rw, 2) = 1
            Application.ScreenUpdating = True
            Application.ScreenUpdating = False
            .Parent.Save
        Next rw
        .Activate
    End With
FÃ¬n:
    Application.DisplayAlerts = True
    Application.ScreenUpdating = True
End Sub

"
4119,4119,6573,How do I prevent unwanted routing errors in production,"ActionController::RoutingError (No route matches [GET] ""/google83362a7a0f381ff0.html""):


I see the above logs in production, how should I prevent it.
If user mistypes a URL, how should I re-direct to a common error page

",Rpj,https://stackoverflow.com/users/1900290,"You can redirect the user to the desire page you want if no route matchs

Write down the following code at the bottom of your routes.rb file

In /config/routes.rb

#If no route matches
match "":url"" =&gt; ""application#redirect_user"", :constraints =&gt; { :url =&gt; /.*/ }


Then redirect the user to the error page in the application_controller.rb file

*In /app/controllers/application_controller.rb*

def redirect_user
  redirect_to '/404'
end

",Suman Ranjan Panda,https://stackoverflow.com/users/1254012,http://stackoverflow.com/questions/17678087/how-do-i-prevent-unwanted-routing-errors-in-production,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,How to prevent unnecessary routing errors in production,"ActionController::RoutingError (No route matches [GET] ""/google83362a7a0f381ff0.html""):


I see the above logs in production, how should I prevent it.
If user mistypes a URL, how should I re-direct to a common error page

","You can redirect the user to the desire page you want if no route matchs

Write down the following code at the bottom of your routes.rb file

In /config/routes.rb

#If no route matches
match "":url"" =&gt; ""application#redirect_user"", :constraints =&gt; { :url =&gt; /.*/ }


Then redirect the user to the error page in the application_controller.rb file

*In /app/controllers/application_controller.rb*

def redirect_user
  redirect_to '/404'
end

"
254,254,410,"Was the Second Doctor's ""regeneration"" actually a regeneration?","I recently saw a mix up of all of the Doctors regeneration scenes.

When the second Doctor changes to the third (from Patrick Troughton to Jon Pertwee in ""The War Games, Part Ten"" (1969)), it is forced on him as punishment before being exiled to earth. The Doctor was not critically injured or dying. The transformation was the Time Lords doing.

Does this really count as one of the 12 regenerations? 
",Keo,https://scifi.stackexchange.com/users/16220,"Yes, that was regeneration.

There is no indication in Old Who or the New Series that regeneration is exclusively limited to being uncontrollably triggered by fatal events.

Although regeneration is usually seen in the show as an ""emergency fail-safe"" feature, we're also shown very explicitly that most Time Lords choose to regenerate for reasons other than imminent death. Romana is the most prominent example, although Borusa also comes to mind (the man seems to have gone through bodies like some people go through ties).

The Doctor just leads such a hard life that his regenerations come more violently than most Time Lords'.

The fact that it was forced on him by the Time Lords doesn't change anything either; the High Council has repeatedly been shown to have control over the regeneration technology (for example, offering the Master a new set of regenerations if he helped them in The Five Doctors). There's no reason to assume that the process they used to change the Second Doctor into the Third was not regeneration; in fact, their dialogue in that scene makes it clear that the process is identical to that which turned the First into the Second (though ""regeneration"" wasn't yet really a term being used by the show).
",BESW,https://scifi.stackexchange.com/users/13941,http://scifi.stackexchange.com/questions/39036/was-the-second-doctors-regeneration-actually-a-regeneration,LIFE_ARTS,scifi.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"Is the second doctor's ""regeneration"" really regeneration?","I recently saw a mix up of all of the Doctors regeneration scenes.

When the second Doctor changes to the third (from Patrick Troughton to Jon Pertwee in ""The War Games, Part Ten"" (1969)), it is forced on him as punishment before being exiled to earth. The Doctor was not critically injured or dying. The transformation was the Time Lords doing.

Does this really count as one of the 12 regenerations? 
","Yes, that was regeneration.

There is no indication in Old Who or the New Series that regeneration is exclusively limited to being uncontrollably triggered by fatal events.

Although regeneration is usually seen in the show as an ""emergency fail-safe"" feature, we're also shown very explicitly that most Time Lords choose to regenerate for reasons other than imminent death. Romana is the most prominent example, although Borusa also comes to mind (the man seems to have gone through bodies like some people go through ties).

The Doctor just leads such a hard life that his regenerations come more violently than most Time Lords'.

The fact that it was forced on him by the Time Lords doesn't change anything either; the High Council has repeatedly been shown to have control over the regeneration technology (for example, offering the Master a new set of regenerations if he helped them in The Five Doctors). There's no reason to assume that the process they used to change the Second Doctor into the Third was not regeneration; in fact, their dialogue in that scene makes it clear that the process is identical to that which turned the First into the Second (though ""regeneration"" wasn't yet really a term being used by the show).
"
2324,2324,3706,"What to call ""Cancel"" when ""Cancel"" is already the default action?","When attempting to cancel a service or setting, ""cancel"" is the default action. What should the normal ""cancel"" button be called?

Redbox uses a playful ""just kidding"", which may not be appropriate in all circumstances.


",Luke Charde,https://ux.stackexchange.com/users/5022,"Rewording

I would try my very, very best to avoid using the term 'cancel' for terminating the subscription. Cancel is generally considered to be a safe action. Here, you are using it in a more destructive sense, thus causing the confusion you noticed.

If you manage to avoid the term 'cancel' for the actual activity, you can resume to use it for the cancel action on the dialog. In the mockup below, I used ""Unsubscribe"", but you can also consider other ways to express this like ""terminate"", ""end"", ""remove"" or ""stop"" subscription.  







download bmml source &ndash; Wireframes created with Balsamiq Mockups

Not confirming at all

Alternatively, you could consider getting rid of the confirmation message completely. Instead, you could display something like this:







download bmml source

You could then also send the users a message by email saying essentially the same thing, and also allowing them to change their mind for a limited time. 
",AndrÃ©,https://ux.stackexchange.com/users/13223,http://ux.stackexchange.com/questions/35753/what-to-call-cancel-when-cancel-is-already-the-default-action,TECHNOLOGY,ux.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.3333333333333333,0.3333333333333333,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,"When cancel is already the default operation, what is the name of cancel?","Cancel is the default action when attempting to cancel a service or setting. What should a normal ""Cancel"" button be called?","Rewording

I would try my very, very best to avoid using the term 'cancel' for terminating the subscription. Cancel is generally considered to be a safe action. Here, you are using it in a more destructive sense, thus causing the confusion you noticed.

If you manage to avoid the term 'cancel' for the actual activity, you can resume to use it for the cancel action on the dialog. In the mockup below, I used ""Unsubscribe"", but you can also consider other ways to express this like ""terminate"", ""end"", ""remove"" or ""stop"" subscription.  







download bmml source &ndash; Wireframes created with Balsamiq Mockups

Not confirming at all

Alternatively, you could consider getting rid of the confirmation message completely. Instead, you could display something like this:







download bmml source

You could then also send the users a message by email saying essentially the same thing, and also allowing them to change their mind for a limited time. 
"
5667,5667,8985,Unable to Import Data,"I am following this tutorial,

but i am not able to get the right username and password to import data. How do I know what the username password is? By default I see tomcat6 as database and username and no password in the textbox. As i am following the tutorial I changed it to username: postgis and password: postgres.

How do I know what my username and password is?

EDIT

Import the data in PostGIS, which requires PostGIS connection.

UPDATE

Ok so i got the user and passwd but when I am trying to add the shapefile using the Shape File to PostGIS Importer Plugin and having made connection successfully, I am getting this error when I am adding the shapefile.

Connecting: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Connection succeeded.
Connection: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Destination: public.AllQuebecSpecies
Source File: /home/smaranh/development/Biodiversity/biodiversity/shapefile/AllQuebecSpecies
Shapefile type: Point
Postgis type: POINT[2]
Failed SQL begins: ""SET CLIENT_ENCODING TO UTF8;
SET STANDARD_CONFORMING_STRINGS TO ON;
BEGIN;
CREATE TABLE ""public"".""AllQuebecSpecies"" (gid serial PRIMARY KEY,
""family"" varchar(50),
""species"" varchar(50));
SELECT AddGeometryColumn('public','AllQuebecSpecies','the_geom','-1""
Failed in pgui_exec(): ERROR:  function addgeometrycolumn(unknown, unknown, unknown, unknown, unknown, integer) does not exist
LINE 7: SELECT AddGeometryColumn('public','AllQuebecSpecies','the_ge...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

Shapefile import failed.


Can somebody tell me where am I going wrong?
",Sam007,https://gis.stackexchange.com/users/4333,"Here is one way to import data in postGIS from shapefile.

http://gis-techniques.blogspot.com/2012/04/how-to-connect-spatial-databasepostgis.html
",EvilInside,https://gis.stackexchange.com/users/3114,http://gis.stackexchange.com/questions/25437/unable-to-import-data,TECHNOLOGY,gis.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.7777777777777778,0.6666666666666666,0.5,0.7777777777777778,0.8888888888888888,0.6,0.6666666666666666,0.0,0.0,0.7777777777777778,Unable to import data,"I am following this tutorial,

but i am not able to get the right username and password to import data. How do I know what the username password is? By default I see tomcat6 as database and username and no password in the textbox. As i am following the tutorial I changed it to username: postgis and password: postgres.

How do I know what my username and password is?

EDIT

Import the data in PostGIS, which requires PostGIS connection.

UPDATE

Ok so i got the user and passwd but when I am trying to add the shapefile using the Shape File to PostGIS Importer Plugin and having made connection successfully, I am getting this error when I am adding the shapefile.

Connecting: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Connection succeeded.
Connection: host=localhost port=5432 user=admin dbname=shpRepo password='**********' 
Destination: public.AllQuebecSpecies
Source File: /home/smaranh/development/Biodiversity/biodiversity/shapefile/AllQuebecSpecies
Shapefile type: Point
Postgis type: POINT[2]
Failed SQL begins: ""SET CLIENT_ENCODING TO UTF8;
SET STANDARD_CONFORMING_STRINGS TO ON;
BEGIN;
CREATE TABLE ""public"".""AllQuebecSpecies"" (gid serial PRIMARY KEY,
""family"" varchar(50),
""species"" varchar(50));
SELECT AddGeometryColumn('public','AllQuebecSpecies','the_geom','-1""
Failed in pgui_exec(): ERROR:  function addgeometrycolumn(unknown, unknown, unknown, unknown, unknown, integer) does not exist
LINE 7: SELECT AddGeometryColumn('public','AllQuebecSpecies','the_ge...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

Shapefile import failed.


Can somebody tell me where am I going wrong?
","Here is one way to import data in postGIS from shapefile.

http://gis-techniques.blogspot.com/2012/04/how-to-connect-spatial-databasepostgis.html
"
5333,5333,8472,Salesforce Mobile SDK Community Registration,"I am developing a mobile application for one of our client using Salesforce SDk. I haven't found any documentation regarding the community registration vai Salsforce SDK. Is this possible? 
Because when i complete the registration from ""Not a member"" link the page is still loading in the webview , not getting redirected to the application ( to mobile). Is there any way to accomplish registration via SDK?
",Ragesh,https://salesforce.stackexchange.com/users/5184,"This link provides all configuration items that you need to have in place to use Communities with the Salesforce Mobile SDK. Depending on the kind of user license, you also need to have appropriate permissions (such as API enabled for Portal users) - refer this link.


SDK does not provide any explicit support for self-registration.

",Gaurav Kheterpal,https://salesforce.stackexchange.com/users/10881,http://salesforce.stackexchange.com/questions/60754/salesforce-mobile-sdk-community-registration,TECHNOLOGY,salesforce.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,0.0,1.0,Salesforce Mobile SDK community registration,"I am developing a mobile application for one of our client using Salesforce SDk. I haven't found any documentation regarding the community registration vai Salsforce SDK. Is this possible? 
Because when i complete the registration from ""Not a member"" link the page is still loading in the webview , not getting redirected to the application ( to mobile). Is there any way to accomplish registration via SDK?
","This link provides all the configuration items needed to use the salesforce Mobile SDK community. Depending on the type of user license, you also need to have the appropriate permissions (such as APIs enabled for portal users) - see this link."
5057,5057,8042,What is the best way for a user to select an item by unique identifier?,"My team and I are building a mobile app where the user will need to input a human-readable unique identifier (the serial number) of a single unit of inventory. Our system tracks the serial numbers that the user can access. We have considered three possible input modes:

1. We show the user the entire list of serial numbers they can access and allow him to select one from the list (like how a select element would work on an HTML page).

Pros:


The user doesn't have to type anything in.
The user can't enter an invalid serial number.


Cons:


The list is likely to be overwhelmingly large.
The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Data usage for downloading the entire list of serial numbers


2. We allow the user to start entering the serial number in a text input and have an auto-suggest drop-down with a filtered list of serial numbers the user can access.

Pros:


The user doesn't have to type in a complete serial number.
The user is unlikely to enter an invalid serial number.
Smaller list to choose from than Option 1.


Cons:


The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Auto-suggest may have limited value since the unit has a barcode that we could read.
Data usage for downloading a sizable list of serial numbers


3. We require the entire serial number to be entered, and once we recognize the correct number of characters, we validate the serial number against the user's accessible list and show feedback.

Pros:


The unit has a barcode that we could read, so this has the potential to be simpler than an auto-suggest or select-from-list paradigm.
Simpler implementation
Significantly reduced data usage vs. Option 1 and Option 2


Cons:


The unit has multiple barcodes, so it might take a couple of tries for the user to capture the correct one.
Typing manually would be tedious if the camera is unavailable or barcode scanner isn't working for whatever reason (lighting, etc.)


Which of these three is the best approach? Is there a better approach than what we have considered?
",Nick Saunders,https://ux.stackexchange.com/users/50391,"Well, if you can do this using barcode OR manual input, and you say serial numbers are sequential, so both teh barcode AND teh serial numbers will have common characters, you can do something like this:

1- Offer the user to scan the barcode (include some hint message)
   1.1 - If user scans barcode
      1.1.1 - on success --&gt; stop
      1.1.2 - on failure --&gt; goto 2
2- Offer the user to manually input the value. Here you can ask to enter barcode or SN number. Strip all common elements and ask your user to input the values that are not common. 
    2.1- If sequentially generated series: ask to enter the last 3, 4, 5 numbers (based on the pattern structure of your serial number)
    2.2- If barcode number, you'll have quite some common numbers. For example, on UPC based barcodes, you'll probably need to ask for the last 4 numbers
3- Validate and provide instant feedback
    3.1 - If correct, stop process and display success message
    --else
    3.2 - Ask user to correct input, go to 3


Sorry about the very basic explanation, but hope it's enough to understand the idea
",Devin,https://ux.stackexchange.com/users/54669,http://ux.stackexchange.com/questions/77187/what-is-the-best-way-for-a-user-to-select-an-item-by-unique-identifier,TECHNOLOGY,ux.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.7777777777777778,What is the best way for users to select items by unique identifier?,"My team and I are building a mobile app where the user will need to input a human-readable unique identifier (the serial number) of a single unit of inventory. Our system tracks the serial numbers that the user can access. We have considered three possible input modes:

1. We show the user the entire list of serial numbers they can access and allow him to select one from the list (like how a select element would work on an HTML page).

Pros:


The user doesn't have to type anything in.
The user can't enter an invalid serial number.


Cons:


The list is likely to be overwhelmingly large.
The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Data usage for downloading the entire list of serial numbers


2. We allow the user to start entering the serial number in a text input and have an auto-suggest drop-down with a filtered list of serial numbers the user can access.

Pros:


The user doesn't have to type in a complete serial number.
The user is unlikely to enter an invalid serial number.
Smaller list to choose from than Option 1.


Cons:


The serial numbers usually have the same format and are often sequential, so it might be hard to read the list.
Auto-suggest may have limited value since the unit has a barcode that we could read.
Data usage for downloading a sizable list of serial numbers


3. We require the entire serial number to be entered, and once we recognize the correct number of characters, we validate the serial number against the user's accessible list and show feedback.

Pros:


The unit has a barcode that we could read, so this has the potential to be simpler than an auto-suggest or select-from-list paradigm.
Simpler implementation
Significantly reduced data usage vs. Option 1 and Option 2


Cons:


The unit has multiple barcodes, so it might take a couple of tries for the user to capture the correct one.
Typing manually would be tedious if the camera is unavailable or barcode scanner isn't working for whatever reason (lighting, etc.)


Which of these three is the best approach? Is there a better approach than what we have considered?
","Well, if you can do this using barcode OR manual input, and you say serial numbers are sequential, so both teh barcode AND teh serial numbers will have common characters, you can do something like this:

1- Offer the user to scan the barcode (include some hint message)
   1.1 - If user scans barcode
      1.1.1 - on success --&gt; stop
      1.1.2 - on failure --&gt; goto 2
2- Offer the user to manually input the value. Here you can ask to enter barcode or SN number. Strip all common elements and ask your user to input the values that are not common. 
    2.1- If sequentially generated series: ask to enter the last 3, 4, 5 numbers (based on the pattern structure of your serial number)
    2.2- If barcode number, you'll have quite some common numbers. For example, on UPC based barcodes, you'll probably need to ask for the last 4 numbers
3- Validate and provide instant feedback
    3.1 - If correct, stop process and display success message
    --else
    3.2 - Ask user to correct input, go to 3


Sorry about the very basic explanation, but hope it's enough to understand the idea
"
1082,1082,1710,Preventing player passivity in GUMSHOE?,"I really like the game worlds of the various GUMSHOE games I have (Fear Itself, Esoterrorists, Mutant City Blues) but haven't run it yet.  My big concern is that I've seen the ""ablative skill system"" kind of mechanic work very poorly in other games - players hoard their ""uses,"" or use them all and then sit on their hands during the latter part of the game session because they know they're not going to be able to succeed at anything and trying will just get them killed.  

In GUMSHOE, your skills are a ""pool"" of points that you spend either for benefits or for adds to the dice when testing.  You basically roll d6 + spend vs a difficulty, typically 4 for general stuff but often going higher.  Fighting works the same way, so if you have a Scuffling pool of 8, once you've used them all, you know you won't live through any meaningful combat.  

For those that have run GUMSHOE or similar ablative systems, do you find that happening, and what are ways to avoid it?  I mean, I don't mind trying to capture the ""downward spiral"" but it risks characters just checking out if they don't think whatever plot is at hand is really worth all their lives.  ""Let's try to save her next session..."" 
",mxyzplk,https://rpg.stackexchange.com/users/140,"It seems to me that there are a number of things that you could do to help ameliorate this sort of risk.

The first would be to allow ablative skills to regenerate more frequently rather than just at the start of a session. If you intend to have a couple of scenes in a session which require the same skills (such as a combat), allow the PCs to regenerate their skills between. This would allow for the drama of getting tired (running out of points) during a scene, without that scene affecting others. Depending on how finely tuned GUMSHOE is however, this could be unbalancing.

Another option would be to reward ingenuity, good tactics, good role-playing or heroism etc. with point pool replenishments after or even during the scene. Since it's more under your control, it should be less prone to unbalancing the game.

I have seen this sort of thing with players in card based systems like SAGA, but only with relatively new players. Once you've played SAGA for a while you realise that the best thing you can do with a hand of low cards is to play them and hope to draw better cards, so any solution to this problem is likely to involve players being encouraged to be more active, more inventive, more dramatic when they get down to fewer pool points.

I know my thoughts are rather general, since I haven't played GUMSHOE, but I hope they were useful nevertheless.
",Mark Booth,https://rpg.stackexchange.com/users/1658,http://rpg.stackexchange.com/questions/2311/preventing-player-passivity-in-gumshoe,CULTURE,rpg.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.0,1.0,Prevent players from being passive in rubber shoes?,"I really like the game worlds of the various GUMSHOE games I have (Fear Itself, Esoterrorists, Mutant City Blues) but haven't run it yet.  My big concern is that I've seen the ""ablative skill system"" kind of mechanic work very poorly in other games - players hoard their ""uses,"" or use them all and then sit on their hands during the latter part of the game session because they know they're not going to be able to succeed at anything and trying will just get them killed.  

In GUMSHOE, your skills are a ""pool"" of points that you spend either for benefits or for adds to the dice when testing.  You basically roll d6 + spend vs a difficulty, typically 4 for general stuff but often going higher.  Fighting works the same way, so if you have a Scuffling pool of 8, once you've used them all, you know you won't live through any meaningful combat.  

For those that have run GUMSHOE or similar ablative systems, do you find that happening, and what are ways to avoid it?  I mean, I don't mind trying to capture the ""downward spiral"" but it risks characters just checking out if they don't think whatever plot is at hand is really worth all their lives.  ""Let's try to save her next session..."" 
","It seems to me that there are a number of things that you could do to help ameliorate this sort of risk.

The first would be to allow ablative skills to regenerate more frequently rather than just at the start of a session. If you intend to have a couple of scenes in a session which require the same skills (such as a combat), allow the PCs to regenerate their skills between. This would allow for the drama of getting tired (running out of points) during a scene, without that scene affecting others. Depending on how finely tuned GUMSHOE is however, this could be unbalancing.

Another option would be to reward ingenuity, good tactics, good role-playing or heroism etc. with point pool replenishments after or even during the scene. Since it's more under your control, it should be less prone to unbalancing the game.

I have seen this sort of thing with players in card based systems like SAGA, but only with relatively new players. Once you've played SAGA for a while you realise that the best thing you can do with a hand of low cards is to play them and hope to draw better cards, so any solution to this problem is likely to involve players being encouraged to be more active, more inventive, more dramatic when they get down to fewer pool points.

I know my thoughts are rather general, since I haven't played GUMSHOE, but I hope they were useful nevertheless.
"
3989,3989,6367,Why does this sequence converges to $\pi$?,"One of my daughters was having a small programming exercise. 

Let's consider following algorithm:


Take a list of length $n$: $\ (1\,\ 2\,\ \ldots\,\ n)$.
Remove every $2$nd number.
From the resulting list, remove every $3$rd number.
From the resulting list, remove every $4$th number.
... Follow on until the list remains unchanged and let $u_n$ be the number of remaining elements.


Example with $n=11$


$(\ 1\,\ 2\,\ 3\,\ 4\,\ 5\,\ 6\,\ 7\,\ 8\,\ 9\,\ 10\,\ 11\ )\quad \Rightarrow\quad (\ 1\ *\ 3\ *\ 5\ *\ 7\ *\ 9 \ *\ 11\ )$
$(\ 1\,\ 3\,\ 5\,\ 7\,\ 9\,\ 11\ )\quad \Rightarrow\quad (\ 1\,\ 3\ *\ 7\,\ 9\ *\ )$
$(\ 1\, 3\,\ 7\,\ 9\ )\quad \Rightarrow\quad (\ 1\,\ 3\,\ 7\ *\ )$
$(\ 1\,\ 3\,\ 7\ )\ $ -- will not be modified anymore, and therefore $u_n=3$.


QUESTION: &nbsp; why do we have $\lim\limits_{n \to +\infty} \frac{n}{u_n^2}=\frac{\pi}{4}$ ?

Thanks!
",mathcounterexamples.net,https://mathoverflow.net/users/41060,"This problem was studied first by the founder of sieve theory, Brun himself, who proved this asymptotic.  For a fairly recent paper on this subject look at Andersson who gives more precise estimates for $u_n$.  The MO question Sequences with integral means is also closely related, and see also my answer there.  
",Lucia,https://mathoverflow.net/users/38624,http://mathoverflow.net/questions/193933,SCIENCE,mathoverflow.net,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.5,1.0,1.0,0.8,0.0,0.0,0.3333333333333333,0.8888888888888888,Why does this sequence converge to $\ PI $?,"One of my daughters was having a small programming exercise. 

Let's consider following algorithm:


Take a list of length $n$: $\ (1\,\ 2\,\ \ldots\,\ n)$.
Remove every $2$nd number.
From the resulting list, remove every $3$rd number.
From the resulting list, remove every $4$th number.
... Follow on until the list remains unchanged and let $u_n$ be the number of remaining elements.


Example with $n=11$


$(\ 1\,\ 2\,\ 3\,\ 4\,\ 5\,\ 6\,\ 7\,\ 8\,\ 9\,\ 10\,\ 11\ )\quad \Rightarrow\quad (\ 1\ *\ 3\ *\ 5\ *\ 7\ *\ 9 \ *\ 11\ )$
$(\ 1\,\ 3\,\ 5\,\ 7\,\ 9\,\ 11\ )\quad \Rightarrow\quad (\ 1\,\ 3\ *\ 7\,\ 9\ *\ )$
$(\ 1\, 3\,\ 7\,\ 9\ )\quad \Rightarrow\quad (\ 1\,\ 3\,\ 7\ *\ )$
$(\ 1\,\ 3\,\ 7\ )\ $ -- will not be modified anymore, and therefore $u_n=3$.


QUESTION: &nbsp; why do we have $\lim\limits_{n \to +\infty} \frac{n}{u_n^2}=\frac{\pi}{4}$ ?

Thanks!
","This problem was studied first by the founder of sieve theory, Brun himself, who proved this asymptotic.  For a fairly recent paper on this subject look at Andersson who gives more precise estimates for $u_n$.  The MO question Sequences with integral means is also closely related, and see also my answer there.  
"
887,887,1407,What do you call a group of people that move a lot?,"I can't think of the word to describe it. Something similar to ""wanderer"" or ""roamer"". 

It's often used to describe people that don't stay in one place... not ""migratory""...
",Marty,https://english.stackexchange.com/users/9704,"I voted up ""nomadic"" because it is probably the best word to use. However, if we are asking about English as it is commonly used, I have most often heard the word ""gypsy"" used for that type of person. 

The problem is that this is the name of an actual group of people in Europe, and thus the term is somewhat racist. Oddly, it mostly lost its negative connotations here in the USA, but I suspect that isn't the case the closer you get to their homeland in Eastern Europe.

Anyway, if you are talking about an actual culture of people (as it looks like you are), calling them ""gypsies"" when they aren't actually ethnic gypsies would be very confusing.
",T.E.D.,https://english.stackexchange.com/users/9186,http://english.stackexchange.com/questions/29078/what-do-you-call-a-group-of-people-that-move-a-lot,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,What do you call people who move a lot?,"I can't think of the word to describe it. Something similar to ""wanderer"" or ""roamer"". 

It's often used to describe people that don't stay in one place... not ""migratory""...
","I voted up ""nomadic"" because it is probably the best word to use. However, if we are asking about English as it is commonly used, I have most often heard the word ""gypsy"" used for that type of person. 

The problem is that this is the name of an actual group of people in Europe, and thus the term is somewhat racist. Oddly, it mostly lost its negative connotations here in the USA, but I suspect that isn't the case the closer you get to their homeland in Eastern Europe.

Anyway, if you are talking about an actual culture of people (as it looks like you are), calling them ""gypsies"" when they aren't actually ethnic gypsies would be very confusing.
"
4179,4179,6668,Lyx citation problem,"I'm trying to get citations working with LyX but I've found that I'm getting the entire citation listed. So where it should say [1] I am getting Example(John Toshâ¦) ect. My document preamble is:

\usepackage{nag}
\usepackage[style=british]{csquotes}
\usepackage{fancyhdr} 
\usepackage{microtype}
\usepackage[T1]{fontenc}
\usepackage{pslatex}
\usepackage[style=oscola,
natbib=true]{biblatex}
\bibliography{/Users/jamie/Documents/Law and History}


Is there a way to resolve this?

MWE:

\documentclass[british]{article}
\usepackage{mathpazo}
\usepackage[OT1]{fontenc}
\usepackage[latin9]{inputenc}

\makeatletter
\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.

\usepackage[natbib=true,
style=numeric,
style=oscola]{biblatex}
\bibliography{/Users/jamie/Documents/Law and History}


\usepackage{babel}
\begin{document}
THE QUICK BROWN FOX JUMPED OVER THE LAZY DOG\citet{Tosh:2010aa} dfdasfads
\citep{Tosh:2010aa}



\printbibliography
\end{document}


With that document I am getting: THE QUICK BROWN FOX JUMPED OVER THE LAZY DOG\footciteref Tosh dfdasfads (ibid)' instead ofthe quick brown fox jumped over the lazy dog. [1]
",Jim,https://tex.stackexchange.com/users/50100,"Here is a partial, possible solution. I'm not sure if this will work for you or not because it depends a great deal on what else is going on in your document. This reformats footnote markers so that they conform to the requirements of the citation style.

I've used a sample bib entry from the example file provided by the package and some of the code you originally posted. I've also noted a couple of other things I think you could improve easily in terms of options you are using.

\documentclass[british]{article}
\usepackage{babel}
\usepackage[T1]{fontenc}% much better than OT1
\usepackage{mathpazo}
\usepackage[utf8]{inputenc}% much better to switch to utf8 if you can
\usepackage[style=british]{csquotes}
\usepackage[style=oscola,natbib=true]{biblatex}
\usepackage{filecontents}
\begin{filecontents}{\jobname.bib}
@legislation{gorchymyn,
    title          = {Gorchymyn Mesur Teithio gan Ddysgwyr (Cymru) (Cychwyn Rhif 2)\nopunct},
    number         = {SI 2009\slash 2819},
    pagination     = {regulation},
    keywords       = {cy},
    userb          = {Cy 245},
    entrysubtype   = {secondary},
    language       = {welsh},
}% entry from oscola documentation
\end{filecontents}

\bibliography{\jobname}
\let\citet\footcite% horrible kludge

\makeatletter
  \def\@makefnmark{\hbox{\normalfont[\@thefnmark]}}% this redefines the way footnote markers are formatted. It will affect *all* footnotes - not just citations.
\makeatother

\begin{document}

THE QUICK BROWN FOX JUMPED OVER THE LAZY DOG\citet{gorchymyn} dfdasfads

\printbibliography

\end{document}




\citet does not seem to work without a kludge (above) but \citep does.
",cfr,https://tex.stackexchange.com/users/39222,http://tex.stackexchange.com/questions/172126/lyx-citation-problem,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,1.0,Lyx citation questions,"I'm trying to get citations working with LyX but I've found that I'm getting the entire citation listed. So where it should say [1] I am getting Example(John Toshâ¦) ect. My document preamble is:

\usepackage{nag}
\usepackage[style=british]{csquotes}
\usepackage{fancyhdr} 
\usepackage{microtype}
\usepackage[T1]{fontenc}
\usepackage{pslatex}
\usepackage[style=oscola,
natbib=true]{biblatex}
\bibliography{/Users/jamie/Documents/Law and History}


Is there a way to resolve this?

MWE:

\documentclass[british]{article}
\usepackage{mathpazo}
\usepackage[OT1]{fontenc}
\usepackage[latin9]{inputenc}

\makeatletter
\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.

\usepackage[natbib=true,
style=numeric,
style=oscola]{biblatex}
\bibliography{/Users/jamie/Documents/Law and History}


\usepackage{babel}
\begin{document}
THE QUICK BROWN FOX JUMPED OVER THE LAZY DOG\citet{Tosh:2010aa} dfdasfads
\citep{Tosh:2010aa}



\printbibliography
\end{document}


With that document I am getting: THE QUICK BROWN FOX JUMPED OVER THE LAZY DOG\footciteref Tosh dfdasfads (ibid)' instead ofthe quick brown fox jumped over the lazy dog. [1]
","Here is a partial, possible solution. I'm not sure if this will work for you or not because it depends a great deal on what else is going on in your document. This reformats footnote markers so that they conform to the requirements of the citation style.

I've used a sample bib entry from the example file provided by the package and some of the code you originally posted. I've also noted a couple of other things I think you could improve easily in terms of options you are using.

\documentclass[british]{article}
\usepackage{babel}
\usepackage[T1]{fontenc}% much better than OT1
\usepackage{mathpazo}
\usepackage[utf8]{inputenc}% much better to switch to utf8 if you can
\usepackage[style=british]{csquotes}
\usepackage[style=oscola,natbib=true]{biblatex}
\usepackage{filecontents}
\begin{filecontents}{\jobname.bib}
@legislation{gorchymyn,
    title          = {Gorchymyn Mesur Teithio gan Ddysgwyr (Cymru) (Cychwyn Rhif 2)\nopunct},
    number         = {SI 2009\slash 2819},
    pagination     = {regulation},
    keywords       = {cy},
    userb          = {Cy 245},
    entrysubtype   = {secondary},
    language       = {welsh},
}% entry from oscola documentation
\end{filecontents}

\bibliography{\jobname}
\let\citet\footcite% horrible kludge

\makeatletter
  \def\@makefnmark{\hbox{\normalfont[\@thefnmark]}}% this redefines the way footnote markers are formatted. It will affect *all* footnotes - not just citations.
\makeatother

\begin{document}

THE QUICK BROWN FOX JUMPED OVER THE LAZY DOG\citet{gorchymyn} dfdasfads

\printbibliography

\end{document}




\citet does not seem to work without a kludge (above) but \citep does.
"
3980,3980,6354,Creating Excel document is very slow,"Attached is a generic code I wrote to create an Excel file with x number of worksheets.

The problem I am having is that it's pretty slow, like 5 seconds a sheet. It was my understanding that using a for loop when creating the tables was ideal, but the issue seems to be with tables containing over a thousand or so records... still wouldn't think it should take this long.

Any pointers would be appreciated, also, if I am completely left field with this code let me know, up-to-date Excel code resources seem to be hard to find.

public static string Export(string excelFileName, 
                            string[] excelWorksheetName, 
                            string tableStyle, 
                            params System.Data.DataTable[] dt)
{
    Application xls = new Application();
    xls.SheetsInNewWorkbook = dt.Length;

    // Create our new excel application and add our workbooks/worksheets
    Workbooks workbooks = xls.Workbooks;
    Workbook workbook = workbooks.Add();
    // Hide our excel object if it's visible.
    xls.Visible = false;
    // Turn off calculations if set to automatic; this can help prevent memory leaks.
    xls.Calculation = xls.Calculation == XlCalculation.xlCalculationAutomatic ? XlCalculation.xlCalculationManual : XlCalculation.xlCalculationManual;
    // Turn off screen updating so our export will process more quickly.
    xls.ScreenUpdating = false;
    // Create an excel table and fill it will our query table.

    int iterator = dt.Length - 1;
    for (int i = 0; i &lt;= iterator; i++)
    {
        // Turn off calculations if set to automatic; this can help prevent memory leaks.
        Worksheet worksheet = (Worksheet)xls.Worksheets[i + 1];
        worksheet.Name = excelWorksheetName[i];
        worksheet.Select();
        if (dt[i].Rows.Count &gt; 0)
        {
            // Format this information as a table.
            Range tblRange = worksheet.get_Range(""$A$1"");//string.Format(""$A$1"", dt[i].Rows.Count + 1));
            tblRange.Worksheet.ListObjects.Add(XlListObjectSourceType.xlSrcRange,
                                               tblRange,
                                               System.Type.Missing,
                                               XlYesNoGuess.xlYes,
                                               System.Type.Missing).Name = excelWorksheetName[i];
            tblRange.Select();
            tblRange.Worksheet.ListObjects[excelWorksheetName[i]].TableStyle = tableStyle;
            // Create a row with our column headers.
            for (int column = 0; column &lt; dt[i].Columns.Count; column++)
            {
                worksheet.Cells[1, column + 1] = dt[i].Columns[column].ColumnName;
            }

            // Export our data table information to excel.
            for (int row = 0; row &lt; dt[i].Rows.Count; row++)
            {
                for (int column = 0; column &lt; dt[i].Columns.Count; column++)
                {
                    worksheet.Cells[row + 2, column + 1] = (dt[i].Rows[row][column].ToString());
                }
            }
        }
        // Freeze our column headers.
        xls.Application.Range[""2:2""].Select();
        xls.ActiveWindow.FreezePanes = true;

        xls.ActiveWindow.DisplayGridlines = false;

        // Auto fit our rows and columns.
        xls.Application.Cells.EntireColumn.AutoFit();
        xls.Application.Cells.EntireRow.AutoFit();

        // Select the first cell in the worksheet.
        xls.Application.Range[""$A$2""].Select();

        // Turn off alerts to prevent asking for 'overwrite existing' and 'save changes' messages.
        xls.DisplayAlerts = false;
    }
    string SaveFilePath = string.Format(@""{0}.xls"", excelFileName);
    workbook.SaveAs(SaveFilePath, XlFileFormat.xlWorkbookNormal, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlExclusive, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);
    workbook.Close();

    // Release our resources.
    Marshal.ReleaseComObject(workbook);
    Marshal.ReleaseComObject(workbooks);
    Marshal.ReleaseComObject(xls);
    Marshal.FinalReleaseComObject(xls);

    return SaveFilePath;
}

",Volearix,https://codereview.stackexchange.com/users/38632,"Completed the new code, runs much faster than before without switching to XML options. This is almost instantaneous creation even with large files.

public static string Export(string excelFileName, 
                            string[] excelWorksheetName, 
                            string tableStyle, 
                            params System.Data.DataTable[] dt)
{
    Application excel = new Application();
    excel.DisplayAlerts = false;
    excel.Visible = false;
    excel.ScreenUpdating = false;

    Workbooks workbooks = excel.Workbooks;
    Workbook workbook = workbooks.Add(Type.Missing);

    // Count of data tables provided.
    int iterator = dt.Length;
    for (int i = 0; i &lt; iterator; i++)
    {
        Sheets worksheets = workbook.Sheets;
        Worksheet worksheet = (Worksheet)worksheets[i + 1];
        worksheet.Name = excelWorksheetName[i];

        int rows = dt[i].Rows.Count;
        int columns = dt[i].Columns.Count;
        // Add the +1 to allow room for column headers.
        var data = new object[rows + 1, columns];

        // Insert column headers.
        for (var column = 0; column &lt; columns; column++)
        {
            data[0, column] = dt[i].Columns[column].ColumnName;
        }

        // Insert the provided records.
        for (var row = 0; row &lt; rows; row++)
        {
            for (var column = 0; column &lt; columns; column++)
            {
                data[row + 1, column] = dt[i].Rows[row][column];
            }
        }

        // Write this data to the excel worksheet.
        Range beginWrite = (Range)worksheet.Cells[1, 1];
        Range endWrite = (Range)worksheet.Cells[rows + 1, columns];
        Range sheetData = worksheet.Range[beginWrite, endWrite];
        sheetData.Value2 = data;

        // Additional row, column and table formatting.
        worksheet.Select();
        sheetData.Worksheet.ListObjects.Add(XlListObjectSourceType.xlSrcRange,
                                           sheetData,
                                           System.Type.Missing,
                                           XlYesNoGuess.xlYes,
                                           System.Type.Missing).Name = excelWorksheetName[i];
        sheetData.Select();
        sheetData.Worksheet.ListObjects[excelWorksheetName[i]].TableStyle = tableStyle;
        excel.Application.Range[""2:2""].Select();
        excel.ActiveWindow.FreezePanes = true;
        excel.ActiveWindow.DisplayGridlines = false;
        excel.Application.Cells.EntireColumn.AutoFit();
        excel.Application.Cells.EntireRow.AutoFit();

        // Select the first cell in the worksheet.
        excel.Application.Range[""$A$2""].Select();
    }

    // Turn off alerts to prevent asking for 'overwrite existing' and 'save changes' messages.
    excel.DisplayAlerts = false;

    // Save our workbook and close excel.
    string SaveFilePath = string.Format(@""{0}.xls"", excelFileName);
    workbook.SaveAs(SaveFilePath, XlFileFormat.xlWorkbookNormal, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlExclusive, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);
    workbook.Close(false, Type.Missing, Type.Missing);
    excel.Quit();

    // Release our resources.
    Marshal.ReleaseComObject(workbook);
    Marshal.ReleaseComObject(workbooks);
    Marshal.ReleaseComObject(excel);
    Marshal.FinalReleaseComObject(excel);

    return SaveFilePath;
}

",Volearix,https://codereview.stackexchange.com/users/38632,http://codereview.stackexchange.com/questions/44169/creating-excel-document-is-very-slow,TECHNOLOGY,codereview.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Creating EXCEL documents is very slow,"Attached is a generic code I wrote to create an Excel file with x number of worksheets.

The problem I am having is that it's pretty slow, like 5 seconds a sheet. It was my understanding that using a for loop when creating the tables was ideal, but the issue seems to be with tables containing over a thousand or so records... still wouldn't think it should take this long.

Any pointers would be appreciated, also, if I am completely left field with this code let me know, up-to-date Excel code resources seem to be hard to find.

public static string Export(string excelFileName, 
                            string[] excelWorksheetName, 
                            string tableStyle, 
                            params System.Data.DataTable[] dt)
{
    Application xls = new Application();
    xls.SheetsInNewWorkbook = dt.Length;

    // Create our new excel application and add our workbooks/worksheets
    Workbooks workbooks = xls.Workbooks;
    Workbook workbook = workbooks.Add();
    // Hide our excel object if it's visible.
    xls.Visible = false;
    // Turn off calculations if set to automatic; this can help prevent memory leaks.
    xls.Calculation = xls.Calculation == XlCalculation.xlCalculationAutomatic ? XlCalculation.xlCalculationManual : XlCalculation.xlCalculationManual;
    // Turn off screen updating so our export will process more quickly.
    xls.ScreenUpdating = false;
    // Create an excel table and fill it will our query table.

    int iterator = dt.Length - 1;
    for (int i = 0; i &lt;= iterator; i++)
    {
        // Turn off calculations if set to automatic; this can help prevent memory leaks.
        Worksheet worksheet = (Worksheet)xls.Worksheets[i + 1];
        worksheet.Name = excelWorksheetName[i];
        worksheet.Select();
        if (dt[i].Rows.Count &gt; 0)
        {
            // Format this information as a table.
            Range tblRange = worksheet.get_Range(""$A$1"");//string.Format(""$A$1"", dt[i].Rows.Count + 1));
            tblRange.Worksheet.ListObjects.Add(XlListObjectSourceType.xlSrcRange,
                                               tblRange,
                                               System.Type.Missing,
                                               XlYesNoGuess.xlYes,
                                               System.Type.Missing).Name = excelWorksheetName[i];
            tblRange.Select();
            tblRange.Worksheet.ListObjects[excelWorksheetName[i]].TableStyle = tableStyle;
            // Create a row with our column headers.
            for (int column = 0; column &lt; dt[i].Columns.Count; column++)
            {
                worksheet.Cells[1, column + 1] = dt[i].Columns[column].ColumnName;
            }

            // Export our data table information to excel.
            for (int row = 0; row &lt; dt[i].Rows.Count; row++)
            {
                for (int column = 0; column &lt; dt[i].Columns.Count; column++)
                {
                    worksheet.Cells[row + 2, column + 1] = (dt[i].Rows[row][column].ToString());
                }
            }
        }
        // Freeze our column headers.
        xls.Application.Range[""2:2""].Select();
        xls.ActiveWindow.FreezePanes = true;

        xls.ActiveWindow.DisplayGridlines = false;

        // Auto fit our rows and columns.
        xls.Application.Cells.EntireColumn.AutoFit();
        xls.Application.Cells.EntireRow.AutoFit();

        // Select the first cell in the worksheet.
        xls.Application.Range[""$A$2""].Select();

        // Turn off alerts to prevent asking for 'overwrite existing' and 'save changes' messages.
        xls.DisplayAlerts = false;
    }
    string SaveFilePath = string.Format(@""{0}.xls"", excelFileName);
    workbook.SaveAs(SaveFilePath, XlFileFormat.xlWorkbookNormal, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlExclusive, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);
    workbook.Close();

    // Release our resources.
    Marshal.ReleaseComObject(workbook);
    Marshal.ReleaseComObject(workbooks);
    Marshal.ReleaseComObject(xls);
    Marshal.FinalReleaseComObject(xls);

    return SaveFilePath;
}

","Completed the new code, runs much faster than before without switching to XML options. This is almost instantaneous creation even with large files.

public static string Export(string excelFileName, 
                            string[] excelWorksheetName, 
                            string tableStyle, 
                            params System.Data.DataTable[] dt)
{
    Application excel = new Application();
    excel.DisplayAlerts = false;
    excel.Visible = false;
    excel.ScreenUpdating = false;

    Workbooks workbooks = excel.Workbooks;
    Workbook workbook = workbooks.Add(Type.Missing);

    // Count of data tables provided.
    int iterator = dt.Length;
    for (int i = 0; i &lt; iterator; i++)
    {
        Sheets worksheets = workbook.Sheets;
        Worksheet worksheet = (Worksheet)worksheets[i + 1];
        worksheet.Name = excelWorksheetName[i];

        int rows = dt[i].Rows.Count;
        int columns = dt[i].Columns.Count;
        // Add the +1 to allow room for column headers.
        var data = new object[rows + 1, columns];

        // Insert column headers.
        for (var column = 0; column &lt; columns; column++)
        {
            data[0, column] = dt[i].Columns[column].ColumnName;
        }

        // Insert the provided records.
        for (var row = 0; row &lt; rows; row++)
        {
            for (var column = 0; column &lt; columns; column++)
            {
                data[row + 1, column] = dt[i].Rows[row][column];
            }
        }

        // Write this data to the excel worksheet.
        Range beginWrite = (Range)worksheet.Cells[1, 1];
        Range endWrite = (Range)worksheet.Cells[rows + 1, columns];
        Range sheetData = worksheet.Range[beginWrite, endWrite];
        sheetData.Value2 = data;

        // Additional row, column and table formatting.
        worksheet.Select();
        sheetData.Worksheet.ListObjects.Add(XlListObjectSourceType.xlSrcRange,
                                           sheetData,
                                           System.Type.Missing,
                                           XlYesNoGuess.xlYes,
                                           System.Type.Missing).Name = excelWorksheetName[i];
        sheetData.Select();
        sheetData.Worksheet.ListObjects[excelWorksheetName[i]].TableStyle = tableStyle;
        excel.Application.Range[""2:2""].Select();
        excel.ActiveWindow.FreezePanes = true;
        excel.ActiveWindow.DisplayGridlines = false;
        excel.Application.Cells.EntireColumn.AutoFit();
        excel.Application.Cells.EntireRow.AutoFit();

        // Select the first cell in the worksheet.
        excel.Application.Range[""$A$2""].Select();
    }

    // Turn off alerts to prevent asking for 'overwrite existing' and 'save changes' messages.
    excel.DisplayAlerts = false;

    // Save our workbook and close excel.
    string SaveFilePath = string.Format(@""{0}.xls"", excelFileName);
    workbook.SaveAs(SaveFilePath, XlFileFormat.xlWorkbookNormal, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlExclusive, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);
    workbook.Close(false, Type.Missing, Type.Missing);
    excel.Quit();

    // Release our resources.
    Marshal.ReleaseComObject(workbook);
    Marshal.ReleaseComObject(workbooks);
    Marshal.ReleaseComObject(excel);
    Marshal.FinalReleaseComObject(excel);

    return SaveFilePath;
}

"
1048,1048,1648,Regular Expression to Match String Exactly?,"I'll preface this question by mentioning that while I'm far from a regular expressions guru, they are not completely foreign to me. Building a regular expression to search for a pattern inside a particular string generally isn't a problem for me, but I have a (maybe?) unique situation.

I have a set of values, say:


  028938
  DEF567987
  390987.456
  GHI345928.039  


I want to match a certain set of strings, such as:


Strings composed of exactly 6 digits
Strings composed of exactly 6 digits, a decimal, followed by exactly 3 more digits


In the above examples, the first and third values should be matched.

I'm using the regular expressions:

[0-9]{6}
[0-9]{6}.[0-9]{3}


Unfortunately, since all the above examples contain the specified pattern, all values are matched. This is not my intention.

So my question, in a nutshell, is how to write a regular expression that matches a string exactly and completely, with no additional characters to the right or left of the matched pattern? Is there a term for this type of matching? (Google was no help.) TIA
",Craig Otis,https://stackoverflow.com/users/88111,"^\d{6}$
^\d{6}\.\d{3}$


are the correct patterns you can test them 6 digits only and 6 digits dot 3 digits.

^\d{6}((\.\d{3}$)|$)


will match either 6 digits or 6 digits dot 3 digits

Rubular is your friend!
",Jarrod Roberson,https://stackoverflow.com/users/177800,http://stackoverflow.com/questions/3479324/regular-expression-to-match-string-exactly,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,1.0,0.8333333333333334,0.7,0.5,0.0,0.0,0.6666666666666666,A regular expression that exactly matches a string?,"I'll preface this question by mentioning that while I'm far from a regular expressions guru, they are not completely foreign to me. Building a regular expression to search for a pattern inside a particular string generally isn't a problem for me, but I have a (maybe?) unique situation.

I have a set of values, say:


  028938
  DEF567987
  390987.456
  GHI345928.039  


I want to match a certain set of strings, such as:


Strings composed of exactly 6 digits
Strings composed of exactly 6 digits, a decimal, followed by exactly 3 more digits


In the above examples, the first and third values should be matched.

I'm using the regular expressions:

[0-9]{6}
[0-9]{6}.[0-9]{3}


Unfortunately, since all the above examples contain the specified pattern, all values are matched. This is not my intention.

So my question, in a nutshell, is how to write a regular expression that matches a string exactly and completely, with no additional characters to the right or left of the matched pattern? Is there a term for this type of matching? (Google was no help.) TIA
","^\d{6}$
^\d{6}\.\d{3}$


are the correct patterns you can test them 6 digits only and 6 digits dot 3 digits.

^\d{6}((\.\d{3}$)|$)


will match either 6 digits or 6 digits dot 3 digits

Rubular is your friend!
"
6044,6044,9589,"What is another way to put ""mistaken about what one saw""?","Is there any more slangy/easy way of saying ""mistakenly about what one saw""?
Like in the below example what else can be replaced Maybe I was mistaken.?


  A: I think I heard something in the dark.
  
  B: I didn't hear anything.
  
  A: Maybe I was mistaken.

",user49119,https://ell.stackexchange.com/users/3086,"There is nothing wrong with ""Maybe I was mistaken.""
It does seem odd because Mistaken is more formal than maybe.
I think it would be more congruent to say ""Perhaps I was mistaken."" 

Something less formal with the same meaning:
""I could be wrong.""
",Kirt,https://ell.stackexchange.com/users/20756,http://ell.stackexchange.com/questions/19037/what-is-another-way-to-put-mistaken-about-what-one-saw,CULTURE,ell.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,0.0,0.3333333333333333,0.7777777777777778,0.8888888888888888,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,0.0,1.0,What else can you do to make a mistake about what a person sees?,"Is there any more slangy/easy way of saying ""mistakenly about what one saw""?
Like in the below example what else can be replaced Maybe I was mistaken.?


  A: I think I heard something in the dark.
  
  B: I didn't hear anything.
  
  A: Maybe I was mistaken.

","There is nothing wrong with ""Maybe I was mistaken.""
It does seem odd because Mistaken is more formal than maybe.
I think it would be more congruent to say ""Perhaps I was mistaken."" 

Something less formal with the same meaning:
""I could be wrong.""
"
2936,2936,4675,Macbook Pro is unresponsive for about a minute when waking up. Is this normal?,"Whenever I wake up my 2012 Macbook Pro after it's been asleep for a few hours, the screen turns on, but it is unresponsive for about a minute.  During this time, the mouse cursor does not move at all whenever I touch the trackpad and the computer is unresponsive to the keyboard.  I also see the WiFi icon in the taskbar act as if it is searching for WiFi (the WiFi icon is gray, but each bar turns black consecutively from bottom to top repeatedly).  The computer is finally responsive after a minute or so and the WiFi icon stops searching.  

Is this normal behavior for a Macbook Pro when waking?  If not, what could a potential issue be?  

My computer is a 2012 Macbook Pro 13 in, non Retina Display.  
",Chance,https://apple.stackexchange.com/users/6597,"Actually it may be coming out of hibernation.

Do you ever get a milky white screen with a progress bar? That then goes away and you can see the screen but not operate anything?

It may be coming out of hibernation.
",Steve Chambers,https://apple.stackexchange.com/users/33273,http://apple.stackexchange.com/questions/105680/macbook-pro-is-unresponsive-for-about-a-minute-when-waking-up-is-this-normal,TECHNOLOGY,apple.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,MacBook Pro woke up unresponsive for about a minute. Is this normal?,"Every time I wake up after a few hours of sleep on the 2012 MacBook Pro, the screen opens, but there is no response for about a minute. During this period, whenever I touch the touchpad, the mouse cursor does not move at all, and the computer does not respond to the keyboard. I also see that the WiFi icon in the taskbar is like searching for WiFi (the WiFi icon is gray, but each bar goes black continuously from bottom to top). About a minute later, the computer finally responds, and the WiFi icon stops searching.","Actually it may be coming out of hibernation.

Do you ever get a milky white screen with a progress bar? That then goes away and you can see the screen but not operate anything?

It may be coming out of hibernation.
"
477,477,742,check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
",Oneb,https://stackoverflow.com/users/1012518,"here is an idea that doesn't use regex:
all characters have an ansi value and usually consecutive. so abcd should have let's say the following ansi values:64,65,66,67

pseudocode:

for (i=string.start;i&lt;string.end-4;i++) {
   check=string.substring(i,4);
   c1=check.substring(0,1);
   c2=check.substring(1,1);
   c3=check.substring(2,1);
   c4=check.substring(3,1);
   if (c1.ansival==c2.ansival+1 &amp;&amp; c2.ansival==c3.ansival+1 &amp;&amp; c3.ansival==c4.ansival+1) {
      return false;
   } else {
      return true;
   }
}


also repeat in reverse order (c1.ansival+1==c2.ansival) for descending order
",MIrrorMirror,https://stackoverflow.com/users/1032650,http://stackoverflow.com/questions/12493931/check-if-a-string-has-four-consecutive-letters-in-ascending-or-descending-order,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,Check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
","here is an idea that doesn't use regex:
all characters have an ansi value and usually consecutive. so abcd should have let's say the following ansi values:64,65,66,67

pseudocode:

for (i=string.start;i&lt;string.end-4;i++) {
   check=string.substring(i,4);
   c1=check.substring(0,1);
   c2=check.substring(1,1);
   c3=check.substring(2,1);
   c4=check.substring(3,1);
   if (c1.ansival==c2.ansival+1 &amp;&amp; c2.ansival==c3.ansival+1 &amp;&amp; c3.ansival==c4.ansival+1) {
      return false;
   } else {
      return true;
   }
}


also repeat in reverse order (c1.ansival+1==c2.ansival) for descending order
"
2650,2650,4209,Looking up for an item in a list and different table styles in iOS,"I have a settings view with a grouped table. One of the cells of such table is intended to show a very long list of items from where I want the user to select one. Due to the length of the list, I need to provide a way to make easier to find a certain item.

One of the options I think there are, is to show letters of alphabet as indexes at the right side of a plain table. Since my first table is a grouped one, my navigation hierarchy would be then like this:

  

Would it be inconsistent to navigate from a grouped table to a plain table? If so, could somebody give an existing example? I didn't find anything related to this in iOS Human Interface Guidelines, maybe it is described somewhere else and this navigation pattern breaks the guidelines.

Another option could be having a search bar. Can a search bar be used in both a plain table and a grouped table? The existing example of such bar I found is in Contacts app and it is a plain table. In a plain table, could both an alphabet index and a search bar be shown?
",AppsDev,https://ux.stackexchange.com/users/30975,"IDEA 1: Grouping

Can you group items in the second table (plain table) further? If so, the interface is much simplified.

IDEA 2: Filtering

If IDEA 1 is impossible to follow, then you can do another thing. Implement a filter feature to the long list. Just place an icon at the top of the list. Clicking on it should bring a new page. Provide checkboxes, sliders, or some other facility according to your situation. Avoid the search bar if possible -- users don't know what words you have used in your list.

IDEA 3: Sorting

If IDEA 2 fails, then you must sort and present the list manually. Think about the options again and decide which are the most used options? Guess what most users want. Show those options first!

IDEA 4: Visual cues

Use icons or pictures relating to the actions/properties of the items in the list. This allows easy scanning.
",StupendousMan,https://ux.stackexchange.com/users/33311,http://ux.stackexchange.com/questions/42839/looking-up-for-an-item-in-a-list-and-different-table-styles-in-ios,TECHNOLOGY,ux.stackexchange.com,0.8333333333333334,0.3333333333333333,0.0,0.0,1.0,0.5,0.7777777777777778,0.5555555555555556,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Find items in the list and different table styles in IOS,"I have a settings view with a grouped table. One of the cells of such table is intended to show a very long list of items from where I want the user to select one. Due to the length of the list, I need to provide a way to make easier to find a certain item.

One of the options I think there are, is to show letters of alphabet as indexes at the right side of a plain table. Since my first table is a grouped one, my navigation hierarchy would be then like this:

  

Would it be inconsistent to navigate from a grouped table to a plain table? If so, could somebody give an existing example? I didn't find anything related to this in iOS Human Interface Guidelines, maybe it is described somewhere else and this navigation pattern breaks the guidelines.

Another option could be having a search bar. Can a search bar be used in both a plain table and a grouped table? The existing example of such bar I found is in Contacts app and it is a plain table. In a plain table, could both an alphabet index and a search bar be shown?
","IDEA 1: Grouping

Can you group items in the second table (plain table) further? If so, the interface is much simplified.

IDEA 2: Filtering

If IDEA 1 is impossible to follow, then you can do another thing. Implement a filter feature to the long list. Just place an icon at the top of the list. Clicking on it should bring a new page. Provide checkboxes, sliders, or some other facility according to your situation. Avoid the search bar if possible -- users don't know what words you have used in your list.

IDEA 3: Sorting

If IDEA 2 fails, then you must sort and present the list manually. Think about the options again and decide which are the most used options? Guess what most users want. Show those options first!

IDEA 4: Visual cues

Use icons or pictures relating to the actions/properties of the items in the list. This allows easy scanning.
"
490,490,764,"Why did my sweet potato hash turn soggy when frying in a non-stick pan, and crispy in a cast iron?","I was making a sweet potato hash for pizza topping the other night, and tried to fry the first batch in a non-stick pan. The hash never crisped up and was soggy, so I ended up mashing it instead. The next batch I fried in my seasoned cast iron, and it crisped up like a good hash.

Does anyone know why this happened? To me, it doesn't make a lot of sense if both the pans were equivalently hot with the same amount of oil to fry in. The hash in the non-stick pan also seemed to absorb more oil, but again, not sure why. 


Details:


I used a similar amount of bacon fat to fry both batches in
The hash was seasoned with garlic, salt and various spices (no onion)
Similar heating levels, preheated both pans
No lids were used
The non-stick pan is a nice Teflon coated Calphalon, and has pretty good heat retention; I use it for stir fry successfully

",Alex Bruce,https://cooking.stackexchange.com/users/33072,"The theories that have come out in comments are most likely right on. Cast iron is special in how well it retains heat. Give cast iron ample preheating time, and you can drop in cold food without a significant drop in the temperature of the pan. That equals crispy. Even a pretty good and heavy non-stick pan is not going to give sweet potatoes the kind of crisp you can achieve with cast iron.

You mention higher sides in the non-stick pan. That alone probably wouldn't make much of a difference, but considering that you're already seeing a greater drop in temperature as you put in the potatoes, the higher sides would hold in more moisture in the cooler pan. That is not a friend of crispiness.

You say that you preheated both pans to about the same temperature. I actually hope your memory is a little off on that :) One of the great joys of cooking with cast iron is that you can and usually should pre-heat it to a quite high temperature without damaging the pan. Teflon, on the other hand, should never be preheated beyond a very moderate temperature for a very short time. Some people go so far as to say that you shouldn't preheat it all. So if your beginning temperatures were about the same in the pans, they shouldn't have been. After you put in the potatoes, forget about it. You'll never get the same kind of crispy sear with a teflon pan as you will with cast iron, even if you don't know how to best exploit the advantages of cast iron.
",Jolenealaska,https://cooking.stackexchange.com/users/20183,http://cooking.stackexchange.com/questions/54022/why-did-my-sweet-potato-hash-turn-soggy-when-frying-in-a-non-stick-pan-and-cris,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"Why does my sweet potato mash get wet when it's fried in a non stick pot, and brittle in cast iron?","I was making a sweet potato hash for pizza topping the other night, and tried to fry the first batch in a non-stick pan. The hash never crisped up and was soggy, so I ended up mashing it instead. The next batch I fried in my seasoned cast iron, and it crisped up like a good hash.

Does anyone know why this happened? To me, it doesn't make a lot of sense if both the pans were equivalently hot with the same amount of oil to fry in. The hash in the non-stick pan also seemed to absorb more oil, but again, not sure why. 


Details:


I used a similar amount of bacon fat to fry both batches in
The hash was seasoned with garlic, salt and various spices (no onion)
Similar heating levels, preheated both pans
No lids were used
The non-stick pan is a nice Teflon coated Calphalon, and has pretty good heat retention; I use it for stir fry successfully

","The theories that have come out in comments are most likely right on. Cast iron is special in how well it retains heat. Give cast iron ample preheating time, and you can drop in cold food without a significant drop in the temperature of the pan. That equals crispy. Even a pretty good and heavy non-stick pan is not going to give sweet potatoes the kind of crisp you can achieve with cast iron.

You mention higher sides in the non-stick pan. That alone probably wouldn't make much of a difference, but considering that you're already seeing a greater drop in temperature as you put in the potatoes, the higher sides would hold in more moisture in the cooler pan. That is not a friend of crispiness.

You say that you preheated both pans to about the same temperature. I actually hope your memory is a little off on that :) One of the great joys of cooking with cast iron is that you can and usually should pre-heat it to a quite high temperature without damaging the pan. Teflon, on the other hand, should never be preheated beyond a very moderate temperature for a very short time. Some people go so far as to say that you shouldn't preheat it all. So if your beginning temperatures were about the same in the pans, they shouldn't have been. After you put in the potatoes, forget about it. You'll never get the same kind of crispy sear with a teflon pan as you will with cast iron, even if you don't know how to best exploit the advantages of cast iron.
"
3579,3579,5719,"Do Americans pronounce ""Ellen"" and ""Alan"" in the same way?","Do Americans pronounce ""Ellen"" and ""Alan"" in the same way? I am especially concerned with the first vowel.

EDIT:

Here is a quote that may be a case in point:


  Being a Brit also, the names ""Ellen"" and ""Alan"" tend to sound the same
  when spoken with an American tongue. It was just unfortunate that the
  child was very tom boyish and had an ambiguous sounding name


Context: discussion on why they chose a boy-looking girl for the movie ""Fatal Attraction""

Link: http://www.imdb.com/title/tt0093010/board/thread/186160978?d=186229310&amp;p=1#186229310
",brilliant,https://english.stackexchange.com/users/2270,"Ellen /ÉlÉn/ (with variant Helen) is pronounced with an /É/. This is the vowel found in SET and FELL. Alan /Ã¦lÉn/ (with variants Allan and Allen) with an /Ã¦/. This is the vowel found in CAT and PAL. 

But the vowels /É/ and /Ã¦/ are admittedly fairly close in sound, and can be difficult to differentiate for those who don't use both vowels in speech. This may be where your confusion lies.  As you can see on this general American vowel chart, they are very close to each other on the lower left.



EDIT: To the specific point in your question, ""Being a Brit also, the names 'Ellen' and 'Alan' tend to sound the same when spoken with an American tongue"" - well, that IMDB commenter from somewhere in the British Islands (an area with hundreds of dialects) may not hear the difference - but Americans certainly pronounce the difference.
",Mark Beadles,https://english.stackexchange.com/users/16191,http://english.stackexchange.com/questions/64225/do-americans-pronounce-ellen-and-alan-in-the-same-way,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,"Do Americans pronounce ""Allan"" the same way as ""Allan""?","Do Americans pronounce ""Ellen"" and ""Alan"" in the same way? I am especially concerned with the first vowel.

EDIT:

Here is a quote that may be a case in point:


  Being a Brit also, the names ""Ellen"" and ""Alan"" tend to sound the same
  when spoken with an American tongue. It was just unfortunate that the
  child was very tom boyish and had an ambiguous sounding name


Context: discussion on why they chose a boy-looking girl for the movie ""Fatal Attraction""

Link: http://www.imdb.com/title/tt0093010/board/thread/186160978?d=186229310&amp;p=1#186229310
","Ellen /ÉlÉn/ (with variant Helen) is pronounced with an /É/. This is the vowel found in SET and FELL. Alan /Ã¦lÉn/ (with variants Allan and Allen) with an /Ã¦/. This is the vowel found in CAT and PAL. 

But the vowels /É/ and /Ã¦/ are admittedly fairly close in sound, and can be difficult to differentiate for those who don't use both vowels in speech. This may be where your confusion lies.  As you can see on this general American vowel chart, they are very close to each other on the lower left.



EDIT: To the specific point in your question, ""Being a Brit also, the names 'Ellen' and 'Alan' tend to sound the same when spoken with an American tongue"" - well, that IMDB commenter from somewhere in the British Islands (an area with hundreds of dialects) may not hear the difference - but Americans certainly pronounce the difference.
"
4711,4711,7471,How do I connect to a remote MySQL database through an android device?,"    public static final String URL=""jdbc:mysql://10.0.2.2/mydatabase"";
    public static final String USER=""root"";
    public static final String PASSWORD=""apple"";
    public static final String Driver_Class=""com.mysql.jdbc.Driver"";


The above URL works fine when i connect to it locally... My question is what change do I make in order to have a remote access through a device??? (Its to do with ""http"" but how do i write it,the URL?)
",Jerry Wattre,https://stackoverflow.com/users/2890538,"Make sure root is configured to be able to login remotely. Quick tutorial 
Also make sure 3306 tcp port for MySQL server is open. 

I've used this tutorial in past, give it a try.
",Parry,https://stackoverflow.com/users/1146580,http://stackoverflow.com/questions/23039661/how-do-i-connect-to-a-remote-mysql-database-through-an-android-device,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,How to connect to remote MySQL database through Android device?,"    public static final String URL=""jdbc:mysql://10.0.2.2/mydatabase"";
    public static final String USER=""root"";
    public static final String PASSWORD=""apple"";
    public static final String Driver_Class=""com.mysql.jdbc.Driver"";


The above URL works fine when i connect to it locally... My question is what change do I make in order to have a remote access through a device??? (Its to do with ""http"" but how do i write it,the URL?)
","Make sure root is configured to be able to login remotely. Quick tutorial 
Also make sure 3306 tcp port for MySQL server is open. 

I've used this tutorial in past, give it a try.
"
4281,4281,6823,Defining a persistent static route on Mac OS X,"How does one define a static route on MacOS X which persists through reboots? The only suggestion I've found on Google advises setting up a launchd service to run at boot, which seems like a horrible hack (does it survive a network restart without rebooting, for instance?)

To set up the route I need temporarily, I can run the following:

route add -net ${network} ${gateway} ${netmask}


How would I make this persist?
",Charles Duffy,https://serverfault.com/users/38326,"Three approaches, in ascending order of goodness:


Manually create a launchd service to set up the route, as per http://osxfaq.com/tips/kluskens/index.ws
Use Lingon to automate the creation of a service, otherwise as above; this software is unmaintained, but still works fine as of OS X 10.5.8.
Use RouteSplit, a tool built for the purpose.

",BNFaustin,https://serverfault.com/users/38433,http://serverfault.com/questions/124954,TECHNOLOGY,serverfault.com,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Defining persistent static routes on Mac OS X,"How to define a static route on Mac OS X that persists during restart? The only advice I find on Google is to set up a startup service to run at startup, which looks like a terrible hack attack (for example, can it survive without restarting the network?)","Three approaches, in ascending order of goodness:


Manually create a launchd service to set up the route, as per http://osxfaq.com/tips/kluskens/index.ws
Use Lingon to automate the creation of a service, otherwise as above; this software is unmaintained, but still works fine as of OS X 10.5.8.
Use RouteSplit, a tool built for the purpose.

"
5827,5827,9233,What were the first anime based on manga and light novels?,"I know that original animes weren't based on light novels or mangas (see: this). However, I think there are some early shows that are based on mangas (Astro Boy for example, I think). What was the first anime based on a manga? Also, what was the first anime based on a light novel?
",kuwaly,https://anime.stackexchange.com/users/93,"While not the most scientific method, one could generate a list of anime entries over at Anime News Network, sort it by order and see what is the earliest entry in their database that fits the criterion we're looking for. Here would be an example of such a list. 

Obviously the service's database is most likely incomplete, but regardless, it is still an authoritative source for anime information, and given the size, and time range of the database, it can be trusted as a good estimation.


First anime based off of manga: 

Astro Boy, 1963

First anime based off light novels:

Legend of the Galactic Heroes (OAV) 1988
Slayers (1995)


",Miguel,https://anime.stackexchange.com/users/1600,http://anime.stackexchange.com/questions/3583/what-were-the-first-anime-based-on-manga-and-light-novels,CULTURE,anime.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,0.8888888888888888,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,What is the first cartoon based on comics and light novels?,"I know that the original animation is not based on light novels or comics. However, I think some of the early shows were based on comics (I think Astro Boy, for example). What is the first cartoon adapted from cartoon? What's the first animation based on light fiction?","While not the most scientific method, one could generate a list of anime entries over at Anime News Network, sort it by order and see what is the earliest entry in their database that fits the criterion we're looking for. Here would be an example of such a list. 

Obviously the service's database is most likely incomplete, but regardless, it is still an authoritative source for anime information, and given the size, and time range of the database, it can be trusted as a good estimation.


First anime based off of manga: 

Astro Boy, 1963

First anime based off light novels:

Legend of the Galactic Heroes (OAV) 1988
Slayers (1995)


"
2706,2706,4316,Exit Google Chrome from terminal,"Is there a way to cause google-chrome to quit, from the terminal, besides using killall google-chrome? 
I would like to be able to close it from a script without killing it.
",slybloty,https://unix.stackexchange.com/users/14775,"This command exits the chrome process tree gracefully, in all window managers:

pkill --oldest chrome


or if you prefer:

/usr/bin/pkill --oldest --signal TERM -f chrome    


Details:


gracefully means: avoid seeing âGoogle Chrome didn't shut down correctly. To repoen ...â next time chrome starts
chrome browser (e.g. version 39.0.2171.95) traps and gracefully handles SIGTERM
signal a single process, the root of chromeâs process tree, hence --oldest
SIGTERM is the same as signal 15, hence --signal TERM, or just leave it out since SIGTERM is the default signal
wmctrl works with Unity and some others but it does not work with all window managers
wmctrl -c closes one window at a time so to close all chrome windows you would need something like while wmctrl -c 'Google Chrome'; do sleep 0.2; done

",Keith Cascio,https://unix.stackexchange.com/users/85669,http://unix.stackexchange.com/questions/34101/exit-google-chrome-from-terminal,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Exit Google browser from the terminal,"Besides using killall Google Chrome, is there any way to get Google Chrome out of the terminal?","This command exits the chrome process tree gracefully, in all window managers:

pkill --oldest chrome


or if you prefer:

/usr/bin/pkill --oldest --signal TERM -f chrome    


Details:


gracefully means: avoid seeing âGoogle Chrome didn't shut down correctly. To repoen ...â next time chrome starts
chrome browser (e.g. version 39.0.2171.95) traps and gracefully handles SIGTERM
signal a single process, the root of chromeâs process tree, hence --oldest
SIGTERM is the same as signal 15, hence --signal TERM, or just leave it out since SIGTERM is the default signal
wmctrl works with Unity and some others but it does not work with all window managers
wmctrl -c closes one window at a time so to close all chrome windows you would need something like while wmctrl -c 'Google Chrome'; do sleep 0.2; done

"
1327,1327,2092,Path Variable Not Working,"I tried everything, but I still can't get my Path working:


This is my PATH:


This is my environment variables:


My java bin folder contains java.exe

@David Wallace

Microsoft Windows [Version 6.3.9600]
(c) 2013 Microsoft Corporation. All rights reserved.

C:\Users\Andy\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup>echo
 %PATH%
c:\Program Files (x86)\Intel\iCLS Client\;c:\Program Files\Intel\iCLS Client\;C:
\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\Window
sPowerShell\v1.0\;C:\Program Files (x86)\Intel\OpenCL SDK\3.0\bin\x86;C:\Program
 Files (x86)\Intel\OpenCL SDK\3.0\bin\x64;C:\Program Files\Intel\Intel(R) Manage
ment Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Com
ponents\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\D
AL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Pro
gram Files (x86)\Windows Live\Shared

C:\Users\Andy\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup>
",nulldev,https://stackoverflow.com/users/2898813,"I solved it. Instead of using a GUI to set the path, I used:

Path = %PATH%;C:\Program Files\Java\jdk1.7.0_45\bin

",nulldev,https://stackoverflow.com/users/2898813,http://stackoverflow.com/questions/20896848/path-variable-not-working,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Path variable does not work,"I tried everything, but I still can't get my Path working:


This is my PATH:


This is my environment variables:


My java bin folder contains java.exe

@David Wallace

Microsoft Windows [Version 6.3.9600]
(c) 2013 Microsoft Corporation. All rights reserved.

C:\Users\Andy\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup>echo
 %PATH%
c:\Program Files (x86)\Intel\iCLS Client\;c:\Program Files\Intel\iCLS Client\;C:
\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\Window
sPowerShell\v1.0\;C:\Program Files (x86)\Intel\OpenCL SDK\3.0\bin\x86;C:\Program
 Files (x86)\Intel\OpenCL SDK\3.0\bin\x64;C:\Program Files\Intel\Intel(R) Manage
ment Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Com
ponents\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\D
AL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Pro
gram Files (x86)\Windows Live\Shared

C:\Users\Andy\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup>
","I solved it. Instead of using a GUI to set the path, I used:

Path = %PATH%;C:\Program Files\Java\jdk1.7.0_45\bin

"
2343,2343,3733,Looking up for an item in a list and different table styles in iOS,"I have a settings view with a grouped table. One of the cells of such table is intended to show a very long list of items from where I want the user to select one. Due to the length of the list, I need to provide a way to make easier to find a certain item.

One of the options I think there are, is to show letters of alphabet as indexes at the right side of a plain table. Since my first table is a grouped one, my navigation hierarchy would be then like this:

  

Would it be inconsistent to navigate from a grouped table to a plain table? If so, could somebody give an existing example? I didn't find anything related to this in iOS Human Interface Guidelines, maybe it is described somewhere else and this navigation pattern breaks the guidelines.

Another option could be having a search bar. Can a search bar be used in both a plain table and a grouped table? The existing example of such bar I found is in Contacts app and it is a plain table. In a plain table, could both an alphabet index and a search bar be shown?
",AppsDev,https://ux.stackexchange.com/users/30975,"Users a tend to remember list structure, so it is not a good idea to reorder it. I would say the following:


long lists are not that good
search field is a bad idea (usually the user doesn't know what to search)
complex components (list withing a cell of the treetable) do not usually work well


Please check Miller columns and this topic. I will also add list of options from my other answer:


",Renat Gilmanov,https://ux.stackexchange.com/users/21423,http://ux.stackexchange.com/questions/42839/looking-up-for-an-item-in-a-list-and-different-table-styles-in-ios,TECHNOLOGY,ux.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,Find items in the list and different table styles in IOS,"I have a settings view with a grouped table. One of the cells of such table is intended to show a very long list of items from where I want the user to select one. Due to the length of the list, I need to provide a way to make easier to find a certain item.

One of the options I think there are, is to show letters of alphabet as indexes at the right side of a plain table. Since my first table is a grouped one, my navigation hierarchy would be then like this:

  

Would it be inconsistent to navigate from a grouped table to a plain table? If so, could somebody give an existing example? I didn't find anything related to this in iOS Human Interface Guidelines, maybe it is described somewhere else and this navigation pattern breaks the guidelines.

Another option could be having a search bar. Can a search bar be used in both a plain table and a grouped table? The existing example of such bar I found is in Contacts app and it is a plain table. In a plain table, could both an alphabet index and a search bar be shown?
","Users a tend to remember list structure, so it is not a good idea to reorder it. I would say the following:


long lists are not that good
search field is a bad idea (usually the user doesn't know what to search)
complex components (list withing a cell of the treetable) do not usually work well


Please check Miller columns and this topic. I will also add list of options from my other answer:


"
2876,2876,4577,What to do with old connections when moving outlet to dedicated circuit?,"I would like to remove one of the outlets from a circuit, and run a dedicated wire to it from a separate breaker, placing it on it's own circuit.

When I disconnect the existing circuit from the receptical, that will leave pigtails for the old circuit.

What do I do with the pigtails from the old circuit that the outlet will no longer be wired to?  

-Do they need to stay in the box(which would mean they would be pigtailed in the box, but not connected to the outlet, and new wiring would also run into the box for the new circuit connected to the outlet)?

-Get pushed into the wall?

-What seems the safest thing: Remove the outlet, leave the pigtails in the box, and put a blank over it. Then cut a new hole for a new box for the receptacle and new wiring to go into.
",AaronLS,https://diy.stackexchange.com/users/5218,"Of the three options you mention, the first is fine; leave the wires in the box, spliced.

The second, no good at all. Splices must be in an accessible box.

Third, also fine. You can certainly blank up the existing box and run new.

I prefer a fourth option; Leave the existing receptacle alone and run a new circuit to a new box. WHY do you need the existing one removed? 
",Speedy Petey,https://diy.stackexchange.com/users/19875,http://diy.stackexchange.com/questions/57790/what-to-do-with-old-connections-when-moving-outlet-to-dedicated-circuit,LIFE_ARTS,diy.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,How to deal with the old connection when the socket is moved to a dedicated circuit?,"I would like to remove one of the outlets from a circuit, and run a dedicated wire to it from a separate breaker, placing it on it's own circuit.

When I disconnect the existing circuit from the receptical, that will leave pigtails for the old circuit.

What do I do with the pigtails from the old circuit that the outlet will no longer be wired to?  

-Do they need to stay in the box(which would mean they would be pigtailed in the box, but not connected to the outlet, and new wiring would also run into the box for the new circuit connected to the outlet)?

-Get pushed into the wall?

-What seems the safest thing: Remove the outlet, leave the pigtails in the box, and put a blank over it. Then cut a new hole for a new box for the receptacle and new wiring to go into.
","Of the three options you mention, the first is fine; leave the wires in the box, spliced.

The second, no good at all. Splices must be in an accessible box.

Third, also fine. You can certainly blank up the existing box and run new.

I prefer a fourth option; Leave the existing receptacle alone and run a new circuit to a new box. WHY do you need the existing one removed? 
"
681,681,1074,Using jdbc-user-service inside user-service-ref,"I am using spring security and for database based authentication I used following configuration and its working fine

&lt;authentication-manager alias=""authenticationManager""&gt;
  &lt;authentication-provider&gt;
     &lt;jdbc-user-service data-source-ref=""dataSource""
      users-by-username-query=""SELECT ...... U.email_address=?""
      authorities-by-username-query=""SELECT ... U.email_address=?""&gt;
  &lt;/authentication-provider&gt;
&lt;/authentication-manager&gt;


now I wanted to add extra info to the session and came across Adding user to session, spring security default login, I tried it and now I have a problem.

XML says I cant use user-service-ref and jdbc-user-service combined. Is there a way to sort it out or else what I have to do if I have to use user-service-ref tag only to authenticate users? What can be the other way to add extra info say a whole Users object to the session.?

Your help will be appreciated.
",khobab,https://stackoverflow.com/users/1468338,"After hours of searching and experimenting I was able to do it like this. 


Make a new service say MyUserService that will implement org.springframework.security.core.userdetails.UserDetailsService and has annotation @Service. UserDetailsService only has one method loadUserByUserName. Implementation of this method will be in MyUserService. It will look like this.

@Service
public class MyUserService implements UserDetailsService {

@Override
public UserDetails loadUserByUsername(String arg0)
        throws UsernameNotFoundException {

    MyUser user=new MyUser();
    /*get details of user and authorities from database whose username is   
            arg0 and place them in user instance */
    return user;
}

}

MyUser is also a new class that implements org.springframework.security.core.userdetails.UserDetails and all its methods are implemented inside MyUser class. It will look like this.

public class MyUser implements UserDetails {
    private static final long serialVersionUID = 1L;
/*All the variables their getter setters that you wish to store in session. And    
   implementation of all the methods of UserDetails go here.*/

 }

Define a bean like this
&lt;bean id=""customUserDetailsService"" class=""org.aurora.timeexpense.service.MyUserService""/&gt;


Where org.aurora.timeexpense.service.MyUserService is the path of my defined service that implements UserDetailsService.

4.And Spring Security Configuration will go like this
 &lt;authentication-manager alias=""authenticationManager""&gt;
       &lt;authentication-provider user-service-ref=""customUserDetailsService""&gt;
        &lt;/authentication-provider&gt;
   &lt;/authentication-manager&gt;

You are good to go.
",khobab,https://stackoverflow.com/users/1468338,http://stackoverflow.com/questions/13475575/using-jdbc-user-service-inside-user-service-ref,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Using JDBC user service in user service ref,"I am using spring security and for database based authentication I used following configuration and its working fine

&lt;authentication-manager alias=""authenticationManager""&gt;
  &lt;authentication-provider&gt;
     &lt;jdbc-user-service data-source-ref=""dataSource""
      users-by-username-query=""SELECT ...... U.email_address=?""
      authorities-by-username-query=""SELECT ... U.email_address=?""&gt;
  &lt;/authentication-provider&gt;
&lt;/authentication-manager&gt;


now I wanted to add extra info to the session and came across Adding user to session, spring security default login, I tried it and now I have a problem.

XML says I cant use user-service-ref and jdbc-user-service combined. Is there a way to sort it out or else what I have to do if I have to use user-service-ref tag only to authenticate users? What can be the other way to add extra info say a whole Users object to the session.?

Your help will be appreciated.
","After hours of searching and experimenting I was able to do it like this. 


Make a new service say MyUserService that will implement org.springframework.security.core.userdetails.UserDetailsService and has annotation @Service. UserDetailsService only has one method loadUserByUserName. Implementation of this method will be in MyUserService. It will look like this.

@Service
public class MyUserService implements UserDetailsService {

@Override
public UserDetails loadUserByUsername(String arg0)
        throws UsernameNotFoundException {

    MyUser user=new MyUser();
    /*get details of user and authorities from database whose username is   
            arg0 and place them in user instance */
    return user;
}

}

MyUser is also a new class that implements org.springframework.security.core.userdetails.UserDetails and all its methods are implemented inside MyUser class. It will look like this.

public class MyUser implements UserDetails {
    private static final long serialVersionUID = 1L;
/*All the variables their getter setters that you wish to store in session. And    
   implementation of all the methods of UserDetails go here.*/

 }

Define a bean like this
&lt;bean id=""customUserDetailsService"" class=""org.aurora.timeexpense.service.MyUserService""/&gt;


Where org.aurora.timeexpense.service.MyUserService is the path of my defined service that implements UserDetailsService.

4.And Spring Security Configuration will go like this
 &lt;authentication-manager alias=""authenticationManager""&gt;
       &lt;authentication-provider user-service-ref=""customUserDetailsService""&gt;
        &lt;/authentication-provider&gt;
   &lt;/authentication-manager&gt;

You are good to go.
"
1710,1710,2709,Roguelike Class Structure Makes Everything Effectively Global,"A brief rundown of the hierarchy of the game data objects:

Configuration - loaded from XML files, has Descriptors, among other things

Atlas - has a Configuration, has a CreatureInstance(represents the player's creature instance), is an associative array of AtlasColumns

AtlasColumn - has an Atlas(parent), is an associative array of AtlasCells

AtlasCell - has an AtlasColumn(parent), is an associative array of Layers

Layer - has an AtlasCell(parent), is an associative array of LayerColumns

LayerColumn - has a Layer(parent), is an associative array of LayerCells

LayerCell - has a LayerColumn(parent), has a CreatureInstance, a array of ItemInstances, and a TerrainInstance

CreatureInstance/ItemInstance/TerrainInstance - has a LayerCell(parent), has a Descriptor

Descriptor - has an associative array of properties needed by an instance to do its particular function

The most important thing in the Configuration are the Descriptors.  A Descriptor has all of the properties that are needed by the various types of instances. It has properties that drive behavior, what it looks like on screen, and so on.

So here's the part that bothers me:

Everything... EVERYTHING, from Atlas to TerrainInstance can talk up and down the entire chain, the reason being that if, for example, the TerrainInstance is a square upon which a player steps and suddenly a number of monsters are conjured around him, the TerrainInstance needs to have access to the neighboring LayerCells.  Or for another example if a CreatureInstance when attacking the player's CreatureInstance is able to take items from the player's inventory, and relocate them somewhere else in the dungeon, it needs access to a different Layer or AtlasCell in order to put the item where it needs to go.

An alternative that would appear to be ""better encapsulated"" might be a messaging system that sends little message objects up and down the chain and handles things at the appropriate level, but is that really any BETTER than just having the objects be aware of one another?

The game I'm writing started out with mostly hardcoded item and creature types, and gradually morphed its way into something similar to the more flexible roguelike framework that I've detailed above. I'm finally switching from C# to Java for it(the language is immaterial, however), and I'd like to not have missed something glaringly obvious that will cause great pains later when I need to refactor it.

So, the question: is the apparent lack of encapsulation within the data/business objects of the game demonstrate a fatal flaw in the architecture?  And if so, what is that flaw and how can I correct it before I get too far along?
",PlayDeezGames,https://gamedev.stackexchange.com/users/12875,"I've been designing my roguelike framework on and off for the past few years and I come to think that the traditional OOP approach doesn't provide a very useful abstraction for a typical roguelike world for the reasons that you mentioned - everything is so interdependent on each other that each class may potentially need to know about every other class. 

For example, AI routines should logically be a part of the Creature class, but AI potentially needs to know everything - the current dungeon map, the state of PC's quests, current World events etc. Even implementing simplest actions such as moving isn't straightforward: do you have a Creature.move(x,y) method and require every Creature object to know its current dungeon level, OR you have a DungeonLevel.moveCreature(creature, x, y) method? What if monsters in your game can move from one dungeon level to another - do you need an even higher level method, e.g. World.moveCreature(creature, dungeonLevel, x, y) ?

So in the end I decided to simply make most functions global, instead of agonizing over the correct location of each method in the class hierarchy, and use classes mostly as data structures. Now my Creature object doesn't have to link back to the parent object, and it contains only simplest code that doesn't need to be aware of other classes.
",ramirami,https://gamedev.stackexchange.com/users/14203,http://gamedev.stackexchange.com/questions/24023/roguelike-class-structure-makes-everything-effectively-global,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,1.0,0.8888888888888888,Roguelike class structure effectively globalizes all content,"A brief rundown of the hierarchy of the game data objects:

Configuration - loaded from XML files, has Descriptors, among other things

Atlas - has a Configuration, has a CreatureInstance(represents the player's creature instance), is an associative array of AtlasColumns

AtlasColumn - has an Atlas(parent), is an associative array of AtlasCells

AtlasCell - has an AtlasColumn(parent), is an associative array of Layers

Layer - has an AtlasCell(parent), is an associative array of LayerColumns

LayerColumn - has a Layer(parent), is an associative array of LayerCells

LayerCell - has a LayerColumn(parent), has a CreatureInstance, a array of ItemInstances, and a TerrainInstance

CreatureInstance/ItemInstance/TerrainInstance - has a LayerCell(parent), has a Descriptor

Descriptor - has an associative array of properties needed by an instance to do its particular function

The most important thing in the Configuration are the Descriptors.  A Descriptor has all of the properties that are needed by the various types of instances. It has properties that drive behavior, what it looks like on screen, and so on.

So here's the part that bothers me:

Everything... EVERYTHING, from Atlas to TerrainInstance can talk up and down the entire chain, the reason being that if, for example, the TerrainInstance is a square upon which a player steps and suddenly a number of monsters are conjured around him, the TerrainInstance needs to have access to the neighboring LayerCells.  Or for another example if a CreatureInstance when attacking the player's CreatureInstance is able to take items from the player's inventory, and relocate them somewhere else in the dungeon, it needs access to a different Layer or AtlasCell in order to put the item where it needs to go.

An alternative that would appear to be ""better encapsulated"" might be a messaging system that sends little message objects up and down the chain and handles things at the appropriate level, but is that really any BETTER than just having the objects be aware of one another?

The game I'm writing started out with mostly hardcoded item and creature types, and gradually morphed its way into something similar to the more flexible roguelike framework that I've detailed above. I'm finally switching from C# to Java for it(the language is immaterial, however), and I'd like to not have missed something glaringly obvious that will cause great pains later when I need to refactor it.

So, the question: is the apparent lack of encapsulation within the data/business objects of the game demonstrate a fatal flaw in the architecture?  And if so, what is that flaw and how can I correct it before I get too far along?
","I've been designing my roguelike framework on and off for the past few years and I come to think that the traditional OOP approach doesn't provide a very useful abstraction for a typical roguelike world for the reasons that you mentioned - everything is so interdependent on each other that each class may potentially need to know about every other class. 

For example, AI routines should logically be a part of the Creature class, but AI potentially needs to know everything - the current dungeon map, the state of PC's quests, current World events etc. Even implementing simplest actions such as moving isn't straightforward: do you have a Creature.move(x,y) method and require every Creature object to know its current dungeon level, OR you have a DungeonLevel.moveCreature(creature, x, y) method? What if monsters in your game can move from one dungeon level to another - do you need an even higher level method, e.g. World.moveCreature(creature, dungeonLevel, x, y) ?

So in the end I decided to simply make most functions global, instead of agonizing over the correct location of each method in the class hierarchy, and use classes mostly as data structures. Now my Creature object doesn't have to link back to the parent object, and it contains only simplest code that doesn't need to be aware of other classes.
"
3733,3733,5948,Differences between no child vs no children,"a) They have no child.
b) They have no children.

Are both a) and b) correct? Though b) seems more common.
",fiksuu,https://english.stackexchange.com/users/89409,"Swan in Practical English Usage (p352) has a good entry on this question:


  After no, countable nouns are usually plural unless the sense makes a
  singular noun necessary. Compare: 
  
  
  He's got no children. (More natural than He's got no child.) 
  He's got no wife. (More normal than He's got no wives.)
  


So, They have no children is indeed more common and natural than They have no child. Conversely, They have no car seems more natural than They have no cars.
",Shoe,https://english.stackexchange.com/users/11146,http://english.stackexchange.com/questions/193366/differences-between-no-child-vs-no-children,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.0,0.0,0.6666666666666666,0.7777777777777778,The difference between childless and childless,"a) They have no child.
b) They have no children.

Are both a) and b) correct? Though b) seems more common.
","Swan in Practical English Usage (p352) has a good entry on this question:


  After no, countable nouns are usually plural unless the sense makes a
  singular noun necessary. Compare: 
  
  
  He's got no children. (More natural than He's got no child.) 
  He's got no wife. (More normal than He's got no wives.)
  


So, They have no children is indeed more common and natural than They have no child. Conversely, They have no car seems more natural than They have no cars.
"
58,58,88,What is the best way to paste code into a Trello card?,"When I try to paste code in Trello, I get very weird formatting after saving, but it seems like it does format for code, I just can't get it to work right. What is the best way to paste code into Trello?

Currently I'm just putting links to Gist, but I would prefer to just paste it straight in there.
",GiH,https://webapps.stackexchange.com/users/4534,"Include formatted code by wrapping it in three backticks (```) at the beginning and end of the block, or by starting a line with four spaces. Note that the triple backticks have to be on a separate line and ensure you have a blank line before and after the code block.
",U A,https://webapps.stackexchange.com/users/94002,http://webapps.stackexchange.com/questions/26799/what-is-the-best-way-to-paste-code-into-a-trello-card,TECHNOLOGY,webapps.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.7777777777777778,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,What is the best way to paste code into a trello card?,"When I try to paste the code in trello, I will get a very strange format after saving, but it seems that it does format the code, I just can't let it work properly. What is the best way to paste code into trello?","Enclose the formatted code by using three backslashes (` `) at the beginning and end of the block, or by starting a line with four spaces. Note that the three checkmarks must be on separate lines and make sure there is a blank line before and after the code block."
4271,4271,6808,What is a sci-fi system that would feel familiar to reluctant Pathfinder players?,"For the last few months I've been running a Pathfinder campaign, and recently I told my players that I needed a break and they agreed on switching games for a few months. I'm a fan of the works of Isaac Asimov, Larry Niven and so on, and science fiction would be a great change of pace. So here is my opportunity! At last! Or not?

My problem is my players have never liked anything that isn't D&amp;D or Pathfinder. We're all well into the thirties, and the majority have a taste for long campaigns (they really enjoy character development) and some big differences about what we want in a game. The one player who's also a regular GM has a greater appreciation for new games, but the rest is usually scared off by words like ""indie"", and ""FATE"".

I ran a Traveller campaign years ago using GURPS. They hated GURPS. I took off the GURPS part and added ""Mongoose"". They hated Mongoose. I tried Diaspora. They hate FATE. I talked about Ringworld, but I found BRP is not a good system for sci-fi. Jovian Chronicles? ""It has to be as bad as Tribe 8."" (Their words, not mine). Every time I suggest anything that's not Pathfinder it's the same song.

Though I find Traveller good enough, obviously now it's not an option. My latest reading has been a game based on FUDGE (far enough from FATE) inspired by movies like Alien, Predator and alike. I fear a one-session campaign and new ""hate"". It has to be a game that fits my group. Right?

Of course it may be that there's no such game and I have to deal with my players instead, so ""There is no such game"" is an answer I'll reluctantly accept.
",Cazacurdas,https://rpg.stackexchange.com/users/7885,"It might be harder to get hold of now, but any of the d20 Star Wars versions could work. Alternatively, d20 Modern with d20 Future tacked on could be familiar enough ground.
",YogoZuno,https://rpg.stackexchange.com/users/6031,http://rpg.stackexchange.com/questions/24444/what-is-a-sci-fi-system-that-would-feel-familiar-to-reluctant-pathfinder-players,CULTURE,rpg.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.7777777777777778,1.0,0.7333333333333333,0.0,0.0,0.6666666666666666,0.7777777777777778,What is the familiar science fiction system for reluctant Pathfinder players?,"For the last few months I've been running a Pathfinder campaign, and recently I told my players that I needed a break and they agreed on switching games for a few months. I'm a fan of the works of Isaac Asimov, Larry Niven and so on, and science fiction would be a great change of pace. So here is my opportunity! At last! Or not?

My problem is my players have never liked anything that isn't D&amp;D or Pathfinder. We're all well into the thirties, and the majority have a taste for long campaigns (they really enjoy character development) and some big differences about what we want in a game. The one player who's also a regular GM has a greater appreciation for new games, but the rest is usually scared off by words like ""indie"", and ""FATE"".

I ran a Traveller campaign years ago using GURPS. They hated GURPS. I took off the GURPS part and added ""Mongoose"". They hated Mongoose. I tried Diaspora. They hate FATE. I talked about Ringworld, but I found BRP is not a good system for sci-fi. Jovian Chronicles? ""It has to be as bad as Tribe 8."" (Their words, not mine). Every time I suggest anything that's not Pathfinder it's the same song.

Though I find Traveller good enough, obviously now it's not an option. My latest reading has been a game based on FUDGE (far enough from FATE) inspired by movies like Alien, Predator and alike. I fear a one-session campaign and new ""hate"". It has to be a game that fits my group. Right?

Of course it may be that there's no such game and I have to deal with my players instead, so ""There is no such game"" is an answer I'll reluctantly accept.
","It may be harder to master now, but any version of the D20 star wars will work. Or, the D20 modern and the D20 future pegs may be familiar enough to the ground."
5904,5904,9351,check if a string has four consecutive letters in ascending or descending order,"Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
",Oneb,https://stackoverflow.com/users/1012518,"This is my solution. It uses only a single loop.

Keep in mind that you'll need more logic if you want to constrain it to pure ASCII.

static boolean isWeak(String pass) {
  Character prev = null;
  Boolean asc = null;
  int streak = 0;
  for (char c : pass.toCharArray()) {
    if (prev != null) {
      switch (c - prev) {
      case -1:
        if (Boolean.FALSE.equals(asc)) streak++;
        else { asc = false; streak = 2; }
        break;
      case 1:
        if (Boolean.TRUE.equals(asc)) streak++;
        else { asc = true; streak = 2; }
        break;
      default: asc = null; streak = 0;
      }
      if (streak == 4) return true;
    }
    prev = c;
  }
  return false;
}

",Marko Topolnik,https://stackoverflow.com/users/1103872,http://stackoverflow.com/questions/12493931/check-if-a-string-has-four-consecutive-letters-in-ascending-or-descending-order,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,"Check if the string has four consecutive letters, in ascending or descending order","Good day stack overflow.

I'm a noob in using regex and here is my problem - I need to check a password if it contains 4 consecutive characters. so far what I have just covered is regarding the digits. Here is my regex:

ascending digits - ^.?(?:0123|1234|2345|3456|4567|5678|6789).$

descending digits - ^.?(?:9876|8765|7654|6543|5432|4321|3210).$

This works only for the digits. I know this is already an overkill in regex so I dont want to do it with the letters. It will be waaay too overkill if I do that.

abcdblah //true because of abcd

helobcde //true because of bcde

dcbablah //true beacause of dcba

heloedcb //true because of edcb

Any help would be highly appreciated. Thanks stackoverflow.
","This is my solution. It uses only a single loop.

Keep in mind that you'll need more logic if you want to constrain it to pure ASCII.

static boolean isWeak(String pass) {
  Character prev = null;
  Boolean asc = null;
  int streak = 0;
  for (char c : pass.toCharArray()) {
    if (prev != null) {
      switch (c - prev) {
      case -1:
        if (Boolean.FALSE.equals(asc)) streak++;
        else { asc = false; streak = 2; }
        break;
      case 1:
        if (Boolean.TRUE.equals(asc)) streak++;
        else { asc = true; streak = 2; }
        break;
      default: asc = null; streak = 0;
      }
      if (streak == 4) return true;
    }
    prev = c;
  }
  return false;
}

"
2613,2613,4156,What to do about students who ask for help too often?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
",Village,https://academia.stackexchange.com/users/600,"While there are some good answers here, I will just add a few thoughts from my own experiences.

I also have plenty of students who try for minimal work just to get a pass. I used to explain to them what their grade would be and why but in the end, all they heard was what their grade would be. If it was pass they stopped listening. Of course, this is quite unhealthy for their longer-term success.

I have since changed to not telling them what grade I would give them before they submit, partially because of JeffE's comment to this question. Now, I focus ONLY on showing the students how to judge their own papers. I explain that I will mark when they submit but if they want to understand how to mark their own papers, I will help them.

I do not check for plagiarism on drafts (though some students do ask me to). If I see something which looks like plagiarism, like the level of English goes from very poor to perfect, I do let the students know that this looks like plagiarism and, if it is, they should fix it with proper citation before submitting.

In short, focus on teaching them how to grade their own papers. This helps a lot if you provide a rubric. Do not tell them ""I will give you a  'D' if you submit this."" Instead, tell them ""Tell me what you think this paper deserves and explain to me why you believe that."" Then help them develop that skill.

They should become independent learners, even if they don't want to.
",earthling,https://academia.stackexchange.com/users/2692,http://academia.stackexchange.com/questions/28504/what-to-do-about-students-who-ask-for-help-too-often,LIFE_ARTS,academia.stackexchange.com,1.0,0.7777777777777778,0.0,0.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,What to do with students who often ask for help?,"For my writing courses, about 5% of students will come to me prior to deadlines asking for help with their paper. I see no problem advising students, as I often similarly came for help when I was an undergraduate. Recently, though, I found an increase in students who apparently just want to abuse this:


Students will bring me some plagiarized work, showing it to me early, as a sort of test if I will notice. It seems difficult to punish plagiarism when the paper is not yet submitted.
Students will bring in papers again and again, with little changes put in at each stage, hoping their minimal effort each time will be sufficient to reach their goal of a ""D"".


I've tried stopping students, but then they are angry when they see the ""F"" that they hoped I would help them get away from. While most of these students are probably just incredibly lazy, there is a chance that some among them are genuinely trying to improve, but just struggling a great deal, and I can't see it.

How might I go about blocking such abuses?
","While there are some good answers here, I will just add a few thoughts from my own experiences.

I also have plenty of students who try for minimal work just to get a pass. I used to explain to them what their grade would be and why but in the end, all they heard was what their grade would be. If it was pass they stopped listening. Of course, this is quite unhealthy for their longer-term success.

I have since changed to not telling them what grade I would give them before they submit, partially because of JeffE's comment to this question. Now, I focus ONLY on showing the students how to judge their own papers. I explain that I will mark when they submit but if they want to understand how to mark their own papers, I will help them.

I do not check for plagiarism on drafts (though some students do ask me to). If I see something which looks like plagiarism, like the level of English goes from very poor to perfect, I do let the students know that this looks like plagiarism and, if it is, they should fix it with proper citation before submitting.

In short, focus on teaching them how to grade their own papers. This helps a lot if you provide a rubric. Do not tell them ""I will give you a  'D' if you submit this."" Instead, tell them ""Tell me what you think this paper deserves and explain to me why you believe that."" Then help them develop that skill.

They should become independent learners, even if they don't want to.
"
4012,4012,6407,Story about Big-Brother-like society where everybody wears a controlling wristwatch,"A future Big-Brother society where people wore wristwatches which both monitored their movements and kept them informed about their role in society. 

I don't remember whether the story was located on Earth or a fictional planet.
The book was read late 60's or early 70's. I only read a small number of authors (max 10) so I would immediately recognise the author's name if the storyline was identified.

Possibilities:
Brian Aldiss,
Piers Anthony,
Isaac Asimov,
Ray Bradbury,
Arthur C. Clarke,
Robert Heinlein,
Frank Herbert,
Ursula K. Le Guin,
Theodore Sturgeon,
Kurt Vonnegut Jr.

What I'm thinking now is how uncannily like the Apple Watch and similar products this was. This is the only story I remember that foresaw the wireless/digital age.
",Mike Wilson,https://scifi.stackexchange.com/users/38791,"To me, this sounds somewhat similar to the story ""Criminal in Utopia"" by Mack Reynolds. (A google search for that title turns up at least one link to the text online, but it isn't clear whether this is legal or not, so the link is not included here.)
",This isn't my real name,https://scifi.stackexchange.com/users/38970,http://scifi.stackexchange.com/questions/76811/story-about-big-brother-like-society-where-everybody-wears-a-controlling-wristwa,LIFE_ARTS,scifi.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.0,0.0,0.0,0.8888888888888888,The story of everyone wearing watch in big brother Society,"A future Big-Brother society where people wore wristwatches which both monitored their movements and kept them informed about their role in society. 

I don't remember whether the story was located on Earth or a fictional planet.
The book was read late 60's or early 70's. I only read a small number of authors (max 10) so I would immediately recognise the author's name if the storyline was identified.

Possibilities:
Brian Aldiss,
Piers Anthony,
Isaac Asimov,
Ray Bradbury,
Arthur C. Clarke,
Robert Heinlein,
Frank Herbert,
Ursula K. Le Guin,
Theodore Sturgeon,
Kurt Vonnegut Jr.

What I'm thinking now is how uncannily like the Apple Watch and similar products this was. This is the only story I remember that foresaw the wireless/digital age.
","To me, this sounds somewhat similar to the story ""Criminal in Utopia"" by Mack Reynolds. (A google search for that title turns up at least one link to the text online, but it isn't clear whether this is legal or not, so the link is not included here.)
"
6063,6063,9620,Can't install Pantheon desktop environment,"I've tried to install Pantheon desktop environment several times. I tried sudo apt-get update and sudo apt-get upgrade, but it's no use. Iâm just a very new beginner. This is what Iâve done:

quanglong@ubuntu:~$ sudo add-apt-repository ppa:elementary-os/daily
[sudo] password for quanglong: 
You are about to add the following PPA to your system:
 ATTENTION!
Do NOT install this PPA if you want a tested running system, this PPA contains the newest and most unstable development of elementary, it's useful only if you are a developer and are not afraid to encounter CRITICAL BUGS.
Also this PPA may overwrite already installed packages you don't want it to!
 More info: https://launchpad.net/~elementary-os/+archive/daily
Press [ENTER] to continue or ctrl-c to cancel adding it

gpg: keyring `/tmp/tmpkz5d_z/secring.gpg' created
gpg: keyring `/tmp/tmpkz5d_z/pubring.gpg' created
gpg: requesting key 4E1F8A59 from hkp server keyserver.ubuntu.com
gpg: /tmp/tmpkz5d_z/trustdb.gpg: trustdb created
gpg: key 4E1F8A59: public key ""Launchpad PPA for elementary OS team"" imported
gpg: Total number processed: 1
gpg:               imported: 1  (RSA: 1)
OK
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get update
Hit http://ppa.launchpad.net quantal Release.gpg                               
Get:1 http://security.ubuntu.com quantal-security Release.gpg [933 B]          
Hit http://us.archive.ubuntu.com quantal Release.gpg                           
Hit http://ppa.launchpad.net quantal Release.gpg
Get:2 http://security.ubuntu.com quantal-security Release [49.6 kB]
Get:3 http://us.archive.ubuntu.com quantal-updates Release.gpg [933 B]       
Hit http://us.archive.ubuntu.com quantal-backports Release.gpg                 
Hit http://ppa.launchpad.net quantal Release             
Hit http://us.archive.ubuntu.com quantal Release                               
Hit http://ppa.launchpad.net quantal Release                                   
Get:4 http://us.archive.ubuntu.com quantal-updates Release [49.6 kB]           
Hit http://ppa.launchpad.net quantal/main Sources                             
Get:5 http://security.ubuntu.com quantal-security/main Sources [74.3 kB]      
Hit http://ppa.launchpad.net quantal/main amd64 Packages                       
Hit http://ppa.launchpad.net quantal/main i386 Packages                        
Hit http://us.archive.ubuntu.com quantal-backports Release                     
Hit http://us.archive.ubuntu.com quantal/main Sources                          
Hit http://us.archive.ubuntu.com quantal/restricted Sources                    
Hit http://us.archive.ubuntu.com quantal/universe Sources
Hit http://ppa.launchpad.net quantal/main Sources                              
Hit http://us.archive.ubuntu.com quantal/multiverse Sources           
Get:6 http://security.ubuntu.com quantal-security/restricted Sources [1,833 B]
Hit http://us.archive.ubuntu.com quantal/main amd64 Packages                   
Hit http://ppa.launchpad.net quantal/main amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/restricted amd64 Packages
Get:7 http://security.ubuntu.com quantal-security/universe Sources [23.8 kB]
Hit http://ppa.launchpad.net quantal/main i386 Packages                       
Hit http://us.archive.ubuntu.com quantal/universe amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/multiverse amd64 Packages             
Get:8 http://security.ubuntu.com quantal-security/multiverse Sources [1,169 B]
Hit http://us.archive.ubuntu.com quantal/main i386 Packages                    
Hit http://us.archive.ubuntu.com quantal/restricted i386 Packages     
Get:9 http://security.ubuntu.com quantal-security/main amd64 Packages [207 kB]
Hit http://us.archive.ubuntu.com quantal/universe i386 Packages               
Hit http://us.archive.ubuntu.com quantal/multiverse i386 Packages              
Hit http://us.archive.ubuntu.com quantal/main Translation-en                   
Hit http://us.archive.ubuntu.com quantal/multiverse Translation-en             
Hit http://us.archive.ubuntu.com quantal/restricted Translation-en             
Hit http://us.archive.ubuntu.com quantal/universe Translation-en               
Get:10 http://us.archive.ubuntu.com quantal-updates/main Sources [134 kB]      
Get:11 http://security.ubuntu.com quantal-security/restricted amd64 Packages [3,469 B]
Get:12 http://security.ubuntu.com quantal-security/universe amd64 Packages [72.4 kB]
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:13 http://us.archive.ubuntu.com quantal-updates/restricted Sources [2,564 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:14 http://us.archive.ubuntu.com quantal-updates/universe Sources [96.7 kB] 
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:15 http://security.ubuntu.com quantal-security/multiverse amd64 Packages [1,488 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:16 http://security.ubuntu.com quantal-security/main i386 Packages [205 kB] 
Get:17 http://us.archive.ubuntu.com quantal-updates/multiverse Sources [5,269 B]
Get:18 http://us.archive.ubuntu.com quantal-updates/main amd64 Packages [337 kB]
Get:19 http://us.archive.ubuntu.com quantal-updates/restricted amd64 Packages [4,804 B]
Get:20 http://us.archive.ubuntu.com quantal-updates/universe amd64 Packages [218 kB]
Get:21 http://security.ubuntu.com quantal-security/restricted i386 Packages [3,531 B]
Get:22 http://security.ubuntu.com quantal-security/universe i386 Packages [73.0 kB]
Get:23 http://us.archive.ubuntu.com quantal-updates/multiverse amd64 Packages [12.1 kB]
Get:24 http://security.ubuntu.com quantal-security/multiverse i386 Packages [1,726 B]
Hit http://security.ubuntu.com quantal-security/main Translation-en            
Get:25 http://us.archive.ubuntu.com quantal-updates/main i386 Packages [334 kB]
Hit http://security.ubuntu.com quantal-security/multiverse Translation-en      
Hit http://security.ubuntu.com quantal-security/restricted Translation-en      
Hit http://security.ubuntu.com quantal-security/universe Translation-en        
Get:26 http://us.archive.ubuntu.com quantal-updates/restricted i386 Packages [4,841 B]
Get:27 http://us.archive.ubuntu.com quantal-updates/universe i386 Packages [219 kB]
Get:28 http://us.archive.ubuntu.com quantal-updates/multiverse i386 Packages [12.3 kB]
Hit http://us.archive.ubuntu.com quantal-updates/main Translation-en           
Hit http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/restricted Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/universe Translation-en       
Hit http://us.archive.ubuntu.com quantal-backports/main Sources                
Hit http://us.archive.ubuntu.com quantal-backports/restricted Sources          
Ign http://security.ubuntu.com quantal-security/main Translation-en_US         
Hit http://us.archive.ubuntu.com quantal-backports/universe Sources            
Ign http://security.ubuntu.com quantal-security/multiverse Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Sources          
Ign http://security.ubuntu.com quantal-security/restricted Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/main amd64 Packages         
Ign http://security.ubuntu.com quantal-security/universe Translation-en_US     
Hit http://us.archive.ubuntu.com quantal-backports/restricted amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/universe amd64 Packages     
Hit http://us.archive.ubuntu.com quantal-backports/multiverse amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/main i386 Packages          
Hit http://us.archive.ubuntu.com quantal-backports/restricted i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/universe i386 Packages      
Hit http://us.archive.ubuntu.com quantal-backports/multiverse i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/main Translation-en         
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/restricted Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/universe Translation-en     
Ign http://us.archive.ubuntu.com quantal/main Translation-en_US                
Ign http://us.archive.ubuntu.com quantal/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/universe Translation-en_US
Fetched 2,151 kB in 45s (47.7 kB/s)
Reading package lists... Done
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get install elementary-desktop
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package elementary-desktop
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ 

",user275846,https://askubuntu.com/users/275846,"A quick look shows that there isn't a elementary-desktop in the PPA. Have a look at these instructions.
",arty,https://askubuntu.com/users/275388,http://askubuntu.com/questions/457673/cant-install-pantheon-desktop-environment,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,1.0,0.0,0.3333333333333333,0.8888888888888888,Unable to install Pantheon desktop environment,"I've tried to install Pantheon desktop environment several times. I tried sudo apt-get update and sudo apt-get upgrade, but it's no use. Iâm just a very new beginner. This is what Iâve done:

quanglong@ubuntu:~$ sudo add-apt-repository ppa:elementary-os/daily
[sudo] password for quanglong: 
You are about to add the following PPA to your system:
 ATTENTION!
Do NOT install this PPA if you want a tested running system, this PPA contains the newest and most unstable development of elementary, it's useful only if you are a developer and are not afraid to encounter CRITICAL BUGS.
Also this PPA may overwrite already installed packages you don't want it to!
 More info: https://launchpad.net/~elementary-os/+archive/daily
Press [ENTER] to continue or ctrl-c to cancel adding it

gpg: keyring `/tmp/tmpkz5d_z/secring.gpg' created
gpg: keyring `/tmp/tmpkz5d_z/pubring.gpg' created
gpg: requesting key 4E1F8A59 from hkp server keyserver.ubuntu.com
gpg: /tmp/tmpkz5d_z/trustdb.gpg: trustdb created
gpg: key 4E1F8A59: public key ""Launchpad PPA for elementary OS team"" imported
gpg: Total number processed: 1
gpg:               imported: 1  (RSA: 1)
OK
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get update
Hit http://ppa.launchpad.net quantal Release.gpg                               
Get:1 http://security.ubuntu.com quantal-security Release.gpg [933 B]          
Hit http://us.archive.ubuntu.com quantal Release.gpg                           
Hit http://ppa.launchpad.net quantal Release.gpg
Get:2 http://security.ubuntu.com quantal-security Release [49.6 kB]
Get:3 http://us.archive.ubuntu.com quantal-updates Release.gpg [933 B]       
Hit http://us.archive.ubuntu.com quantal-backports Release.gpg                 
Hit http://ppa.launchpad.net quantal Release             
Hit http://us.archive.ubuntu.com quantal Release                               
Hit http://ppa.launchpad.net quantal Release                                   
Get:4 http://us.archive.ubuntu.com quantal-updates Release [49.6 kB]           
Hit http://ppa.launchpad.net quantal/main Sources                             
Get:5 http://security.ubuntu.com quantal-security/main Sources [74.3 kB]      
Hit http://ppa.launchpad.net quantal/main amd64 Packages                       
Hit http://ppa.launchpad.net quantal/main i386 Packages                        
Hit http://us.archive.ubuntu.com quantal-backports Release                     
Hit http://us.archive.ubuntu.com quantal/main Sources                          
Hit http://us.archive.ubuntu.com quantal/restricted Sources                    
Hit http://us.archive.ubuntu.com quantal/universe Sources
Hit http://ppa.launchpad.net quantal/main Sources                              
Hit http://us.archive.ubuntu.com quantal/multiverse Sources           
Get:6 http://security.ubuntu.com quantal-security/restricted Sources [1,833 B]
Hit http://us.archive.ubuntu.com quantal/main amd64 Packages                   
Hit http://ppa.launchpad.net quantal/main amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/restricted amd64 Packages
Get:7 http://security.ubuntu.com quantal-security/universe Sources [23.8 kB]
Hit http://ppa.launchpad.net quantal/main i386 Packages                       
Hit http://us.archive.ubuntu.com quantal/universe amd64 Packages              
Hit http://us.archive.ubuntu.com quantal/multiverse amd64 Packages             
Get:8 http://security.ubuntu.com quantal-security/multiverse Sources [1,169 B]
Hit http://us.archive.ubuntu.com quantal/main i386 Packages                    
Hit http://us.archive.ubuntu.com quantal/restricted i386 Packages     
Get:9 http://security.ubuntu.com quantal-security/main amd64 Packages [207 kB]
Hit http://us.archive.ubuntu.com quantal/universe i386 Packages               
Hit http://us.archive.ubuntu.com quantal/multiverse i386 Packages              
Hit http://us.archive.ubuntu.com quantal/main Translation-en                   
Hit http://us.archive.ubuntu.com quantal/multiverse Translation-en             
Hit http://us.archive.ubuntu.com quantal/restricted Translation-en             
Hit http://us.archive.ubuntu.com quantal/universe Translation-en               
Get:10 http://us.archive.ubuntu.com quantal-updates/main Sources [134 kB]      
Get:11 http://security.ubuntu.com quantal-security/restricted amd64 Packages [3,469 B]
Get:12 http://security.ubuntu.com quantal-security/universe amd64 Packages [72.4 kB]
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:13 http://us.archive.ubuntu.com quantal-updates/restricted Sources [2,564 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:14 http://us.archive.ubuntu.com quantal-updates/universe Sources [96.7 kB] 
Ign http://ppa.launchpad.net quantal/main Translation-en_US                    
Get:15 http://security.ubuntu.com quantal-security/multiverse amd64 Packages [1,488 B]
Ign http://ppa.launchpad.net quantal/main Translation-en                       
Get:16 http://security.ubuntu.com quantal-security/main i386 Packages [205 kB] 
Get:17 http://us.archive.ubuntu.com quantal-updates/multiverse Sources [5,269 B]
Get:18 http://us.archive.ubuntu.com quantal-updates/main amd64 Packages [337 kB]
Get:19 http://us.archive.ubuntu.com quantal-updates/restricted amd64 Packages [4,804 B]
Get:20 http://us.archive.ubuntu.com quantal-updates/universe amd64 Packages [218 kB]
Get:21 http://security.ubuntu.com quantal-security/restricted i386 Packages [3,531 B]
Get:22 http://security.ubuntu.com quantal-security/universe i386 Packages [73.0 kB]
Get:23 http://us.archive.ubuntu.com quantal-updates/multiverse amd64 Packages [12.1 kB]
Get:24 http://security.ubuntu.com quantal-security/multiverse i386 Packages [1,726 B]
Hit http://security.ubuntu.com quantal-security/main Translation-en            
Get:25 http://us.archive.ubuntu.com quantal-updates/main i386 Packages [334 kB]
Hit http://security.ubuntu.com quantal-security/multiverse Translation-en      
Hit http://security.ubuntu.com quantal-security/restricted Translation-en      
Hit http://security.ubuntu.com quantal-security/universe Translation-en        
Get:26 http://us.archive.ubuntu.com quantal-updates/restricted i386 Packages [4,841 B]
Get:27 http://us.archive.ubuntu.com quantal-updates/universe i386 Packages [219 kB]
Get:28 http://us.archive.ubuntu.com quantal-updates/multiverse i386 Packages [12.3 kB]
Hit http://us.archive.ubuntu.com quantal-updates/main Translation-en           
Hit http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/restricted Translation-en     
Hit http://us.archive.ubuntu.com quantal-updates/universe Translation-en       
Hit http://us.archive.ubuntu.com quantal-backports/main Sources                
Hit http://us.archive.ubuntu.com quantal-backports/restricted Sources          
Ign http://security.ubuntu.com quantal-security/main Translation-en_US         
Hit http://us.archive.ubuntu.com quantal-backports/universe Sources            
Ign http://security.ubuntu.com quantal-security/multiverse Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Sources          
Ign http://security.ubuntu.com quantal-security/restricted Translation-en_US   
Hit http://us.archive.ubuntu.com quantal-backports/main amd64 Packages         
Ign http://security.ubuntu.com quantal-security/universe Translation-en_US     
Hit http://us.archive.ubuntu.com quantal-backports/restricted amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/universe amd64 Packages     
Hit http://us.archive.ubuntu.com quantal-backports/multiverse amd64 Packages   
Hit http://us.archive.ubuntu.com quantal-backports/main i386 Packages          
Hit http://us.archive.ubuntu.com quantal-backports/restricted i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/universe i386 Packages      
Hit http://us.archive.ubuntu.com quantal-backports/multiverse i386 Packages    
Hit http://us.archive.ubuntu.com quantal-backports/main Translation-en         
Hit http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/restricted Translation-en   
Hit http://us.archive.ubuntu.com quantal-backports/universe Translation-en     
Ign http://us.archive.ubuntu.com quantal/main Translation-en_US                
Ign http://us.archive.ubuntu.com quantal/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-updates/universe Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/main Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/multiverse Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/restricted Translation-en_US
Ign http://us.archive.ubuntu.com quantal-backports/universe Translation-en_US
Fetched 2,151 kB in 45s (47.7 kB/s)
Reading package lists... Done
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ sudo apt-get install elementary-desktop
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package elementary-desktop
/bin/rm: cannot remove `/run/user/root/gvfs': Is a directory
quanglong@ubuntu:~$ 

",A quick view is displayed in the PPA without a basic desktop. Look at these instructions.
387,387,609,"Excel VBA App stops spontaneously with message ""Code execution has been halted""","From what I can see on the web, this is a fairly common complaint, but answers seem to be rarer. The problem is this:

We have a number of Excel VBA apps which work perfectly on a number of users' machines. However on one machine they stop on certain lines of code. It is always the same lines, but those lines seem to have nothing in common with one another.

If you press F5 (run) after the halt, the app continues, so it's almost like a break point has been added. We've tried selecting 'remove all breaks' from the menu and even adding a break and removing it again.

We've had this issue with single apps before and we've 'bodged' it by cutting code out of modules, compiling and then pasting it back in etc.

The problem now seems to relate to Excel itself rather than a single .xls, so we're a little unsure how to manage this.

Any help would be gratefully received :)

Thanks,

Philip Whittington
",Phil Whittington,https://stackoverflow.com/users/223126,"Thanks to everyone for their input. This problem got solved by choosing REPAIR in Control Panel. I guess this explicitly re-registers some of Office's native COM components and does stuff that REINSTALL doesn't. I expect the latter just goes through a checklist and sometimes accepts what's there if it's already installed, maybe. I then had a separate issue with registering my own .NET dll for COM interop on the user's machine (despite this also working on other machines) though I think this was my error rather than Microsoft. Thanks again, I really appreciate it.
",Phil Whittington,https://stackoverflow.com/users/223126,http://stackoverflow.com/questions/2154699/excel-vba-app-stops-spontaneously-with-message-code-execution-has-been-halted,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,"Excel VBA Application stops automatically with the message ""code execution stopped""","From what I can see on the web, this is a fairly common complaint, but answers seem to be rarer. The problem is this:

We have a number of Excel VBA apps which work perfectly on a number of users' machines. However on one machine they stop on certain lines of code. It is always the same lines, but those lines seem to have nothing in common with one another.

If you press F5 (run) after the halt, the app continues, so it's almost like a break point has been added. We've tried selecting 'remove all breaks' from the menu and even adding a break and removing it again.

We've had this issue with single apps before and we've 'bodged' it by cutting code out of modules, compiling and then pasting it back in etc.

The problem now seems to relate to Excel itself rather than a single .xls, so we're a little unsure how to manage this.

Any help would be gratefully received :)

Thanks,

Philip Whittington
","Thank you for your input. This problem is solved by selecting repair in the control panel. I think this will explicitly re register some native COM components of office and do something that doesn't need to be reinstalled. I hope the latter just passes a checklist and sometimes accepts what has already been installed, perhaps. Then, I ran into another problem when registering my. Net DLL on the user's computer for com interoperability (although this applies to other computers as well), even though I thought it was my fault, not Microsoft. Thank you again. I really appreciate it."
1100,1100,1733,How do electrical devices suck electricity?,"If the electric potential is 220V and some device needs 1500watts then how does it suck exactly that amount of electrical energy from outlet?
",Ron,https://physics.stackexchange.com/users/7253,"If it's a light bulb or heater, it's just a resistor.

First, forget that it's alternating current, just to simplify things.
Think of the power source as a really big 220 volt battery.

If it's drawing 1500 watts, divide that by 220, and that will tell you the current I in Amperes.
(That just measures how many electrons per second are flowing. An Ampere is about 6x10^23 electrons per second.)

To get the resistance R in Ohms, just divide the voltage V (220 volts) by the current I that you got above.
(An Ohm is just the number of volts it takes to push one Ampere through the resistor.)

I hope you can see that the smaller the resistance is, the bigger the current is, and when you multiply that by the voltage, you get the power.

So the way you make a bigger heater or light bulb is by giving it less electrical resistance.

If you want to go back to alternating current (AC) the power is a time-average, and it swings up and down at twice the AC frequency.
I'll let you figure out why, if you want.
",Mike Dunlavey,https://physics.stackexchange.com/users/5223,http://physics.stackexchange.com/questions/19838/how-do-electrical-devices-suck-electricity,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.0,0.6666666666666666,1.0,How do electrical appliances absorb electricity?,"If the potential is 220 volts and some devices need 1500 watts, how does it accurately absorb so much power from the power outlet?","If it's a light bulb or heater, it's just a resistor.

First, forget that it's alternating current, just to simplify things.
Think of the power source as a really big 220 volt battery.

If it's drawing 1500 watts, divide that by 220, and that will tell you the current I in Amperes.
(That just measures how many electrons per second are flowing. An Ampere is about 6x10^23 electrons per second.)

To get the resistance R in Ohms, just divide the voltage V (220 volts) by the current I that you got above.
(An Ohm is just the number of volts it takes to push one Ampere through the resistor.)

I hope you can see that the smaller the resistance is, the bigger the current is, and when you multiply that by the voltage, you get the power.

So the way you make a bigger heater or light bulb is by giving it less electrical resistance.

If you want to go back to alternating current (AC) the power is a time-average, and it swings up and down at twice the AC frequency.
I'll let you figure out why, if you want.
"
596,596,933,How much of the English language comes from each of its influences?,"I was watching a video linked in this answer and it made the following claim:


  [...] like most words in English is derived from German.


That got me thinking. While I know that Germanic languages have greatly influenced English, so have the Latin and Celtic ones (and various others to a greater or lesser degree). Is it true that more than 50% of the English vocabulary is derived from Germanic roots?

More generally, can someone point me to data on this? I imagine attempts have been made to quantify the contribution of different languages to English; what were the results? What percentage of the language comes from each source?

Ideally I would like to see this expressed in terms of % of words but I am aware that, at least to some linguists, attempting to quantify vocabulary is anathema (to give a simple reason, all languages that allow number construction have an infinite  vocabulary by definition), so alternative approaches to quantifying this are also welcome.
",terdon,https://english.stackexchange.com/users/25030,"The question is: Is the English language a Germanic or Romance language, and what criteria will you use to determine the answer? One could argue that the History of England is similar to that of. the other five Romance languages in that the Romans conquered France, Spain, Portugal, Romania, and Italy. The presence of the Romans in England lasted approx. 400 years. Then the French invaded and they added many new words. The scientific revolution added also. Therefore, if the preponderance of the words are derived from Latin and uses the above comments, the conclusion is: that English is a Romance language.
",john DiFeliciantonio,https://english.stackexchange.com/users/102084,http://english.stackexchange.com/questions/155705/how-much-of-the-english-language-comes-from-each-of-its-influences,CULTURE,english.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.8888888888888888,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.4444444444444444,0.7777777777777778,0.8888888888888888,0.6666666666666667,0.0,0.0,1.0,1.0,How much of the English language comes from each of its influences?,"I was watching a video linked in this answer and it made the following claim:


  [...] like most words in English is derived from German.


That got me thinking. While I know that Germanic languages have greatly influenced English, so have the Latin and Celtic ones (and various others to a greater or lesser degree). Is it true that more than 50% of the English vocabulary is derived from Germanic roots?

More generally, can someone point me to data on this? I imagine attempts have been made to quantify the contribution of different languages to English; what were the results? What percentage of the language comes from each source?

Ideally I would like to see this expressed in terms of % of words but I am aware that, at least to some linguists, attempting to quantify vocabulary is anathema (to give a simple reason, all languages that allow number construction have an infinite  vocabulary by definition), so alternative approaches to quantifying this are also welcome.
","The question is: Is the English language a Germanic or Romance language, and what criteria will you use to determine the answer? One could argue that the History of England is similar to that of. the other five Romance languages in that the Romans conquered France, Spain, Portugal, Romania, and Italy. The presence of the Romans in England lasted approx. 400 years. Then the French invaded and they added many new words. The scientific revolution added also. Therefore, if the preponderance of the words are derived from Latin and uses the above comments, the conclusion is: that English is a Romance language.
"
